{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth',  None)\n",
    "\n",
    "with open('result.json') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "df.fillna(0, inplace=True)\n",
    "df = df.apply(lambda series: pd.to_numeric(series, errors='coerce'))\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:, -3:]\n",
    "y = df.iloc[:, -4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "ss = StandardScaler().fit(X_train)\n",
    "\n",
    "X_train = ss.transform(X_train)\n",
    "X_test = ss.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tothb\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\data_adapter.py:1699: FutureWarning: The behavior of `series[i:j]` with an integer-dtype index is deprecated. In a future version, this will be treated as *label-based* indexing, consistent with e.g. `series[i]` lookups. To retain the old behavior, use `series.iloc[i:j]`. To get the future behavior, use `series.loc[i:j]`.\n",
      "  return t[start:end]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 1s 19ms/step - loss: 3642.5386 - accuracy: 0.0130 - val_loss: 5527.1479 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 3629.4355 - accuracy: 0.0130 - val_loss: 5508.6836 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 3608.6108 - accuracy: 0.0130 - val_loss: 5479.6338 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 3577.0767 - accuracy: 0.0000e+00 - val_loss: 5434.9741 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 3529.5972 - accuracy: 0.0000e+00 - val_loss: 5367.7764 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 3454.0818 - accuracy: 0.0000e+00 - val_loss: 5263.4263 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 3341.6746 - accuracy: 0.0000e+00 - val_loss: 5101.9106 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 3174.0217 - accuracy: 0.0000e+00 - val_loss: 4866.0439 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 2937.8032 - accuracy: 0.0000e+00 - val_loss: 4535.9541 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 2612.5723 - accuracy: 0.0000e+00 - val_loss: 4099.6084 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 2211.4741 - accuracy: 0.0000e+00 - val_loss: 3566.4402 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 1749.9614 - accuracy: 0.0000e+00 - val_loss: 2995.9280 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 1331.4930 - accuracy: 0.0000e+00 - val_loss: 2509.2251 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/500\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 1027.4542 - accuracy: 0.0000e+00 - val_loss: 2231.4973 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 931.5393 - accuracy: 0.0000e+00 - val_loss: 2142.1860 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/500\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 900.5302 - accuracy: 0.0000e+00 - val_loss: 2128.3110 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/500\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 891.4144 - accuracy: 0.0000e+00 - val_loss: 2115.6350 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/500\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 878.4578 - accuracy: 0.0000e+00 - val_loss: 2125.6130 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/500\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 871.2129 - accuracy: 0.0000e+00 - val_loss: 2117.3862 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/500\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 863.1389 - accuracy: 0.0000e+00 - val_loss: 2115.4141 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/500\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 860.5300 - accuracy: 0.0000e+00 - val_loss: 2099.4563 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 852.3475 - accuracy: 0.0000e+00 - val_loss: 2102.6030 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 847.1919 - accuracy: 0.0000e+00 - val_loss: 2090.2432 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 839.4919 - accuracy: 0.0000e+00 - val_loss: 2089.5464 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 833.7042 - accuracy: 0.0000e+00 - val_loss: 2084.7405 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 830.8423 - accuracy: 0.0000e+00 - val_loss: 2079.5457 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 823.4871 - accuracy: 0.0000e+00 - val_loss: 2079.6294 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 820.2021 - accuracy: 0.0000e+00 - val_loss: 2081.0002 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 817.9595 - accuracy: 0.0000e+00 - val_loss: 2082.3025 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 817.4683 - accuracy: 0.0000e+00 - val_loss: 2085.4272 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 813.7992 - accuracy: 0.0000e+00 - val_loss: 2072.9304 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 816.8482 - accuracy: 0.0000e+00 - val_loss: 2061.3811 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 809.8337 - accuracy: 0.0000e+00 - val_loss: 2065.2998 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 807.6288 - accuracy: 0.0000e+00 - val_loss: 2067.8740 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/500\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 807.8173 - accuracy: 0.0000e+00 - val_loss: 2071.5786 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 805.9816 - accuracy: 0.0000e+00 - val_loss: 2057.9309 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 805.7971 - accuracy: 0.0000e+00 - val_loss: 2065.1221 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 804.3074 - accuracy: 0.0000e+00 - val_loss: 2064.8755 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 802.6329 - accuracy: 0.0000e+00 - val_loss: 2054.4016 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 800.6600 - accuracy: 0.0000e+00 - val_loss: 2059.9663 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 800.7784 - accuracy: 0.0000e+00 - val_loss: 2069.1025 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/500\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 798.9695 - accuracy: 0.0000e+00 - val_loss: 2061.8247 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 798.1395 - accuracy: 0.0000e+00 - val_loss: 2059.2810 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 797.4513 - accuracy: 0.0000e+00 - val_loss: 2060.6658 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 797.0043 - accuracy: 0.0000e+00 - val_loss: 2059.8826 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 797.5040 - accuracy: 0.0000e+00 - val_loss: 2038.8794 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 795.9118 - accuracy: 0.0000e+00 - val_loss: 2047.7454 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 794.2430 - accuracy: 0.0000e+00 - val_loss: 2048.3225 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 792.5965 - accuracy: 0.0000e+00 - val_loss: 2051.6182 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 793.0942 - accuracy: 0.0000e+00 - val_loss: 2057.1987 - val_accuracy: 0.0000e+00\n",
      "Epoch 51/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 792.3836 - accuracy: 0.0000e+00 - val_loss: 2050.5676 - val_accuracy: 0.0000e+00\n",
      "Epoch 52/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 791.9334 - accuracy: 0.0000e+00 - val_loss: 2047.8032 - val_accuracy: 0.0000e+00\n",
      "Epoch 53/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 791.0605 - accuracy: 0.0000e+00 - val_loss: 2060.0659 - val_accuracy: 0.0000e+00\n",
      "Epoch 54/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 790.2698 - accuracy: 0.0000e+00 - val_loss: 2057.0198 - val_accuracy: 0.0000e+00\n",
      "Epoch 55/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 790.4690 - accuracy: 0.0000e+00 - val_loss: 2048.6567 - val_accuracy: 0.0000e+00\n",
      "Epoch 56/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 788.4478 - accuracy: 0.0000e+00 - val_loss: 2050.9045 - val_accuracy: 0.0000e+00\n",
      "Epoch 57/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 790.3898 - accuracy: 0.0000e+00 - val_loss: 2047.7555 - val_accuracy: 0.0000e+00\n",
      "Epoch 58/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 787.1846 - accuracy: 0.0000e+00 - val_loss: 2057.6675 - val_accuracy: 0.0000e+00\n",
      "Epoch 59/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 787.6277 - accuracy: 0.0000e+00 - val_loss: 2052.8088 - val_accuracy: 0.0000e+00\n",
      "Epoch 60/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 787.4290 - accuracy: 0.0000e+00 - val_loss: 2056.0188 - val_accuracy: 0.0000e+00\n",
      "Epoch 61/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 786.8590 - accuracy: 0.0000e+00 - val_loss: 2061.9265 - val_accuracy: 0.0000e+00\n",
      "Epoch 62/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 783.6840 - accuracy: 0.0000e+00 - val_loss: 2047.4088 - val_accuracy: 0.0000e+00\n",
      "Epoch 63/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 790.4707 - accuracy: 0.0000e+00 - val_loss: 2037.6521 - val_accuracy: 0.0000e+00\n",
      "Epoch 64/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 786.8161 - accuracy: 0.0000e+00 - val_loss: 2052.2732 - val_accuracy: 0.0000e+00\n",
      "Epoch 65/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 784.3458 - accuracy: 0.0000e+00 - val_loss: 2048.1279 - val_accuracy: 0.0000e+00\n",
      "Epoch 66/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 783.6218 - accuracy: 0.0000e+00 - val_loss: 2046.1787 - val_accuracy: 0.0000e+00\n",
      "Epoch 67/500\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 783.2433 - accuracy: 0.0000e+00 - val_loss: 2047.9800 - val_accuracy: 0.0000e+00\n",
      "Epoch 68/500\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 785.6919 - accuracy: 0.0000e+00 - val_loss: 2060.9407 - val_accuracy: 0.0000e+00\n",
      "Epoch 69/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 781.3706 - accuracy: 0.0000e+00 - val_loss: 2056.4128 - val_accuracy: 0.0000e+00\n",
      "Epoch 70/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 782.3412 - accuracy: 0.0000e+00 - val_loss: 2059.3435 - val_accuracy: 0.0000e+00\n",
      "Epoch 71/500\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 791.0912 - accuracy: 0.0000e+00 - val_loss: 2034.8494 - val_accuracy: 0.0000e+00\n",
      "Epoch 72/500\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 780.3223 - accuracy: 0.0000e+00 - val_loss: 2042.9991 - val_accuracy: 0.0000e+00\n",
      "Epoch 73/500\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 783.2357 - accuracy: 0.0000e+00 - val_loss: 2053.1228 - val_accuracy: 0.0000e+00\n",
      "Epoch 74/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 780.9615 - accuracy: 0.0000e+00 - val_loss: 2047.9014 - val_accuracy: 0.0000e+00\n",
      "Epoch 75/500\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 778.8766 - accuracy: 0.0000e+00 - val_loss: 2049.6025 - val_accuracy: 0.0000e+00\n",
      "Epoch 76/500\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 778.6314 - accuracy: 0.0000e+00 - val_loss: 2048.5139 - val_accuracy: 0.0000e+00\n",
      "Epoch 77/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 781.6017 - accuracy: 0.0000e+00 - val_loss: 2064.9485 - val_accuracy: 0.0000e+00\n",
      "Epoch 78/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 779.4769 - accuracy: 0.0000e+00 - val_loss: 2040.2550 - val_accuracy: 0.0000e+00\n",
      "Epoch 79/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 778.5145 - accuracy: 0.0000e+00 - val_loss: 2048.0503 - val_accuracy: 0.0000e+00\n",
      "Epoch 80/500\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 776.3594 - accuracy: 0.0000e+00 - val_loss: 2045.0629 - val_accuracy: 0.0000e+00\n",
      "Epoch 81/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 774.4963 - accuracy: 0.0000e+00 - val_loss: 2049.6150 - val_accuracy: 0.0000e+00\n",
      "Epoch 82/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 773.6456 - accuracy: 0.0000e+00 - val_loss: 2058.0256 - val_accuracy: 0.0000e+00\n",
      "Epoch 83/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 775.9162 - accuracy: 0.0000e+00 - val_loss: 2054.3977 - val_accuracy: 0.0000e+00\n",
      "Epoch 84/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 775.5087 - accuracy: 0.0000e+00 - val_loss: 2064.6104 - val_accuracy: 0.0000e+00\n",
      "Epoch 85/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 774.0302 - accuracy: 0.0000e+00 - val_loss: 2056.4092 - val_accuracy: 0.0000e+00\n",
      "Epoch 86/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 773.1799 - accuracy: 0.0000e+00 - val_loss: 2056.4531 - val_accuracy: 0.0000e+00\n",
      "Epoch 87/500\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 775.3541 - accuracy: 0.0000e+00 - val_loss: 2053.4587 - val_accuracy: 0.0000e+00\n",
      "Epoch 88/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 774.5103 - accuracy: 0.0000e+00 - val_loss: 2069.7866 - val_accuracy: 0.0000e+00\n",
      "Epoch 89/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 773.2603 - accuracy: 0.0000e+00 - val_loss: 2068.9500 - val_accuracy: 0.0000e+00\n",
      "Epoch 90/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 772.9501 - accuracy: 0.0000e+00 - val_loss: 2041.0236 - val_accuracy: 0.0000e+00\n",
      "Epoch 91/500\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 772.7658 - accuracy: 0.0000e+00 - val_loss: 2044.9791 - val_accuracy: 0.0000e+00\n",
      "Epoch 92/500\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 774.7192 - accuracy: 0.0000e+00 - val_loss: 2058.3564 - val_accuracy: 0.0000e+00\n",
      "Epoch 93/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 774.5420 - accuracy: 0.0000e+00 - val_loss: 2037.1921 - val_accuracy: 0.0000e+00\n",
      "Epoch 94/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 770.3537 - accuracy: 0.0000e+00 - val_loss: 2041.1450 - val_accuracy: 0.0000e+00\n",
      "Epoch 95/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 772.3127 - accuracy: 0.0000e+00 - val_loss: 2058.5354 - val_accuracy: 0.0000e+00\n",
      "Epoch 96/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 768.1365 - accuracy: 0.0000e+00 - val_loss: 2055.5715 - val_accuracy: 0.0000e+00\n",
      "Epoch 97/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 769.8636 - accuracy: 0.0000e+00 - val_loss: 2048.2468 - val_accuracy: 0.0000e+00\n",
      "Epoch 98/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 766.6493 - accuracy: 0.0000e+00 - val_loss: 2055.9651 - val_accuracy: 0.0000e+00\n",
      "Epoch 99/500\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 766.0830 - accuracy: 0.0000e+00 - val_loss: 2061.2751 - val_accuracy: 0.0000e+00\n",
      "Epoch 100/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 765.7276 - accuracy: 0.0000e+00 - val_loss: 2061.3718 - val_accuracy: 0.0000e+00\n",
      "Epoch 101/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 767.6254 - accuracy: 0.0000e+00 - val_loss: 2052.4585 - val_accuracy: 0.0000e+00\n",
      "Epoch 102/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 767.3181 - accuracy: 0.0000e+00 - val_loss: 2050.5710 - val_accuracy: 0.0000e+00\n",
      "Epoch 103/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 766.8089 - accuracy: 0.0000e+00 - val_loss: 2066.4404 - val_accuracy: 0.0000e+00\n",
      "Epoch 104/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 765.1924 - accuracy: 0.0000e+00 - val_loss: 2060.7070 - val_accuracy: 0.0000e+00\n",
      "Epoch 105/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 766.5572 - accuracy: 0.0000e+00 - val_loss: 2058.1726 - val_accuracy: 0.0000e+00\n",
      "Epoch 106/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 764.9868 - accuracy: 0.0000e+00 - val_loss: 2070.5466 - val_accuracy: 0.0000e+00\n",
      "Epoch 107/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 764.2133 - accuracy: 0.0000e+00 - val_loss: 2069.2834 - val_accuracy: 0.0000e+00\n",
      "Epoch 108/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 763.4077 - accuracy: 0.0000e+00 - val_loss: 2071.4395 - val_accuracy: 0.0000e+00\n",
      "Epoch 109/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 761.1843 - accuracy: 0.0000e+00 - val_loss: 2062.5664 - val_accuracy: 0.0000e+00\n",
      "Epoch 110/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 761.0678 - accuracy: 0.0000e+00 - val_loss: 2061.4072 - val_accuracy: 0.0000e+00\n",
      "Epoch 111/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 761.7239 - accuracy: 0.0000e+00 - val_loss: 2064.5461 - val_accuracy: 0.0000e+00\n",
      "Epoch 112/500\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 763.7866 - accuracy: 0.0000e+00 - val_loss: 2059.7788 - val_accuracy: 0.0000e+00\n",
      "Epoch 113/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 760.7152 - accuracy: 0.0000e+00 - val_loss: 2065.3049 - val_accuracy: 0.0000e+00\n",
      "Epoch 114/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 760.1492 - accuracy: 0.0000e+00 - val_loss: 2070.1389 - val_accuracy: 0.0000e+00\n",
      "Epoch 115/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 759.9115 - accuracy: 0.0000e+00 - val_loss: 2067.2632 - val_accuracy: 0.0000e+00\n",
      "Epoch 116/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 758.5858 - accuracy: 0.0000e+00 - val_loss: 2070.0261 - val_accuracy: 0.0000e+00\n",
      "Epoch 117/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 759.1528 - accuracy: 0.0000e+00 - val_loss: 2069.2358 - val_accuracy: 0.0000e+00\n",
      "Epoch 118/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 757.5074 - accuracy: 0.0000e+00 - val_loss: 2070.7292 - val_accuracy: 0.0000e+00\n",
      "Epoch 119/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 757.8884 - accuracy: 0.0000e+00 - val_loss: 2068.7935 - val_accuracy: 0.0000e+00\n",
      "Epoch 120/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 758.1179 - accuracy: 0.0000e+00 - val_loss: 2076.2092 - val_accuracy: 0.0000e+00\n",
      "Epoch 121/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 758.6973 - accuracy: 0.0000e+00 - val_loss: 2070.0227 - val_accuracy: 0.0000e+00\n",
      "Epoch 122/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 758.2505 - accuracy: 0.0000e+00 - val_loss: 2078.8032 - val_accuracy: 0.0000e+00\n",
      "Epoch 123/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 757.1197 - accuracy: 0.0000e+00 - val_loss: 2074.7644 - val_accuracy: 0.0000e+00\n",
      "Epoch 124/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 755.0844 - accuracy: 0.0000e+00 - val_loss: 2070.6248 - val_accuracy: 0.0000e+00\n",
      "Epoch 125/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 756.5854 - accuracy: 0.0000e+00 - val_loss: 2069.9250 - val_accuracy: 0.0000e+00\n",
      "Epoch 126/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 761.0891 - accuracy: 0.0000e+00 - val_loss: 2091.0916 - val_accuracy: 0.0000e+00\n",
      "Epoch 127/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 762.4971 - accuracy: 0.0000e+00 - val_loss: 2057.8682 - val_accuracy: 0.0000e+00\n",
      "Epoch 128/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 755.1285 - accuracy: 0.0000e+00 - val_loss: 2059.3467 - val_accuracy: 0.0000e+00\n",
      "Epoch 129/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 755.8581 - accuracy: 0.0000e+00 - val_loss: 2071.2712 - val_accuracy: 0.0000e+00\n",
      "Epoch 130/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 752.9296 - accuracy: 0.0000e+00 - val_loss: 2069.4888 - val_accuracy: 0.0000e+00\n",
      "Epoch 131/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 753.5135 - accuracy: 0.0000e+00 - val_loss: 2072.6675 - val_accuracy: 0.0000e+00\n",
      "Epoch 132/500\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 759.3773 - accuracy: 0.0000e+00 - val_loss: 2090.7969 - val_accuracy: 0.0000e+00\n",
      "Epoch 133/500\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 749.2496 - accuracy: 0.0000e+00 - val_loss: 2063.2961 - val_accuracy: 0.0000e+00\n",
      "Epoch 134/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 752.5095 - accuracy: 0.0000e+00 - val_loss: 2066.8743 - val_accuracy: 0.0000e+00\n",
      "Epoch 135/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 753.3488 - accuracy: 0.0000e+00 - val_loss: 2064.7673 - val_accuracy: 0.0000e+00\n",
      "Epoch 136/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 754.4527 - accuracy: 0.0000e+00 - val_loss: 2084.3926 - val_accuracy: 0.0000e+00\n",
      "Epoch 137/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 755.1841 - accuracy: 0.0000e+00 - val_loss: 2056.3765 - val_accuracy: 0.0000e+00\n",
      "Epoch 138/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 753.2408 - accuracy: 0.0000e+00 - val_loss: 2069.7129 - val_accuracy: 0.0000e+00\n",
      "Epoch 139/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 747.8937 - accuracy: 0.0000e+00 - val_loss: 2068.5107 - val_accuracy: 0.0000e+00\n",
      "Epoch 140/500\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 746.8482 - accuracy: 0.0000e+00 - val_loss: 2070.8040 - val_accuracy: 0.0000e+00\n",
      "Epoch 141/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 748.1101 - accuracy: 0.0000e+00 - val_loss: 2070.7803 - val_accuracy: 0.0000e+00\n",
      "Epoch 142/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 754.6343 - accuracy: 0.0000e+00 - val_loss: 2090.3718 - val_accuracy: 0.0000e+00\n",
      "Epoch 143/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 746.6819 - accuracy: 0.0000e+00 - val_loss: 2081.2561 - val_accuracy: 0.0000e+00\n",
      "Epoch 144/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 744.7173 - accuracy: 0.0000e+00 - val_loss: 2077.8972 - val_accuracy: 0.0000e+00\n",
      "Epoch 145/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 746.2074 - accuracy: 0.0000e+00 - val_loss: 2086.1304 - val_accuracy: 0.0000e+00\n",
      "Epoch 146/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 745.7297 - accuracy: 0.0000e+00 - val_loss: 2081.7021 - val_accuracy: 0.0000e+00\n",
      "Epoch 147/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 743.6322 - accuracy: 0.0000e+00 - val_loss: 2080.1956 - val_accuracy: 0.0000e+00\n",
      "Epoch 148/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 742.4927 - accuracy: 0.0000e+00 - val_loss: 2088.2327 - val_accuracy: 0.0000e+00\n",
      "Epoch 149/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 742.5643 - accuracy: 0.0000e+00 - val_loss: 2086.3594 - val_accuracy: 0.0000e+00\n",
      "Epoch 150/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 741.3774 - accuracy: 0.0000e+00 - val_loss: 2086.1794 - val_accuracy: 0.0000e+00\n",
      "Epoch 151/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 739.5180 - accuracy: 0.0000e+00 - val_loss: 2093.4673 - val_accuracy: 0.0000e+00\n",
      "Epoch 152/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 741.3283 - accuracy: 0.0000e+00 - val_loss: 2094.4395 - val_accuracy: 0.0000e+00\n",
      "Epoch 153/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 740.6636 - accuracy: 0.0000e+00 - val_loss: 2100.6741 - val_accuracy: 0.0000e+00\n",
      "Epoch 154/500\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 740.3169 - accuracy: 0.0000e+00 - val_loss: 2103.5840 - val_accuracy: 0.0000e+00\n",
      "Epoch 155/500\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 737.3943 - accuracy: 0.0000e+00 - val_loss: 2095.6575 - val_accuracy: 0.0000e+00\n",
      "Epoch 156/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 736.1471 - accuracy: 0.0000e+00 - val_loss: 2091.7673 - val_accuracy: 0.0000e+00\n",
      "Epoch 157/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 735.8676 - accuracy: 0.0000e+00 - val_loss: 2093.0796 - val_accuracy: 0.0000e+00\n",
      "Epoch 158/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 735.4878 - accuracy: 0.0000e+00 - val_loss: 2089.1877 - val_accuracy: 0.0000e+00\n",
      "Epoch 159/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 736.6630 - accuracy: 0.0000e+00 - val_loss: 2098.3804 - val_accuracy: 0.0000e+00\n",
      "Epoch 160/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 735.0073 - accuracy: 0.0000e+00 - val_loss: 2091.1951 - val_accuracy: 0.0000e+00\n",
      "Epoch 161/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 734.8697 - accuracy: 0.0000e+00 - val_loss: 2091.6155 - val_accuracy: 0.0000e+00\n",
      "Epoch 162/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 734.6241 - accuracy: 0.0000e+00 - val_loss: 2088.9573 - val_accuracy: 0.0000e+00\n",
      "Epoch 163/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 730.6651 - accuracy: 0.0000e+00 - val_loss: 2100.6987 - val_accuracy: 0.0000e+00\n",
      "Epoch 164/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 734.3770 - accuracy: 0.0000e+00 - val_loss: 2096.4866 - val_accuracy: 0.0000e+00\n",
      "Epoch 165/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 733.5404 - accuracy: 0.0000e+00 - val_loss: 2107.3179 - val_accuracy: 0.0000e+00\n",
      "Epoch 166/500\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 727.7217 - accuracy: 0.0000e+00 - val_loss: 2089.7932 - val_accuracy: 0.0000e+00\n",
      "Epoch 167/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 733.3162 - accuracy: 0.0000e+00 - val_loss: 2085.5420 - val_accuracy: 0.0000e+00\n",
      "Epoch 168/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 736.5383 - accuracy: 0.0000e+00 - val_loss: 2103.7776 - val_accuracy: 0.0000e+00\n",
      "Epoch 169/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 731.9438 - accuracy: 0.0000e+00 - val_loss: 2093.5073 - val_accuracy: 0.0000e+00\n",
      "Epoch 170/500\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 727.8788 - accuracy: 0.0000e+00 - val_loss: 2098.6946 - val_accuracy: 0.0000e+00\n",
      "Epoch 171/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 731.2565 - accuracy: 0.0000e+00 - val_loss: 2113.0447 - val_accuracy: 0.0000e+00\n",
      "Epoch 172/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 730.0515 - accuracy: 0.0000e+00 - val_loss: 2116.3364 - val_accuracy: 0.0000e+00\n",
      "Epoch 173/500\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 726.9235 - accuracy: 0.0000e+00 - val_loss: 2116.5732 - val_accuracy: 0.0000e+00\n",
      "Epoch 174/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 719.8124 - accuracy: 0.0000e+00 - val_loss: 2097.1248 - val_accuracy: 0.0000e+00\n",
      "Epoch 175/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 736.3179 - accuracy: 0.0000e+00 - val_loss: 2088.1589 - val_accuracy: 0.0000e+00\n",
      "Epoch 176/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 727.2781 - accuracy: 0.0000e+00 - val_loss: 2110.9626 - val_accuracy: 0.0000e+00\n",
      "Epoch 177/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 724.6191 - accuracy: 0.0000e+00 - val_loss: 2109.4172 - val_accuracy: 0.0000e+00\n",
      "Epoch 178/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 724.6960 - accuracy: 0.0000e+00 - val_loss: 2114.2256 - val_accuracy: 0.0000e+00\n",
      "Epoch 179/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 721.7447 - accuracy: 0.0000e+00 - val_loss: 2109.6147 - val_accuracy: 0.0000e+00\n",
      "Epoch 180/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 721.1603 - accuracy: 0.0000e+00 - val_loss: 2108.4631 - val_accuracy: 0.0000e+00\n",
      "Epoch 181/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 721.9049 - accuracy: 0.0000e+00 - val_loss: 2112.0461 - val_accuracy: 0.0000e+00\n",
      "Epoch 182/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 721.4061 - accuracy: 0.0000e+00 - val_loss: 2113.1414 - val_accuracy: 0.0000e+00\n",
      "Epoch 183/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 719.9244 - accuracy: 0.0000e+00 - val_loss: 2118.4155 - val_accuracy: 0.0000e+00\n",
      "Epoch 184/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 722.5234 - accuracy: 0.0000e+00 - val_loss: 2129.5000 - val_accuracy: 0.0000e+00\n",
      "Epoch 185/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 721.5110 - accuracy: 0.0000e+00 - val_loss: 2118.8623 - val_accuracy: 0.0000e+00\n",
      "Epoch 186/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 718.6135 - accuracy: 0.0000e+00 - val_loss: 2118.5837 - val_accuracy: 0.0000e+00\n",
      "Epoch 187/500\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 717.6569 - accuracy: 0.0000e+00 - val_loss: 2123.2410 - val_accuracy: 0.0000e+00\n",
      "Epoch 188/500\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 718.8358 - accuracy: 0.0000e+00 - val_loss: 2131.4338 - val_accuracy: 0.0000e+00\n",
      "Epoch 189/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 720.3306 - accuracy: 0.0000e+00 - val_loss: 2116.6648 - val_accuracy: 0.0000e+00\n",
      "Epoch 190/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 717.5673 - accuracy: 0.0000e+00 - val_loss: 2118.2756 - val_accuracy: 0.0000e+00\n",
      "Epoch 191/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 714.1388 - accuracy: 0.0000e+00 - val_loss: 2128.2971 - val_accuracy: 0.0000e+00\n",
      "Epoch 192/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 715.5742 - accuracy: 0.0000e+00 - val_loss: 2125.3218 - val_accuracy: 0.0000e+00\n",
      "Epoch 193/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 714.5438 - accuracy: 0.0000e+00 - val_loss: 2129.3833 - val_accuracy: 0.0000e+00\n",
      "Epoch 194/500\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 719.0627 - accuracy: 0.0000e+00 - val_loss: 2122.4016 - val_accuracy: 0.0000e+00\n",
      "Epoch 195/500\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 712.3157 - accuracy: 0.0000e+00 - val_loss: 2130.8101 - val_accuracy: 0.0000e+00\n",
      "Epoch 196/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 712.9232 - accuracy: 0.0000e+00 - val_loss: 2134.5618 - val_accuracy: 0.0000e+00\n",
      "Epoch 197/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 714.4645 - accuracy: 0.0000e+00 - val_loss: 2127.6179 - val_accuracy: 0.0000e+00\n",
      "Epoch 198/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 711.2971 - accuracy: 0.0000e+00 - val_loss: 2131.4143 - val_accuracy: 0.0000e+00\n",
      "Epoch 199/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 712.8159 - accuracy: 0.0000e+00 - val_loss: 2128.5149 - val_accuracy: 0.0000e+00\n",
      "Epoch 200/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 710.3454 - accuracy: 0.0000e+00 - val_loss: 2132.6792 - val_accuracy: 0.0000e+00\n",
      "Epoch 201/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 714.0690 - accuracy: 0.0000e+00 - val_loss: 2148.0735 - val_accuracy: 0.0000e+00\n",
      "Epoch 202/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 709.1522 - accuracy: 0.0000e+00 - val_loss: 2142.8525 - val_accuracy: 0.0000e+00\n",
      "Epoch 203/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 710.1613 - accuracy: 0.0000e+00 - val_loss: 2141.9658 - val_accuracy: 0.0000e+00\n",
      "Epoch 204/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 712.0102 - accuracy: 0.0000e+00 - val_loss: 2120.8564 - val_accuracy: 0.0000e+00\n",
      "Epoch 205/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 710.9943 - accuracy: 0.0000e+00 - val_loss: 2129.8486 - val_accuracy: 0.0000e+00\n",
      "Epoch 206/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 704.8970 - accuracy: 0.0000e+00 - val_loss: 2117.9868 - val_accuracy: 0.0000e+00\n",
      "Epoch 207/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 710.6877 - accuracy: 0.0000e+00 - val_loss: 2118.4590 - val_accuracy: 0.0000e+00\n",
      "Epoch 208/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 706.1598 - accuracy: 0.0000e+00 - val_loss: 2125.4419 - val_accuracy: 0.0000e+00\n",
      "Epoch 209/500\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 705.3965 - accuracy: 0.0000e+00 - val_loss: 2131.6123 - val_accuracy: 0.0000e+00\n",
      "Epoch 210/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 705.5945 - accuracy: 0.0000e+00 - val_loss: 2138.4832 - val_accuracy: 0.0000e+00\n",
      "Epoch 211/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 706.2827 - accuracy: 0.0000e+00 - val_loss: 2135.3486 - val_accuracy: 0.0000e+00\n",
      "Epoch 212/500\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 705.4980 - accuracy: 0.0000e+00 - val_loss: 2147.0110 - val_accuracy: 0.0000e+00\n",
      "Epoch 213/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 703.0790 - accuracy: 0.0000e+00 - val_loss: 2143.1404 - val_accuracy: 0.0000e+00\n",
      "Epoch 214/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 706.9360 - accuracy: 0.0000e+00 - val_loss: 2151.4595 - val_accuracy: 0.0000e+00\n",
      "Epoch 215/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 703.2950 - accuracy: 0.0000e+00 - val_loss: 2151.1802 - val_accuracy: 0.0000e+00\n",
      "Epoch 216/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 707.3256 - accuracy: 0.0000e+00 - val_loss: 2140.3489 - val_accuracy: 0.0000e+00\n",
      "Epoch 217/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 700.1847 - accuracy: 0.0000e+00 - val_loss: 2147.4463 - val_accuracy: 0.0000e+00\n",
      "Epoch 218/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 704.4556 - accuracy: 0.0000e+00 - val_loss: 2141.6292 - val_accuracy: 0.0000e+00\n",
      "Epoch 219/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 699.8196 - accuracy: 0.0000e+00 - val_loss: 2148.2886 - val_accuracy: 0.0000e+00\n",
      "Epoch 220/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 699.4822 - accuracy: 0.0000e+00 - val_loss: 2149.5186 - val_accuracy: 0.0000e+00\n",
      "Epoch 221/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 702.6967 - accuracy: 0.0000e+00 - val_loss: 2160.1013 - val_accuracy: 0.0000e+00\n",
      "Epoch 222/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 701.5931 - accuracy: 0.0000e+00 - val_loss: 2148.9468 - val_accuracy: 0.0000e+00\n",
      "Epoch 223/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 699.6967 - accuracy: 0.0000e+00 - val_loss: 2148.3350 - val_accuracy: 0.0000e+00\n",
      "Epoch 224/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 697.7792 - accuracy: 0.0000e+00 - val_loss: 2151.5215 - val_accuracy: 0.0000e+00\n",
      "Epoch 225/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 700.0707 - accuracy: 0.0000e+00 - val_loss: 2159.0095 - val_accuracy: 0.0000e+00\n",
      "Epoch 226/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 697.6237 - accuracy: 0.0000e+00 - val_loss: 2161.4287 - val_accuracy: 0.0000e+00\n",
      "Epoch 227/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 699.6873 - accuracy: 0.0000e+00 - val_loss: 2157.8064 - val_accuracy: 0.0000e+00\n",
      "Epoch 228/500\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 696.2053 - accuracy: 0.0000e+00 - val_loss: 2163.6431 - val_accuracy: 0.0000e+00\n",
      "Epoch 229/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 698.7329 - accuracy: 0.0000e+00 - val_loss: 2157.0396 - val_accuracy: 0.0000e+00\n",
      "Epoch 230/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 697.2170 - accuracy: 0.0000e+00 - val_loss: 2167.3909 - val_accuracy: 0.0000e+00\n",
      "Epoch 231/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 699.3064 - accuracy: 0.0000e+00 - val_loss: 2175.5322 - val_accuracy: 0.0000e+00\n",
      "Epoch 232/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 694.8611 - accuracy: 0.0000e+00 - val_loss: 2165.0403 - val_accuracy: 0.0000e+00\n",
      "Epoch 233/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 694.3647 - accuracy: 0.0000e+00 - val_loss: 2159.5623 - val_accuracy: 0.0000e+00\n",
      "Epoch 234/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 697.4793 - accuracy: 0.0000e+00 - val_loss: 2155.8640 - val_accuracy: 0.0000e+00\n",
      "Epoch 235/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 699.0284 - accuracy: 0.0000e+00 - val_loss: 2168.6475 - val_accuracy: 0.0000e+00\n",
      "Epoch 236/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 692.8121 - accuracy: 0.0000e+00 - val_loss: 2164.7498 - val_accuracy: 0.0000e+00\n",
      "Epoch 237/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 696.6270 - accuracy: 0.0000e+00 - val_loss: 2175.3972 - val_accuracy: 0.0000e+00\n",
      "Epoch 238/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 697.6478 - accuracy: 0.0000e+00 - val_loss: 2161.2817 - val_accuracy: 0.0000e+00\n",
      "Epoch 239/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 692.4428 - accuracy: 0.0000e+00 - val_loss: 2166.2241 - val_accuracy: 0.0000e+00\n",
      "Epoch 240/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 692.9040 - accuracy: 0.0000e+00 - val_loss: 2173.7275 - val_accuracy: 0.0000e+00\n",
      "Epoch 241/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 691.9448 - accuracy: 0.0000e+00 - val_loss: 2173.2151 - val_accuracy: 0.0000e+00\n",
      "Epoch 242/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 694.5330 - accuracy: 0.0000e+00 - val_loss: 2178.9333 - val_accuracy: 0.0000e+00\n",
      "Epoch 243/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 692.5695 - accuracy: 0.0000e+00 - val_loss: 2173.5303 - val_accuracy: 0.0000e+00\n",
      "Epoch 244/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 694.6819 - accuracy: 0.0000e+00 - val_loss: 2168.3943 - val_accuracy: 0.0000e+00\n",
      "Epoch 245/500\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 691.2739 - accuracy: 0.0000e+00 - val_loss: 2179.2219 - val_accuracy: 0.0000e+00\n",
      "Epoch 246/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 690.7932 - accuracy: 0.0000e+00 - val_loss: 2177.9551 - val_accuracy: 0.0000e+00\n",
      "Epoch 247/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 691.6552 - accuracy: 0.0000e+00 - val_loss: 2170.2109 - val_accuracy: 0.0000e+00\n",
      "Epoch 248/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 692.8887 - accuracy: 0.0000e+00 - val_loss: 2168.6833 - val_accuracy: 0.0000e+00\n",
      "Epoch 249/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 688.3036 - accuracy: 0.0000e+00 - val_loss: 2174.5459 - val_accuracy: 0.0000e+00\n",
      "Epoch 250/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 690.3500 - accuracy: 0.0000e+00 - val_loss: 2180.5134 - val_accuracy: 0.0000e+00\n",
      "Epoch 251/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 689.4746 - accuracy: 0.0000e+00 - val_loss: 2181.9587 - val_accuracy: 0.0000e+00\n",
      "Epoch 252/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 692.9377 - accuracy: 0.0000e+00 - val_loss: 2174.0818 - val_accuracy: 0.0000e+00\n",
      "Epoch 253/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 690.7663 - accuracy: 0.0000e+00 - val_loss: 2186.0366 - val_accuracy: 0.0000e+00\n",
      "Epoch 254/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 687.0588 - accuracy: 0.0000e+00 - val_loss: 2179.9326 - val_accuracy: 0.0000e+00\n",
      "Epoch 255/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 686.1960 - accuracy: 0.0000e+00 - val_loss: 2183.7886 - val_accuracy: 0.0000e+00\n",
      "Epoch 256/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 690.2879 - accuracy: 0.0000e+00 - val_loss: 2174.6472 - val_accuracy: 0.0000e+00\n",
      "Epoch 257/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 691.0366 - accuracy: 0.0000e+00 - val_loss: 2191.7217 - val_accuracy: 0.0000e+00\n",
      "Epoch 258/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 689.4886 - accuracy: 0.0000e+00 - val_loss: 2191.3926 - val_accuracy: 0.0000e+00\n",
      "Epoch 259/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 686.5725 - accuracy: 0.0000e+00 - val_loss: 2177.4802 - val_accuracy: 0.0000e+00\n",
      "Epoch 260/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 689.6819 - accuracy: 0.0000e+00 - val_loss: 2186.6924 - val_accuracy: 0.0000e+00\n",
      "Epoch 261/500\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 682.8716 - accuracy: 0.0000e+00 - val_loss: 2181.9104 - val_accuracy: 0.0000e+00\n",
      "Epoch 262/500\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 690.6523 - accuracy: 0.0000e+00 - val_loss: 2187.4912 - val_accuracy: 0.0000e+00\n",
      "Epoch 263/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 683.8618 - accuracy: 0.0000e+00 - val_loss: 2184.2249 - val_accuracy: 0.0000e+00\n",
      "Epoch 264/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 684.1401 - accuracy: 0.0000e+00 - val_loss: 2186.9673 - val_accuracy: 0.0000e+00\n",
      "Epoch 265/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 685.9979 - accuracy: 0.0000e+00 - val_loss: 2180.2393 - val_accuracy: 0.0000e+00\n",
      "Epoch 266/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 683.4990 - accuracy: 0.0000e+00 - val_loss: 2183.0447 - val_accuracy: 0.0000e+00\n",
      "Epoch 267/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 683.5363 - accuracy: 0.0000e+00 - val_loss: 2192.1724 - val_accuracy: 0.0000e+00\n",
      "Epoch 268/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 685.8162 - accuracy: 0.0000e+00 - val_loss: 2190.8757 - val_accuracy: 0.0000e+00\n",
      "Epoch 269/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 682.0906 - accuracy: 0.0000e+00 - val_loss: 2193.4241 - val_accuracy: 0.0000e+00\n",
      "Epoch 270/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 683.8389 - accuracy: 0.0000e+00 - val_loss: 2193.7556 - val_accuracy: 0.0000e+00\n",
      "Epoch 271/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 681.9803 - accuracy: 0.0000e+00 - val_loss: 2191.1365 - val_accuracy: 0.0000e+00\n",
      "Epoch 272/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 688.3152 - accuracy: 0.0000e+00 - val_loss: 2206.2437 - val_accuracy: 0.0000e+00\n",
      "Epoch 273/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 697.1865 - accuracy: 0.0000e+00 - val_loss: 2181.2478 - val_accuracy: 0.0000e+00\n",
      "Epoch 274/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 685.9435 - accuracy: 0.0000e+00 - val_loss: 2186.5789 - val_accuracy: 0.0000e+00\n",
      "Epoch 275/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 686.6509 - accuracy: 0.0000e+00 - val_loss: 2189.3601 - val_accuracy: 0.0000e+00\n",
      "Epoch 276/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 684.1462 - accuracy: 0.0000e+00 - val_loss: 2196.9236 - val_accuracy: 0.0000e+00\n",
      "Epoch 277/500\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 682.5256 - accuracy: 0.0000e+00 - val_loss: 2202.6196 - val_accuracy: 0.0000e+00\n",
      "Epoch 278/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 679.2651 - accuracy: 0.0000e+00 - val_loss: 2205.2151 - val_accuracy: 0.0000e+00\n",
      "Epoch 279/500\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 684.2194 - accuracy: 0.0000e+00 - val_loss: 2201.4424 - val_accuracy: 0.0000e+00\n",
      "Epoch 280/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 684.3196 - accuracy: 0.0000e+00 - val_loss: 2213.4128 - val_accuracy: 0.0000e+00\n",
      "Epoch 281/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 680.1360 - accuracy: 0.0000e+00 - val_loss: 2211.4519 - val_accuracy: 0.0000e+00\n",
      "Epoch 282/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 678.8965 - accuracy: 0.0000e+00 - val_loss: 2201.3508 - val_accuracy: 0.0000e+00\n",
      "Epoch 283/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 681.8975 - accuracy: 0.0000e+00 - val_loss: 2197.7546 - val_accuracy: 0.0000e+00\n",
      "Epoch 284/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 681.2555 - accuracy: 0.0000e+00 - val_loss: 2204.2773 - val_accuracy: 0.0000e+00\n",
      "Epoch 285/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 682.0295 - accuracy: 0.0000e+00 - val_loss: 2200.8511 - val_accuracy: 0.0000e+00\n",
      "Epoch 286/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 684.2469 - accuracy: 0.0000e+00 - val_loss: 2209.4263 - val_accuracy: 0.0000e+00\n",
      "Epoch 287/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 679.3840 - accuracy: 0.0000e+00 - val_loss: 2202.1787 - val_accuracy: 0.0000e+00\n",
      "Epoch 288/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 684.5444 - accuracy: 0.0000e+00 - val_loss: 2212.8943 - val_accuracy: 0.0000e+00\n",
      "Epoch 289/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 679.9975 - accuracy: 0.0000e+00 - val_loss: 2215.8479 - val_accuracy: 0.0000e+00\n",
      "Epoch 290/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 677.5815 - accuracy: 0.0000e+00 - val_loss: 2207.6230 - val_accuracy: 0.0000e+00\n",
      "Epoch 291/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 679.4533 - accuracy: 0.0000e+00 - val_loss: 2189.1101 - val_accuracy: 0.0000e+00\n",
      "Epoch 292/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 680.1935 - accuracy: 0.0000e+00 - val_loss: 2193.0420 - val_accuracy: 0.0000e+00\n",
      "Epoch 293/500\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 680.7781 - accuracy: 0.0000e+00 - val_loss: 2195.4424 - val_accuracy: 0.0000e+00\n",
      "Epoch 294/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 676.6929 - accuracy: 0.0000e+00 - val_loss: 2207.9780 - val_accuracy: 0.0000e+00\n",
      "Epoch 295/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 677.8192 - accuracy: 0.0000e+00 - val_loss: 2214.0232 - val_accuracy: 0.0000e+00\n",
      "Epoch 296/500\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 679.9323 - accuracy: 0.0000e+00 - val_loss: 2211.9712 - val_accuracy: 0.0000e+00\n",
      "Epoch 297/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 677.0260 - accuracy: 0.0000e+00 - val_loss: 2214.2585 - val_accuracy: 0.0000e+00\n",
      "Epoch 298/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 677.4845 - accuracy: 0.0000e+00 - val_loss: 2212.6711 - val_accuracy: 0.0000e+00\n",
      "Epoch 299/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 682.2272 - accuracy: 0.0000e+00 - val_loss: 2225.8125 - val_accuracy: 0.0000e+00\n",
      "Epoch 300/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 675.7205 - accuracy: 0.0000e+00 - val_loss: 2204.2666 - val_accuracy: 0.0000e+00\n",
      "Epoch 301/500\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 678.1312 - accuracy: 0.0000e+00 - val_loss: 2201.0837 - val_accuracy: 0.0000e+00\n",
      "Epoch 302/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 681.5915 - accuracy: 0.0000e+00 - val_loss: 2211.9917 - val_accuracy: 0.0000e+00\n",
      "Epoch 303/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 675.3099 - accuracy: 0.0000e+00 - val_loss: 2201.6333 - val_accuracy: 0.0000e+00\n",
      "Epoch 304/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 679.1323 - accuracy: 0.0000e+00 - val_loss: 2196.2114 - val_accuracy: 0.0000e+00\n",
      "Epoch 305/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 678.8240 - accuracy: 0.0000e+00 - val_loss: 2202.8118 - val_accuracy: 0.0000e+00\n",
      "Epoch 306/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 677.2517 - accuracy: 0.0000e+00 - val_loss: 2209.1304 - val_accuracy: 0.0000e+00\n",
      "Epoch 307/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 678.2690 - accuracy: 0.0000e+00 - val_loss: 2217.6040 - val_accuracy: 0.0000e+00\n",
      "Epoch 308/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 678.0613 - accuracy: 0.0000e+00 - val_loss: 2223.0022 - val_accuracy: 0.0000e+00\n",
      "Epoch 309/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 677.7932 - accuracy: 0.0000e+00 - val_loss: 2236.0237 - val_accuracy: 0.0000e+00\n",
      "Epoch 310/500\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 676.6282 - accuracy: 0.0000e+00 - val_loss: 2232.4099 - val_accuracy: 0.0000e+00\n",
      "Epoch 311/500\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 677.4836 - accuracy: 0.0000e+00 - val_loss: 2228.6553 - val_accuracy: 0.0000e+00\n",
      "Epoch 312/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 675.4932 - accuracy: 0.0000e+00 - val_loss: 2233.8101 - val_accuracy: 0.0000e+00\n",
      "Epoch 313/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 677.4011 - accuracy: 0.0000e+00 - val_loss: 2226.2461 - val_accuracy: 0.0000e+00\n",
      "Epoch 314/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 681.3124 - accuracy: 0.0000e+00 - val_loss: 2245.6853 - val_accuracy: 0.0000e+00\n",
      "Epoch 315/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 673.9313 - accuracy: 0.0000e+00 - val_loss: 2222.3872 - val_accuracy: 0.0000e+00\n",
      "Epoch 316/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 677.5312 - accuracy: 0.0000e+00 - val_loss: 2217.0752 - val_accuracy: 0.0000e+00\n",
      "Epoch 317/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 677.0139 - accuracy: 0.0000e+00 - val_loss: 2220.6431 - val_accuracy: 0.0000e+00\n",
      "Epoch 318/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 675.4550 - accuracy: 0.0000e+00 - val_loss: 2227.6543 - val_accuracy: 0.0000e+00\n",
      "Epoch 319/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 676.4891 - accuracy: 0.0000e+00 - val_loss: 2225.1216 - val_accuracy: 0.0000e+00\n",
      "Epoch 320/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 673.3566 - accuracy: 0.0000e+00 - val_loss: 2229.7400 - val_accuracy: 0.0000e+00\n",
      "Epoch 321/500\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 675.3539 - accuracy: 0.0000e+00 - val_loss: 2230.7524 - val_accuracy: 0.0000e+00\n",
      "Epoch 322/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 674.3060 - accuracy: 0.0000e+00 - val_loss: 2231.4878 - val_accuracy: 0.0000e+00\n",
      "Epoch 323/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 677.3279 - accuracy: 0.0000e+00 - val_loss: 2233.9355 - val_accuracy: 0.0000e+00\n",
      "Epoch 324/500\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 675.8839 - accuracy: 0.0000e+00 - val_loss: 2235.9417 - val_accuracy: 0.0000e+00\n",
      "Epoch 325/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 674.6763 - accuracy: 0.0000e+00 - val_loss: 2237.7195 - val_accuracy: 0.0000e+00\n",
      "Epoch 326/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 678.4032 - accuracy: 0.0000e+00 - val_loss: 2238.0649 - val_accuracy: 0.0000e+00\n",
      "Epoch 327/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 675.5943 - accuracy: 0.0000e+00 - val_loss: 2228.6763 - val_accuracy: 0.0000e+00\n",
      "Epoch 328/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 676.6509 - accuracy: 0.0000e+00 - val_loss: 2228.1995 - val_accuracy: 0.0000e+00\n",
      "Epoch 329/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 674.3843 - accuracy: 0.0000e+00 - val_loss: 2234.5435 - val_accuracy: 0.0000e+00\n",
      "Epoch 330/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 675.3156 - accuracy: 0.0000e+00 - val_loss: 2234.6475 - val_accuracy: 0.0000e+00\n",
      "Epoch 331/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 674.0152 - accuracy: 0.0000e+00 - val_loss: 2237.7285 - val_accuracy: 0.0000e+00\n",
      "Epoch 332/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 675.4999 - accuracy: 0.0000e+00 - val_loss: 2242.8604 - val_accuracy: 0.0000e+00\n",
      "Epoch 333/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 683.5801 - accuracy: 0.0000e+00 - val_loss: 2227.0969 - val_accuracy: 0.0000e+00\n",
      "Epoch 334/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 677.3107 - accuracy: 0.0000e+00 - val_loss: 2248.3169 - val_accuracy: 0.0000e+00\n",
      "Epoch 335/500\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 675.8552 - accuracy: 0.0000e+00 - val_loss: 2245.1284 - val_accuracy: 0.0000e+00\n",
      "Epoch 336/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 672.4281 - accuracy: 0.0000e+00 - val_loss: 2240.3733 - val_accuracy: 0.0000e+00\n",
      "Epoch 337/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 674.2498 - accuracy: 0.0000e+00 - val_loss: 2237.0178 - val_accuracy: 0.0000e+00\n",
      "Epoch 338/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 675.1279 - accuracy: 0.0000e+00 - val_loss: 2239.0884 - val_accuracy: 0.0000e+00\n",
      "Epoch 339/500\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 672.5474 - accuracy: 0.0000e+00 - val_loss: 2232.7014 - val_accuracy: 0.0000e+00\n",
      "Epoch 340/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 673.3761 - accuracy: 0.0000e+00 - val_loss: 2230.1816 - val_accuracy: 0.0000e+00\n",
      "Epoch 341/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 673.8831 - accuracy: 0.0000e+00 - val_loss: 2235.9160 - val_accuracy: 0.0000e+00\n",
      "Epoch 342/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 675.0308 - accuracy: 0.0000e+00 - val_loss: 2233.3220 - val_accuracy: 0.0000e+00\n",
      "Epoch 343/500\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 672.7311 - accuracy: 0.0000e+00 - val_loss: 2238.4160 - val_accuracy: 0.0000e+00\n",
      "Epoch 344/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 675.0150 - accuracy: 0.0000e+00 - val_loss: 2245.5696 - val_accuracy: 0.0000e+00\n",
      "Epoch 345/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 677.0896 - accuracy: 0.0000e+00 - val_loss: 2233.5903 - val_accuracy: 0.0000e+00\n",
      "Epoch 346/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 672.9811 - accuracy: 0.0000e+00 - val_loss: 2235.7825 - val_accuracy: 0.0000e+00\n",
      "Epoch 347/500\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 677.6160 - accuracy: 0.0000e+00 - val_loss: 2233.9893 - val_accuracy: 0.0000e+00\n",
      "Epoch 348/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 675.3071 - accuracy: 0.0000e+00 - val_loss: 2247.8396 - val_accuracy: 0.0000e+00\n",
      "Epoch 349/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 673.0590 - accuracy: 0.0000e+00 - val_loss: 2245.6687 - val_accuracy: 0.0000e+00\n",
      "Epoch 350/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 672.6997 - accuracy: 0.0000e+00 - val_loss: 2237.3342 - val_accuracy: 0.0000e+00\n",
      "Epoch 351/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 675.6611 - accuracy: 0.0000e+00 - val_loss: 2245.3484 - val_accuracy: 0.0000e+00\n",
      "Epoch 352/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 672.5513 - accuracy: 0.0000e+00 - val_loss: 2241.5200 - val_accuracy: 0.0000e+00\n",
      "Epoch 353/500\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 673.9094 - accuracy: 0.0000e+00 - val_loss: 2235.0154 - val_accuracy: 0.0000e+00\n",
      "Epoch 354/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 679.8864 - accuracy: 0.0000e+00 - val_loss: 2227.6221 - val_accuracy: 0.0000e+00\n",
      "Epoch 355/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 670.7985 - accuracy: 0.0000e+00 - val_loss: 2232.3413 - val_accuracy: 0.0000e+00\n",
      "Epoch 356/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 678.5579 - accuracy: 0.0000e+00 - val_loss: 2253.1975 - val_accuracy: 0.0000e+00\n",
      "Epoch 357/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 673.7160 - accuracy: 0.0000e+00 - val_loss: 2249.2881 - val_accuracy: 0.0000e+00\n",
      "Epoch 358/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 672.9453 - accuracy: 0.0000e+00 - val_loss: 2234.2986 - val_accuracy: 0.0000e+00\n",
      "Epoch 359/500\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 671.0182 - accuracy: 0.0000e+00 - val_loss: 2233.8442 - val_accuracy: 0.0000e+00\n",
      "Epoch 360/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 675.3041 - accuracy: 0.0000e+00 - val_loss: 2245.0061 - val_accuracy: 0.0000e+00\n",
      "Epoch 361/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 675.6262 - accuracy: 0.0000e+00 - val_loss: 2230.6997 - val_accuracy: 0.0000e+00\n",
      "Epoch 362/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 673.5405 - accuracy: 0.0000e+00 - val_loss: 2233.3445 - val_accuracy: 0.0000e+00\n",
      "Epoch 363/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 672.7529 - accuracy: 0.0000e+00 - val_loss: 2253.9951 - val_accuracy: 0.0000e+00\n",
      "Epoch 364/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 673.8147 - accuracy: 0.0000e+00 - val_loss: 2245.6958 - val_accuracy: 0.0000e+00\n",
      "Epoch 365/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 675.4680 - accuracy: 0.0000e+00 - val_loss: 2239.6570 - val_accuracy: 0.0000e+00\n",
      "Epoch 366/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 670.1088 - accuracy: 0.0000e+00 - val_loss: 2239.7908 - val_accuracy: 0.0000e+00\n",
      "Epoch 367/500\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 671.7420 - accuracy: 0.0000e+00 - val_loss: 2249.9109 - val_accuracy: 0.0000e+00\n",
      "Epoch 368/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 673.2898 - accuracy: 0.0000e+00 - val_loss: 2253.9978 - val_accuracy: 0.0000e+00\n",
      "Epoch 369/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 675.0106 - accuracy: 0.0000e+00 - val_loss: 2238.1077 - val_accuracy: 0.0000e+00\n",
      "Epoch 370/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 670.3586 - accuracy: 0.0000e+00 - val_loss: 2240.4712 - val_accuracy: 0.0000e+00\n",
      "Epoch 371/500\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 672.1746 - accuracy: 0.0000e+00 - val_loss: 2243.1069 - val_accuracy: 0.0000e+00\n",
      "Epoch 372/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 672.8311 - accuracy: 0.0000e+00 - val_loss: 2236.7925 - val_accuracy: 0.0000e+00\n",
      "Epoch 373/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 671.1526 - accuracy: 0.0000e+00 - val_loss: 2244.3967 - val_accuracy: 0.0000e+00\n",
      "Epoch 374/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 670.5237 - accuracy: 0.0000e+00 - val_loss: 2241.7600 - val_accuracy: 0.0000e+00\n",
      "Epoch 375/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 668.8362 - accuracy: 0.0000e+00 - val_loss: 2237.2737 - val_accuracy: 0.0000e+00\n",
      "Epoch 376/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 673.5864 - accuracy: 0.0000e+00 - val_loss: 2233.5747 - val_accuracy: 0.0000e+00\n",
      "Epoch 377/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 671.4165 - accuracy: 0.0000e+00 - val_loss: 2244.4343 - val_accuracy: 0.0000e+00\n",
      "Epoch 378/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 669.9808 - accuracy: 0.0000e+00 - val_loss: 2247.6160 - val_accuracy: 0.0000e+00\n",
      "Epoch 379/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 675.1108 - accuracy: 0.0000e+00 - val_loss: 2238.4333 - val_accuracy: 0.0000e+00\n",
      "Epoch 380/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 672.5475 - accuracy: 0.0000e+00 - val_loss: 2249.3928 - val_accuracy: 0.0000e+00\n",
      "Epoch 381/500\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 674.0852 - accuracy: 0.0000e+00 - val_loss: 2239.1572 - val_accuracy: 0.0000e+00\n",
      "Epoch 382/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 674.2171 - accuracy: 0.0000e+00 - val_loss: 2261.3855 - val_accuracy: 0.0000e+00\n",
      "Epoch 383/500\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 672.3879 - accuracy: 0.0000e+00 - val_loss: 2252.4229 - val_accuracy: 0.0000e+00\n",
      "Epoch 384/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 670.8054 - accuracy: 0.0000e+00 - val_loss: 2247.3926 - val_accuracy: 0.0000e+00\n",
      "Epoch 385/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 670.3373 - accuracy: 0.0000e+00 - val_loss: 2243.1501 - val_accuracy: 0.0000e+00\n",
      "Epoch 386/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 668.5854 - accuracy: 0.0000e+00 - val_loss: 2247.4500 - val_accuracy: 0.0000e+00\n",
      "Epoch 387/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 671.7107 - accuracy: 0.0000e+00 - val_loss: 2236.8364 - val_accuracy: 0.0000e+00\n",
      "Epoch 388/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 667.8834 - accuracy: 0.0000e+00 - val_loss: 2239.5808 - val_accuracy: 0.0000e+00\n",
      "Epoch 389/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 670.2807 - accuracy: 0.0000e+00 - val_loss: 2240.4092 - val_accuracy: 0.0000e+00\n",
      "Epoch 390/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 668.8477 - accuracy: 0.0000e+00 - val_loss: 2244.7236 - val_accuracy: 0.0000e+00\n",
      "Epoch 391/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 668.5432 - accuracy: 0.0000e+00 - val_loss: 2247.3228 - val_accuracy: 0.0000e+00\n",
      "Epoch 392/500\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 668.0419 - accuracy: 0.0000e+00 - val_loss: 2244.4436 - val_accuracy: 0.0000e+00\n",
      "Epoch 393/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 675.2580 - accuracy: 0.0000e+00 - val_loss: 2253.7229 - val_accuracy: 0.0000e+00\n",
      "Epoch 394/500\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 671.1786 - accuracy: 0.0000e+00 - val_loss: 2248.4824 - val_accuracy: 0.0000e+00\n",
      "Epoch 395/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 678.9830 - accuracy: 0.0000e+00 - val_loss: 2234.2053 - val_accuracy: 0.0000e+00\n",
      "Epoch 396/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 672.0990 - accuracy: 0.0000e+00 - val_loss: 2245.4954 - val_accuracy: 0.0000e+00\n",
      "Epoch 397/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 671.4152 - accuracy: 0.0000e+00 - val_loss: 2233.6208 - val_accuracy: 0.0000e+00\n",
      "Epoch 398/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 680.2475 - accuracy: 0.0000e+00 - val_loss: 2253.8496 - val_accuracy: 0.0000e+00\n",
      "Epoch 399/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 671.0296 - accuracy: 0.0000e+00 - val_loss: 2250.3279 - val_accuracy: 0.0000e+00\n",
      "Epoch 400/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 672.1237 - accuracy: 0.0000e+00 - val_loss: 2238.9421 - val_accuracy: 0.0000e+00\n",
      "Epoch 401/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 674.2211 - accuracy: 0.0000e+00 - val_loss: 2249.0405 - val_accuracy: 0.0000e+00\n",
      "Epoch 402/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 670.2687 - accuracy: 0.0000e+00 - val_loss: 2237.8706 - val_accuracy: 0.0000e+00\n",
      "Epoch 403/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 670.7579 - accuracy: 0.0000e+00 - val_loss: 2242.6252 - val_accuracy: 0.0000e+00\n",
      "Epoch 404/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 669.3928 - accuracy: 0.0000e+00 - val_loss: 2249.2329 - val_accuracy: 0.0000e+00\n",
      "Epoch 405/500\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 676.8201 - accuracy: 0.0000e+00 - val_loss: 2239.6973 - val_accuracy: 0.0000e+00\n",
      "Epoch 406/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 667.9303 - accuracy: 0.0000e+00 - val_loss: 2250.8721 - val_accuracy: 0.0000e+00\n",
      "Epoch 407/500\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 682.1469 - accuracy: 0.0000e+00 - val_loss: 2227.2354 - val_accuracy: 0.0000e+00\n",
      "Epoch 408/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 666.6886 - accuracy: 0.0000e+00 - val_loss: 2237.7366 - val_accuracy: 0.0000e+00\n",
      "Epoch 409/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 674.0342 - accuracy: 0.0000e+00 - val_loss: 2250.0408 - val_accuracy: 0.0000e+00\n",
      "Epoch 410/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 669.7931 - accuracy: 0.0000e+00 - val_loss: 2239.8296 - val_accuracy: 0.0000e+00\n",
      "Epoch 411/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 667.3544 - accuracy: 0.0000e+00 - val_loss: 2239.5815 - val_accuracy: 0.0000e+00\n",
      "Epoch 412/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 667.4111 - accuracy: 0.0000e+00 - val_loss: 2249.4343 - val_accuracy: 0.0000e+00\n",
      "Epoch 413/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 666.8438 - accuracy: 0.0000e+00 - val_loss: 2247.1509 - val_accuracy: 0.0000e+00\n",
      "Epoch 414/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 671.3674 - accuracy: 0.0000e+00 - val_loss: 2253.4741 - val_accuracy: 0.0000e+00\n",
      "Epoch 415/500\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 671.6282 - accuracy: 0.0000e+00 - val_loss: 2248.7075 - val_accuracy: 0.0000e+00\n",
      "Epoch 416/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 672.3134 - accuracy: 0.0000e+00 - val_loss: 2239.3445 - val_accuracy: 0.0000e+00\n",
      "Epoch 417/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 668.8432 - accuracy: 0.0000e+00 - val_loss: 2243.1782 - val_accuracy: 0.0000e+00\n",
      "Epoch 418/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 678.2196 - accuracy: 0.0000e+00 - val_loss: 2255.7412 - val_accuracy: 0.0000e+00\n",
      "Epoch 419/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 672.8248 - accuracy: 0.0000e+00 - val_loss: 2240.9880 - val_accuracy: 0.0000e+00\n",
      "Epoch 420/500\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 668.1853 - accuracy: 0.0000e+00 - val_loss: 2246.4165 - val_accuracy: 0.0000e+00\n",
      "Epoch 421/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 667.5216 - accuracy: 0.0000e+00 - val_loss: 2251.9812 - val_accuracy: 0.0000e+00\n",
      "Epoch 422/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 666.5324 - accuracy: 0.0000e+00 - val_loss: 2246.7117 - val_accuracy: 0.0000e+00\n",
      "Epoch 423/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 668.9301 - accuracy: 0.0000e+00 - val_loss: 2243.4905 - val_accuracy: 0.0000e+00\n",
      "Epoch 424/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 667.5702 - accuracy: 0.0000e+00 - val_loss: 2245.9360 - val_accuracy: 0.0000e+00\n",
      "Epoch 425/500\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 665.4031 - accuracy: 0.0000e+00 - val_loss: 2249.0562 - val_accuracy: 0.0000e+00\n",
      "Epoch 426/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 666.3040 - accuracy: 0.0000e+00 - val_loss: 2252.4768 - val_accuracy: 0.0000e+00\n",
      "Epoch 427/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 668.2859 - accuracy: 0.0000e+00 - val_loss: 2246.0513 - val_accuracy: 0.0000e+00\n",
      "Epoch 428/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 672.5065 - accuracy: 0.0000e+00 - val_loss: 2253.6360 - val_accuracy: 0.0000e+00\n",
      "Epoch 429/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 672.6411 - accuracy: 0.0000e+00 - val_loss: 2243.8647 - val_accuracy: 0.0000e+00\n",
      "Epoch 430/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 666.7988 - accuracy: 0.0000e+00 - val_loss: 2247.2754 - val_accuracy: 0.0000e+00\n",
      "Epoch 431/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 664.3608 - accuracy: 0.0000e+00 - val_loss: 2247.7739 - val_accuracy: 0.0000e+00\n",
      "Epoch 432/500\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 667.3566 - accuracy: 0.0000e+00 - val_loss: 2245.7981 - val_accuracy: 0.0000e+00\n",
      "Epoch 433/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 667.7797 - accuracy: 0.0000e+00 - val_loss: 2249.6558 - val_accuracy: 0.0000e+00\n",
      "Epoch 434/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 669.7291 - accuracy: 0.0000e+00 - val_loss: 2251.3345 - val_accuracy: 0.0000e+00\n",
      "Epoch 435/500\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 667.6951 - accuracy: 0.0000e+00 - val_loss: 2250.9014 - val_accuracy: 0.0000e+00\n",
      "Epoch 436/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 661.7038 - accuracy: 0.0000e+00 - val_loss: 2231.4565 - val_accuracy: 0.0000e+00\n",
      "Epoch 437/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 669.0627 - accuracy: 0.0000e+00 - val_loss: 2234.4858 - val_accuracy: 0.0000e+00\n",
      "Epoch 438/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 670.0444 - accuracy: 0.0000e+00 - val_loss: 2231.3113 - val_accuracy: 0.0000e+00\n",
      "Epoch 439/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 670.0479 - accuracy: 0.0000e+00 - val_loss: 2245.6804 - val_accuracy: 0.0000e+00\n",
      "Epoch 440/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 667.8890 - accuracy: 0.0000e+00 - val_loss: 2242.6826 - val_accuracy: 0.0000e+00\n",
      "Epoch 441/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 666.8978 - accuracy: 0.0000e+00 - val_loss: 2240.4575 - val_accuracy: 0.0000e+00\n",
      "Epoch 442/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 666.7173 - accuracy: 0.0000e+00 - val_loss: 2248.1287 - val_accuracy: 0.0000e+00\n",
      "Epoch 443/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 665.3630 - accuracy: 0.0000e+00 - val_loss: 2251.4275 - val_accuracy: 0.0000e+00\n",
      "Epoch 444/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 669.5509 - accuracy: 0.0000e+00 - val_loss: 2244.6614 - val_accuracy: 0.0000e+00\n",
      "Epoch 445/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 667.2535 - accuracy: 0.0000e+00 - val_loss: 2246.4612 - val_accuracy: 0.0000e+00\n",
      "Epoch 446/500\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 665.7872 - accuracy: 0.0000e+00 - val_loss: 2244.5161 - val_accuracy: 0.0000e+00\n",
      "Epoch 447/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 666.0305 - accuracy: 0.0000e+00 - val_loss: 2249.0056 - val_accuracy: 0.0000e+00\n",
      "Epoch 448/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 666.1497 - accuracy: 0.0000e+00 - val_loss: 2252.3865 - val_accuracy: 0.0000e+00\n",
      "Epoch 449/500\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 664.6852 - accuracy: 0.0000e+00 - val_loss: 2247.6860 - val_accuracy: 0.0000e+00\n",
      "Epoch 450/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 664.8165 - accuracy: 0.0000e+00 - val_loss: 2249.5098 - val_accuracy: 0.0000e+00\n",
      "Epoch 451/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 665.9445 - accuracy: 0.0000e+00 - val_loss: 2251.8279 - val_accuracy: 0.0000e+00\n",
      "Epoch 452/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 665.6642 - accuracy: 0.0000e+00 - val_loss: 2248.0144 - val_accuracy: 0.0000e+00\n",
      "Epoch 453/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 668.4798 - accuracy: 0.0000e+00 - val_loss: 2258.2493 - val_accuracy: 0.0000e+00\n",
      "Epoch 454/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 666.0012 - accuracy: 0.0000e+00 - val_loss: 2254.3279 - val_accuracy: 0.0000e+00\n",
      "Epoch 455/500\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 674.2108 - accuracy: 0.0000e+00 - val_loss: 2240.2290 - val_accuracy: 0.0000e+00\n",
      "Epoch 456/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 674.8428 - accuracy: 0.0000e+00 - val_loss: 2260.0310 - val_accuracy: 0.0000e+00\n",
      "Epoch 457/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 667.0245 - accuracy: 0.0000e+00 - val_loss: 2251.3708 - val_accuracy: 0.0000e+00\n",
      "Epoch 458/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 663.5143 - accuracy: 0.0000e+00 - val_loss: 2250.1699 - val_accuracy: 0.0000e+00\n",
      "Epoch 459/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 663.6816 - accuracy: 0.0000e+00 - val_loss: 2251.9011 - val_accuracy: 0.0000e+00\n",
      "Epoch 460/500\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 666.1840 - accuracy: 0.0000e+00 - val_loss: 2257.1165 - val_accuracy: 0.0000e+00\n",
      "Epoch 461/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 663.1963 - accuracy: 0.0000e+00 - val_loss: 2248.9395 - val_accuracy: 0.0000e+00\n",
      "Epoch 462/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 665.2843 - accuracy: 0.0000e+00 - val_loss: 2242.9465 - val_accuracy: 0.0000e+00\n",
      "Epoch 463/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 667.0872 - accuracy: 0.0000e+00 - val_loss: 2248.7046 - val_accuracy: 0.0000e+00\n",
      "Epoch 464/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 664.4751 - accuracy: 0.0000e+00 - val_loss: 2253.4712 - val_accuracy: 0.0000e+00\n",
      "Epoch 465/500\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 662.9418 - accuracy: 0.0000e+00 - val_loss: 2247.2930 - val_accuracy: 0.0000e+00\n",
      "Epoch 466/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 669.3027 - accuracy: 0.0000e+00 - val_loss: 2240.6970 - val_accuracy: 0.0000e+00\n",
      "Epoch 467/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 660.6846 - accuracy: 0.0000e+00 - val_loss: 2247.4788 - val_accuracy: 0.0000e+00\n",
      "Epoch 468/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 668.8256 - accuracy: 0.0000e+00 - val_loss: 2257.9736 - val_accuracy: 0.0000e+00\n",
      "Epoch 469/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 670.1963 - accuracy: 0.0000e+00 - val_loss: 2238.9846 - val_accuracy: 0.0000e+00\n",
      "Epoch 470/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 665.8760 - accuracy: 0.0000e+00 - val_loss: 2240.9583 - val_accuracy: 0.0000e+00\n",
      "Epoch 471/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 663.6508 - accuracy: 0.0000e+00 - val_loss: 2249.3647 - val_accuracy: 0.0000e+00\n",
      "Epoch 472/500\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 665.6479 - accuracy: 0.0000e+00 - val_loss: 2263.8513 - val_accuracy: 0.0000e+00\n",
      "Epoch 473/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 664.8554 - accuracy: 0.0000e+00 - val_loss: 2253.5129 - val_accuracy: 0.0000e+00\n",
      "Epoch 474/500\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 665.0449 - accuracy: 0.0000e+00 - val_loss: 2255.0940 - val_accuracy: 0.0000e+00\n",
      "Epoch 475/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 662.0836 - accuracy: 0.0000e+00 - val_loss: 2242.0349 - val_accuracy: 0.0000e+00\n",
      "Epoch 476/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 663.0944 - accuracy: 0.0000e+00 - val_loss: 2240.2021 - val_accuracy: 0.0000e+00\n",
      "Epoch 477/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 665.1723 - accuracy: 0.0000e+00 - val_loss: 2251.5671 - val_accuracy: 0.0000e+00\n",
      "Epoch 478/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 665.1685 - accuracy: 0.0000e+00 - val_loss: 2245.7810 - val_accuracy: 0.0000e+00\n",
      "Epoch 479/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 663.5823 - accuracy: 0.0000e+00 - val_loss: 2246.4958 - val_accuracy: 0.0000e+00\n",
      "Epoch 480/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 666.6838 - accuracy: 0.0000e+00 - val_loss: 2254.3611 - val_accuracy: 0.0000e+00\n",
      "Epoch 481/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 667.9778 - accuracy: 0.0000e+00 - val_loss: 2241.2146 - val_accuracy: 0.0000e+00\n",
      "Epoch 482/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 676.1643 - accuracy: 0.0000e+00 - val_loss: 2264.4919 - val_accuracy: 0.0000e+00\n",
      "Epoch 483/500\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 670.9388 - accuracy: 0.0000e+00 - val_loss: 2255.1123 - val_accuracy: 0.0000e+00\n",
      "Epoch 484/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 665.8108 - accuracy: 0.0000e+00 - val_loss: 2257.5864 - val_accuracy: 0.0000e+00\n",
      "Epoch 485/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 662.6596 - accuracy: 0.0000e+00 - val_loss: 2257.3120 - val_accuracy: 0.0000e+00\n",
      "Epoch 486/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 660.8765 - accuracy: 0.0000e+00 - val_loss: 2241.0217 - val_accuracy: 0.0000e+00\n",
      "Epoch 487/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 662.0618 - accuracy: 0.0000e+00 - val_loss: 2242.7681 - val_accuracy: 0.0000e+00\n",
      "Epoch 488/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 661.9825 - accuracy: 0.0000e+00 - val_loss: 2241.4412 - val_accuracy: 0.0000e+00\n",
      "Epoch 489/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 660.2676 - accuracy: 0.0000e+00 - val_loss: 2242.3308 - val_accuracy: 0.0000e+00\n",
      "Epoch 490/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 661.3730 - accuracy: 0.0000e+00 - val_loss: 2247.5632 - val_accuracy: 0.0000e+00\n",
      "Epoch 491/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 663.7507 - accuracy: 0.0000e+00 - val_loss: 2252.1841 - val_accuracy: 0.0000e+00\n",
      "Epoch 492/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 683.1575 - accuracy: 0.0000e+00 - val_loss: 2232.2136 - val_accuracy: 0.0000e+00\n",
      "Epoch 493/500\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 668.6310 - accuracy: 0.0000e+00 - val_loss: 2236.1023 - val_accuracy: 0.0000e+00\n",
      "Epoch 494/500\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 665.9255 - accuracy: 0.0000e+00 - val_loss: 2239.1753 - val_accuracy: 0.0000e+00\n",
      "Epoch 495/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 662.3995 - accuracy: 0.0000e+00 - val_loss: 2252.8357 - val_accuracy: 0.0000e+00\n",
      "Epoch 496/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 659.5062 - accuracy: 0.0000e+00 - val_loss: 2248.9358 - val_accuracy: 0.0000e+00\n",
      "Epoch 497/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 670.8345 - accuracy: 0.0000e+00 - val_loss: 2260.7883 - val_accuracy: 0.0000e+00\n",
      "Epoch 498/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 667.3188 - accuracy: 0.0000e+00 - val_loss: 2250.0952 - val_accuracy: 0.0000e+00\n",
      "Epoch 499/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 669.2134 - accuracy: 0.0000e+00 - val_loss: 2261.4670 - val_accuracy: 0.0000e+00\n",
      "Epoch 500/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 664.7787 - accuracy: 0.0000e+00 - val_loss: 2235.3494 - val_accuracy: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf \n",
    "from tensorflow import keras\n",
    "\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(X_train.shape[1], activation='relu'),\n",
    "    keras.layers.Dense(X_train.shape[1]*2, activation='relu'),\n",
    "    keras.layers.Dense(X_train.shape[1]*4, activation='relu'),\n",
    "    # keras.layers.Dropout(0.1),\n",
    "    keras.layers.Dense(X_train.shape[1]*8, activation='relu'),\n",
    "    # keras.layers.Dropout(0.1),\n",
    "    keras.layers.Dense(X_train.shape[1]*4, activation='relu'),\n",
    "    # keras.layers.Dropout(0.1),\n",
    "    keras.layers.Dense(1, activation='linear') \n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='mean_squared_error',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "history = model.fit(X_train, y_train, validation_split=0.2, epochs=500, batch_size=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "#plot the training and validation accuracy and loss at each epoch\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1, len(loss) + 1)\n",
    "plt.plot(epochs, loss, 'y', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'mean_absolute_error'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32md:\\OneDrive\\OneDrive - budai egyetem\\work\\gyanta_kombinacio_szamitas\\single_output_nn.ipynb Cell 8\u001b[0m in \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/OneDrive/OneDrive%20-%20%C3%93budai%20egyetem/work/gyanta_kombinacio_szamitas/single_output_nn.ipynb#X10sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m acc \u001b[39m=\u001b[39m history\u001b[39m.\u001b[39;49mhistory[\u001b[39m'\u001b[39;49m\u001b[39mmean_absolute_error\u001b[39;49m\u001b[39m'\u001b[39;49m]\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/OneDrive/OneDrive%20-%20%C3%93budai%20egyetem/work/gyanta_kombinacio_szamitas/single_output_nn.ipynb#X10sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m val_acc \u001b[39m=\u001b[39m history\u001b[39m.\u001b[39mhistory[\u001b[39m'\u001b[39m\u001b[39mval_mean_absolute_error\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/OneDrive/OneDrive%20-%20%C3%93budai%20egyetem/work/gyanta_kombinacio_szamitas/single_output_nn.ipynb#X10sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m plt\u001b[39m.\u001b[39mplot(epochs, acc, \u001b[39m'\u001b[39m\u001b[39my\u001b[39m\u001b[39m'\u001b[39m, label\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mTraining MAE\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'mean_absolute_error'"
     ]
    }
   ],
   "source": [
    "acc = history.history['mean_absolute_error']\n",
    "val_acc = history.history['val_mean_absolute_error']\n",
    "plt.plot(epochs, acc, 'y', label='Training MAE')\n",
    "plt.plot(epochs, val_acc, 'r', label='Validation MAE')\n",
    "plt.title('Training and validation MAE')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tothb\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\tothb\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[ 41.00570879  24.4         30.99300537  66.39332054  24.4\n  43.53288116  43.53288116  59.31259856  53.5889705   66.90097079\n  51.01197126  30.99300537  51.65354643  30.99300537  33.88111086\n  37.40287136  51.65354643  39.53081115  70.09526879  37.99644797\n  45.14629948  41.22811101  43.53288116  58.25085525  61.42361668\n  51.65354643  40.58802504  43.53288116  34.19817471  60.13418784\n  66.42402729  40.44198895  57.84753363  60.13418784  43.07628635\n  48.509212    30.99300537 200.18484288  77.23781568  43.53288116\n  51.65354643  64.2209671   82.94265232  77.23781568  55.30910453\n  69.0981506   39.53081115  43.53288116  31.22866894  24.4\n  51.01197126  44.67965124  68.22672895  37.40287136  43.53288116\n  57.00907579  56.497032    35.81213307  57.84066917  57.84753363\n  58.43266214  42.50987798  43.53288116  57.84753363  52.89801543\n  57.84753363  43.07628635  63.34050237  77.19675157  43.53288116\n  55.20814912  82.17726312  55.91698621].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32md:\\OneDrive\\OneDrive - budai egyetem\\work\\gyanta_kombinacio_szamitas\\single_output_nn.ipynb Cell 8\u001b[0m in \u001b[0;36m6\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/OneDrive/OneDrive%20-%20%C3%93budai%20egyetem/work/gyanta_kombinacio_szamitas/single_output_nn.ipynb#W5sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m \u001b[39mimport\u001b[39;00m metrics\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/OneDrive/OneDrive%20-%20%C3%93budai%20egyetem/work/gyanta_kombinacio_szamitas/single_output_nn.ipynb#W5sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m nn_pred \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict(ss\u001b[39m.\u001b[39mtransform(X_test))\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/OneDrive/OneDrive%20-%20%C3%93budai%20egyetem/work/gyanta_kombinacio_szamitas/single_output_nn.ipynb#W5sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m nn_MSE \u001b[39m=\u001b[39m metrics\u001b[39m.\u001b[39mmean_squared_error(ss\u001b[39m.\u001b[39;49mtransform(y_test), nn_pred)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/OneDrive/OneDrive%20-%20%C3%93budai%20egyetem/work/gyanta_kombinacio_szamitas/single_output_nn.ipynb#W5sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m nn_MAE \u001b[39m=\u001b[39m metrics\u001b[39m.\u001b[39mmean_absolute_error(ss\u001b[39m.\u001b[39mtransform(y_test), nn_pred)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/OneDrive/OneDrive%20-%20%C3%93budai%20egyetem/work/gyanta_kombinacio_szamitas/single_output_nn.ipynb#W5sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m nn_MAPE \u001b[39m=\u001b[39m metrics\u001b[39m.\u001b[39mmean_absolute_percentage_error(ss\u001b[39m.\u001b[39mtransform(y_test), nn_pred)\n",
      "File \u001b[1;32mc:\\Users\\tothb\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:975\u001b[0m, in \u001b[0;36mStandardScaler.transform\u001b[1;34m(self, X, copy)\u001b[0m\n\u001b[0;32m    972\u001b[0m check_is_fitted(\u001b[39mself\u001b[39m)\n\u001b[0;32m    974\u001b[0m copy \u001b[39m=\u001b[39m copy \u001b[39mif\u001b[39;00m copy \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcopy\n\u001b[1;32m--> 975\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(\n\u001b[0;32m    976\u001b[0m     X,\n\u001b[0;32m    977\u001b[0m     reset\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    978\u001b[0m     accept_sparse\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcsr\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    979\u001b[0m     copy\u001b[39m=\u001b[39;49mcopy,\n\u001b[0;32m    980\u001b[0m     dtype\u001b[39m=\u001b[39;49mFLOAT_DTYPES,\n\u001b[0;32m    981\u001b[0m     force_all_finite\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mallow-nan\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    982\u001b[0m )\n\u001b[0;32m    984\u001b[0m \u001b[39mif\u001b[39;00m sparse\u001b[39m.\u001b[39missparse(X):\n\u001b[0;32m    985\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwith_mean:\n",
      "File \u001b[1;32mc:\\Users\\tothb\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:577\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    575\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mValidation should be done on X, y or both.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    576\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m no_val_y:\n\u001b[1;32m--> 577\u001b[0m     X \u001b[39m=\u001b[39m check_array(X, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mX\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_params)\n\u001b[0;32m    578\u001b[0m     out \u001b[39m=\u001b[39m X\n\u001b[0;32m    579\u001b[0m \u001b[39melif\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_y:\n",
      "File \u001b[1;32mc:\\Users\\tothb\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:879\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    877\u001b[0m     \u001b[39m# If input is 1D raise error\u001b[39;00m\n\u001b[0;32m    878\u001b[0m     \u001b[39mif\u001b[39;00m array\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m--> 879\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    880\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mExpected 2D array, got 1D array instead:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39marray=\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    881\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mReshape your data either using array.reshape(-1, 1) if \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    882\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39myour data has a single feature or array.reshape(1, -1) \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    883\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mif it contains a single sample.\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(array)\n\u001b[0;32m    884\u001b[0m         )\n\u001b[0;32m    886\u001b[0m \u001b[39mif\u001b[39;00m dtype_numeric \u001b[39mand\u001b[39;00m array\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mkind \u001b[39min\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mUSV\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    887\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    888\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mdtype=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mnumeric\u001b[39m\u001b[39m'\u001b[39m\u001b[39m is not compatible with arrays of bytes/strings.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    889\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mConvert your data to numeric values explicitly instead.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    890\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[ 41.00570879  24.4         30.99300537  66.39332054  24.4\n  43.53288116  43.53288116  59.31259856  53.5889705   66.90097079\n  51.01197126  30.99300537  51.65354643  30.99300537  33.88111086\n  37.40287136  51.65354643  39.53081115  70.09526879  37.99644797\n  45.14629948  41.22811101  43.53288116  58.25085525  61.42361668\n  51.65354643  40.58802504  43.53288116  34.19817471  60.13418784\n  66.42402729  40.44198895  57.84753363  60.13418784  43.07628635\n  48.509212    30.99300537 200.18484288  77.23781568  43.53288116\n  51.65354643  64.2209671   82.94265232  77.23781568  55.30910453\n  69.0981506   39.53081115  43.53288116  31.22866894  24.4\n  51.01197126  44.67965124  68.22672895  37.40287136  43.53288116\n  57.00907579  56.497032    35.81213307  57.84066917  57.84753363\n  58.43266214  42.50987798  43.53288116  57.84753363  52.89801543\n  57.84753363  43.07628635  63.34050237  77.19675157  43.53288116\n  55.20814912  82.17726312  55.91698621].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "nn_pred = model.predict(ss.transform(X_test))\n",
    "\n",
    "\n",
    "nn_MSE = metrics.mean_squared_error(ss.transform(y_test), nn_pred)\n",
    "nn_MAE = metrics.mean_absolute_error(ss.transform(y_test), nn_pred)\n",
    "nn_MAPE = metrics.mean_absolute_percentage_error(ss.transform(y_test), nn_pred)\n",
    "nn_accuracy = 100-(nn_MAPE*100)\n",
    "\n",
    "print('MSE', nn_MSE )\n",
    "print('MAE', nn_MAE)\n",
    "print('MAPE', nn_MAPE)\n",
    "print('Accuracy', nn_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 52ms/step\n",
      "[[10.608651]]\n"
     ]
    }
   ],
   "source": [
    "print(model.predict([[42, 20, 4]]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
