{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Epidian 6D</th>\n",
       "      <th>Araldite GY260</th>\n",
       "      <th>Araldite GY250CH</th>\n",
       "      <th>CHS-520 (*CHS-530)</th>\n",
       "      <th>CHS-525</th>\n",
       "      <th>CHS-590</th>\n",
       "      <th>Epidian 5</th>\n",
       "      <th>Epidian 6</th>\n",
       "      <th>Epilox AF 18-50</th>\n",
       "      <th>AH-24/Grilonit epoxide 8</th>\n",
       "      <th>...</th>\n",
       "      <th>trisDMP</th>\n",
       "      <th>DCH-99</th>\n",
       "      <th>MXDA</th>\n",
       "      <th>Ethacure 100</th>\n",
       "      <th>nonilfenol</th>\n",
       "      <th>etanol</th>\n",
       "      <th>AHEW</th>\n",
       "      <th>Fazékidő (min)</th>\n",
       "      <th>Szakítószilárdság [MPa]</th>\n",
       "      <th>Szakadási nyúlás [%]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24.400000</td>\n",
       "      <td>46.0</td>\n",
       "      <td>82.57</td>\n",
       "      <td>5.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27.685325</td>\n",
       "      <td>53.0</td>\n",
       "      <td>41.72</td>\n",
       "      <td>3.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>31.228669</td>\n",
       "      <td>34.0</td>\n",
       "      <td>56.60</td>\n",
       "      <td>4.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35.812133</td>\n",
       "      <td>28.0</td>\n",
       "      <td>61.23</td>\n",
       "      <td>5.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27.685325</td>\n",
       "      <td>61.0</td>\n",
       "      <td>41.13</td>\n",
       "      <td>3.67</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Epidian 6D  Araldite GY260  Araldite GY250CH  CHS-520 (*CHS-530)  CHS-525  \\\n",
       "0        20.0             0.0               0.0                 0.0      0.0   \n",
       "1        20.0             0.0               0.0                 0.0      0.0   \n",
       "2        20.0             0.0               0.0                 0.0      0.0   \n",
       "3        20.0             0.0               0.0                 0.0      0.0   \n",
       "4        20.0             0.0               0.0                 0.0      0.0   \n",
       "\n",
       "   CHS-590  Epidian 5  Epidian 6  Epilox AF 18-50  AH-24/Grilonit epoxide 8  \\\n",
       "0      0.0        0.0        0.0             60.0                      20.0   \n",
       "1      0.0        0.0        0.0             60.0                      20.0   \n",
       "2      0.0        0.0        0.0             60.0                      20.0   \n",
       "3      0.0        0.0        0.0             60.0                      20.0   \n",
       "4      0.0        0.0        0.0             60.0                      20.0   \n",
       "\n",
       "   ...  trisDMP  DCH-99  MXDA  Ethacure 100  nonilfenol  etanol       AHEW  \\\n",
       "0  ...      0.0     0.0   0.0           0.0           0       0  24.400000   \n",
       "1  ...      0.0     0.0   0.0           0.0           0       0  27.685325   \n",
       "2  ...      0.0     0.0   0.0           0.0           0       0  31.228669   \n",
       "3  ...      0.0     0.0   0.0           0.0           0       0  35.812133   \n",
       "4  ...      0.0     0.0   0.0           0.0           0       0  27.685325   \n",
       "\n",
       "   Fazékidő (min)  Szakítószilárdság [MPa]  Szakadási nyúlás [%]  \n",
       "0            46.0                    82.57                  5.58  \n",
       "1            53.0                    41.72                  3.35  \n",
       "2            34.0                    56.60                  4.76  \n",
       "3            28.0                    61.23                  5.59  \n",
       "4            61.0                    41.13                  3.67  \n",
       "\n",
       "[5 rows x 37 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "import joblib\n",
    "\n",
    "pd.set_option('display.max_colwidth',  None)\n",
    "\n",
    "with open('result.json') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "df.fillna(0, inplace=True)\n",
    "df = df.apply(lambda series: pd.to_numeric(series, errors='coerce'))\n",
    "df = df.dropna()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Epidian 6D</th>\n",
       "      <th>Araldite GY260</th>\n",
       "      <th>Araldite GY250CH</th>\n",
       "      <th>CHS-520 (*CHS-530)</th>\n",
       "      <th>CHS-525</th>\n",
       "      <th>CHS-590</th>\n",
       "      <th>Epidian 5</th>\n",
       "      <th>Epidian 6</th>\n",
       "      <th>Epilox AF 18-50</th>\n",
       "      <th>AH-24/Grilonit epoxide 8</th>\n",
       "      <th>...</th>\n",
       "      <th>APU-4</th>\n",
       "      <th>trisDMP</th>\n",
       "      <th>DCH-99</th>\n",
       "      <th>MXDA</th>\n",
       "      <th>Ethacure 100</th>\n",
       "      <th>nonilfenol</th>\n",
       "      <th>etanol</th>\n",
       "      <th>Fazékidő (min)</th>\n",
       "      <th>Szakítószilárdság [MPa]</th>\n",
       "      <th>Szakadási nyúlás [%]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>82.57</td>\n",
       "      <td>5.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>41.72</td>\n",
       "      <td>3.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>56.60</td>\n",
       "      <td>4.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>61.23</td>\n",
       "      <td>5.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>41.13</td>\n",
       "      <td>3.67</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Epidian 6D  Araldite GY260  Araldite GY250CH  CHS-520 (*CHS-530)  CHS-525  \\\n",
       "0        20.0             0.0               0.0                 0.0      0.0   \n",
       "1        20.0             0.0               0.0                 0.0      0.0   \n",
       "2        20.0             0.0               0.0                 0.0      0.0   \n",
       "3        20.0             0.0               0.0                 0.0      0.0   \n",
       "4        20.0             0.0               0.0                 0.0      0.0   \n",
       "\n",
       "   CHS-590  Epidian 5  Epidian 6  Epilox AF 18-50  AH-24/Grilonit epoxide 8  \\\n",
       "0      0.0        0.0        0.0             60.0                      20.0   \n",
       "1      0.0        0.0        0.0             60.0                      20.0   \n",
       "2      0.0        0.0        0.0             60.0                      20.0   \n",
       "3      0.0        0.0        0.0             60.0                      20.0   \n",
       "4      0.0        0.0        0.0             60.0                      20.0   \n",
       "\n",
       "   ...  APU-4  trisDMP  DCH-99  MXDA  Ethacure 100  nonilfenol  etanol  \\\n",
       "0  ...    0.0      0.0     0.0   0.0           0.0           0       0   \n",
       "1  ...    0.0      0.0     0.0   0.0           0.0           0       0   \n",
       "2  ...    0.0      0.0     0.0   0.0           0.0           0       0   \n",
       "3  ...    0.0      0.0     0.0   0.0           0.0           0       0   \n",
       "4  ...    0.0      0.0     0.0   0.0           0.0           0       0   \n",
       "\n",
       "   Fazékidő (min)  Szakítószilárdság [MPa]  Szakadási nyúlás [%]  \n",
       "0            46.0                    82.57                  5.58  \n",
       "1            53.0                    41.72                  3.35  \n",
       "2            34.0                    56.60                  4.76  \n",
       "3            28.0                    61.23                  5.59  \n",
       "4            61.0                    41.13                  3.67  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del df[\"EEW\"]\n",
    "# del df[\"nonilfenol\"]\n",
    "# del df[\"etanol\"]\n",
    "del df[\"AHEW\"]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "dataset = torch.FloatTensor(df.iloc[:, -3:].values)\n",
    "ss = StandardScaler().fit(dataset)\n",
    "dataset = ss.transform(dataset)\n",
    "\n",
    "loader = DataLoader(dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss: 36.445194244384766\n",
      "Epoch: 2, Loss: 19.123098373413086\n",
      "Epoch: 3, Loss: 27.429000854492188\n",
      "Epoch: 4, Loss: 17.854982376098633\n",
      "Epoch: 5, Loss: 25.77815055847168\n",
      "Epoch: 6, Loss: 17.520448684692383\n",
      "Epoch: 7, Loss: 19.306396484375\n",
      "Epoch: 8, Loss: 30.690139770507812\n",
      "Epoch: 9, Loss: 15.989909172058105\n",
      "Epoch: 10, Loss: 20.901887893676758\n",
      "Epoch: 11, Loss: 24.823360443115234\n",
      "Epoch: 12, Loss: 19.841588973999023\n",
      "Epoch: 13, Loss: 15.126029014587402\n",
      "Epoch: 14, Loss: 17.507604598999023\n",
      "Epoch: 15, Loss: 13.709592819213867\n",
      "Epoch: 16, Loss: 15.726800918579102\n",
      "Epoch: 17, Loss: 19.573524475097656\n",
      "Epoch: 18, Loss: 15.9361572265625\n",
      "Epoch: 19, Loss: 11.2841796875\n",
      "Epoch: 20, Loss: 20.508216857910156\n",
      "Epoch: 21, Loss: 14.140878677368164\n",
      "Epoch: 22, Loss: 15.234188079833984\n",
      "Epoch: 23, Loss: 14.71925163269043\n",
      "Epoch: 24, Loss: 11.461821556091309\n",
      "Epoch: 25, Loss: 12.219651222229004\n",
      "Epoch: 26, Loss: 18.175691604614258\n",
      "Epoch: 27, Loss: 20.780494689941406\n",
      "Epoch: 28, Loss: 14.114869117736816\n",
      "Epoch: 29, Loss: 11.362635612487793\n",
      "Epoch: 30, Loss: 12.401168823242188\n",
      "Epoch: 31, Loss: 14.002703666687012\n",
      "Epoch: 32, Loss: 14.853100776672363\n",
      "Epoch: 33, Loss: 15.858905792236328\n",
      "Epoch: 34, Loss: 12.59006118774414\n",
      "Epoch: 35, Loss: 19.132869720458984\n",
      "Epoch: 36, Loss: 15.268412590026855\n",
      "Epoch: 37, Loss: 30.73750114440918\n",
      "Epoch: 38, Loss: 17.16789436340332\n",
      "Epoch: 39, Loss: 14.907350540161133\n",
      "Epoch: 40, Loss: 20.062583923339844\n",
      "Epoch: 41, Loss: 14.801234245300293\n",
      "Epoch: 42, Loss: 16.76702308654785\n",
      "Epoch: 43, Loss: 12.61495304107666\n",
      "Epoch: 44, Loss: 13.658547401428223\n",
      "Epoch: 45, Loss: 15.096209526062012\n",
      "Epoch: 46, Loss: 13.846351623535156\n",
      "Epoch: 47, Loss: 41.8232421875\n",
      "Epoch: 48, Loss: 12.332154273986816\n",
      "Epoch: 49, Loss: 12.380830764770508\n",
      "Epoch: 50, Loss: 16.773216247558594\n",
      "Epoch: 51, Loss: 13.38144302368164\n",
      "Epoch: 52, Loss: 16.127193450927734\n",
      "Epoch: 53, Loss: 21.4304256439209\n",
      "Epoch: 54, Loss: 13.670445442199707\n",
      "Epoch: 55, Loss: 14.02465534210205\n",
      "Epoch: 56, Loss: 10.073102951049805\n",
      "Epoch: 57, Loss: 12.374013900756836\n",
      "Epoch: 58, Loss: 37.1673469543457\n",
      "Epoch: 59, Loss: 19.438556671142578\n",
      "Epoch: 60, Loss: 15.673964500427246\n",
      "Epoch: 61, Loss: 14.21666145324707\n",
      "Epoch: 62, Loss: 14.147721290588379\n",
      "Epoch: 63, Loss: 19.330873489379883\n",
      "Epoch: 64, Loss: 11.685320854187012\n",
      "Epoch: 65, Loss: 14.92893123626709\n",
      "Epoch: 66, Loss: 20.8563289642334\n",
      "Epoch: 67, Loss: 14.764084815979004\n",
      "Epoch: 68, Loss: 29.25758934020996\n",
      "Epoch: 69, Loss: 13.836867332458496\n",
      "Epoch: 70, Loss: 13.034873008728027\n",
      "Epoch: 71, Loss: 10.110281944274902\n",
      "Epoch: 72, Loss: 14.69045639038086\n",
      "Epoch: 73, Loss: 12.944215774536133\n",
      "Epoch: 74, Loss: 14.290830612182617\n",
      "Epoch: 75, Loss: 13.370576858520508\n",
      "Epoch: 76, Loss: 14.753340721130371\n",
      "Epoch: 77, Loss: 15.353100776672363\n",
      "Epoch: 78, Loss: 14.180917739868164\n",
      "Epoch: 79, Loss: 14.105788230895996\n",
      "Epoch: 80, Loss: 13.767149925231934\n",
      "Epoch: 81, Loss: 11.917176246643066\n",
      "Epoch: 82, Loss: 16.231464385986328\n",
      "Epoch: 83, Loss: 12.503117561340332\n",
      "Epoch: 84, Loss: 17.031160354614258\n",
      "Epoch: 85, Loss: 15.777721405029297\n",
      "Epoch: 86, Loss: 23.846696853637695\n",
      "Epoch: 87, Loss: 36.44191360473633\n",
      "Epoch: 88, Loss: 8.66687297821045\n",
      "Epoch: 89, Loss: 14.502866744995117\n",
      "Epoch: 90, Loss: 15.194755554199219\n",
      "Epoch: 91, Loss: 12.621816635131836\n",
      "Epoch: 92, Loss: 13.713395118713379\n",
      "Epoch: 93, Loss: 11.93677806854248\n",
      "Epoch: 94, Loss: 24.039413452148438\n",
      "Epoch: 95, Loss: 11.201549530029297\n",
      "Epoch: 96, Loss: 15.471988677978516\n",
      "Epoch: 97, Loss: 13.985509872436523\n",
      "Epoch: 98, Loss: 17.438772201538086\n",
      "Epoch: 99, Loss: 11.043524742126465\n",
      "Epoch: 100, Loss: 21.455280303955078\n",
      "Epoch: 101, Loss: 14.671276092529297\n",
      "Epoch: 102, Loss: 16.03986930847168\n",
      "Epoch: 103, Loss: 11.556827545166016\n",
      "Epoch: 104, Loss: 9.606278419494629\n",
      "Epoch: 105, Loss: 13.029434204101562\n",
      "Epoch: 106, Loss: 11.624859809875488\n",
      "Epoch: 107, Loss: 11.373861312866211\n",
      "Epoch: 108, Loss: 15.923885345458984\n",
      "Epoch: 109, Loss: 14.163254737854004\n",
      "Epoch: 110, Loss: 16.33251190185547\n",
      "Epoch: 111, Loss: 14.50651741027832\n",
      "Epoch: 112, Loss: 17.64093017578125\n",
      "Epoch: 113, Loss: 14.400134086608887\n",
      "Epoch: 114, Loss: 13.369704246520996\n",
      "Epoch: 115, Loss: 11.016142845153809\n",
      "Epoch: 116, Loss: 10.59268569946289\n",
      "Epoch: 117, Loss: 15.756442070007324\n",
      "Epoch: 118, Loss: 13.953043937683105\n",
      "Epoch: 119, Loss: 15.104958534240723\n",
      "Epoch: 120, Loss: 16.234539031982422\n",
      "Epoch: 121, Loss: 32.72919845581055\n",
      "Epoch: 122, Loss: 27.63544273376465\n",
      "Epoch: 123, Loss: 14.198506355285645\n",
      "Epoch: 124, Loss: 13.212778091430664\n",
      "Epoch: 125, Loss: 13.13589859008789\n",
      "Epoch: 126, Loss: 14.121731758117676\n",
      "Epoch: 127, Loss: 19.33186912536621\n",
      "Epoch: 128, Loss: 17.508512496948242\n",
      "Epoch: 129, Loss: 33.303749084472656\n",
      "Epoch: 130, Loss: 12.77208137512207\n",
      "Epoch: 131, Loss: 15.020620346069336\n",
      "Epoch: 132, Loss: 16.864513397216797\n",
      "Epoch: 133, Loss: 27.25217056274414\n",
      "Epoch: 134, Loss: 12.605667114257812\n",
      "Epoch: 135, Loss: 12.816752433776855\n",
      "Epoch: 136, Loss: 12.443435668945312\n",
      "Epoch: 137, Loss: 20.63751792907715\n",
      "Epoch: 138, Loss: 18.304481506347656\n",
      "Epoch: 139, Loss: 15.844353675842285\n",
      "Epoch: 140, Loss: 38.209442138671875\n",
      "Epoch: 141, Loss: 13.895611763000488\n",
      "Epoch: 142, Loss: 28.820568084716797\n",
      "Epoch: 143, Loss: 14.216167449951172\n",
      "Epoch: 144, Loss: 14.023965835571289\n",
      "Epoch: 145, Loss: 16.472700119018555\n",
      "Epoch: 146, Loss: 12.98586368560791\n",
      "Epoch: 147, Loss: 12.341475486755371\n",
      "Epoch: 148, Loss: 16.109508514404297\n",
      "Epoch: 149, Loss: 15.329442977905273\n",
      "Epoch: 150, Loss: 17.071475982666016\n",
      "Epoch: 151, Loss: 13.756556510925293\n",
      "Epoch: 152, Loss: 13.860861778259277\n",
      "Epoch: 153, Loss: 12.2363920211792\n",
      "Epoch: 154, Loss: 17.444406509399414\n",
      "Epoch: 155, Loss: 12.421014785766602\n",
      "Epoch: 156, Loss: 21.003009796142578\n",
      "Epoch: 157, Loss: 13.01308822631836\n",
      "Epoch: 158, Loss: 10.72656536102295\n",
      "Epoch: 159, Loss: 13.051094055175781\n",
      "Epoch: 160, Loss: 19.853790283203125\n",
      "Epoch: 161, Loss: 16.48465347290039\n",
      "Epoch: 162, Loss: 14.377540588378906\n",
      "Epoch: 163, Loss: 16.839366912841797\n",
      "Epoch: 164, Loss: 21.88553810119629\n",
      "Epoch: 165, Loss: 19.30803871154785\n",
      "Epoch: 166, Loss: 11.384653091430664\n",
      "Epoch: 167, Loss: 9.39841079711914\n",
      "Epoch: 168, Loss: 11.558023452758789\n",
      "Epoch: 169, Loss: 14.831395149230957\n",
      "Epoch: 170, Loss: 14.4326171875\n",
      "Epoch: 171, Loss: 15.812004089355469\n",
      "Epoch: 172, Loss: 13.863166809082031\n",
      "Epoch: 173, Loss: 13.69827938079834\n",
      "Epoch: 174, Loss: 18.01369857788086\n",
      "Epoch: 175, Loss: 13.396584510803223\n",
      "Epoch: 176, Loss: 17.39791488647461\n",
      "Epoch: 177, Loss: 11.006479263305664\n",
      "Epoch: 178, Loss: 10.563424110412598\n",
      "Epoch: 179, Loss: 16.114765167236328\n",
      "Epoch: 180, Loss: 11.610679626464844\n",
      "Epoch: 181, Loss: 16.68106460571289\n",
      "Epoch: 182, Loss: 15.651559829711914\n",
      "Epoch: 183, Loss: 25.415029525756836\n",
      "Epoch: 184, Loss: 15.007635116577148\n",
      "Epoch: 185, Loss: 18.004837036132812\n",
      "Epoch: 186, Loss: 22.737548828125\n",
      "Epoch: 187, Loss: 15.332040786743164\n",
      "Epoch: 188, Loss: 19.434240341186523\n",
      "Epoch: 189, Loss: 22.47487449645996\n",
      "Epoch: 190, Loss: 19.615957260131836\n",
      "Epoch: 191, Loss: 12.843873023986816\n",
      "Epoch: 192, Loss: 21.471464157104492\n",
      "Epoch: 193, Loss: 30.274564743041992\n",
      "Epoch: 194, Loss: 15.166332244873047\n",
      "Epoch: 195, Loss: 14.118269920349121\n",
      "Epoch: 196, Loss: 11.008910179138184\n",
      "Epoch: 197, Loss: 14.20977783203125\n",
      "Epoch: 198, Loss: 12.782078742980957\n",
      "Epoch: 199, Loss: 18.98006820678711\n",
      "Epoch: 200, Loss: 16.751340866088867\n",
      "Epoch: 201, Loss: 12.667923927307129\n",
      "Epoch: 202, Loss: 19.176944732666016\n",
      "Epoch: 203, Loss: 10.305732727050781\n",
      "Epoch: 204, Loss: 19.834444046020508\n",
      "Epoch: 205, Loss: 9.91893482208252\n",
      "Epoch: 206, Loss: 13.569208145141602\n",
      "Epoch: 207, Loss: 17.26184844970703\n",
      "Epoch: 208, Loss: 14.263862609863281\n",
      "Epoch: 209, Loss: 17.665071487426758\n",
      "Epoch: 210, Loss: 17.125213623046875\n",
      "Epoch: 211, Loss: 19.049846649169922\n",
      "Epoch: 212, Loss: 19.54774284362793\n",
      "Epoch: 213, Loss: 20.651227951049805\n",
      "Epoch: 214, Loss: 16.817768096923828\n",
      "Epoch: 215, Loss: 11.3433256149292\n",
      "Epoch: 216, Loss: 17.49917984008789\n",
      "Epoch: 217, Loss: 15.4630126953125\n",
      "Epoch: 218, Loss: 16.896371841430664\n",
      "Epoch: 219, Loss: 15.642337799072266\n",
      "Epoch: 220, Loss: 14.964800834655762\n",
      "Epoch: 221, Loss: 18.205394744873047\n",
      "Epoch: 222, Loss: 14.781222343444824\n",
      "Epoch: 223, Loss: 16.181255340576172\n",
      "Epoch: 224, Loss: 15.365705490112305\n",
      "Epoch: 225, Loss: 13.251282691955566\n",
      "Epoch: 226, Loss: 20.272418975830078\n",
      "Epoch: 227, Loss: 13.373922348022461\n",
      "Epoch: 228, Loss: 21.300201416015625\n",
      "Epoch: 229, Loss: 10.705814361572266\n",
      "Epoch: 230, Loss: 22.270204544067383\n",
      "Epoch: 231, Loss: 12.343416213989258\n",
      "Epoch: 232, Loss: 39.23538589477539\n",
      "Epoch: 233, Loss: 10.894095420837402\n",
      "Epoch: 234, Loss: 21.56145477294922\n",
      "Epoch: 235, Loss: 17.143848419189453\n",
      "Epoch: 236, Loss: 20.673376083374023\n",
      "Epoch: 237, Loss: 31.634897232055664\n",
      "Epoch: 238, Loss: 15.970817565917969\n",
      "Epoch: 239, Loss: 33.26725769042969\n",
      "Epoch: 240, Loss: 31.82479476928711\n",
      "Epoch: 241, Loss: 10.352770805358887\n",
      "Epoch: 242, Loss: 16.713226318359375\n",
      "Epoch: 243, Loss: 12.841947555541992\n",
      "Epoch: 244, Loss: 13.620292663574219\n",
      "Epoch: 245, Loss: 17.78411865234375\n",
      "Epoch: 246, Loss: 14.927668571472168\n",
      "Epoch: 247, Loss: 12.069731712341309\n",
      "Epoch: 248, Loss: 14.700859069824219\n",
      "Epoch: 249, Loss: 15.063112258911133\n",
      "Epoch: 250, Loss: 12.791326522827148\n",
      "Epoch: 251, Loss: 39.519954681396484\n",
      "Epoch: 252, Loss: 9.193947792053223\n",
      "Epoch: 253, Loss: 16.37709617614746\n",
      "Epoch: 254, Loss: 12.02314281463623\n",
      "Epoch: 255, Loss: 28.0079345703125\n",
      "Epoch: 256, Loss: 28.07179832458496\n",
      "Epoch: 257, Loss: 14.604660034179688\n",
      "Epoch: 258, Loss: 11.681461334228516\n",
      "Epoch: 259, Loss: 9.024288177490234\n",
      "Epoch: 260, Loss: 16.125232696533203\n",
      "Epoch: 261, Loss: 17.091835021972656\n",
      "Epoch: 262, Loss: 16.09428596496582\n",
      "Epoch: 263, Loss: 17.879953384399414\n",
      "Epoch: 264, Loss: 16.799711227416992\n",
      "Epoch: 265, Loss: 28.877168655395508\n",
      "Epoch: 266, Loss: 15.791848182678223\n",
      "Epoch: 267, Loss: 11.7260160446167\n",
      "Epoch: 268, Loss: 14.226232528686523\n",
      "Epoch: 269, Loss: 19.315914154052734\n",
      "Epoch: 270, Loss: 32.397769927978516\n",
      "Epoch: 271, Loss: 13.040718078613281\n",
      "Epoch: 272, Loss: 10.93143367767334\n",
      "Epoch: 273, Loss: 14.548861503601074\n",
      "Epoch: 274, Loss: 9.806571006774902\n",
      "Epoch: 275, Loss: 11.835701942443848\n",
      "Epoch: 276, Loss: 16.998586654663086\n",
      "Epoch: 277, Loss: 16.31186294555664\n",
      "Epoch: 278, Loss: 15.347850799560547\n",
      "Epoch: 279, Loss: 11.865486145019531\n",
      "Epoch: 280, Loss: 17.555204391479492\n",
      "Epoch: 281, Loss: 29.276622772216797\n",
      "Epoch: 282, Loss: 10.954150199890137\n",
      "Epoch: 283, Loss: 20.547197341918945\n",
      "Epoch: 284, Loss: 16.162221908569336\n",
      "Epoch: 285, Loss: 10.370429992675781\n",
      "Epoch: 286, Loss: 18.988595962524414\n",
      "Epoch: 287, Loss: 14.215534210205078\n",
      "Epoch: 288, Loss: 24.769529342651367\n",
      "Epoch: 289, Loss: 11.22567367553711\n",
      "Epoch: 290, Loss: 14.520547866821289\n",
      "Epoch: 291, Loss: 15.48523998260498\n",
      "Epoch: 292, Loss: 15.606658935546875\n",
      "Epoch: 293, Loss: 11.974220275878906\n",
      "Epoch: 294, Loss: 18.447799682617188\n",
      "Epoch: 295, Loss: 18.27562141418457\n",
      "Epoch: 296, Loss: 10.686354637145996\n",
      "Epoch: 297, Loss: 16.012935638427734\n",
      "Epoch: 298, Loss: 17.274072647094727\n",
      "Epoch: 299, Loss: 11.216174125671387\n",
      "Epoch: 300, Loss: 15.071911811828613\n",
      "Epoch: 301, Loss: 10.320033073425293\n",
      "Epoch: 302, Loss: 27.470558166503906\n",
      "Epoch: 303, Loss: 11.555680274963379\n",
      "Epoch: 304, Loss: 14.858976364135742\n",
      "Epoch: 305, Loss: 10.20361614227295\n",
      "Epoch: 306, Loss: 10.621155738830566\n",
      "Epoch: 307, Loss: 16.266319274902344\n",
      "Epoch: 308, Loss: 17.56737518310547\n",
      "Epoch: 309, Loss: 13.184700012207031\n",
      "Epoch: 310, Loss: 19.972000122070312\n",
      "Epoch: 311, Loss: 10.404142379760742\n",
      "Epoch: 312, Loss: 12.697632789611816\n",
      "Epoch: 313, Loss: 11.561476707458496\n",
      "Epoch: 314, Loss: 11.42797565460205\n",
      "Epoch: 315, Loss: 23.089942932128906\n",
      "Epoch: 316, Loss: 14.153008460998535\n",
      "Epoch: 317, Loss: 16.225234985351562\n",
      "Epoch: 318, Loss: 10.320185661315918\n",
      "Epoch: 319, Loss: 8.902891159057617\n",
      "Epoch: 320, Loss: 10.91970443725586\n",
      "Epoch: 321, Loss: 12.05379867553711\n",
      "Epoch: 322, Loss: 19.563133239746094\n",
      "Epoch: 323, Loss: 16.549894332885742\n",
      "Epoch: 324, Loss: 16.620744705200195\n",
      "Epoch: 325, Loss: 16.275676727294922\n",
      "Epoch: 326, Loss: 11.65828800201416\n",
      "Epoch: 327, Loss: 14.461044311523438\n",
      "Epoch: 328, Loss: 20.158966064453125\n",
      "Epoch: 329, Loss: 12.806083679199219\n",
      "Epoch: 330, Loss: 20.119674682617188\n",
      "Epoch: 331, Loss: 14.33869743347168\n",
      "Epoch: 332, Loss: 19.013282775878906\n",
      "Epoch: 333, Loss: 18.016571044921875\n",
      "Epoch: 334, Loss: 13.656078338623047\n",
      "Epoch: 335, Loss: 17.61988067626953\n",
      "Epoch: 336, Loss: 12.206815719604492\n",
      "Epoch: 337, Loss: 17.250568389892578\n",
      "Epoch: 338, Loss: 35.321929931640625\n",
      "Epoch: 339, Loss: 13.369573593139648\n",
      "Epoch: 340, Loss: 14.655607223510742\n",
      "Epoch: 341, Loss: 14.214369773864746\n",
      "Epoch: 342, Loss: 21.48713493347168\n",
      "Epoch: 343, Loss: 15.520652770996094\n",
      "Epoch: 344, Loss: 14.517562866210938\n",
      "Epoch: 345, Loss: 14.04007625579834\n",
      "Epoch: 346, Loss: 20.539304733276367\n",
      "Epoch: 347, Loss: 11.78679370880127\n",
      "Epoch: 348, Loss: 15.32382869720459\n",
      "Epoch: 349, Loss: 14.140656471252441\n",
      "Epoch: 350, Loss: 18.314870834350586\n",
      "Epoch: 351, Loss: 23.504674911499023\n",
      "Epoch: 352, Loss: 13.003552436828613\n",
      "Epoch: 353, Loss: 11.642511367797852\n",
      "Epoch: 354, Loss: 15.719463348388672\n",
      "Epoch: 355, Loss: 15.78700065612793\n",
      "Epoch: 356, Loss: 18.647624969482422\n",
      "Epoch: 357, Loss: 11.701086044311523\n",
      "Epoch: 358, Loss: 11.24850082397461\n",
      "Epoch: 359, Loss: 16.67373275756836\n",
      "Epoch: 360, Loss: 15.514740943908691\n",
      "Epoch: 361, Loss: 20.369081497192383\n",
      "Epoch: 362, Loss: 10.939446449279785\n",
      "Epoch: 363, Loss: 11.88161849975586\n",
      "Epoch: 364, Loss: 19.184417724609375\n",
      "Epoch: 365, Loss: 13.469649314880371\n",
      "Epoch: 366, Loss: 16.184738159179688\n",
      "Epoch: 367, Loss: 12.290230751037598\n",
      "Epoch: 368, Loss: 16.587444305419922\n",
      "Epoch: 369, Loss: 15.022342681884766\n",
      "Epoch: 370, Loss: 14.017537117004395\n",
      "Epoch: 371, Loss: 10.576760292053223\n",
      "Epoch: 372, Loss: 14.144918441772461\n",
      "Epoch: 373, Loss: 11.816004753112793\n",
      "Epoch: 374, Loss: 10.770719528198242\n",
      "Epoch: 375, Loss: 16.94003677368164\n",
      "Epoch: 376, Loss: 19.3378963470459\n",
      "Epoch: 377, Loss: 18.063823699951172\n",
      "Epoch: 378, Loss: 12.717188835144043\n",
      "Epoch: 379, Loss: 17.60916519165039\n",
      "Epoch: 380, Loss: 14.138583183288574\n",
      "Epoch: 381, Loss: 16.76235008239746\n",
      "Epoch: 382, Loss: 14.97950553894043\n",
      "Epoch: 383, Loss: 11.554167747497559\n",
      "Epoch: 384, Loss: 13.840582847595215\n",
      "Epoch: 385, Loss: 15.159439086914062\n",
      "Epoch: 386, Loss: 19.61102294921875\n",
      "Epoch: 387, Loss: 16.784286499023438\n",
      "Epoch: 388, Loss: 33.20366668701172\n",
      "Epoch: 389, Loss: 13.497833251953125\n",
      "Epoch: 390, Loss: 13.172401428222656\n",
      "Epoch: 391, Loss: 15.020109176635742\n",
      "Epoch: 392, Loss: 11.584772109985352\n",
      "Epoch: 393, Loss: 16.705177307128906\n",
      "Epoch: 394, Loss: 9.55706787109375\n",
      "Epoch: 395, Loss: 15.063291549682617\n",
      "Epoch: 396, Loss: 12.61916446685791\n",
      "Epoch: 397, Loss: 18.535505294799805\n",
      "Epoch: 398, Loss: 28.962522506713867\n",
      "Epoch: 399, Loss: 17.937923431396484\n",
      "Epoch: 400, Loss: 12.555732727050781\n",
      "Epoch: 401, Loss: 17.14948081970215\n",
      "Epoch: 402, Loss: 23.77968406677246\n",
      "Epoch: 403, Loss: 36.79997253417969\n",
      "Epoch: 404, Loss: 11.747804641723633\n",
      "Epoch: 405, Loss: 17.814170837402344\n",
      "Epoch: 406, Loss: 18.079790115356445\n",
      "Epoch: 407, Loss: 18.994356155395508\n",
      "Epoch: 408, Loss: 15.72671127319336\n",
      "Epoch: 409, Loss: 8.496501922607422\n",
      "Epoch: 410, Loss: 12.089704513549805\n",
      "Epoch: 411, Loss: 25.558897018432617\n",
      "Epoch: 412, Loss: 10.943098068237305\n",
      "Epoch: 413, Loss: 23.980581283569336\n",
      "Epoch: 414, Loss: 13.34890365600586\n",
      "Epoch: 415, Loss: 15.651021003723145\n",
      "Epoch: 416, Loss: 13.101112365722656\n",
      "Epoch: 417, Loss: 16.625341415405273\n",
      "Epoch: 418, Loss: 12.105487823486328\n",
      "Epoch: 419, Loss: 40.295379638671875\n",
      "Epoch: 420, Loss: 13.755624771118164\n",
      "Epoch: 421, Loss: 16.8361873626709\n",
      "Epoch: 422, Loss: 12.578086853027344\n",
      "Epoch: 423, Loss: 20.468050003051758\n",
      "Epoch: 424, Loss: 15.333964347839355\n",
      "Epoch: 425, Loss: 14.884254455566406\n",
      "Epoch: 426, Loss: 16.497329711914062\n",
      "Epoch: 427, Loss: 15.51351547241211\n",
      "Epoch: 428, Loss: 15.118866920471191\n",
      "Epoch: 429, Loss: 12.647567749023438\n",
      "Epoch: 430, Loss: 13.125041961669922\n",
      "Epoch: 431, Loss: 14.045976638793945\n",
      "Epoch: 432, Loss: 13.206916809082031\n",
      "Epoch: 433, Loss: 20.286142349243164\n",
      "Epoch: 434, Loss: 17.874250411987305\n",
      "Epoch: 435, Loss: 13.143104553222656\n",
      "Epoch: 436, Loss: 12.396376609802246\n",
      "Epoch: 437, Loss: 11.48359203338623\n",
      "Epoch: 438, Loss: 29.874000549316406\n",
      "Epoch: 439, Loss: 17.286518096923828\n",
      "Epoch: 440, Loss: 31.529315948486328\n",
      "Epoch: 441, Loss: 13.51378345489502\n",
      "Epoch: 442, Loss: 19.576509475708008\n",
      "Epoch: 443, Loss: 37.812923431396484\n",
      "Epoch: 444, Loss: 20.121742248535156\n",
      "Epoch: 445, Loss: 11.214692115783691\n",
      "Epoch: 446, Loss: 17.66609764099121\n",
      "Epoch: 447, Loss: 15.20459270477295\n",
      "Epoch: 448, Loss: 12.98603343963623\n",
      "Epoch: 449, Loss: 12.261959075927734\n",
      "Epoch: 450, Loss: 16.01464080810547\n",
      "Epoch: 451, Loss: 15.844281196594238\n",
      "Epoch: 452, Loss: 13.255507469177246\n",
      "Epoch: 453, Loss: 25.293834686279297\n",
      "Epoch: 454, Loss: 18.96089744567871\n",
      "Epoch: 455, Loss: 10.867524147033691\n",
      "Epoch: 456, Loss: 15.307497024536133\n",
      "Epoch: 457, Loss: 10.290533065795898\n",
      "Epoch: 458, Loss: 18.936540603637695\n",
      "Epoch: 459, Loss: 31.635812759399414\n",
      "Epoch: 460, Loss: 22.063247680664062\n",
      "Epoch: 461, Loss: 15.170740127563477\n",
      "Epoch: 462, Loss: 14.257258415222168\n",
      "Epoch: 463, Loss: 17.331501007080078\n",
      "Epoch: 464, Loss: 22.696067810058594\n",
      "Epoch: 465, Loss: 19.12618637084961\n",
      "Epoch: 466, Loss: 13.913787841796875\n",
      "Epoch: 467, Loss: 10.146754264831543\n",
      "Epoch: 468, Loss: 17.318021774291992\n",
      "Epoch: 469, Loss: 13.258182525634766\n",
      "Epoch: 470, Loss: 11.878904342651367\n",
      "Epoch: 471, Loss: 10.022642135620117\n",
      "Epoch: 472, Loss: 17.101823806762695\n",
      "Epoch: 473, Loss: 17.070409774780273\n",
      "Epoch: 474, Loss: 25.04615020751953\n",
      "Epoch: 475, Loss: 21.6859073638916\n",
      "Epoch: 476, Loss: 13.293879508972168\n",
      "Epoch: 477, Loss: 14.707734107971191\n",
      "Epoch: 478, Loss: 13.408035278320312\n",
      "Epoch: 479, Loss: 14.00946044921875\n",
      "Epoch: 480, Loss: 14.666064262390137\n",
      "Epoch: 481, Loss: 17.83180809020996\n",
      "Epoch: 482, Loss: 11.917375564575195\n",
      "Epoch: 483, Loss: 12.273834228515625\n",
      "Epoch: 484, Loss: 15.031990051269531\n",
      "Epoch: 485, Loss: 14.140822410583496\n",
      "Epoch: 486, Loss: 16.51270866394043\n",
      "Epoch: 487, Loss: 17.587766647338867\n",
      "Epoch: 488, Loss: 15.262643814086914\n",
      "Epoch: 489, Loss: 18.193004608154297\n",
      "Epoch: 490, Loss: 20.301624298095703\n",
      "Epoch: 491, Loss: 15.019777297973633\n",
      "Epoch: 492, Loss: 18.82089614868164\n",
      "Epoch: 493, Loss: 14.055296897888184\n",
      "Epoch: 494, Loss: 17.46321678161621\n",
      "Epoch: 495, Loss: 13.97408676147461\n",
      "Epoch: 496, Loss: 12.464139938354492\n",
      "Epoch: 497, Loss: 23.717182159423828\n",
      "Epoch: 498, Loss: 20.615800857543945\n",
      "Epoch: 499, Loss: 20.05743408203125\n",
      "Epoch: 500, Loss: 18.74964141845703\n",
      "Epoch: 501, Loss: 11.322386741638184\n",
      "Epoch: 502, Loss: 19.62870979309082\n",
      "Epoch: 503, Loss: 14.356938362121582\n",
      "Epoch: 504, Loss: 12.880629539489746\n",
      "Epoch: 505, Loss: 22.39455795288086\n",
      "Epoch: 506, Loss: 14.048723220825195\n",
      "Epoch: 507, Loss: 21.491870880126953\n",
      "Epoch: 508, Loss: 9.847946166992188\n",
      "Epoch: 509, Loss: 17.899904251098633\n",
      "Epoch: 510, Loss: 16.299551010131836\n",
      "Epoch: 511, Loss: 21.893407821655273\n",
      "Epoch: 512, Loss: 13.327781677246094\n",
      "Epoch: 513, Loss: 11.255285263061523\n",
      "Epoch: 514, Loss: 12.916605949401855\n",
      "Epoch: 515, Loss: 13.360819816589355\n",
      "Epoch: 516, Loss: 18.688852310180664\n",
      "Epoch: 517, Loss: 14.374800682067871\n",
      "Epoch: 518, Loss: 11.82027816772461\n",
      "Epoch: 519, Loss: 19.43634033203125\n",
      "Epoch: 520, Loss: 17.427677154541016\n",
      "Epoch: 521, Loss: 12.485830307006836\n",
      "Epoch: 522, Loss: 17.30683135986328\n",
      "Epoch: 523, Loss: 20.20969581604004\n",
      "Epoch: 524, Loss: 17.011625289916992\n",
      "Epoch: 525, Loss: 14.89885425567627\n",
      "Epoch: 526, Loss: 17.720849990844727\n",
      "Epoch: 527, Loss: 12.442968368530273\n",
      "Epoch: 528, Loss: 12.447871208190918\n",
      "Epoch: 529, Loss: 14.038812637329102\n",
      "Epoch: 530, Loss: 12.486485481262207\n",
      "Epoch: 531, Loss: 20.125614166259766\n",
      "Epoch: 532, Loss: 16.982892990112305\n",
      "Epoch: 533, Loss: 13.475695610046387\n",
      "Epoch: 534, Loss: 13.654614448547363\n",
      "Epoch: 535, Loss: 10.542339324951172\n",
      "Epoch: 536, Loss: 10.378068923950195\n",
      "Epoch: 537, Loss: 13.316547393798828\n",
      "Epoch: 538, Loss: 15.084441184997559\n",
      "Epoch: 539, Loss: 11.64720630645752\n",
      "Epoch: 540, Loss: 10.729448318481445\n",
      "Epoch: 541, Loss: 17.963586807250977\n",
      "Epoch: 542, Loss: 15.986898422241211\n",
      "Epoch: 543, Loss: 19.902315139770508\n",
      "Epoch: 544, Loss: 11.319252967834473\n",
      "Epoch: 545, Loss: 37.39213943481445\n",
      "Epoch: 546, Loss: 15.767778396606445\n",
      "Epoch: 547, Loss: 22.08525848388672\n",
      "Epoch: 548, Loss: 16.60858154296875\n",
      "Epoch: 549, Loss: 11.458479881286621\n",
      "Epoch: 550, Loss: 18.020973205566406\n",
      "Epoch: 551, Loss: 21.444988250732422\n",
      "Epoch: 552, Loss: 12.053232192993164\n",
      "Epoch: 553, Loss: 40.129356384277344\n",
      "Epoch: 554, Loss: 14.28062915802002\n",
      "Epoch: 555, Loss: 13.229476928710938\n",
      "Epoch: 556, Loss: 14.655441284179688\n",
      "Epoch: 557, Loss: 14.160116195678711\n",
      "Epoch: 558, Loss: 17.377765655517578\n",
      "Epoch: 559, Loss: 13.463440895080566\n",
      "Epoch: 560, Loss: 15.101900100708008\n",
      "Epoch: 561, Loss: 14.282384872436523\n",
      "Epoch: 562, Loss: 21.251964569091797\n",
      "Epoch: 563, Loss: 9.876642227172852\n",
      "Epoch: 564, Loss: 19.682693481445312\n",
      "Epoch: 565, Loss: 20.452159881591797\n",
      "Epoch: 566, Loss: 14.323822975158691\n",
      "Epoch: 567, Loss: 12.835457801818848\n",
      "Epoch: 568, Loss: 13.439981460571289\n",
      "Epoch: 569, Loss: 19.671215057373047\n",
      "Epoch: 570, Loss: 12.422700881958008\n",
      "Epoch: 571, Loss: 13.156830787658691\n",
      "Epoch: 572, Loss: 12.95206356048584\n",
      "Epoch: 573, Loss: 19.957448959350586\n",
      "Epoch: 574, Loss: 12.628345489501953\n",
      "Epoch: 575, Loss: 35.42466735839844\n",
      "Epoch: 576, Loss: 15.410477638244629\n",
      "Epoch: 577, Loss: 14.039323806762695\n",
      "Epoch: 578, Loss: 12.37357234954834\n",
      "Epoch: 579, Loss: 14.002211570739746\n",
      "Epoch: 580, Loss: 10.800565719604492\n",
      "Epoch: 581, Loss: 15.546415328979492\n",
      "Epoch: 582, Loss: 17.22748374938965\n",
      "Epoch: 583, Loss: 12.456912994384766\n",
      "Epoch: 584, Loss: 15.426262855529785\n",
      "Epoch: 585, Loss: 14.334003448486328\n",
      "Epoch: 586, Loss: 36.470794677734375\n",
      "Epoch: 587, Loss: 13.644818305969238\n",
      "Epoch: 588, Loss: 13.287100791931152\n",
      "Epoch: 589, Loss: 15.418598175048828\n",
      "Epoch: 590, Loss: 13.535120010375977\n",
      "Epoch: 591, Loss: 12.714129447937012\n",
      "Epoch: 592, Loss: 12.532849311828613\n",
      "Epoch: 593, Loss: 15.499425888061523\n",
      "Epoch: 594, Loss: 14.551366806030273\n",
      "Epoch: 595, Loss: 18.97414779663086\n",
      "Epoch: 596, Loss: 14.232419967651367\n",
      "Epoch: 597, Loss: 18.025203704833984\n",
      "Epoch: 598, Loss: 11.893754005432129\n",
      "Epoch: 599, Loss: 19.65985107421875\n",
      "Epoch: 600, Loss: 12.386396408081055\n",
      "Epoch: 601, Loss: 33.386634826660156\n",
      "Epoch: 602, Loss: 12.818373680114746\n",
      "Epoch: 603, Loss: 18.64628028869629\n",
      "Epoch: 604, Loss: 11.886272430419922\n",
      "Epoch: 605, Loss: 11.452493667602539\n",
      "Epoch: 606, Loss: 21.949190139770508\n",
      "Epoch: 607, Loss: 13.565323829650879\n",
      "Epoch: 608, Loss: 17.07122230529785\n",
      "Epoch: 609, Loss: 11.415053367614746\n",
      "Epoch: 610, Loss: 14.668416976928711\n",
      "Epoch: 611, Loss: 20.17341423034668\n",
      "Epoch: 612, Loss: 11.422378540039062\n",
      "Epoch: 613, Loss: 10.89067268371582\n",
      "Epoch: 614, Loss: 13.442456245422363\n",
      "Epoch: 615, Loss: 14.519532203674316\n",
      "Epoch: 616, Loss: 17.977611541748047\n",
      "Epoch: 617, Loss: 15.701630592346191\n",
      "Epoch: 618, Loss: 15.45913028717041\n",
      "Epoch: 619, Loss: 11.148229598999023\n",
      "Epoch: 620, Loss: 13.794198036193848\n",
      "Epoch: 621, Loss: 12.360107421875\n",
      "Epoch: 622, Loss: 10.466329574584961\n",
      "Epoch: 623, Loss: 12.165544509887695\n",
      "Epoch: 624, Loss: 20.602476119995117\n",
      "Epoch: 625, Loss: 24.374069213867188\n",
      "Epoch: 626, Loss: 16.620826721191406\n",
      "Epoch: 627, Loss: 11.047199249267578\n",
      "Epoch: 628, Loss: 16.154367446899414\n",
      "Epoch: 629, Loss: 12.109092712402344\n",
      "Epoch: 630, Loss: 17.308687210083008\n",
      "Epoch: 631, Loss: 12.070308685302734\n",
      "Epoch: 632, Loss: 17.96817970275879\n",
      "Epoch: 633, Loss: 14.027000427246094\n",
      "Epoch: 634, Loss: 18.970232009887695\n",
      "Epoch: 635, Loss: 14.858823776245117\n",
      "Epoch: 636, Loss: 13.195030212402344\n",
      "Epoch: 637, Loss: 11.081707954406738\n",
      "Epoch: 638, Loss: 15.338532447814941\n",
      "Epoch: 639, Loss: 12.647875785827637\n",
      "Epoch: 640, Loss: 12.651424407958984\n",
      "Epoch: 641, Loss: 21.13791275024414\n",
      "Epoch: 642, Loss: 11.144142150878906\n",
      "Epoch: 643, Loss: 15.92211627960205\n",
      "Epoch: 644, Loss: 14.552709579467773\n",
      "Epoch: 645, Loss: 16.20467758178711\n",
      "Epoch: 646, Loss: 11.96541976928711\n",
      "Epoch: 647, Loss: 15.402015686035156\n",
      "Epoch: 648, Loss: 20.98288345336914\n",
      "Epoch: 649, Loss: 14.557272911071777\n",
      "Epoch: 650, Loss: 8.323707580566406\n",
      "Epoch: 651, Loss: 27.73712158203125\n",
      "Epoch: 652, Loss: 16.74735450744629\n",
      "Epoch: 653, Loss: 16.17729377746582\n",
      "Epoch: 654, Loss: 13.488716125488281\n",
      "Epoch: 655, Loss: 13.730224609375\n",
      "Epoch: 656, Loss: 14.341821670532227\n",
      "Epoch: 657, Loss: 11.161359786987305\n",
      "Epoch: 658, Loss: 14.719082832336426\n",
      "Epoch: 659, Loss: 12.531220436096191\n",
      "Epoch: 660, Loss: 12.696297645568848\n",
      "Epoch: 661, Loss: 15.416593551635742\n",
      "Epoch: 662, Loss: 12.664563179016113\n",
      "Epoch: 663, Loss: 11.624975204467773\n",
      "Epoch: 664, Loss: 10.695162773132324\n",
      "Epoch: 665, Loss: 10.137382507324219\n",
      "Epoch: 666, Loss: 16.444068908691406\n",
      "Epoch: 667, Loss: 10.900272369384766\n",
      "Epoch: 668, Loss: 13.240799903869629\n",
      "Epoch: 669, Loss: 16.393823623657227\n",
      "Epoch: 670, Loss: 14.660293579101562\n",
      "Epoch: 671, Loss: 13.376025199890137\n",
      "Epoch: 672, Loss: 14.7330961227417\n",
      "Epoch: 673, Loss: 16.19980812072754\n",
      "Epoch: 674, Loss: 32.60856246948242\n",
      "Epoch: 675, Loss: 13.787542343139648\n",
      "Epoch: 676, Loss: 14.095864295959473\n",
      "Epoch: 677, Loss: 18.077857971191406\n",
      "Epoch: 678, Loss: 9.667621612548828\n",
      "Epoch: 679, Loss: 12.09631061553955\n",
      "Epoch: 680, Loss: 9.882796287536621\n",
      "Epoch: 681, Loss: 16.88330078125\n",
      "Epoch: 682, Loss: 13.501592636108398\n",
      "Epoch: 683, Loss: 14.232110023498535\n",
      "Epoch: 684, Loss: 12.488054275512695\n",
      "Epoch: 685, Loss: 15.01241683959961\n",
      "Epoch: 686, Loss: 13.071572303771973\n",
      "Epoch: 687, Loss: 13.514533042907715\n",
      "Epoch: 688, Loss: 17.26091766357422\n",
      "Epoch: 689, Loss: 12.599592208862305\n",
      "Epoch: 690, Loss: 22.432727813720703\n",
      "Epoch: 691, Loss: 12.069037437438965\n",
      "Epoch: 692, Loss: 17.653976440429688\n",
      "Epoch: 693, Loss: 18.30634880065918\n",
      "Epoch: 694, Loss: 19.850786209106445\n",
      "Epoch: 695, Loss: 15.00914478302002\n",
      "Epoch: 696, Loss: 15.562070846557617\n",
      "Epoch: 697, Loss: 15.071588516235352\n",
      "Epoch: 698, Loss: 19.149147033691406\n",
      "Epoch: 699, Loss: 22.44524383544922\n",
      "Epoch: 700, Loss: 12.537936210632324\n",
      "Epoch: 701, Loss: 9.186962127685547\n",
      "Epoch: 702, Loss: 11.468830108642578\n",
      "Epoch: 703, Loss: 17.275165557861328\n",
      "Epoch: 704, Loss: 15.586755752563477\n",
      "Epoch: 705, Loss: 24.692119598388672\n",
      "Epoch: 706, Loss: 13.464836120605469\n",
      "Epoch: 707, Loss: 14.922419548034668\n",
      "Epoch: 708, Loss: 10.825115203857422\n",
      "Epoch: 709, Loss: 14.433181762695312\n",
      "Epoch: 710, Loss: 11.820343017578125\n",
      "Epoch: 711, Loss: 21.35055923461914\n",
      "Epoch: 712, Loss: 15.411699295043945\n",
      "Epoch: 713, Loss: 17.94813346862793\n",
      "Epoch: 714, Loss: 12.173422813415527\n",
      "Epoch: 715, Loss: 17.03008460998535\n",
      "Epoch: 716, Loss: 25.926950454711914\n",
      "Epoch: 717, Loss: 13.426180839538574\n",
      "Epoch: 718, Loss: 32.82698440551758\n",
      "Epoch: 719, Loss: 11.340885162353516\n",
      "Epoch: 720, Loss: 11.422048568725586\n",
      "Epoch: 721, Loss: 13.26254940032959\n",
      "Epoch: 722, Loss: 14.77438735961914\n",
      "Epoch: 723, Loss: 16.967443466186523\n",
      "Epoch: 724, Loss: 19.039695739746094\n",
      "Epoch: 725, Loss: 18.974777221679688\n",
      "Epoch: 726, Loss: 12.605936050415039\n",
      "Epoch: 727, Loss: 10.576659202575684\n",
      "Epoch: 728, Loss: 18.760610580444336\n",
      "Epoch: 729, Loss: 17.368839263916016\n",
      "Epoch: 730, Loss: 21.55544090270996\n",
      "Epoch: 731, Loss: 12.260326385498047\n",
      "Epoch: 732, Loss: 13.237054824829102\n",
      "Epoch: 733, Loss: 11.233038902282715\n",
      "Epoch: 734, Loss: 9.792256355285645\n",
      "Epoch: 735, Loss: 16.82322883605957\n",
      "Epoch: 736, Loss: 14.211355209350586\n",
      "Epoch: 737, Loss: 14.190071105957031\n",
      "Epoch: 738, Loss: 18.372028350830078\n",
      "Epoch: 739, Loss: 12.914158821105957\n",
      "Epoch: 740, Loss: 13.1893949508667\n",
      "Epoch: 741, Loss: 17.151609420776367\n",
      "Epoch: 742, Loss: 14.055630683898926\n",
      "Epoch: 743, Loss: 13.256002426147461\n",
      "Epoch: 744, Loss: 12.182563781738281\n",
      "Epoch: 745, Loss: 21.392587661743164\n",
      "Epoch: 746, Loss: 13.644970893859863\n",
      "Epoch: 747, Loss: 17.108196258544922\n",
      "Epoch: 748, Loss: 15.012471199035645\n",
      "Epoch: 749, Loss: 14.77653980255127\n",
      "Epoch: 750, Loss: 10.81633186340332\n",
      "Epoch: 751, Loss: 15.223231315612793\n",
      "Epoch: 752, Loss: 13.645526885986328\n",
      "Epoch: 753, Loss: 10.384761810302734\n",
      "Epoch: 754, Loss: 14.798474311828613\n",
      "Epoch: 755, Loss: 14.905055046081543\n",
      "Epoch: 756, Loss: 15.188355445861816\n",
      "Epoch: 757, Loss: 15.023348808288574\n",
      "Epoch: 758, Loss: 20.090740203857422\n",
      "Epoch: 759, Loss: 16.138080596923828\n",
      "Epoch: 760, Loss: 26.368865966796875\n",
      "Epoch: 761, Loss: 9.8715238571167\n",
      "Epoch: 762, Loss: 36.035579681396484\n",
      "Epoch: 763, Loss: 13.040369987487793\n",
      "Epoch: 764, Loss: 11.671414375305176\n",
      "Epoch: 765, Loss: 17.35478401184082\n",
      "Epoch: 766, Loss: 10.606451988220215\n",
      "Epoch: 767, Loss: 13.117345809936523\n",
      "Epoch: 768, Loss: 22.917964935302734\n",
      "Epoch: 769, Loss: 12.278260231018066\n",
      "Epoch: 770, Loss: 16.76119613647461\n",
      "Epoch: 771, Loss: 14.393980026245117\n",
      "Epoch: 772, Loss: 15.252007484436035\n",
      "Epoch: 773, Loss: 20.49750328063965\n",
      "Epoch: 774, Loss: 10.739791870117188\n",
      "Epoch: 775, Loss: 12.74029541015625\n",
      "Epoch: 776, Loss: 19.975568771362305\n",
      "Epoch: 777, Loss: 41.374549865722656\n",
      "Epoch: 778, Loss: 10.972546577453613\n",
      "Epoch: 779, Loss: 16.6086368560791\n",
      "Epoch: 780, Loss: 15.368749618530273\n",
      "Epoch: 781, Loss: 14.76220417022705\n",
      "Epoch: 782, Loss: 13.975318908691406\n",
      "Epoch: 783, Loss: 12.507986068725586\n",
      "Epoch: 784, Loss: 12.115830421447754\n",
      "Epoch: 785, Loss: 13.761813163757324\n",
      "Epoch: 786, Loss: 22.448381423950195\n",
      "Epoch: 787, Loss: 17.70953941345215\n",
      "Epoch: 788, Loss: 19.03947639465332\n",
      "Epoch: 789, Loss: 17.80986785888672\n",
      "Epoch: 790, Loss: 16.409250259399414\n",
      "Epoch: 791, Loss: 15.038497924804688\n",
      "Epoch: 792, Loss: 16.694568634033203\n",
      "Epoch: 793, Loss: 17.703027725219727\n",
      "Epoch: 794, Loss: 14.182019233703613\n",
      "Epoch: 795, Loss: 12.544466972351074\n",
      "Epoch: 796, Loss: 12.691818237304688\n",
      "Epoch: 797, Loss: 12.024969100952148\n",
      "Epoch: 798, Loss: 10.407447814941406\n",
      "Epoch: 799, Loss: 18.013410568237305\n",
      "Epoch: 800, Loss: 7.846987724304199\n",
      "Epoch: 801, Loss: 15.408711433410645\n",
      "Epoch: 802, Loss: 14.300605773925781\n",
      "Epoch: 803, Loss: 12.697366714477539\n",
      "Epoch: 804, Loss: 15.487531661987305\n",
      "Epoch: 805, Loss: 20.38141632080078\n",
      "Epoch: 806, Loss: 13.386350631713867\n",
      "Epoch: 807, Loss: 29.748855590820312\n",
      "Epoch: 808, Loss: 13.619818687438965\n",
      "Epoch: 809, Loss: 15.750948905944824\n",
      "Epoch: 810, Loss: 12.810212135314941\n",
      "Epoch: 811, Loss: 18.474485397338867\n",
      "Epoch: 812, Loss: 11.90970230102539\n",
      "Epoch: 813, Loss: 15.102823257446289\n",
      "Epoch: 814, Loss: 20.753128051757812\n",
      "Epoch: 815, Loss: 11.796126365661621\n",
      "Epoch: 816, Loss: 13.967549324035645\n",
      "Epoch: 817, Loss: 14.358278274536133\n",
      "Epoch: 818, Loss: 16.529970169067383\n",
      "Epoch: 819, Loss: 14.286931037902832\n",
      "Epoch: 820, Loss: 19.396442413330078\n",
      "Epoch: 821, Loss: 15.683442115783691\n",
      "Epoch: 822, Loss: 13.676289558410645\n",
      "Epoch: 823, Loss: 18.04265785217285\n",
      "Epoch: 824, Loss: 11.196194648742676\n",
      "Epoch: 825, Loss: 13.676953315734863\n",
      "Epoch: 826, Loss: 17.862993240356445\n",
      "Epoch: 827, Loss: 16.839658737182617\n",
      "Epoch: 828, Loss: 11.399138450622559\n",
      "Epoch: 829, Loss: 20.73427391052246\n",
      "Epoch: 830, Loss: 14.037711143493652\n",
      "Epoch: 831, Loss: 10.78856086730957\n",
      "Epoch: 832, Loss: 13.16083812713623\n",
      "Epoch: 833, Loss: 20.25897979736328\n",
      "Epoch: 834, Loss: 15.976269721984863\n",
      "Epoch: 835, Loss: 12.568489074707031\n",
      "Epoch: 836, Loss: 12.846532821655273\n",
      "Epoch: 837, Loss: 15.4150390625\n",
      "Epoch: 838, Loss: 17.194324493408203\n",
      "Epoch: 839, Loss: 15.401881217956543\n",
      "Epoch: 840, Loss: 13.684779167175293\n",
      "Epoch: 841, Loss: 13.468694686889648\n",
      "Epoch: 842, Loss: 14.07259464263916\n",
      "Epoch: 843, Loss: 14.534281730651855\n",
      "Epoch: 844, Loss: 12.406987190246582\n",
      "Epoch: 845, Loss: 14.082114219665527\n",
      "Epoch: 846, Loss: 13.050119400024414\n",
      "Epoch: 847, Loss: 12.642661094665527\n",
      "Epoch: 848, Loss: 16.622745513916016\n",
      "Epoch: 849, Loss: 12.761948585510254\n",
      "Epoch: 850, Loss: 16.59096908569336\n",
      "Epoch: 851, Loss: 10.197360038757324\n",
      "Epoch: 852, Loss: 12.755313873291016\n",
      "Epoch: 853, Loss: 22.606626510620117\n",
      "Epoch: 854, Loss: 14.15884017944336\n",
      "Epoch: 855, Loss: 13.121079444885254\n",
      "Epoch: 856, Loss: 11.872849464416504\n",
      "Epoch: 857, Loss: 19.095478057861328\n",
      "Epoch: 858, Loss: 19.829727172851562\n",
      "Epoch: 859, Loss: 10.91065788269043\n",
      "Epoch: 860, Loss: 11.960813522338867\n",
      "Epoch: 861, Loss: 14.435290336608887\n",
      "Epoch: 862, Loss: 12.75542163848877\n",
      "Epoch: 863, Loss: 20.806888580322266\n",
      "Epoch: 864, Loss: 18.321792602539062\n",
      "Epoch: 865, Loss: 17.295337677001953\n",
      "Epoch: 866, Loss: 16.704607009887695\n",
      "Epoch: 867, Loss: 12.786809921264648\n",
      "Epoch: 868, Loss: 18.932580947875977\n",
      "Epoch: 869, Loss: 14.1359224319458\n",
      "Epoch: 870, Loss: 18.241823196411133\n",
      "Epoch: 871, Loss: 17.94696617126465\n",
      "Epoch: 872, Loss: 9.528289794921875\n",
      "Epoch: 873, Loss: 13.996211051940918\n",
      "Epoch: 874, Loss: 17.33667755126953\n",
      "Epoch: 875, Loss: 14.723957061767578\n",
      "Epoch: 876, Loss: 16.03447723388672\n",
      "Epoch: 877, Loss: 13.956029891967773\n",
      "Epoch: 878, Loss: 21.24054527282715\n",
      "Epoch: 879, Loss: 13.656452178955078\n",
      "Epoch: 880, Loss: 14.66342544555664\n",
      "Epoch: 881, Loss: 15.320269584655762\n",
      "Epoch: 882, Loss: 17.7729549407959\n",
      "Epoch: 883, Loss: 32.9514274597168\n",
      "Epoch: 884, Loss: 12.22451400756836\n",
      "Epoch: 885, Loss: 19.286117553710938\n",
      "Epoch: 886, Loss: 15.421499252319336\n",
      "Epoch: 887, Loss: 19.54088020324707\n",
      "Epoch: 888, Loss: 16.518808364868164\n",
      "Epoch: 889, Loss: 28.3153018951416\n",
      "Epoch: 890, Loss: 10.163508415222168\n",
      "Epoch: 891, Loss: 11.458526611328125\n",
      "Epoch: 892, Loss: 18.510540008544922\n",
      "Epoch: 893, Loss: 12.226042747497559\n",
      "Epoch: 894, Loss: 10.251338958740234\n",
      "Epoch: 895, Loss: 16.040870666503906\n",
      "Epoch: 896, Loss: 16.53400230407715\n",
      "Epoch: 897, Loss: 10.386760711669922\n",
      "Epoch: 898, Loss: 12.390166282653809\n",
      "Epoch: 899, Loss: 15.133769035339355\n",
      "Epoch: 900, Loss: 22.031349182128906\n",
      "Epoch: 901, Loss: 17.0596981048584\n",
      "Epoch: 902, Loss: 14.325410842895508\n",
      "Epoch: 903, Loss: 10.391231536865234\n",
      "Epoch: 904, Loss: 18.29882049560547\n",
      "Epoch: 905, Loss: 14.241147994995117\n",
      "Epoch: 906, Loss: 10.745352745056152\n",
      "Epoch: 907, Loss: 17.850927352905273\n",
      "Epoch: 908, Loss: 13.508570671081543\n",
      "Epoch: 909, Loss: 11.114173889160156\n",
      "Epoch: 910, Loss: 15.2613525390625\n",
      "Epoch: 911, Loss: 14.450013160705566\n",
      "Epoch: 912, Loss: 13.115629196166992\n",
      "Epoch: 913, Loss: 12.127958297729492\n",
      "Epoch: 914, Loss: 14.18018913269043\n",
      "Epoch: 915, Loss: 14.442887306213379\n",
      "Epoch: 916, Loss: 13.473719596862793\n",
      "Epoch: 917, Loss: 13.105843544006348\n",
      "Epoch: 918, Loss: 20.08095359802246\n",
      "Epoch: 919, Loss: 18.647329330444336\n",
      "Epoch: 920, Loss: 12.84762954711914\n",
      "Epoch: 921, Loss: 34.435611724853516\n",
      "Epoch: 922, Loss: 13.844635963439941\n",
      "Epoch: 923, Loss: 10.779494285583496\n",
      "Epoch: 924, Loss: 15.588983535766602\n",
      "Epoch: 925, Loss: 8.127431869506836\n",
      "Epoch: 926, Loss: 15.300491333007812\n",
      "Epoch: 927, Loss: 20.076236724853516\n",
      "Epoch: 928, Loss: 13.675657272338867\n",
      "Epoch: 929, Loss: 12.320230484008789\n",
      "Epoch: 930, Loss: 12.92326831817627\n",
      "Epoch: 931, Loss: 15.60500717163086\n",
      "Epoch: 932, Loss: 24.213300704956055\n",
      "Epoch: 933, Loss: 19.86086082458496\n",
      "Epoch: 934, Loss: 16.690322875976562\n",
      "Epoch: 935, Loss: 17.315181732177734\n",
      "Epoch: 936, Loss: 19.662630081176758\n",
      "Epoch: 937, Loss: 9.273796081542969\n",
      "Epoch: 938, Loss: 21.549026489257812\n",
      "Epoch: 939, Loss: 9.54798412322998\n",
      "Epoch: 940, Loss: 13.918234825134277\n",
      "Epoch: 941, Loss: 14.49500846862793\n",
      "Epoch: 942, Loss: 18.6484375\n",
      "Epoch: 943, Loss: 14.580863952636719\n",
      "Epoch: 944, Loss: 13.27059268951416\n",
      "Epoch: 945, Loss: 36.599388122558594\n",
      "Epoch: 946, Loss: 19.3648738861084\n",
      "Epoch: 947, Loss: 8.738618850708008\n",
      "Epoch: 948, Loss: 11.310420036315918\n",
      "Epoch: 949, Loss: 15.01983642578125\n",
      "Epoch: 950, Loss: 20.309011459350586\n",
      "Epoch: 951, Loss: 39.24089813232422\n",
      "Epoch: 952, Loss: 16.95685386657715\n",
      "Epoch: 953, Loss: 12.525951385498047\n",
      "Epoch: 954, Loss: 12.551824569702148\n",
      "Epoch: 955, Loss: 14.067492485046387\n",
      "Epoch: 956, Loss: 13.16227912902832\n",
      "Epoch: 957, Loss: 11.976568222045898\n",
      "Epoch: 958, Loss: 15.778288841247559\n",
      "Epoch: 959, Loss: 12.432722091674805\n",
      "Epoch: 960, Loss: 9.894522666931152\n",
      "Epoch: 961, Loss: 15.575242042541504\n",
      "Epoch: 962, Loss: 10.941469192504883\n",
      "Epoch: 963, Loss: 11.225541114807129\n",
      "Epoch: 964, Loss: 15.501251220703125\n",
      "Epoch: 965, Loss: 17.020309448242188\n",
      "Epoch: 966, Loss: 13.076042175292969\n",
      "Epoch: 967, Loss: 10.545267105102539\n",
      "Epoch: 968, Loss: 14.405057907104492\n",
      "Epoch: 969, Loss: 14.189703941345215\n",
      "Epoch: 970, Loss: 8.270153045654297\n",
      "Epoch: 971, Loss: 18.728910446166992\n",
      "Epoch: 972, Loss: 20.31035041809082\n",
      "Epoch: 973, Loss: 11.360187530517578\n",
      "Epoch: 974, Loss: 14.71215534210205\n",
      "Epoch: 975, Loss: 25.621095657348633\n",
      "Epoch: 976, Loss: 14.152077674865723\n",
      "Epoch: 977, Loss: 19.59950828552246\n",
      "Epoch: 978, Loss: 15.442301750183105\n",
      "Epoch: 979, Loss: 14.673526763916016\n",
      "Epoch: 980, Loss: 21.317811965942383\n",
      "Epoch: 981, Loss: 11.374309539794922\n",
      "Epoch: 982, Loss: 13.670373916625977\n",
      "Epoch: 983, Loss: 12.197745323181152\n",
      "Epoch: 984, Loss: 18.1655216217041\n",
      "Epoch: 985, Loss: 12.838631629943848\n",
      "Epoch: 986, Loss: 14.532626152038574\n",
      "Epoch: 987, Loss: 14.465889930725098\n",
      "Epoch: 988, Loss: 30.044940948486328\n",
      "Epoch: 989, Loss: 22.8245792388916\n",
      "Epoch: 990, Loss: 14.646871566772461\n",
      "Epoch: 991, Loss: 18.51822853088379\n",
      "Epoch: 992, Loss: 11.70020580291748\n",
      "Epoch: 993, Loss: 14.912944793701172\n",
      "Epoch: 994, Loss: 16.294931411743164\n",
      "Epoch: 995, Loss: 15.542764663696289\n",
      "Epoch: 996, Loss: 12.070582389831543\n",
      "Epoch: 997, Loss: 12.02141284942627\n",
      "Epoch: 998, Loss: 14.109495162963867\n",
      "Epoch: 999, Loss: 11.418389320373535\n",
      "Epoch: 1000, Loss: 13.665335655212402\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VAE, self).__init__()\n",
    "\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(3, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 6)  # Output size needs to be twice the size of your latent space (for mean and variance)\n",
    "        )\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(3, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 3),\n",
    "            nn.Sigmoid()  # Use sigmoid if your data is normalized between 0 and 1\n",
    "        )\n",
    "\n",
    "    def reparameterize(self, mu, log_var):\n",
    "        std = torch.exp(log_var/2)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = self.encoder(x)\n",
    "        mu, log_var = h.chunk(2, dim=1)  # Split your hidden state into mean and variance components\n",
    "        z = self.reparameterize(mu, log_var)\n",
    "        x_reconstructed = self.decoder(z)\n",
    "        return x_reconstructed, mu, log_var\n",
    "\n",
    "\n",
    "# Instantiate the model\n",
    "model = VAE()\n",
    "\n",
    "# Create your optimizer\n",
    "optimizer = Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "# Loss function\n",
    "def vae_loss(x_reconstructed, x, mu, log_var):\n",
    "    reconstruction_loss = nn.functional.l1_loss(x_reconstructed, x, reduction='sum')\n",
    "    kl_divergence = -0.5 * torch.sum(1 + log_var - mu.pow(2) - log_var.exp())\n",
    "    return reconstruction_loss + kl_divergence\n",
    "\n",
    "\n",
    "# Training loop\n",
    "def train(model, data_loader, epochs=50):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        for batch in data_loader:\n",
    "            batch = batch.float() # Ensuring your data is of the correct dtype\n",
    "            optimizer.zero_grad()\n",
    "            x_reconstructed, mu, log_var = model(batch)\n",
    "            loss = vae_loss(x_reconstructed, batch, mu, log_var)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        print(f\"Epoch: {epoch+1}, Loss: {loss.item()}\")\n",
    "\n",
    "# Assuming your data is a PyTorch DataLoader\n",
    "train(model, loader, epochs=1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[33.64820068 65.58874538  4.8379227 ]]\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    z = torch.randn(1, 3)  # Generate a random latent vector\n",
    "    synthetic_data = model.decoder(z)  # Decode the latent vector into a synthetic data point\n",
    "print(ss.inverse_transform(synthetic_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Epidian 6D</th>\n",
       "      <th>Araldite GY260</th>\n",
       "      <th>Araldite GY250CH</th>\n",
       "      <th>CHS-520 (*CHS-530)</th>\n",
       "      <th>CHS-525</th>\n",
       "      <th>CHS-590</th>\n",
       "      <th>Epidian 5</th>\n",
       "      <th>Epidian 6</th>\n",
       "      <th>Epilox AF 18-50</th>\n",
       "      <th>AH-24/Grilonit epoxide 8</th>\n",
       "      <th>...</th>\n",
       "      <th>trisDMP</th>\n",
       "      <th>DCH-99</th>\n",
       "      <th>MXDA</th>\n",
       "      <th>Ethacure 100</th>\n",
       "      <th>nonilfenol</th>\n",
       "      <th>etanol</th>\n",
       "      <th>AHEW</th>\n",
       "      <th>Fazékidő (min)</th>\n",
       "      <th>Szakítószilárdság [MPa]</th>\n",
       "      <th>Szakadási nyúlás [%]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24.400000</td>\n",
       "      <td>46.0</td>\n",
       "      <td>82.57</td>\n",
       "      <td>5.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27.685325</td>\n",
       "      <td>53.0</td>\n",
       "      <td>41.72</td>\n",
       "      <td>3.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>31.228669</td>\n",
       "      <td>34.0</td>\n",
       "      <td>56.60</td>\n",
       "      <td>4.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35.812133</td>\n",
       "      <td>28.0</td>\n",
       "      <td>61.23</td>\n",
       "      <td>5.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27.685325</td>\n",
       "      <td>61.0</td>\n",
       "      <td>41.13</td>\n",
       "      <td>3.67</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Epidian 6D  Araldite GY260  Araldite GY250CH  CHS-520 (*CHS-530)  CHS-525  \\\n",
       "0        20.0             0.0               0.0                 0.0      0.0   \n",
       "1        20.0             0.0               0.0                 0.0      0.0   \n",
       "2        20.0             0.0               0.0                 0.0      0.0   \n",
       "3        20.0             0.0               0.0                 0.0      0.0   \n",
       "4        20.0             0.0               0.0                 0.0      0.0   \n",
       "\n",
       "   CHS-590  Epidian 5  Epidian 6  Epilox AF 18-50  AH-24/Grilonit epoxide 8  \\\n",
       "0      0.0        0.0        0.0             60.0                      20.0   \n",
       "1      0.0        0.0        0.0             60.0                      20.0   \n",
       "2      0.0        0.0        0.0             60.0                      20.0   \n",
       "3      0.0        0.0        0.0             60.0                      20.0   \n",
       "4      0.0        0.0        0.0             60.0                      20.0   \n",
       "\n",
       "   ...  trisDMP  DCH-99  MXDA  Ethacure 100  nonilfenol  etanol       AHEW  \\\n",
       "0  ...      0.0     0.0   0.0           0.0           0       0  24.400000   \n",
       "1  ...      0.0     0.0   0.0           0.0           0       0  27.685325   \n",
       "2  ...      0.0     0.0   0.0           0.0           0       0  31.228669   \n",
       "3  ...      0.0     0.0   0.0           0.0           0       0  35.812133   \n",
       "4  ...      0.0     0.0   0.0           0.0           0       0  27.685325   \n",
       "\n",
       "   Fazékidő (min)  Szakítószilárdság [MPa]  Szakadási nyúlás [%]  \n",
       "0            46.0                    82.57                  5.58  \n",
       "1            53.0                    41.72                  3.35  \n",
       "2            34.0                    56.60                  4.76  \n",
       "3            28.0                    61.23                  5.59  \n",
       "4            61.0                    41.13                  3.67  \n",
       "\n",
       "[5 rows x 37 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "import joblib\n",
    "\n",
    "pd.set_option('display.max_colwidth',  None)\n",
    "\n",
    "with open('result.json') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "df.fillna(0, inplace=True)\n",
    "df = df.apply(lambda series: pd.to_numeric(series, errors='coerce'))\n",
    "df = df.dropna()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Epidian 6D</th>\n",
       "      <th>Araldite GY260</th>\n",
       "      <th>Araldite GY250CH</th>\n",
       "      <th>CHS-520 (*CHS-530)</th>\n",
       "      <th>CHS-525</th>\n",
       "      <th>CHS-590</th>\n",
       "      <th>Epidian 5</th>\n",
       "      <th>Epidian 6</th>\n",
       "      <th>Epilox AF 18-50</th>\n",
       "      <th>AH-24/Grilonit epoxide 8</th>\n",
       "      <th>...</th>\n",
       "      <th>TEA/</th>\n",
       "      <th>Dytek A-MPMD/APU-2**</th>\n",
       "      <th>APU-4</th>\n",
       "      <th>trisDMP</th>\n",
       "      <th>DCH-99</th>\n",
       "      <th>MXDA</th>\n",
       "      <th>Ethacure 100</th>\n",
       "      <th>Fazékidő (min)</th>\n",
       "      <th>Szakítószilárdság [MPa]</th>\n",
       "      <th>Szakadási nyúlás [%]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>82.57</td>\n",
       "      <td>5.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>41.72</td>\n",
       "      <td>3.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>56.60</td>\n",
       "      <td>4.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>...</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>61.23</td>\n",
       "      <td>5.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>41.13</td>\n",
       "      <td>3.67</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Epidian 6D  Araldite GY260  Araldite GY250CH  CHS-520 (*CHS-530)  CHS-525  \\\n",
       "0        20.0             0.0               0.0                 0.0      0.0   \n",
       "1        20.0             0.0               0.0                 0.0      0.0   \n",
       "2        20.0             0.0               0.0                 0.0      0.0   \n",
       "3        20.0             0.0               0.0                 0.0      0.0   \n",
       "4        20.0             0.0               0.0                 0.0      0.0   \n",
       "\n",
       "   CHS-590  Epidian 5  Epidian 6  Epilox AF 18-50  AH-24/Grilonit epoxide 8  \\\n",
       "0      0.0        0.0        0.0             60.0                      20.0   \n",
       "1      0.0        0.0        0.0             60.0                      20.0   \n",
       "2      0.0        0.0        0.0             60.0                      20.0   \n",
       "3      0.0        0.0        0.0             60.0                      20.0   \n",
       "4      0.0        0.0        0.0             60.0                      20.0   \n",
       "\n",
       "   ...  TEA/   Dytek A-MPMD/APU-2**  APU-4  trisDMP  DCH-99  MXDA  \\\n",
       "0  ...    0.0                   0.0    0.0      0.0     0.0   0.0   \n",
       "1  ...    0.0                   0.0    0.0      0.0     0.0   0.0   \n",
       "2  ...   10.0                   0.0    0.0      0.0     0.0   0.0   \n",
       "3  ...   20.0                   0.0    0.0      0.0     0.0   0.0   \n",
       "4  ...    0.0                   0.0    0.0      0.0     0.0   0.0   \n",
       "\n",
       "   Ethacure 100  Fazékidő (min)  Szakítószilárdság [MPa]  Szakadási nyúlás [%]  \n",
       "0           0.0            46.0                    82.57                  5.58  \n",
       "1           0.0            53.0                    41.72                  3.35  \n",
       "2           0.0            34.0                    56.60                  4.76  \n",
       "3           0.0            28.0                    61.23                  5.59  \n",
       "4           0.0            61.0                    41.13                  3.67  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del df[\"EEW\"]\n",
    "del df[\"nonilfenol\"]\n",
    "del df[\"etanol\"]\n",
    "del df[\"AHEW\"]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import autograd\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(Generator, self).__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(input_dim, input_dim*2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(input_dim*2, input_dim*4),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(input_dim*4, output_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc(x)\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(input_dim, input_dim*2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(input_dim*2, input_dim*4),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(input_dim*4, 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc(x)\n",
    "\n",
    "def compute_gradient_penalty(D, real_samples, fake_samples):\n",
    "    alpha = torch.Tensor(np.random.random((real_samples.size(0), 1))).to(DEVICE)\n",
    "    interpolates = (alpha * real_samples + ((1 - alpha) * fake_samples)).requires_grad_(True)\n",
    "    d_interpolates = D(interpolates)\n",
    "    fake = Variable(torch.Tensor(real_samples.shape[0], 1).to(DEVICE).fill_(1.0), requires_grad=False)\n",
    "    gradients = autograd.grad(\n",
    "        outputs=d_interpolates,\n",
    "        inputs=interpolates,\n",
    "        grad_outputs=fake,\n",
    "        create_graph=True,\n",
    "        retain_graph=True,\n",
    "        only_inputs=True,\n",
    "    )[0]\n",
    "    gradient_penalty = ((gradients.norm(2, dim=1) - 1) ** 2).mean()\n",
    "    return gradient_penalty\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0/200] Batch 11/12                 Loss D: -13.9864, loss G: 13.4762\n",
      "Epoch [1/200] Batch 11/12                 Loss D: -128.2570, loss G: 11.9365\n",
      "Epoch [2/200] Batch 11/12                 Loss D: -222.2312, loss G: 18.0087\n",
      "Epoch [3/200] Batch 11/12                 Loss D: -84.8377, loss G: 16.1789\n",
      "Epoch [4/200] Batch 11/12                 Loss D: -57.8543, loss G: 15.2520\n",
      "Epoch [5/200] Batch 11/12                 Loss D: -97.7984, loss G: 14.6323\n",
      "Epoch [6/200] Batch 11/12                 Loss D: -138.5695, loss G: 13.4757\n",
      "Epoch [7/200] Batch 11/12                 Loss D: 36.2070, loss G: 20.8466\n",
      "Epoch [8/200] Batch 11/12                 Loss D: -6.5119, loss G: 16.4785\n",
      "Epoch [9/200] Batch 11/12                 Loss D: -18.3103, loss G: 16.2390\n",
      "Epoch [10/200] Batch 11/12                 Loss D: -21.2227, loss G: 16.1621\n",
      "Epoch [11/200] Batch 11/12                 Loss D: -19.6769, loss G: 16.1400\n",
      "Epoch [12/200] Batch 11/12                 Loss D: -20.4518, loss G: 16.1907\n",
      "Epoch [13/200] Batch 11/12                 Loss D: -17.0956, loss G: 16.0915\n",
      "Epoch [14/200] Batch 11/12                 Loss D: -12.2419, loss G: 16.0996\n",
      "Epoch [15/200] Batch 11/12                 Loss D: 1.4257, loss G: 16.1352\n",
      "Epoch [16/200] Batch 11/12                 Loss D: 17.2163, loss G: 16.1336\n",
      "Epoch [17/200] Batch 11/12                 Loss D: 10.0067, loss G: 16.3033\n",
      "Epoch [18/200] Batch 11/12                 Loss D: 6.3364, loss G: 16.4368\n",
      "Epoch [19/200] Batch 11/12                 Loss D: 2.4373, loss G: 16.4235\n",
      "Epoch [20/200] Batch 11/12                 Loss D: -4.7336, loss G: 16.4146\n",
      "Epoch [21/200] Batch 11/12                 Loss D: -15.0285, loss G: 16.3522\n",
      "Epoch [22/200] Batch 11/12                 Loss D: -16.2387, loss G: 16.3183\n",
      "Epoch [23/200] Batch 11/12                 Loss D: -3.9509, loss G: 16.3501\n",
      "Epoch [24/200] Batch 11/12                 Loss D: 13.5868, loss G: 16.2818\n",
      "Epoch [25/200] Batch 11/12                 Loss D: 9.2389, loss G: 16.4672\n",
      "Epoch [26/200] Batch 11/12                 Loss D: 6.0277, loss G: 16.5669\n",
      "Epoch [27/200] Batch 11/12                 Loss D: -0.2259, loss G: 16.6313\n",
      "Epoch [28/200] Batch 11/12                 Loss D: -6.3170, loss G: 16.6409\n",
      "Epoch [29/200] Batch 11/12                 Loss D: -9.6064, loss G: 16.5953\n",
      "Epoch [30/200] Batch 11/12                 Loss D: -2.1821, loss G: 16.6011\n",
      "Epoch [31/200] Batch 11/12                 Loss D: 3.5240, loss G: 16.6440\n",
      "Epoch [32/200] Batch 11/12                 Loss D: 4.8742, loss G: 16.7277\n",
      "Epoch [33/200] Batch 11/12                 Loss D: 2.9440, loss G: 16.8278\n",
      "Epoch [34/200] Batch 11/12                 Loss D: -3.7901, loss G: 16.8711\n",
      "Epoch [35/200] Batch 11/12                 Loss D: -6.2178, loss G: 16.8717\n",
      "Epoch [36/200] Batch 11/12                 Loss D: -4.9939, loss G: 16.9348\n",
      "Epoch [37/200] Batch 11/12                 Loss D: -4.8740, loss G: 16.9964\n",
      "Epoch [38/200] Batch 11/12                 Loss D: -4.9910, loss G: 16.9926\n",
      "Epoch [39/200] Batch 11/12                 Loss D: -4.1687, loss G: 16.9745\n",
      "Epoch [40/200] Batch 11/12                 Loss D: -3.9665, loss G: 16.8767\n",
      "Epoch [41/200] Batch 11/12                 Loss D: -5.0295, loss G: 16.9102\n",
      "Epoch [42/200] Batch 11/12                 Loss D: -6.5156, loss G: 16.9652\n",
      "Epoch [43/200] Batch 11/12                 Loss D: -7.2510, loss G: 17.0075\n",
      "Epoch [44/200] Batch 11/12                 Loss D: -8.4187, loss G: 17.0072\n",
      "Epoch [45/200] Batch 11/12                 Loss D: -9.1552, loss G: 17.0173\n",
      "Epoch [46/200] Batch 11/12                 Loss D: -8.1623, loss G: 16.9786\n",
      "Epoch [47/200] Batch 11/12                 Loss D: -7.5560, loss G: 16.9475\n",
      "Epoch [48/200] Batch 11/12                 Loss D: -7.7826, loss G: 16.9200\n",
      "Epoch [49/200] Batch 11/12                 Loss D: -8.0455, loss G: 16.8998\n",
      "Epoch [50/200] Batch 11/12                 Loss D: -7.3176, loss G: 16.8919\n",
      "Epoch [51/200] Batch 11/12                 Loss D: -10.0744, loss G: 16.8995\n",
      "Epoch [52/200] Batch 11/12                 Loss D: -7.3974, loss G: 16.9481\n",
      "Epoch [53/200] Batch 11/12                 Loss D: -13.1388, loss G: 16.9155\n",
      "Epoch [54/200] Batch 11/12                 Loss D: -10.9770, loss G: 16.9006\n",
      "Epoch [55/200] Batch 11/12                 Loss D: -8.2039, loss G: 16.8837\n",
      "Epoch [56/200] Batch 11/12                 Loss D: -12.9573, loss G: 16.8374\n",
      "Epoch [57/200] Batch 11/12                 Loss D: -12.9628, loss G: 16.8139\n",
      "Epoch [58/200] Batch 11/12                 Loss D: -13.6053, loss G: 16.7848\n",
      "Epoch [59/200] Batch 11/12                 Loss D: -11.1080, loss G: 16.7816\n",
      "Epoch [60/200] Batch 11/12                 Loss D: -12.7735, loss G: 16.7872\n",
      "Epoch [61/200] Batch 11/12                 Loss D: -11.7519, loss G: 16.7659\n",
      "Epoch [62/200] Batch 11/12                 Loss D: -9.5243, loss G: 16.7386\n",
      "Epoch [63/200] Batch 11/12                 Loss D: -12.9796, loss G: 16.7124\n",
      "Epoch [64/200] Batch 11/12                 Loss D: 0.1650, loss G: 16.7626\n",
      "Epoch [65/200] Batch 11/12                 Loss D: -14.0633, loss G: 16.7081\n",
      "Epoch [66/200] Batch 11/12                 Loss D: -10.3101, loss G: 16.6788\n",
      "Epoch [67/200] Batch 11/12                 Loss D: -2.2639, loss G: 16.6913\n",
      "Epoch [68/200] Batch 11/12                 Loss D: -6.4607, loss G: 16.6994\n",
      "Epoch [69/200] Batch 11/12                 Loss D: -13.6203, loss G: 16.6579\n",
      "Epoch [70/200] Batch 11/12                 Loss D: -13.6783, loss G: 16.6242\n",
      "Epoch [71/200] Batch 11/12                 Loss D: -11.7096, loss G: 16.6365\n",
      "Epoch [72/200] Batch 11/12                 Loss D: -2.8364, loss G: 16.6658\n",
      "Epoch [73/200] Batch 11/12                 Loss D: 4.6307, loss G: 16.6738\n",
      "Epoch [74/200] Batch 11/12                 Loss D: 5.4594, loss G: 16.7059\n",
      "Epoch [75/200] Batch 11/12                 Loss D: -3.0822, loss G: 16.6819\n",
      "Epoch [76/200] Batch 11/12                 Loss D: -10.0325, loss G: 16.6628\n",
      "Epoch [77/200] Batch 11/12                 Loss D: -13.3969, loss G: 16.6432\n",
      "Epoch [78/200] Batch 11/12                 Loss D: -12.5940, loss G: 16.6215\n",
      "Epoch [79/200] Batch 11/12                 Loss D: -12.7678, loss G: 16.5998\n",
      "Epoch [80/200] Batch 11/12                 Loss D: -12.7547, loss G: 16.5762\n",
      "Epoch [81/200] Batch 11/12                 Loss D: -11.1232, loss G: 16.5609\n",
      "Epoch [82/200] Batch 11/12                 Loss D: -9.2744, loss G: 16.5334\n",
      "Epoch [83/200] Batch 11/12                 Loss D: -4.5732, loss G: 16.5188\n",
      "Epoch [84/200] Batch 11/12                 Loss D: -7.6859, loss G: 16.4863\n",
      "Epoch [85/200] Batch 11/12                 Loss D: 24.9661, loss G: 16.5400\n",
      "Epoch [86/200] Batch 11/12                 Loss D: 10.2155, loss G: 16.5928\n",
      "Epoch [87/200] Batch 11/12                 Loss D: 13.1111, loss G: 16.6289\n",
      "Epoch [88/200] Batch 11/12                 Loss D: 12.7635, loss G: 16.6814\n",
      "Epoch [89/200] Batch 11/12                 Loss D: 9.5288, loss G: 16.6934\n",
      "Epoch [90/200] Batch 11/12                 Loss D: 7.1556, loss G: 16.7087\n",
      "Epoch [91/200] Batch 11/12                 Loss D: 4.0585, loss G: 16.6898\n",
      "Epoch [92/200] Batch 11/12                 Loss D: -12.3950, loss G: 16.7948\n",
      "Epoch [93/200] Batch 11/12                 Loss D: 4.4576, loss G: 16.8678\n",
      "Epoch [94/200] Batch 11/12                 Loss D: 2.0543, loss G: 16.7376\n",
      "Epoch [95/200] Batch 11/12                 Loss D: -5.0852, loss G: 16.6790\n",
      "Epoch [96/200] Batch 11/12                 Loss D: 1.0260, loss G: 16.8730\n",
      "Epoch [97/200] Batch 11/12                 Loss D: -6.1257, loss G: 16.6748\n",
      "Epoch [98/200] Batch 11/12                 Loss D: -11.1444, loss G: 16.9860\n",
      "Epoch [99/200] Batch 11/12                 Loss D: -4.1373, loss G: 16.7753\n",
      "Epoch [100/200] Batch 11/12                 Loss D: -9.8799, loss G: 16.7962\n",
      "Epoch [101/200] Batch 11/12                 Loss D: -10.0407, loss G: 16.9226\n",
      "Epoch [102/200] Batch 11/12                 Loss D: -6.7643, loss G: 16.9404\n",
      "Epoch [103/200] Batch 11/12                 Loss D: 7.6563, loss G: 16.9164\n",
      "Epoch [104/200] Batch 11/12                 Loss D: 4.2631, loss G: 17.2115\n",
      "Epoch [105/200] Batch 11/12                 Loss D: 8.8610, loss G: 17.4134\n",
      "Epoch [106/200] Batch 11/12                 Loss D: 5.8476, loss G: 17.5242\n",
      "Epoch [107/200] Batch 11/12                 Loss D: -25.1609, loss G: 18.4585\n",
      "Epoch [108/200] Batch 11/12                 Loss D: 15.2729, loss G: 18.0860\n",
      "Epoch [109/200] Batch 11/12                 Loss D: 5.7410, loss G: 17.9139\n",
      "Epoch [110/200] Batch 11/12                 Loss D: 3.2908, loss G: 17.8273\n",
      "Epoch [111/200] Batch 11/12                 Loss D: -0.2866, loss G: 17.7550\n",
      "Epoch [112/200] Batch 11/12                 Loss D: -8.6028, loss G: 17.6707\n",
      "Epoch [113/200] Batch 11/12                 Loss D: -35.0949, loss G: 18.1642\n",
      "Epoch [114/200] Batch 11/12                 Loss D: 15.4677, loss G: 18.1458\n",
      "Epoch [115/200] Batch 11/12                 Loss D: 5.3499, loss G: 17.9902\n",
      "Epoch [116/200] Batch 11/12                 Loss D: 1.8541, loss G: 17.9051\n",
      "Epoch [117/200] Batch 11/12                 Loss D: -44.4719, loss G: 18.0443\n",
      "Epoch [118/200] Batch 11/12                 Loss D: 7.5270, loss G: 18.1744\n",
      "Epoch [119/200] Batch 11/12                 Loss D: 2.2870, loss G: 18.1077\n",
      "Epoch [120/200] Batch 11/12                 Loss D: -0.0774, loss G: 18.0775\n",
      "Epoch [121/200] Batch 11/12                 Loss D: -1.4632, loss G: 18.0660\n",
      "Epoch [122/200] Batch 11/12                 Loss D: -2.8159, loss G: 18.0607\n",
      "Epoch [123/200] Batch 11/12                 Loss D: -4.7350, loss G: 18.0570\n",
      "Epoch [124/200] Batch 11/12                 Loss D: -28.4799, loss G: 18.0634\n",
      "Epoch [125/200] Batch 11/12                 Loss D: -2.7837, loss G: 18.2063\n",
      "Epoch [126/200] Batch 11/12                 Loss D: -3.7138, loss G: 18.1780\n",
      "Epoch [127/200] Batch 11/12                 Loss D: -7.5849, loss G: 18.1631\n",
      "Epoch [128/200] Batch 11/12                 Loss D: -25.4486, loss G: 18.1506\n",
      "Epoch [129/200] Batch 11/12                 Loss D: -20.7542, loss G: 18.3617\n",
      "Epoch [130/200] Batch 11/12                 Loss D: -23.5240, loss G: 18.2843\n",
      "Epoch [131/200] Batch 11/12                 Loss D: -9.9275, loss G: 18.1490\n",
      "Epoch [132/200] Batch 11/12                 Loss D: -21.9021, loss G: 18.1065\n",
      "Epoch [133/200] Batch 11/12                 Loss D: -21.5925, loss G: 18.6170\n",
      "Epoch [134/200] Batch 11/12                 Loss D: -4.7419, loss G: 18.4255\n",
      "Epoch [135/200] Batch 11/12                 Loss D: -6.4036, loss G: 18.3520\n",
      "Epoch [136/200] Batch 11/12                 Loss D: -8.0712, loss G: 18.3139\n",
      "Epoch [137/200] Batch 11/12                 Loss D: -10.9964, loss G: 18.2914\n",
      "Epoch [138/200] Batch 11/12                 Loss D: -13.8686, loss G: 18.2687\n",
      "Epoch [139/200] Batch 11/12                 Loss D: -21.9493, loss G: 18.2464\n",
      "Epoch [140/200] Batch 11/12                 Loss D: -43.1112, loss G: 18.2877\n",
      "Epoch [141/200] Batch 11/12                 Loss D: -20.3559, loss G: 18.6798\n",
      "Epoch [142/200] Batch 11/12                 Loss D: -11.7218, loss G: 18.5317\n",
      "Epoch [143/200] Batch 11/12                 Loss D: -91.0952, loss G: 18.1346\n",
      "Epoch [144/200] Batch 11/12                 Loss D: 360.8171, loss G: -1.7924\n",
      "Epoch [145/200] Batch 11/12                 Loss D: 51536.5469, loss G: -333.2911\n",
      "Epoch [146/200] Batch 11/12                 Loss D: -18384.6230, loss G: 1521.8792\n",
      "Epoch [147/200] Batch 11/12                 Loss D: -713.9360, loss G: 81.6560\n",
      "Epoch [148/200] Batch 11/12                 Loss D: -518.7225, loss G: 54.5820\n",
      "Epoch [149/200] Batch 11/12                 Loss D: -384.3906, loss G: 46.0054\n",
      "Epoch [150/200] Batch 11/12                 Loss D: -381.8354, loss G: 39.9691\n",
      "Epoch [151/200] Batch 11/12                 Loss D: -667.9783, loss G: 53.1219\n",
      "Epoch [152/200] Batch 11/12                 Loss D: -261.7622, loss G: 32.1515\n",
      "Epoch [153/200] Batch 11/12                 Loss D: -774.0331, loss G: 58.1717\n",
      "Epoch [154/200] Batch 11/12                 Loss D: -248.8522, loss G: 35.0063\n",
      "Epoch [155/200] Batch 11/12                 Loss D: -109.0094, loss G: 31.1176\n",
      "Epoch [156/200] Batch 11/12                 Loss D: -667.7842, loss G: 50.7478\n",
      "Epoch [157/200] Batch 11/12                 Loss D: -582.0516, loss G: 46.1716\n",
      "Epoch [158/200] Batch 11/12                 Loss D: -65.9635, loss G: 27.5918\n",
      "Epoch [159/200] Batch 11/12                 Loss D: -416.0562, loss G: 40.2705\n",
      "Epoch [160/200] Batch 11/12                 Loss D: -307.5905, loss G: 32.9025\n",
      "Epoch [161/200] Batch 11/12                 Loss D: -317.8826, loss G: 29.7823\n",
      "Epoch [162/200] Batch 11/12                 Loss D: -431.2820, loss G: 37.5694\n",
      "Epoch [163/200] Batch 11/12                 Loss D: -155.6684, loss G: 28.2207\n",
      "Epoch [164/200] Batch 11/12                 Loss D: -411.0377, loss G: 38.7077\n",
      "Epoch [165/200] Batch 11/12                 Loss D: -328.7607, loss G: 33.0260\n",
      "Epoch [166/200] Batch 11/12                 Loss D: -358.9468, loss G: 31.9866\n",
      "Epoch [167/200] Batch 11/12                 Loss D: -35.1624, loss G: 33.8642\n",
      "Epoch [168/200] Batch 11/12                 Loss D: -237.9912, loss G: 25.8225\n",
      "Epoch [169/200] Batch 11/12                 Loss D: -333.3385, loss G: 31.1524\n",
      "Epoch [170/200] Batch 11/12                 Loss D: -447.1827, loss G: 38.5701\n",
      "Epoch [171/200] Batch 11/12                 Loss D: -170.1246, loss G: 25.6998\n",
      "Epoch [172/200] Batch 11/12                 Loss D: -26.6510, loss G: 27.4487\n",
      "Epoch [173/200] Batch 11/12                 Loss D: -36.8612, loss G: 30.4505\n",
      "Epoch [174/200] Batch 11/12                 Loss D: -225.9082, loss G: 24.3937\n",
      "Epoch [175/200] Batch 11/12                 Loss D: -190.4382, loss G: 25.5492\n",
      "Epoch [176/200] Batch 11/12                 Loss D: -230.2882, loss G: 26.6670\n",
      "Epoch [177/200] Batch 11/12                 Loss D: -47.5534, loss G: 27.7300\n",
      "Epoch [178/200] Batch 11/12                 Loss D: -334.9721, loss G: 30.6121\n",
      "Epoch [179/200] Batch 11/12                 Loss D: -413.1634, loss G: 34.6803\n",
      "Epoch [180/200] Batch 11/12                 Loss D: -225.9116, loss G: 25.4628\n",
      "Epoch [181/200] Batch 11/12                 Loss D: 40.7255, loss G: 32.7038\n",
      "Epoch [182/200] Batch 11/12                 Loss D: -126.4270, loss G: 27.2495\n",
      "Epoch [183/200] Batch 11/12                 Loss D: -127.8759, loss G: 24.9584\n",
      "Epoch [184/200] Batch 11/12                 Loss D: -64.9899, loss G: 26.6253\n",
      "Epoch [185/200] Batch 11/12                 Loss D: -50.7174, loss G: 26.5480\n",
      "Epoch [186/200] Batch 11/12                 Loss D: -208.3171, loss G: 26.0368\n",
      "Epoch [187/200] Batch 11/12                 Loss D: -355.3660, loss G: 30.5362\n",
      "Epoch [188/200] Batch 11/12                 Loss D: -313.9553, loss G: 29.5524\n",
      "Epoch [189/200] Batch 11/12                 Loss D: -94.7179, loss G: 25.9213\n",
      "Epoch [190/200] Batch 11/12                 Loss D: -178.0238, loss G: 24.9562\n",
      "Epoch [191/200] Batch 11/12                 Loss D: -47.0063, loss G: 26.9485\n",
      "Epoch [192/200] Batch 11/12                 Loss D: -173.9937, loss G: 27.4724\n",
      "Epoch [193/200] Batch 11/12                 Loss D: -53.4940, loss G: 26.4459\n",
      "Epoch [194/200] Batch 11/12                 Loss D: -124.4970, loss G: 24.5394\n",
      "Epoch [195/200] Batch 11/12                 Loss D: -156.6068, loss G: 24.2620\n",
      "Epoch [196/200] Batch 11/12                 Loss D: -172.0062, loss G: 24.4809\n",
      "Epoch [197/200] Batch 11/12                 Loss D: -177.1447, loss G: 24.0604\n",
      "Epoch [198/200] Batch 11/12                 Loss D: -363.5226, loss G: 28.1428\n",
      "Epoch [199/200] Batch 11/12                 Loss D: -382.2498, loss G: 29.5634\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "PARAMETERS = 3\n",
    "Z_DIM = 100\n",
    "BATCH_SIZE = 32\n",
    "NUM_EPOCHS = 200\n",
    "CRITIC_ITERATIONS = 1\n",
    "LAMBDA_GP = 1\n",
    "LAMBDA_MEAN = 0.5\n",
    "\n",
    "dataset = torch.FloatTensor(df.iloc[:, -3:].values)\n",
    "ss = StandardScaler().fit(dataset)\n",
    "dataset = ss.transform(dataset)\n",
    "dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "# Initialize generator and discriminator\n",
    "generator = Generator(input_dim=Z_DIM, output_dim=PARAMETERS).to(DEVICE)\n",
    "discriminator = Discriminator(input_dim=PARAMETERS).to(DEVICE)\n",
    "\n",
    "optimizer_G = torch.optim.Adam(generator.parameters(), lr=0.002, betas=(0.5, 0.999))\n",
    "optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=0.002, betas=(0.5, 0.999))\n",
    "\n",
    "Tensor = torch.FloatTensor\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    for batch_idx, data in enumerate(dataloader, 0):\n",
    "        # real_data1 = Variable(data.type(Tensor))\n",
    "        real_data = torch.tensor(df.iloc[:, -3:].values, dtype=torch.float).to(DEVICE)\n",
    "        batch_size = real_data.shape[0]\n",
    "        # ---------------------\n",
    "        #  Train Discriminator\n",
    "        # ---------------------\n",
    "\n",
    "        optimizer_D.zero_grad()\n",
    "\n",
    "        # Sample noise as generator input\n",
    "        # z = Variable(Tensor(np.random.normal(0, 1, (real_data.shape[0], 100))))\n",
    "\n",
    "        # # Generate a batch of images\n",
    "        # fake_data = generator(z)\n",
    "\n",
    "        noise = torch.randn(batch_size, Z_DIM).to(DEVICE)\n",
    "        fake = generator(noise).detach().cpu()\n",
    "        fake = ss.inverse_transform(fake)\n",
    "        fake_data = torch.tensor(fake, dtype=torch.float).to(DEVICE)\n",
    "\n",
    "        # Real images\n",
    "        real_validity = discriminator(real_data)\n",
    "        # Fake images\n",
    "        fake_validity = discriminator(fake_data)\n",
    "\n",
    "        # Gradient penalty\n",
    "        gradient_penalty = compute_gradient_penalty(discriminator, real_data.data, fake_data.data).to(DEVICE)\n",
    "\n",
    "        # Adversarial loss\n",
    "        d_loss = -torch.mean(real_validity) + torch.mean(fake_validity) + LAMBDA_GP * gradient_penalty\n",
    "\n",
    "        d_loss.backward()\n",
    "        optimizer_D.step()\n",
    "\n",
    "        optimizer_G.zero_grad()\n",
    "\n",
    "        # Train the generator every n_critic steps\n",
    "        if batch_idx % CRITIC_ITERATIONS == 0:\n",
    "\n",
    "            # -----------------\n",
    "            #  Train Generator\n",
    "            # -----------------\n",
    "\n",
    "            # Generate a batch of images\n",
    "            fake_data = generator(noise)\n",
    "            # Loss measures generator's ability to fool the discriminator\n",
    "            # Train on fake images\n",
    "            fake_validity = discriminator(fake_data)\n",
    "\n",
    "            # Calculate the mean of the real data and the generated data\n",
    "            mean_real_data = torch.mean(real_data, dim=0)\n",
    "            mean_fake_data = torch.mean(fake_data, dim=0)\n",
    "\n",
    "            # Calculate the absolute difference between the means\n",
    "            mean_diff = torch.abs(mean_real_data - mean_fake_data)\n",
    "\n",
    "            # Calculate the penalty as the mean of the absolute difference\n",
    "            penalty = torch.mean(mean_diff)\n",
    "\n",
    "            g_loss = -torch.mean(fake_validity) + LAMBDA_MEAN * penalty\n",
    "\n",
    "            g_loss.backward()\n",
    "            optimizer_G.step()\n",
    "\n",
    "    print(\n",
    "        f\"Epoch [{epoch}/{NUM_EPOCHS}] Batch {batch_idx}/{len(dataloader)} \\\n",
    "                Loss D: {d_loss:.4f}, loss G: {g_loss:.4f}\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[50.05075812, 65.85009241, 16.52654484]])"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = Variable(Tensor(np.random.normal(0, 1, (1, 100)))).to(DEVICE)\n",
    "\n",
    "# Generate a batch of images\n",
    "fake_data = generator(z).detach().cpu()\n",
    "ss.inverse_transform(fake_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2400x600 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "noise = torch.randn(361, 100).to(DEVICE)\n",
    "fake = generator(noise).detach().cpu()\n",
    "fake = ss.inverse_transform(fake)\n",
    "\n",
    "fake_rounded = [[round(elem, 2) for elem in inner_list] for inner_list in fake]\n",
    "\n",
    "fake_df = pd.DataFrame(fake_rounded, columns = (['Fazékidő (min)', 'Szakítószilárdság [MPa]', 'Szakadási nyúlás [%]']))\n",
    "\n",
    "# Assuming y_true are your true output values and y_pred are your predicted output values\n",
    "y_true = df.iloc[:, -3:]\n",
    "y_pred = fake_df\n",
    "\n",
    "fig, axs = plt.subplots(1, 3, figsize=(24, 6))  # 1 row, 3 columns\n",
    "\n",
    "# Plot the actual values and the predicted values for the first feature\n",
    "axs[0].scatter(range(df.shape[0]), y_true.iloc[:, 0], color='blue', label='Eredeti értékek')\n",
    "axs[0].scatter(range(fake_df.shape[0]), y_pred.iloc[:, 0], color='red', label='Generált értékek')\n",
    "axs[0].set_title('Fazékidő (min)')\n",
    "axs[0].set_xlabel('#')\n",
    "axs[0].set_ylabel('Értékek')\n",
    "axs[0].legend()\n",
    "\n",
    "# Repeat for the second feature\n",
    "axs[1].scatter(range(df.shape[0]), y_true.iloc[:, 1], color='blue', label='Eredeti értékek')\n",
    "axs[1].scatter(range(fake_df.shape[0]), y_pred.iloc[:, 1], color='red', label='Generált értékek')\n",
    "axs[1].set_title('Szakítószilárdság [MPa]')\n",
    "axs[1].set_xlabel('#')\n",
    "axs[1].set_ylabel('Értékek')\n",
    "axs[1].legend()\n",
    "\n",
    "# Repeat for the third feature\n",
    "axs[2].scatter(range(df.shape[0]), y_true.iloc[:, 2], color='blue', label='Eredeti értékek')\n",
    "axs[2].scatter(range(fake_df.shape[0]), y_pred.iloc[:, 2], color='red', label='Generált értékek')\n",
    "axs[2].set_title('Szakadási nyúlás [%]')\n",
    "axs[2].set_xlabel('#')\n",
    "axs[2].set_ylabel('Értékek')\n",
    "axs[2].legend()\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [0/200] Batch 11/12                         Loss D: 8.6723, loss G: 34.3626\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [1/200] Batch 11/12                         Loss D: 8.8321, loss G: 33.7120\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [2/200] Batch 11/12                         Loss D: 8.8591, loss G: 32.6429\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [3/200] Batch 11/12                         Loss D: 8.0719, loss G: 31.0348\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [4/200] Batch 11/12                         Loss D: 4.7780, loss G: 29.4913\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [5/200] Batch 11/12                         Loss D: -1.4534, loss G: 28.1044\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [6/200] Batch 11/12                         Loss D: -11.0779, loss G: 26.8303\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [7/200] Batch 11/12                         Loss D: -25.8632, loss G: 25.2369\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [8/200] Batch 11/12                         Loss D: -45.0837, loss G: 23.5767\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [9/200] Batch 11/12                         Loss D: -71.1893, loss G: 21.6877\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [10/200] Batch 11/12                         Loss D: -106.9011, loss G: 19.4767\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [11/200] Batch 11/12                         Loss D: -152.6040, loss G: 17.2810\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [12/200] Batch 11/12                         Loss D: -179.5135, loss G: 16.3388\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [13/200] Batch 11/12                         Loss D: -199.6266, loss G: 15.6213\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [14/200] Batch 11/12                         Loss D: -226.0301, loss G: 15.2069\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [15/200] Batch 11/12                         Loss D: -254.9038, loss G: 15.1723\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [16/200] Batch 11/12                         Loss D: -272.5114, loss G: 16.6248\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [17/200] Batch 11/12                         Loss D: -295.4458, loss G: 17.5847\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [18/200] Batch 11/12                         Loss D: -313.0221, loss G: 18.7332\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [19/200] Batch 11/12                         Loss D: -334.0459, loss G: 19.8244\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [20/200] Batch 11/12                         Loss D: -354.5900, loss G: 20.8451\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [21/200] Batch 11/12                         Loss D: -373.1398, loss G: 21.9150\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [22/200] Batch 11/12                         Loss D: -387.7758, loss G: 23.0701\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [23/200] Batch 11/12                         Loss D: -411.9524, loss G: 23.8081\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [24/200] Batch 11/12                         Loss D: -418.7879, loss G: 25.0026\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [25/200] Batch 11/12                         Loss D: -440.2242, loss G: 25.8190\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [26/200] Batch 11/12                         Loss D: -445.6129, loss G: 26.9586\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [27/200] Batch 11/12                         Loss D: -473.7217, loss G: 27.7497\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [28/200] Batch 11/12                         Loss D: -481.7381, loss G: 28.7778\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [29/200] Batch 11/12                         Loss D: -482.3511, loss G: 29.9303\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [30/200] Batch 11/12                         Loss D: -512.3347, loss G: 30.7371\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [31/200] Batch 11/12                         Loss D: -523.5627, loss G: 31.7849\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [32/200] Batch 11/12                         Loss D: -542.5656, loss G: 32.8048\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [33/200] Batch 11/12                         Loss D: -566.4391, loss G: 34.1704\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [34/200] Batch 11/12                         Loss D: -553.5223, loss G: 34.9099\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [35/200] Batch 11/12                         Loss D: -571.6323, loss G: 35.9193\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [36/200] Batch 11/12                         Loss D: -570.6851, loss G: 36.8140\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [37/200] Batch 11/12                         Loss D: -559.5967, loss G: 37.6087\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [38/200] Batch 11/12                         Loss D: -560.6568, loss G: 38.4517\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [39/200] Batch 11/12                         Loss D: -541.5323, loss G: 39.0432\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [40/200] Batch 11/12                         Loss D: -526.6343, loss G: 39.5655\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [41/200] Batch 11/12                         Loss D: -497.1043, loss G: 39.8713\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [42/200] Batch 11/12                         Loss D: -466.9231, loss G: 40.0448\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [43/200] Batch 11/12                         Loss D: -438.1390, loss G: 40.2221\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [44/200] Batch 11/12                         Loss D: -384.6306, loss G: 39.7265\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [45/200] Batch 11/12                         Loss D: -341.4286, loss G: 39.3604\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [46/200] Batch 11/12                         Loss D: -286.8610, loss G: 38.7596\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [47/200] Batch 11/12                         Loss D: -220.4009, loss G: 37.8590\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [48/200] Batch 11/12                         Loss D: -138.0857, loss G: 36.6261\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [49/200] Batch 11/12                         Loss D: -91.7838, loss G: 36.2249\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [50/200] Batch 11/12                         Loss D: -53.6604, loss G: 35.5539\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [51/200] Batch 11/12                         Loss D: -20.7576, loss G: 34.6926\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [52/200] Batch 11/12                         Loss D: -16.7676, loss G: 34.3833\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [53/200] Batch 11/12                         Loss D: -17.8166, loss G: 34.3786\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [54/200] Batch 11/12                         Loss D: -18.7750, loss G: 34.4599\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [55/200] Batch 11/12                         Loss D: -18.6381, loss G: 34.4497\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [56/200] Batch 11/12                         Loss D: -19.2763, loss G: 34.4910\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [57/200] Batch 11/12                         Loss D: -19.9321, loss G: 34.5240\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [58/200] Batch 11/12                         Loss D: -20.0375, loss G: 34.5468\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [59/200] Batch 11/12                         Loss D: -20.4871, loss G: 34.5843\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [60/200] Batch 11/12                         Loss D: -21.3112, loss G: 34.6537\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [61/200] Batch 11/12                         Loss D: -19.5326, loss G: 34.6489\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [62/200] Batch 11/12                         Loss D: -21.1463, loss G: 34.6357\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [63/200] Batch 11/12                         Loss D: -5.8415, loss G: 33.9377\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [64/200] Batch 11/12                         Loss D: 4.2856, loss G: 33.8081\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [65/200] Batch 11/12                         Loss D: 0.4945, loss G: 33.9005\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [66/200] Batch 11/12                         Loss D: -1.3527, loss G: 34.0708\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [67/200] Batch 11/12                         Loss D: -3.1577, loss G: 34.2678\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [68/200] Batch 11/12                         Loss D: -5.3291, loss G: 34.4831\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [69/200] Batch 11/12                         Loss D: -6.6702, loss G: 34.5983\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [70/200] Batch 11/12                         Loss D: -4.6254, loss G: 34.7311\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [71/200] Batch 11/12                         Loss D: -3.1787, loss G: 34.7158\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [72/200] Batch 11/12                         Loss D: -2.1258, loss G: 34.7003\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [73/200] Batch 11/12                         Loss D: 0.1270, loss G: 34.6656\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [74/200] Batch 11/12                         Loss D: 2.2701, loss G: 34.6868\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [75/200] Batch 11/12                         Loss D: 0.0511, loss G: 34.7325\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [76/200] Batch 11/12                         Loss D: 0.8058, loss G: 34.7078\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [77/200] Batch 11/12                         Loss D: -2.4818, loss G: 34.7523\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [78/200] Batch 11/12                         Loss D: -3.6661, loss G: 34.8201\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [79/200] Batch 11/12                         Loss D: -0.2086, loss G: 34.7950\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [80/200] Batch 11/12                         Loss D: 1.7494, loss G: 34.8218\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [81/200] Batch 11/12                         Loss D: 0.7816, loss G: 34.8477\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [82/200] Batch 11/12                         Loss D: -6.5637, loss G: 34.9266\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [83/200] Batch 11/12                         Loss D: -5.2794, loss G: 34.9430\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [84/200] Batch 11/12                         Loss D: -4.2517, loss G: 34.9772\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [85/200] Batch 11/12                         Loss D: 1.0451, loss G: 34.9882\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [86/200] Batch 11/12                         Loss D: -1.7628, loss G: 35.0055\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [87/200] Batch 11/12                         Loss D: -5.7737, loss G: 35.0885\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [88/200] Batch 11/12                         Loss D: -3.1202, loss G: 35.1040\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [89/200] Batch 11/12                         Loss D: -0.9828, loss G: 35.1248\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [90/200] Batch 11/12                         Loss D: -2.2237, loss G: 35.1732\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [91/200] Batch 11/12                         Loss D: -1.8301, loss G: 35.2194\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [92/200] Batch 11/12                         Loss D: -2.7658, loss G: 35.2589\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [93/200] Batch 11/12                         Loss D: -2.6502, loss G: 35.3183\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [94/200] Batch 11/12                         Loss D: -5.4383, loss G: 35.3895\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [95/200] Batch 11/12                         Loss D: -1.2732, loss G: 35.4985\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [96/200] Batch 11/12                         Loss D: -9.1053, loss G: 35.5357\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [97/200] Batch 11/12                         Loss D: -4.9319, loss G: 35.5449\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [98/200] Batch 11/12                         Loss D: -4.8594, loss G: 35.5922\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [99/200] Batch 11/12                         Loss D: -5.3245, loss G: 35.6367\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [100/200] Batch 11/12                         Loss D: -4.4279, loss G: 35.6507\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [101/200] Batch 11/12                         Loss D: -3.1576, loss G: 35.6456\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [102/200] Batch 11/12                         Loss D: -1.3826, loss G: 35.6263\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [103/200] Batch 11/12                         Loss D: 3.1873, loss G: 35.5852\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [104/200] Batch 11/12                         Loss D: 4.9533, loss G: 35.6032\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [105/200] Batch 11/12                         Loss D: 1.3640, loss G: 35.6075\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [106/200] Batch 11/12                         Loss D: 6.0217, loss G: 35.6289\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [107/200] Batch 11/12                         Loss D: -0.6304, loss G: 35.6389\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [108/200] Batch 11/12                         Loss D: 4.1311, loss G: 35.6082\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [109/200] Batch 11/12                         Loss D: 4.5333, loss G: 35.6018\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [110/200] Batch 11/12                         Loss D: 6.3955, loss G: 35.6081\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [111/200] Batch 11/12                         Loss D: 2.5773, loss G: 35.6347\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [112/200] Batch 11/12                         Loss D: 3.5829, loss G: 35.6369\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [113/200] Batch 11/12                         Loss D: 5.0489, loss G: 35.6500\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [114/200] Batch 11/12                         Loss D: 7.0606, loss G: 35.6465\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [115/200] Batch 11/12                         Loss D: 6.6419, loss G: 35.6649\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [116/200] Batch 11/12                         Loss D: 0.8537, loss G: 35.7226\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [117/200] Batch 11/12                         Loss D: 6.9901, loss G: 35.6923\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [118/200] Batch 11/12                         Loss D: 8.5299, loss G: 35.7375\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [119/200] Batch 11/12                         Loss D: 8.2043, loss G: 35.7489\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [120/200] Batch 11/12                         Loss D: 6.8517, loss G: 35.7393\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [121/200] Batch 11/12                         Loss D: 7.0247, loss G: 35.7550\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [122/200] Batch 11/12                         Loss D: 6.3297, loss G: 35.7693\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [123/200] Batch 11/12                         Loss D: 0.7810, loss G: 35.7890\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [124/200] Batch 11/12                         Loss D: 3.1248, loss G: 35.7678\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [125/200] Batch 11/12                         Loss D: 4.3763, loss G: 35.7534\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [126/200] Batch 11/12                         Loss D: -1.5277, loss G: 35.7381\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [127/200] Batch 11/12                         Loss D: -1.5152, loss G: 35.7157\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [128/200] Batch 11/12                         Loss D: 2.8940, loss G: 35.6808\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [129/200] Batch 11/12                         Loss D: -0.3112, loss G: 35.7138\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [130/200] Batch 11/12                         Loss D: 4.1288, loss G: 35.7300\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [131/200] Batch 11/12                         Loss D: -2.4131, loss G: 35.7484\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [132/200] Batch 11/12                         Loss D: 2.0657, loss G: 35.7171\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [133/200] Batch 11/12                         Loss D: -1.8138, loss G: 35.7533\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [134/200] Batch 11/12                         Loss D: -0.9744, loss G: 35.7510\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [135/200] Batch 11/12                         Loss D: 3.7507, loss G: 35.7646\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [136/200] Batch 11/12                         Loss D: -2.9564, loss G: 35.7804\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [137/200] Batch 11/12                         Loss D: 1.1910, loss G: 35.7525\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [138/200] Batch 11/12                         Loss D: -2.0723, loss G: 35.7804\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [139/200] Batch 11/12                         Loss D: -0.8653, loss G: 35.7749\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [140/200] Batch 11/12                         Loss D: 3.3526, loss G: 35.7903\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [141/200] Batch 11/12                         Loss D: -2.8868, loss G: 35.8013\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [142/200] Batch 11/12                         Loss D: 1.3198, loss G: 35.7755\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [143/200] Batch 11/12                         Loss D: -0.9269, loss G: 35.7927\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [144/200] Batch 11/12                         Loss D: 0.5154, loss G: 35.7918\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [145/200] Batch 11/12                         Loss D: -2.3018, loss G: 35.8135\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [146/200] Batch 11/12                         Loss D: -1.0540, loss G: 35.8092\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [147/200] Batch 11/12                         Loss D: 2.5092, loss G: 35.8154\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [148/200] Batch 11/12                         Loss D: -3.2833, loss G: 35.8363\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [149/200] Batch 11/12                         Loss D: 0.2163, loss G: 35.8171\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [150/200] Batch 11/12                         Loss D: -0.8952, loss G: 35.8266\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [151/200] Batch 11/12                         Loss D: -0.0712, loss G: 35.8287\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [152/200] Batch 11/12                         Loss D: -1.0785, loss G: 35.8377\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [153/200] Batch 11/12                         Loss D: 2.1236, loss G: 35.8452\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [154/200] Batch 11/12                         Loss D: -4.1235, loss G: 35.8721\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [155/200] Batch 11/12                         Loss D: 1.4565, loss G: 35.8417\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [156/200] Batch 11/12                         Loss D: 1.1398, loss G: 35.8466\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [157/200] Batch 11/12                         Loss D: 0.3378, loss G: 35.8512\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [158/200] Batch 11/12                         Loss D: -2.7856, loss G: 35.8786\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [159/200] Batch 11/12                         Loss D: -2.1360, loss G: 35.8781\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [160/200] Batch 11/12                         Loss D: 2.4475, loss G: 35.8940\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [161/200] Batch 11/12                         Loss D: -4.1531, loss G: 35.9054\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [162/200] Batch 11/12                         Loss D: 0.1215, loss G: 35.8765\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [163/200] Batch 11/12                         Loss D: -2.9644, loss G: 35.9042\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [164/200] Batch 11/12                         Loss D: -2.2102, loss G: 35.9019\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [165/200] Batch 11/12                         Loss D: 2.7009, loss G: 35.9308\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [166/200] Batch 11/12                         Loss D: -3.9226, loss G: 35.9294\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [167/200] Batch 11/12                         Loss D: 0.5229, loss G: 35.8964\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [168/200] Batch 11/12                         Loss D: -3.2150, loss G: 35.9323\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [169/200] Batch 11/12                         Loss D: -1.7833, loss G: 35.9230\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [170/200] Batch 11/12                         Loss D: 0.3712, loss G: 35.9083\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [171/200] Batch 11/12                         Loss D: -2.2279, loss G: 35.9448\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [172/200] Batch 11/12                         Loss D: -1.1702, loss G: 35.9373\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [173/200] Batch 11/12                         Loss D: -0.4764, loss G: 35.9330\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [174/200] Batch 11/12                         Loss D: 1.0189, loss G: 35.9205\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [175/200] Batch 11/12                         Loss D: 1.7598, loss G: 35.9176\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [176/200] Batch 11/12                         Loss D: 0.6058, loss G: 35.9308\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [177/200] Batch 11/12                         Loss D: 3.2019, loss G: 35.9396\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [178/200] Batch 11/12                         Loss D: 3.1669, loss G: 35.9420\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [179/200] Batch 11/12                         Loss D: 1.1315, loss G: 35.9345\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [180/200] Batch 11/12                         Loss D: 3.7381, loss G: 35.9660\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [181/200] Batch 11/12                         Loss D: -1.0983, loss G: 35.9656\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [182/200] Batch 11/12                         Loss D: 4.1216, loss G: 35.9826\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [183/200] Batch 11/12                         Loss D: -1.8245, loss G: 35.9773\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [184/200] Batch 11/12                         Loss D: 3.2614, loss G: 35.9620\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [185/200] Batch 11/12                         Loss D: -1.3465, loss G: 35.9795\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [186/200] Batch 11/12                         Loss D: -0.1527, loss G: 35.9683\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [187/200] Batch 11/12                         Loss D: 0.0421, loss G: 35.9699\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [188/200] Batch 11/12                         Loss D: 1.2712, loss G: 35.9595\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [189/200] Batch 11/12                         Loss D: -0.1733, loss G: 35.9789\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [190/200] Batch 11/12                         Loss D: 3.9358, loss G: 35.9997\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [191/200] Batch 11/12                         Loss D: -2.8477, loss G: 36.0122\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [192/200] Batch 11/12                         Loss D: -1.6665, loss G: 36.0036\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [193/200] Batch 11/12                         Loss D: -0.8033, loss G: 35.9980\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [194/200] Batch 11/12                         Loss D: -1.8170, loss G: 36.0137\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [195/200] Batch 11/12                         Loss D: 2.7250, loss G: 35.9739\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [196/200] Batch 11/12                         Loss D: 0.0216, loss G: 36.0082\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [197/200] Batch 11/12                         Loss D: 13.5064, loss G: 35.8316\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [198/200] Batch 11/12                         Loss D: 12.4868, loss G: 35.7767\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [199/200] Batch 11/12                         Loss D: 12.4831, loss G: 35.7697\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [0/200] Batch 11/12                         Loss D: 8.8000, loss G: 17.2415\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [1/200] Batch 11/12                         Loss D: 9.8968, loss G: 16.9064\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [2/200] Batch 11/12                         Loss D: 11.2888, loss G: 16.3506\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [3/200] Batch 11/12                         Loss D: 11.6956, loss G: 15.7296\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [4/200] Batch 11/12                         Loss D: 11.3054, loss G: 15.4244\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [5/200] Batch 11/12                         Loss D: 10.4353, loss G: 14.7704\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [6/200] Batch 11/12                         Loss D: 9.4141, loss G: 13.9498\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [7/200] Batch 11/12                         Loss D: 7.5718, loss G: 12.9448\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [8/200] Batch 11/12                         Loss D: 4.6401, loss G: 11.6127\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [9/200] Batch 11/12                         Loss D: -0.1006, loss G: 9.9132\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [10/200] Batch 11/12                         Loss D: -7.1370, loss G: 8.2466\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [11/200] Batch 11/12                         Loss D: -13.9766, loss G: 7.6882\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [12/200] Batch 11/12                         Loss D: -21.6631, loss G: 7.3642\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [13/200] Batch 11/12                         Loss D: -32.2005, loss G: 6.9040\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [14/200] Batch 11/12                         Loss D: -43.5760, loss G: 6.3019\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [15/200] Batch 11/12                         Loss D: -57.0168, loss G: 5.8533\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [16/200] Batch 11/12                         Loss D: -75.3087, loss G: 5.6845\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [17/200] Batch 11/12                         Loss D: -86.9146, loss G: 6.3747\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [18/200] Batch 11/12                         Loss D: -97.8417, loss G: 6.9726\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [19/200] Batch 11/12                         Loss D: -108.2069, loss G: 7.6354\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [20/200] Batch 11/12                         Loss D: -116.8331, loss G: 8.4522\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [21/200] Batch 11/12                         Loss D: -129.0426, loss G: 8.9815\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [22/200] Batch 11/12                         Loss D: -135.5175, loss G: 9.7884\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [23/200] Batch 11/12                         Loss D: -145.8435, loss G: 10.3284\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [24/200] Batch 11/12                         Loss D: -154.2425, loss G: 10.9505\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [25/200] Batch 11/12                         Loss D: -164.5177, loss G: 11.4824\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [26/200] Batch 11/12                         Loss D: -174.1636, loss G: 12.0134\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [27/200] Batch 11/12                         Loss D: -181.5043, loss G: 12.5911\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [28/200] Batch 11/12                         Loss D: -188.6342, loss G: 13.1013\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [29/200] Batch 11/12                         Loss D: -197.9069, loss G: 13.7058\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [30/200] Batch 11/12                         Loss D: -203.1240, loss G: 14.2708\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [31/200] Batch 11/12                         Loss D: -205.0144, loss G: 14.7223\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [32/200] Batch 11/12                         Loss D: -213.3525, loss G: 15.2379\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [33/200] Batch 11/12                         Loss D: -218.5397, loss G: 15.8814\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [34/200] Batch 11/12                         Loss D: -216.1059, loss G: 16.3421\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [35/200] Batch 11/12                         Loss D: -218.7104, loss G: 16.8527\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [36/200] Batch 11/12                         Loss D: -211.7004, loss G: 17.0991\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [37/200] Batch 11/12                         Loss D: -203.9901, loss G: 17.3624\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [38/200] Batch 11/12                         Loss D: -196.3402, loss G: 17.5065\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [39/200] Batch 11/12                         Loss D: -179.1009, loss G: 17.4006\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [40/200] Batch 11/12                         Loss D: -159.7748, loss G: 17.2512\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [41/200] Batch 11/12                         Loss D: -140.8250, loss G: 16.8715\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [42/200] Batch 11/12                         Loss D: -128.8321, loss G: 16.8899\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [43/200] Batch 11/12                         Loss D: -117.7473, loss G: 16.9515\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [44/200] Batch 11/12                         Loss D: -115.0803, loss G: 16.9956\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [45/200] Batch 11/12                         Loss D: -115.8499, loss G: 17.0485\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [46/200] Batch 11/12                         Loss D: -117.8727, loss G: 17.2728\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [47/200] Batch 11/12                         Loss D: -124.4997, loss G: 17.5130\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [48/200] Batch 11/12                         Loss D: -129.0465, loss G: 17.7553\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [49/200] Batch 11/12                         Loss D: -133.0391, loss G: 17.9990\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [50/200] Batch 11/12                         Loss D: -135.7242, loss G: 18.2319\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [51/200] Batch 11/12                         Loss D: -136.4152, loss G: 18.4545\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [52/200] Batch 11/12                         Loss D: -135.3825, loss G: 18.6401\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [53/200] Batch 11/12                         Loss D: -137.0267, loss G: 18.8357\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [54/200] Batch 11/12                         Loss D: -133.0970, loss G: 18.9648\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [55/200] Batch 11/12                         Loss D: -130.7409, loss G: 19.0885\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [56/200] Batch 11/12                         Loss D: -126.6332, loss G: 19.1792\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [57/200] Batch 11/12                         Loss D: -119.9296, loss G: 19.2195\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [58/200] Batch 11/12                         Loss D: -113.9612, loss G: 19.2231\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [59/200] Batch 11/12                         Loss D: -107.6091, loss G: 19.2119\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [60/200] Batch 11/12                         Loss D: -95.9074, loss G: 19.1243\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [61/200] Batch 11/12                         Loss D: -86.1117, loss G: 18.9932\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [62/200] Batch 11/12                         Loss D: -72.5715, loss G: 18.7924\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [63/200] Batch 11/12                         Loss D: -56.5004, loss G: 18.5211\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [64/200] Batch 11/12                         Loss D: -37.5114, loss G: 18.1814\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [65/200] Batch 11/12                         Loss D: -12.9338, loss G: 17.7677\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [66/200] Batch 11/12                         Loss D: -2.6602, loss G: 17.6366\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [67/200] Batch 11/12                         Loss D: 20.1788, loss G: 16.6976\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [68/200] Batch 11/12                         Loss D: 20.2444, loss G: 16.8119\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [69/200] Batch 11/12                         Loss D: 20.6249, loss G: 16.8504\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [70/200] Batch 11/12                         Loss D: 20.0588, loss G: 16.8845\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [71/200] Batch 11/12                         Loss D: 19.8289, loss G: 16.8968\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [72/200] Batch 11/12                         Loss D: 18.9778, loss G: 16.8978\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [73/200] Batch 11/12                         Loss D: 17.4342, loss G: 16.8942\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [74/200] Batch 11/12                         Loss D: 17.4542, loss G: 16.9349\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [75/200] Batch 11/12                         Loss D: 17.3652, loss G: 16.8881\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [76/200] Batch 11/12                         Loss D: 17.3334, loss G: 16.8970\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [77/200] Batch 11/12                         Loss D: 16.8152, loss G: 16.8977\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [78/200] Batch 11/12                         Loss D: 17.9658, loss G: 16.9159\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [79/200] Batch 11/12                         Loss D: 17.3559, loss G: 16.9094\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [80/200] Batch 11/12                         Loss D: 17.7306, loss G: 16.8820\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [81/200] Batch 11/12                         Loss D: 17.3098, loss G: 16.8921\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [82/200] Batch 11/12                         Loss D: 17.6990, loss G: 16.8959\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [83/200] Batch 11/12                         Loss D: 17.5602, loss G: 16.8990\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [84/200] Batch 11/12                         Loss D: 18.3685, loss G: 16.8800\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [85/200] Batch 11/12                         Loss D: 17.1716, loss G: 16.8772\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [86/200] Batch 11/12                         Loss D: 17.9061, loss G: 16.8774\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [87/200] Batch 11/12                         Loss D: 18.0910, loss G: 16.8768\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [88/200] Batch 11/12                         Loss D: 17.9779, loss G: 16.8874\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [89/200] Batch 11/12                         Loss D: 17.7235, loss G: 16.8748\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [90/200] Batch 11/12                         Loss D: 18.2508, loss G: 16.8603\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [91/200] Batch 11/12                         Loss D: 17.6467, loss G: 16.8528\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [92/200] Batch 11/12                         Loss D: 16.9334, loss G: 16.8469\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [93/200] Batch 11/12                         Loss D: 18.0174, loss G: 16.8634\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [94/200] Batch 11/12                         Loss D: 17.6466, loss G: 16.8496\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [95/200] Batch 11/12                         Loss D: 17.1387, loss G: 16.8525\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [96/200] Batch 11/12                         Loss D: 17.3657, loss G: 16.8446\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [97/200] Batch 11/12                         Loss D: 17.0465, loss G: 16.8333\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [98/200] Batch 11/12                         Loss D: 17.4962, loss G: 16.8489\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [99/200] Batch 11/12                         Loss D: 17.4854, loss G: 16.8338\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [100/200] Batch 11/12                         Loss D: 16.9780, loss G: 16.8249\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [101/200] Batch 11/12                         Loss D: 16.7634, loss G: 16.8108\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [102/200] Batch 11/12                         Loss D: 17.6191, loss G: 16.8440\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [103/200] Batch 11/12                         Loss D: 17.0596, loss G: 16.8062\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [104/200] Batch 11/12                         Loss D: 16.4266, loss G: 16.7886\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [105/200] Batch 11/12                         Loss D: 16.7531, loss G: 16.7786\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [106/200] Batch 11/12                         Loss D: 16.0024, loss G: 16.7655\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [107/200] Batch 11/12                         Loss D: 15.4923, loss G: 16.7767\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [108/200] Batch 11/12                         Loss D: 14.8248, loss G: 16.7422\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [109/200] Batch 11/12                         Loss D: 14.9010, loss G: 16.7302\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [110/200] Batch 11/12                         Loss D: 14.9151, loss G: 16.7253\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [111/200] Batch 11/12                         Loss D: 15.1346, loss G: 16.7526\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [112/200] Batch 11/12                         Loss D: 15.2155, loss G: 16.7757\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [113/200] Batch 11/12                         Loss D: 15.0191, loss G: 16.7736\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [114/200] Batch 11/12                         Loss D: 14.7877, loss G: 16.7650\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [115/200] Batch 11/12                         Loss D: 14.8311, loss G: 16.7814\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [116/200] Batch 11/12                         Loss D: 14.4547, loss G: 16.7933\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [117/200] Batch 11/12                         Loss D: 14.9181, loss G: 16.7973\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [118/200] Batch 11/12                         Loss D: 14.3353, loss G: 16.8307\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [119/200] Batch 11/12                         Loss D: 14.8371, loss G: 16.8584\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [120/200] Batch 11/12                         Loss D: 13.9644, loss G: 16.8313\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [121/200] Batch 11/12                         Loss D: 14.2325, loss G: 16.8340\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [122/200] Batch 11/12                         Loss D: 14.0642, loss G: 16.8585\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [123/200] Batch 11/12                         Loss D: 14.1477, loss G: 16.8598\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [124/200] Batch 11/12                         Loss D: 13.8809, loss G: 16.8759\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [125/200] Batch 11/12                         Loss D: 13.4346, loss G: 16.9168\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [126/200] Batch 11/12                         Loss D: 12.7808, loss G: 16.8881\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [127/200] Batch 11/12                         Loss D: 13.3664, loss G: 16.8878\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [128/200] Batch 11/12                         Loss D: 12.2937, loss G: 16.8838\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [129/200] Batch 11/12                         Loss D: 13.0511, loss G: 16.9206\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [130/200] Batch 11/12                         Loss D: 12.2911, loss G: 16.9288\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [131/200] Batch 11/12                         Loss D: 11.2625, loss G: 16.9202\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [132/200] Batch 11/12                         Loss D: 10.4969, loss G: 16.9187\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [133/200] Batch 11/12                         Loss D: 10.7961, loss G: 16.9276\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [134/200] Batch 11/12                         Loss D: 10.7258, loss G: 16.9180\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [135/200] Batch 11/12                         Loss D: 10.6130, loss G: 16.9513\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [136/200] Batch 11/12                         Loss D: 9.8141, loss G: 16.9453\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [137/200] Batch 11/12                         Loss D: 9.6351, loss G: 16.9544\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [138/200] Batch 11/12                         Loss D: 8.2707, loss G: 16.9677\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [139/200] Batch 11/12                         Loss D: 8.3311, loss G: 16.9685\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [140/200] Batch 11/12                         Loss D: 7.9158, loss G: 16.9684\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [141/200] Batch 11/12                         Loss D: 7.4186, loss G: 16.9660\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [142/200] Batch 11/12                         Loss D: 6.6766, loss G: 16.9657\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [143/200] Batch 11/12                         Loss D: 6.1905, loss G: 16.9706\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [144/200] Batch 11/12                         Loss D: 5.9408, loss G: 16.9701\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [145/200] Batch 11/12                         Loss D: 5.3869, loss G: 16.9741\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [146/200] Batch 11/12                         Loss D: 5.2680, loss G: 16.9682\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [147/200] Batch 11/12                         Loss D: 5.1652, loss G: 16.9802\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [148/200] Batch 11/12                         Loss D: 4.9937, loss G: 16.9817\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [149/200] Batch 11/12                         Loss D: 4.6012, loss G: 16.9760\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [150/200] Batch 11/12                         Loss D: 3.9056, loss G: 16.9966\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [151/200] Batch 11/12                         Loss D: 3.1984, loss G: 16.9969\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [152/200] Batch 11/12                         Loss D: 2.7383, loss G: 16.9958\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [153/200] Batch 11/12                         Loss D: 2.4498, loss G: 17.0038\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [154/200] Batch 11/12                         Loss D: 1.9428, loss G: 17.0101\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [155/200] Batch 11/12                         Loss D: 1.9639, loss G: 17.0071\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [156/200] Batch 11/12                         Loss D: 1.4560, loss G: 17.0396\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [157/200] Batch 11/12                         Loss D: 0.8555, loss G: 17.0553\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [158/200] Batch 11/12                         Loss D: 0.2846, loss G: 17.0487\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [159/200] Batch 11/12                         Loss D: -0.2674, loss G: 17.0608\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [160/200] Batch 11/12                         Loss D: -0.7794, loss G: 17.0613\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [161/200] Batch 11/12                         Loss D: -1.3310, loss G: 17.0772\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [162/200] Batch 11/12                         Loss D: -2.0949, loss G: 17.0912\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [163/200] Batch 11/12                         Loss D: -2.2922, loss G: 17.0889\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [164/200] Batch 11/12                         Loss D: -2.2575, loss G: 17.1355\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [165/200] Batch 11/12                         Loss D: -3.6887, loss G: 17.1466\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [166/200] Batch 11/12                         Loss D: -4.2129, loss G: 17.1523\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [167/200] Batch 11/12                         Loss D: -4.6160, loss G: 17.1648\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [168/200] Batch 11/12                         Loss D: -5.6915, loss G: 17.1729\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [169/200] Batch 11/12                         Loss D: -6.0469, loss G: 17.2099\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [170/200] Batch 11/12                         Loss D: -6.8685, loss G: 17.1970\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [171/200] Batch 11/12                         Loss D: -7.4891, loss G: 17.2143\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [172/200] Batch 11/12                         Loss D: -8.1122, loss G: 17.2304\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [173/200] Batch 11/12                         Loss D: -7.9619, loss G: 17.2517\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [174/200] Batch 11/12                         Loss D: -8.8185, loss G: 17.2898\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [175/200] Batch 11/12                         Loss D: -10.1958, loss G: 17.2906\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [176/200] Batch 11/12                         Loss D: -11.0054, loss G: 17.2946\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [177/200] Batch 11/12                         Loss D: -11.8984, loss G: 17.2903\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [178/200] Batch 11/12                         Loss D: -12.7155, loss G: 17.2829\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [179/200] Batch 11/12                         Loss D: -13.3234, loss G: 17.2785\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [180/200] Batch 11/12                         Loss D: -13.7357, loss G: 17.2760\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [181/200] Batch 11/12                         Loss D: -13.8393, loss G: 17.2683\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [182/200] Batch 11/12                         Loss D: -14.2250, loss G: 17.2732\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [183/200] Batch 11/12                         Loss D: -14.1773, loss G: 17.2663\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [184/200] Batch 11/12                         Loss D: -14.3751, loss G: 17.2669\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [185/200] Batch 11/12                         Loss D: -14.1521, loss G: 17.2565\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [186/200] Batch 11/12                         Loss D: -14.3097, loss G: 17.2581\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [187/200] Batch 11/12                         Loss D: -14.8400, loss G: 17.2621\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [188/200] Batch 11/12                         Loss D: -15.4235, loss G: 17.2700\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [189/200] Batch 11/12                         Loss D: -16.0348, loss G: 17.2663\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [190/200] Batch 11/12                         Loss D: -16.0254, loss G: 17.2489\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [191/200] Batch 11/12                         Loss D: -16.9159, loss G: 17.2514\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [192/200] Batch 11/12                         Loss D: -17.5912, loss G: 17.2481\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [193/200] Batch 11/12                         Loss D: -18.1236, loss G: 17.2448\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [194/200] Batch 11/12                         Loss D: -18.7781, loss G: 17.2406\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [195/200] Batch 11/12                         Loss D: -19.6788, loss G: 17.2372\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [196/200] Batch 11/12                         Loss D: -20.5528, loss G: 17.2362\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [197/200] Batch 11/12                         Loss D: -21.3908, loss G: 17.2352\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [198/200] Batch 11/12                         Loss D: -23.1039, loss G: 17.2269\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [199/200] Batch 11/12                         Loss D: -24.1969, loss G: 17.2291\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [0/200] Batch 11/12                         Loss D: 7.9884, loss G: 3.3827\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [1/200] Batch 11/12                         Loss D: 8.4164, loss G: 3.3546\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [2/200] Batch 11/12                         Loss D: 9.3572, loss G: 3.3108\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [3/200] Batch 11/12                         Loss D: 10.6278, loss G: 3.2469\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [4/200] Batch 11/12                         Loss D: 12.1097, loss G: 3.1459\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [5/200] Batch 11/12                         Loss D: 12.3374, loss G: 3.0697\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [6/200] Batch 11/12                         Loss D: 11.3935, loss G: 3.0372\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [7/200] Batch 11/12                         Loss D: 9.3531, loss G: 3.0255\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [8/200] Batch 11/12                         Loss D: 5.5472, loss G: 3.0083\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [9/200] Batch 11/12                         Loss D: 1.6281, loss G: 2.9685\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [10/200] Batch 11/12                         Loss D: -2.6624, loss G: 3.0192\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [11/200] Batch 11/12                         Loss D: -7.6079, loss G: 3.1042\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [12/200] Batch 11/12                         Loss D: -12.7612, loss G: 3.2432\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [13/200] Batch 11/12                         Loss D: -17.2601, loss G: 3.4018\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [14/200] Batch 11/12                         Loss D: -20.0893, loss G: 3.5480\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [15/200] Batch 11/12                         Loss D: -20.0272, loss G: 3.6524\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [16/200] Batch 11/12                         Loss D: -17.4283, loss G: 3.6598\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [17/200] Batch 11/12                         Loss D: -15.8607, loss G: 3.6746\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [18/200] Batch 11/12                         Loss D: -15.0043, loss G: 3.7574\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [19/200] Batch 11/12                         Loss D: -13.8147, loss G: 3.7853\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [20/200] Batch 11/12                         Loss D: -11.9598, loss G: 3.5797\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [21/200] Batch 11/12                         Loss D: -12.0995, loss G: 3.4631\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [22/200] Batch 11/12                         Loss D: -16.7764, loss G: 3.4366\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [23/200] Batch 11/12                         Loss D: -20.7419, loss G: 3.5371\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [24/200] Batch 11/12                         Loss D: -24.6665, loss G: 3.6759\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [25/200] Batch 11/12                         Loss D: -27.3622, loss G: 3.8086\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [26/200] Batch 11/12                         Loss D: -28.8093, loss G: 3.9166\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [27/200] Batch 11/12                         Loss D: -27.8148, loss G: 3.9825\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [28/200] Batch 11/12                         Loss D: -26.4504, loss G: 4.0292\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [29/200] Batch 11/12                         Loss D: -24.2703, loss G: 4.0521\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [30/200] Batch 11/12                         Loss D: -21.1844, loss G: 4.0491\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [31/200] Batch 11/12                         Loss D: -18.2587, loss G: 4.0375\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [32/200] Batch 11/12                         Loss D: -14.6379, loss G: 4.0068\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [33/200] Batch 11/12                         Loss D: -10.8265, loss G: 3.9653\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [34/200] Batch 11/12                         Loss D: -6.8471, loss G: 3.9154\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [35/200] Batch 11/12                         Loss D: -2.5767, loss G: 3.8495\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [36/200] Batch 11/12                         Loss D: 4.3091, loss G: 3.7084\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [37/200] Batch 11/12                         Loss D: 7.5680, loss G: 3.4653\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [38/200] Batch 11/12                         Loss D: 7.6761, loss G: 3.4647\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [39/200] Batch 11/12                         Loss D: 7.6070, loss G: 3.4648\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [40/200] Batch 11/12                         Loss D: 7.6172, loss G: 3.4648\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [41/200] Batch 11/12                         Loss D: 7.6272, loss G: 3.4650\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [42/200] Batch 11/12                         Loss D: 7.5951, loss G: 3.4655\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [43/200] Batch 11/12                         Loss D: 7.6133, loss G: 3.4660\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [44/200] Batch 11/12                         Loss D: 7.6142, loss G: 3.4665\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [45/200] Batch 11/12                         Loss D: 7.5808, loss G: 3.4675\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [46/200] Batch 11/12                         Loss D: 7.5750, loss G: 3.4682\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [47/200] Batch 11/12                         Loss D: 7.5866, loss G: 3.4693\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [48/200] Batch 11/12                         Loss D: 7.5814, loss G: 3.4705\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [49/200] Batch 11/12                         Loss D: 7.5634, loss G: 3.4713\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [50/200] Batch 11/12                         Loss D: 7.5655, loss G: 3.4728\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [51/200] Batch 11/12                         Loss D: 7.5841, loss G: 3.4741\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [52/200] Batch 11/12                         Loss D: 7.5417, loss G: 3.4756\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [53/200] Batch 11/12                         Loss D: 7.5582, loss G: 3.4770\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [54/200] Batch 11/12                         Loss D: 7.5424, loss G: 3.4790\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [55/200] Batch 11/12                         Loss D: 7.5309, loss G: 3.4807\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [56/200] Batch 11/12                         Loss D: 7.5847, loss G: 3.4827\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [57/200] Batch 11/12                         Loss D: 7.5857, loss G: 3.4844\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [58/200] Batch 11/12                         Loss D: 7.5426, loss G: 3.4866\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [59/200] Batch 11/12                         Loss D: 7.5658, loss G: 3.4883\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [60/200] Batch 11/12                         Loss D: 7.5470, loss G: 3.4902\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [61/200] Batch 11/12                         Loss D: 7.5801, loss G: 3.4919\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [62/200] Batch 11/12                         Loss D: 7.6121, loss G: 3.4941\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [63/200] Batch 11/12                         Loss D: 7.6882, loss G: 3.4952\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [64/200] Batch 11/12                         Loss D: 8.1985, loss G: 3.4926\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [65/200] Batch 11/12                         Loss D: 8.6872, loss G: 3.4915\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [66/200] Batch 11/12                         Loss D: 8.6740, loss G: 3.4895\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [67/200] Batch 11/12                         Loss D: 8.5118, loss G: 3.4884\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [68/200] Batch 11/12                         Loss D: 8.5045, loss G: 3.4875\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [69/200] Batch 11/12                         Loss D: 8.4704, loss G: 3.4872\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [70/200] Batch 11/12                         Loss D: 8.3915, loss G: 3.4867\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [71/200] Batch 11/12                         Loss D: 8.3689, loss G: 3.4862\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [72/200] Batch 11/12                         Loss D: 8.3269, loss G: 3.4871\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [73/200] Batch 11/12                         Loss D: 8.2677, loss G: 3.4850\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [74/200] Batch 11/12                         Loss D: 8.2328, loss G: 3.4843\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [75/200] Batch 11/12                         Loss D: 8.1570, loss G: 3.4846\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [76/200] Batch 11/12                         Loss D: 8.1280, loss G: 3.4828\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [77/200] Batch 11/12                         Loss D: 8.0292, loss G: 3.4817\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [78/200] Batch 11/12                         Loss D: 7.9680, loss G: 3.4805\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [79/200] Batch 11/12                         Loss D: 8.2150, loss G: 3.4837\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [80/200] Batch 11/12                         Loss D: 7.8537, loss G: 3.4800\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [81/200] Batch 11/12                         Loss D: 8.0822, loss G: 3.4810\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [82/200] Batch 11/12                         Loss D: 7.7429, loss G: 3.4795\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [83/200] Batch 11/12                         Loss D: 7.9078, loss G: 3.4803\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [84/200] Batch 11/12                         Loss D: 7.6761, loss G: 3.4780\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [85/200] Batch 11/12                         Loss D: 7.6032, loss G: 3.4782\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [86/200] Batch 11/12                         Loss D: 7.5038, loss G: 3.4756\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [87/200] Batch 11/12                         Loss D: 7.7104, loss G: 3.4753\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [88/200] Batch 11/12                         Loss D: 7.4740, loss G: 3.4774\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [89/200] Batch 11/12                         Loss D: 7.4895, loss G: 3.4762\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [90/200] Batch 11/12                         Loss D: 7.5834, loss G: 3.4788\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [91/200] Batch 11/12                         Loss D: 7.6523, loss G: 3.4805\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [92/200] Batch 11/12                         Loss D: 7.7691, loss G: 3.4806\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [93/200] Batch 11/12                         Loss D: 7.3646, loss G: 3.4750\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [94/200] Batch 11/12                         Loss D: 7.7160, loss G: 3.4802\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [95/200] Batch 11/12                         Loss D: 7.1891, loss G: 3.4741\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [96/200] Batch 11/12                         Loss D: 7.4250, loss G: 3.4847\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [97/200] Batch 11/12                         Loss D: 6.9400, loss G: 3.4830\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [98/200] Batch 11/12                         Loss D: 7.0069, loss G: 3.4832\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [99/200] Batch 11/12                         Loss D: 7.2003, loss G: 3.4755\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [100/200] Batch 11/12                         Loss D: 7.0003, loss G: 3.4693\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [101/200] Batch 11/12                         Loss D: 7.1150, loss G: 3.4721\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [102/200] Batch 11/12                         Loss D: 6.9837, loss G: 3.4694\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [103/200] Batch 11/12                         Loss D: 6.8113, loss G: 3.4747\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [104/200] Batch 11/12                         Loss D: 6.6436, loss G: 3.4669\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [105/200] Batch 11/12                         Loss D: 6.7852, loss G: 3.4639\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [106/200] Batch 11/12                         Loss D: 6.6003, loss G: 3.4602\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [107/200] Batch 11/12                         Loss D: 6.5842, loss G: 3.4607\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [108/200] Batch 11/12                         Loss D: 6.3961, loss G: 3.4619\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [109/200] Batch 11/12                         Loss D: 6.6082, loss G: 3.4573\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [110/200] Batch 11/12                         Loss D: 6.3221, loss G: 3.4532\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [111/200] Batch 11/12                         Loss D: 6.2013, loss G: 3.4495\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [112/200] Batch 11/12                         Loss D: 6.1525, loss G: 3.4476\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [113/200] Batch 11/12                         Loss D: 6.0963, loss G: 3.4457\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [114/200] Batch 11/12                         Loss D: 6.0481, loss G: 3.4430\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [115/200] Batch 11/12                         Loss D: 5.9474, loss G: 3.4407\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [116/200] Batch 11/12                         Loss D: 5.9180, loss G: 3.4379\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [117/200] Batch 11/12                         Loss D: 5.8302, loss G: 3.4355\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [118/200] Batch 11/12                         Loss D: 5.9086, loss G: 3.4343\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [119/200] Batch 11/12                         Loss D: 5.8647, loss G: 3.4345\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [120/200] Batch 11/12                         Loss D: 5.7465, loss G: 3.4308\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [121/200] Batch 11/12                         Loss D: 5.8328, loss G: 3.4304\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [122/200] Batch 11/12                         Loss D: 5.6103, loss G: 3.4272\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [123/200] Batch 11/12                         Loss D: 5.3647, loss G: 3.4198\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [124/200] Batch 11/12                         Loss D: 5.1070, loss G: 3.4157\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [125/200] Batch 11/12                         Loss D: 5.0184, loss G: 3.4105\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [126/200] Batch 11/12                         Loss D: 4.9916, loss G: 3.4119\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [127/200] Batch 11/12                         Loss D: 4.7060, loss G: 3.4012\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [128/200] Batch 11/12                         Loss D: 4.5438, loss G: 3.3964\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [129/200] Batch 11/12                         Loss D: 3.8856, loss G: 3.3927\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [130/200] Batch 11/12                         Loss D: 3.8481, loss G: 3.3818\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [131/200] Batch 11/12                         Loss D: 3.4319, loss G: 3.3691\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [132/200] Batch 11/12                         Loss D: 3.2277, loss G: 3.3608\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [133/200] Batch 11/12                         Loss D: 3.3304, loss G: 3.3574\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [134/200] Batch 11/12                         Loss D: 3.0039, loss G: 3.3455\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [135/200] Batch 11/12                         Loss D: 3.1136, loss G: 3.3448\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [136/200] Batch 11/12                         Loss D: 2.8170, loss G: 3.3305\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [137/200] Batch 11/12                         Loss D: 2.6416, loss G: 3.3285\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [138/200] Batch 11/12                         Loss D: 2.7031, loss G: 3.3175\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [139/200] Batch 11/12                         Loss D: 2.5108, loss G: 3.3103\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [140/200] Batch 11/12                         Loss D: 2.3758, loss G: 3.3010\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [141/200] Batch 11/12                         Loss D: 2.3422, loss G: 3.2937\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [142/200] Batch 11/12                         Loss D: 2.1926, loss G: 3.2861\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [143/200] Batch 11/12                         Loss D: 2.1037, loss G: 3.2782\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [144/200] Batch 11/12                         Loss D: 1.9619, loss G: 3.2722\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [145/200] Batch 11/12                         Loss D: 1.7284, loss G: 3.2615\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [146/200] Batch 11/12                         Loss D: 1.7840, loss G: 3.2544\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [147/200] Batch 11/12                         Loss D: 1.8127, loss G: 3.2489\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [148/200] Batch 11/12                         Loss D: 2.2974, loss G: 3.2487\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [149/200] Batch 11/12                         Loss D: 3.8839, loss G: 3.2522\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [150/200] Batch 11/12                         Loss D: 6.6014, loss G: 3.2550\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [151/200] Batch 11/12                         Loss D: 15.4350, loss G: 3.1912\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [152/200] Batch 11/12                         Loss D: 16.6766, loss G: 3.2695\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [153/200] Batch 11/12                         Loss D: 15.2671, loss G: 3.3689\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [154/200] Batch 11/12                         Loss D: 13.5170, loss G: 3.4392\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [155/200] Batch 11/12                         Loss D: 12.1400, loss G: 3.4877\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [156/200] Batch 11/12                         Loss D: 11.0178, loss G: 3.5171\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [157/200] Batch 11/12                         Loss D: 10.1912, loss G: 3.5360\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [158/200] Batch 11/12                         Loss D: 9.5956, loss G: 3.5479\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [159/200] Batch 11/12                         Loss D: 7.5522, loss G: 3.5547\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [160/200] Batch 11/12                         Loss D: 4.7117, loss G: 3.5369\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [161/200] Batch 11/12                         Loss D: 5.4566, loss G: 3.4776\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [162/200] Batch 11/12                         Loss D: 5.5534, loss G: 3.4777\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [163/200] Batch 11/12                         Loss D: 5.6085, loss G: 3.4760\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [164/200] Batch 11/12                         Loss D: 5.6169, loss G: 3.4758\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [165/200] Batch 11/12                         Loss D: 5.8321, loss G: 3.4751\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [166/200] Batch 11/12                         Loss D: 5.6634, loss G: 3.4747\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [167/200] Batch 11/12                         Loss D: 5.9539, loss G: 3.4754\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [168/200] Batch 11/12                         Loss D: 6.0800, loss G: 3.4748\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [169/200] Batch 11/12                         Loss D: 6.2463, loss G: 3.4740\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [170/200] Batch 11/12                         Loss D: 6.0194, loss G: 3.4743\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [171/200] Batch 11/12                         Loss D: 6.3669, loss G: 3.4754\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [172/200] Batch 11/12                         Loss D: 5.1316, loss G: 3.4768\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [173/200] Batch 11/12                         Loss D: 5.1010, loss G: 3.4703\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [174/200] Batch 11/12                         Loss D: 5.2682, loss G: 3.4681\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [175/200] Batch 11/12                         Loss D: 4.9892, loss G: 3.4669\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [176/200] Batch 11/12                         Loss D: 5.2501, loss G: 3.4712\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [177/200] Batch 11/12                         Loss D: 4.9400, loss G: 3.4672\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [178/200] Batch 11/12                         Loss D: 4.6228, loss G: 3.4649\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [179/200] Batch 11/12                         Loss D: 4.8130, loss G: 3.4646\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [180/200] Batch 11/12                         Loss D: 4.3268, loss G: 3.4638\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [181/200] Batch 11/12                         Loss D: 4.3078, loss G: 3.4614\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [182/200] Batch 11/12                         Loss D: 4.1576, loss G: 3.4611\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [183/200] Batch 11/12                         Loss D: 4.5516, loss G: 3.4641\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [184/200] Batch 11/12                         Loss D: 4.1520, loss G: 3.4572\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [185/200] Batch 11/12                         Loss D: 4.2210, loss G: 3.4667\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [186/200] Batch 11/12                         Loss D: 4.2641, loss G: 3.4564\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [187/200] Batch 11/12                         Loss D: 4.0647, loss G: 3.4520\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [188/200] Batch 11/12                         Loss D: 4.1439, loss G: 3.4543\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [189/200] Batch 11/12                         Loss D: 4.4571, loss G: 3.4552\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [190/200] Batch 11/12                         Loss D: 4.1173, loss G: 3.4567\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [191/200] Batch 11/12                         Loss D: 4.0126, loss G: 3.4509\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [192/200] Batch 11/12                         Loss D: 4.5238, loss G: 3.4535\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [193/200] Batch 11/12                         Loss D: 4.2310, loss G: 3.4569\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [194/200] Batch 11/12                         Loss D: 4.2996, loss G: 3.4633\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [195/200] Batch 11/12                         Loss D: 4.2106, loss G: 3.4525\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [196/200] Batch 11/12                         Loss D: 3.8974, loss G: 3.4546\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [197/200] Batch 11/12                         Loss D: 4.1045, loss G: 3.4594\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [198/200] Batch 11/12                         Loss D: 3.8797, loss G: 3.4632\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [199/200] Batch 11/12                         Loss D: 3.9587, loss G: 3.4627\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [0/200] Batch 11/12                         Loss D: 1.4220, loss G: 34.3161\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [1/200] Batch 11/12                         Loss D: 2.7286, loss G: 33.6261\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [2/200] Batch 11/12                         Loss D: 4.5244, loss G: 32.4485\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [3/200] Batch 11/12                         Loss D: 6.9484, loss G: 30.6642\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [4/200] Batch 11/12                         Loss D: 9.5102, loss G: 28.6997\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [5/200] Batch 11/12                         Loss D: 11.3655, loss G: 27.1281\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [6/200] Batch 11/12                         Loss D: 13.6983, loss G: 24.8350\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [7/200] Batch 11/12                         Loss D: 16.0129, loss G: 22.0537\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [8/200] Batch 11/12                         Loss D: 18.2896, loss G: 18.4410\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [9/200] Batch 11/12                         Loss D: 19.7066, loss G: 14.2738\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [10/200] Batch 11/12                         Loss D: 20.2964, loss G: 9.6729\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [11/200] Batch 11/12                         Loss D: 16.8149, loss G: 7.8358\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [12/200] Batch 11/12                         Loss D: 13.3044, loss G: 6.1325\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [13/200] Batch 11/12                         Loss D: 9.3973, loss G: 4.0417\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [14/200] Batch 11/12                         Loss D: 5.0359, loss G: 1.7107\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [15/200] Batch 11/12                         Loss D: -0.3358, loss G: 0.7868\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [16/200] Batch 11/12                         Loss D: -5.6524, loss G: 0.9999\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [17/200] Batch 11/12                         Loss D: -11.2449, loss G: 1.5532\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [18/200] Batch 11/12                         Loss D: -16.1465, loss G: 1.3865\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [19/200] Batch 11/12                         Loss D: -21.2689, loss G: 1.7160\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [20/200] Batch 11/12                         Loss D: -26.5789, loss G: 2.0139\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [21/200] Batch 11/12                         Loss D: -31.9391, loss G: 2.4015\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [22/200] Batch 11/12                         Loss D: -38.0755, loss G: 2.4591\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [23/200] Batch 11/12                         Loss D: -43.9811, loss G: 2.8457\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [24/200] Batch 11/12                         Loss D: -49.5415, loss G: 3.2915\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [25/200] Batch 11/12                         Loss D: -56.9213, loss G: 4.0107\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [26/200] Batch 11/12                         Loss D: -62.1480, loss G: 3.9264\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [27/200] Batch 11/12                         Loss D: -68.9077, loss G: 4.2088\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [28/200] Batch 11/12                         Loss D: -78.0383, loss G: 5.6630\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [29/200] Batch 11/12                         Loss D: -83.8858, loss G: 5.4409\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [30/200] Batch 11/12                         Loss D: -89.7263, loss G: 5.5380\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [31/200] Batch 11/12                         Loss D: -95.2167, loss G: 6.3837\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [32/200] Batch 11/12                         Loss D: -105.2410, loss G: 6.3551\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [33/200] Batch 11/12                         Loss D: -113.3112, loss G: 6.9129\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [34/200] Batch 11/12                         Loss D: -121.1574, loss G: 7.3146\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [35/200] Batch 11/12                         Loss D: -128.4846, loss G: 7.7661\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [36/200] Batch 11/12                         Loss D: -137.6293, loss G: 8.2734\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [37/200] Batch 11/12                         Loss D: -146.4518, loss G: 8.8628\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [38/200] Batch 11/12                         Loss D: -155.3906, loss G: 9.3903\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [39/200] Batch 11/12                         Loss D: -162.6411, loss G: 9.7528\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [40/200] Batch 11/12                         Loss D: -174.1154, loss G: 10.5401\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [41/200] Batch 11/12                         Loss D: -182.7480, loss G: 10.8607\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [42/200] Batch 11/12                         Loss D: -190.6660, loss G: 11.4127\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [43/200] Batch 11/12                         Loss D: -201.5936, loss G: 11.9384\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [44/200] Batch 11/12                         Loss D: -211.7845, loss G: 12.4776\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [45/200] Batch 11/12                         Loss D: -221.8918, loss G: 13.0809\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [46/200] Batch 11/12                         Loss D: -229.6653, loss G: 13.8615\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [47/200] Batch 11/12                         Loss D: -237.9981, loss G: 14.6992\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [48/200] Batch 11/12                         Loss D: -252.2501, loss G: 15.0339\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [49/200] Batch 11/12                         Loss D: -263.1737, loss G: 15.6441\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [50/200] Batch 11/12                         Loss D: -273.3840, loss G: 16.3729\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [51/200] Batch 11/12                         Loss D: -287.4230, loss G: 16.8974\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [52/200] Batch 11/12                         Loss D: -297.7650, loss G: 17.6558\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [53/200] Batch 11/12                         Loss D: -307.9022, loss G: 18.4351\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [54/200] Batch 11/12                         Loss D: -319.4297, loss G: 19.1949\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [55/200] Batch 11/12                         Loss D: -335.8643, loss G: 19.7388\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [56/200] Batch 11/12                         Loss D: -350.3523, loss G: 20.6902\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [57/200] Batch 11/12                         Loss D: -362.1997, loss G: 21.2403\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [58/200] Batch 11/12                         Loss D: -369.9310, loss G: 22.1787\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [59/200] Batch 11/12                         Loss D: -385.0739, loss G: 22.8967\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [60/200] Batch 11/12                         Loss D: -402.2581, loss G: 23.6228\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [61/200] Batch 11/12                         Loss D: -410.6156, loss G: 24.5570\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [62/200] Batch 11/12                         Loss D: -433.0150, loss G: 25.6061\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [63/200] Batch 11/12                         Loss D: -441.6234, loss G: 26.1812\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [64/200] Batch 11/12                         Loss D: -452.9764, loss G: 27.0630\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [65/200] Batch 11/12                         Loss D: -470.8658, loss G: 27.8883\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [66/200] Batch 11/12                         Loss D: -483.2679, loss G: 28.8283\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [67/200] Batch 11/12                         Loss D: -499.7410, loss G: 29.7153\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [68/200] Batch 11/12                         Loss D: -518.4459, loss G: 30.5833\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [69/200] Batch 11/12                         Loss D: -529.6675, loss G: 31.4854\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [70/200] Batch 11/12                         Loss D: -541.4479, loss G: 32.4375\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [71/200] Batch 11/12                         Loss D: -561.1454, loss G: 33.3719\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [72/200] Batch 11/12                         Loss D: -562.9937, loss G: 34.3119\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [73/200] Batch 11/12                         Loss D: -579.3315, loss G: 35.2569\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [74/200] Batch 11/12                         Loss D: -587.4493, loss G: 36.1243\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [75/200] Batch 11/12                         Loss D: -594.2669, loss G: 37.0253\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [76/200] Batch 11/12                         Loss D: -603.4661, loss G: 37.8921\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [77/200] Batch 11/12                         Loss D: -608.1499, loss G: 38.7188\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [78/200] Batch 11/12                         Loss D: -600.1331, loss G: 39.4088\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [79/200] Batch 11/12                         Loss D: -603.4169, loss G: 40.1409\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [80/200] Batch 11/12                         Loss D: -589.3765, loss G: 40.6310\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [81/200] Batch 11/12                         Loss D: -576.5435, loss G: 41.0622\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [82/200] Batch 11/12                         Loss D: -554.5878, loss G: 41.3163\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [83/200] Batch 11/12                         Loss D: -533.7272, loss G: 41.4968\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [84/200] Batch 11/12                         Loss D: -497.9517, loss G: 41.3762\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [85/200] Batch 11/12                         Loss D: -451.3234, loss G: 41.0234\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [86/200] Batch 11/12                         Loss D: -382.0618, loss G: 40.2051\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [87/200] Batch 11/12                         Loss D: -277.9106, loss G: 38.6607\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [88/200] Batch 11/12                         Loss D: -134.9760, loss G: 36.3968\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [89/200] Batch 11/12                         Loss D: 15.4360, loss G: 33.9194\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [90/200] Batch 11/12                         Loss D: 15.0418, loss G: 33.8932\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [91/200] Batch 11/12                         Loss D: 7.4075, loss G: 33.9141\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [92/200] Batch 11/12                         Loss D: 5.6786, loss G: 33.8133\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [93/200] Batch 11/12                         Loss D: 5.1524, loss G: 33.7703\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [94/200] Batch 11/12                         Loss D: -2.3678, loss G: 33.7130\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [95/200] Batch 11/12                         Loss D: 18.0118, loss G: 28.5031\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [96/200] Batch 11/12                         Loss D: 295.4071, loss G: 12.7864\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [97/200] Batch 11/12                         Loss D: 513.6702, loss G: 1.4827\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [98/200] Batch 11/12                         Loss D: 649.0652, loss G: -1.7585\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [99/200] Batch 11/12                         Loss D: 648.8968, loss G: 2.7642\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [100/200] Batch 11/12                         Loss D: 618.4050, loss G: 7.0660\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [101/200] Batch 11/12                         Loss D: 577.4705, loss G: 10.7675\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [102/200] Batch 11/12                         Loss D: 529.8621, loss G: 13.9946\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [103/200] Batch 11/12                         Loss D: 484.6467, loss G: 16.5445\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [104/200] Batch 11/12                         Loss D: 439.2382, loss G: 18.6994\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [105/200] Batch 11/12                         Loss D: 380.1880, loss G: 20.0806\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [106/200] Batch 11/12                         Loss D: 329.0558, loss G: 21.1926\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [107/200] Batch 11/12                         Loss D: 283.2526, loss G: 21.7527\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [108/200] Batch 11/12                         Loss D: 235.4085, loss G: 22.1249\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [109/200] Batch 11/12                         Loss D: 195.8363, loss G: 21.8764\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [110/200] Batch 11/12                         Loss D: 162.9066, loss G: 22.0085\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [111/200] Batch 11/12                         Loss D: 142.1870, loss G: 22.7969\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [112/200] Batch 11/12                         Loss D: 139.0225, loss G: 23.4568\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [113/200] Batch 11/12                         Loss D: 129.7142, loss G: 24.1950\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [114/200] Batch 11/12                         Loss D: 117.8200, loss G: 24.8116\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [115/200] Batch 11/12                         Loss D: 107.0686, loss G: 25.5227\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [116/200] Batch 11/12                         Loss D: 94.5289, loss G: 26.4028\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [117/200] Batch 11/12                         Loss D: 85.2416, loss G: 26.9388\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [118/200] Batch 11/12                         Loss D: 75.6165, loss G: 27.7080\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [119/200] Batch 11/12                         Loss D: 72.5660, loss G: 28.5204\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [120/200] Batch 11/12                         Loss D: 51.0998, loss G: 29.1727\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [121/200] Batch 11/12                         Loss D: 42.9447, loss G: 29.7989\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [122/200] Batch 11/12                         Loss D: 33.0808, loss G: 30.5436\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [123/200] Batch 11/12                         Loss D: 20.2425, loss G: 31.2704\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [124/200] Batch 11/12                         Loss D: 20.9647, loss G: 32.0796\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [125/200] Batch 11/12                         Loss D: 5.2424, loss G: 32.6222\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [126/200] Batch 11/12                         Loss D: -3.0320, loss G: 33.3404\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [127/200] Batch 11/12                         Loss D: -18.6717, loss G: 33.9599\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [128/200] Batch 11/12                         Loss D: -23.4893, loss G: 34.6129\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [129/200] Batch 11/12                         Loss D: -33.2480, loss G: 35.2603\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [130/200] Batch 11/12                         Loss D: -45.4456, loss G: 35.8840\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [131/200] Batch 11/12                         Loss D: -44.9710, loss G: 36.4299\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [132/200] Batch 11/12                         Loss D: -56.4288, loss G: 36.9263\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [133/200] Batch 11/12                         Loss D: -63.6293, loss G: 37.3989\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [134/200] Batch 11/12                         Loss D: -61.7148, loss G: 37.7912\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [135/200] Batch 11/12                         Loss D: -70.9378, loss G: 38.1161\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [136/200] Batch 11/12                         Loss D: -73.8440, loss G: 38.3909\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [137/200] Batch 11/12                         Loss D: -75.0077, loss G: 38.6059\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [138/200] Batch 11/12                         Loss D: -76.5816, loss G: 38.7579\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [139/200] Batch 11/12                         Loss D: -75.2031, loss G: 38.7869\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [140/200] Batch 11/12                         Loss D: -70.4059, loss G: 38.8679\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [141/200] Batch 11/12                         Loss D: -74.4304, loss G: 38.7943\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [142/200] Batch 11/12                         Loss D: -67.7500, loss G: 38.7750\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [143/200] Batch 11/12                         Loss D: -67.7143, loss G: 38.6040\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [144/200] Batch 11/12                         Loss D: -65.2154, loss G: 38.4049\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [145/200] Batch 11/12                         Loss D: -63.9950, loss G: 38.1988\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [146/200] Batch 11/12                         Loss D: -65.9949, loss G: 37.8950\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [147/200] Batch 11/12                         Loss D: -57.1053, loss G: 37.5913\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [148/200] Batch 11/12                         Loss D: -53.7868, loss G: 37.2588\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [149/200] Batch 11/12                         Loss D: -54.0104, loss G: 36.9518\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [150/200] Batch 11/12                         Loss D: -41.7763, loss G: 36.5672\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [151/200] Batch 11/12                         Loss D: -42.3896, loss G: 36.1805\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [152/200] Batch 11/12                         Loss D: -28.2065, loss G: 35.8017\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [153/200] Batch 11/12                         Loss D: -20.2057, loss G: 35.4366\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [154/200] Batch 11/12                         Loss D: -8.1874, loss G: 35.1391\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [155/200] Batch 11/12                         Loss D: 3.7534, loss G: 34.7708\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [156/200] Batch 11/12                         Loss D: 9.0161, loss G: 34.5068\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [157/200] Batch 11/12                         Loss D: 12.3309, loss G: 34.3481\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [158/200] Batch 11/12                         Loss D: 11.5650, loss G: 34.2188\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [159/200] Batch 11/12                         Loss D: 9.5912, loss G: 34.1178\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [160/200] Batch 11/12                         Loss D: 5.7939, loss G: 34.2386\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [161/200] Batch 11/12                         Loss D: 8.6795, loss G: 34.3586\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [162/200] Batch 11/12                         Loss D: 10.3577, loss G: 34.5586\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [163/200] Batch 11/12                         Loss D: 7.4160, loss G: 34.6912\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [164/200] Batch 11/12                         Loss D: 10.2285, loss G: 34.8800\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [165/200] Batch 11/12                         Loss D: 5.9042, loss G: 35.0499\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [166/200] Batch 11/12                         Loss D: 2.5370, loss G: 35.2623\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [167/200] Batch 11/12                         Loss D: 2.4957, loss G: 35.2899\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [168/200] Batch 11/12                         Loss D: 10.3237, loss G: 35.2936\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [169/200] Batch 11/12                         Loss D: 8.6251, loss G: 35.2392\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [170/200] Batch 11/12                         Loss D: 8.1357, loss G: 35.2910\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [171/200] Batch 11/12                         Loss D: 7.1491, loss G: 35.3476\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [172/200] Batch 11/12                         Loss D: 9.1697, loss G: 35.3976\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [173/200] Batch 11/12                         Loss D: 10.1357, loss G: 35.4017\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [174/200] Batch 11/12                         Loss D: 11.8349, loss G: 35.3847\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [175/200] Batch 11/12                         Loss D: 13.8753, loss G: 35.3135\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [176/200] Batch 11/12                         Loss D: 12.7538, loss G: 35.1451\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [177/200] Batch 11/12                         Loss D: 12.3483, loss G: 35.1517\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [178/200] Batch 11/12                         Loss D: 12.3466, loss G: 35.1636\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [179/200] Batch 11/12                         Loss D: 10.4078, loss G: 35.1508\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [180/200] Batch 11/12                         Loss D: 8.7988, loss G: 35.1418\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [181/200] Batch 11/12                         Loss D: 7.4271, loss G: 35.1345\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [182/200] Batch 11/12                         Loss D: 6.0865, loss G: 35.1265\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [183/200] Batch 11/12                         Loss D: 4.5415, loss G: 35.1164\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [184/200] Batch 11/12                         Loss D: 2.5353, loss G: 35.1026\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [185/200] Batch 11/12                         Loss D: 1.0104, loss G: 35.0930\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [186/200] Batch 11/12                         Loss D: -0.7585, loss G: 35.0793\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [187/200] Batch 11/12                         Loss D: -2.2186, loss G: 35.0695\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [188/200] Batch 11/12                         Loss D: -2.6470, loss G: 35.0700\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [189/200] Batch 11/12                         Loss D: -2.9660, loss G: 35.0668\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [190/200] Batch 11/12                         Loss D: -2.9668, loss G: 35.0666\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [191/200] Batch 11/12                         Loss D: -2.9397, loss G: 35.0662\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [192/200] Batch 11/12                         Loss D: -2.9233, loss G: 35.0687\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [193/200] Batch 11/12                         Loss D: -3.1226, loss G: 35.0665\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [194/200] Batch 11/12                         Loss D: -3.2566, loss G: 35.0656\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [195/200] Batch 11/12                         Loss D: -3.0527, loss G: 35.0666\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [196/200] Batch 11/12                         Loss D: -3.1079, loss G: 35.0669\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [197/200] Batch 11/12                         Loss D: -3.1974, loss G: 35.0643\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [198/200] Batch 11/12                         Loss D: -3.1996, loss G: 35.0673\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [199/200] Batch 11/12                         Loss D: -3.1718, loss G: 35.0663\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [0/200] Batch 11/12                         Loss D: 0.7872, loss G: 16.9897\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [1/200] Batch 11/12                         Loss D: 0.5634, loss G: 16.6923\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [2/200] Batch 11/12                         Loss D: -0.0722, loss G: 16.1956\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [3/200] Batch 11/12                         Loss D: -1.4111, loss G: 15.4292\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [4/200] Batch 11/12                         Loss D: -3.6953, loss G: 14.4210\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [5/200] Batch 11/12                         Loss D: -6.2677, loss G: 13.5870\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [6/200] Batch 11/12                         Loss D: -10.0598, loss G: 12.6856\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [7/200] Batch 11/12                         Loss D: -15.5814, loss G: 11.5740\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [8/200] Batch 11/12                         Loss D: -22.8544, loss G: 10.3052\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [9/200] Batch 11/12                         Loss D: -33.2767, loss G: 8.7899\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [10/200] Batch 11/12                         Loss D: -44.1827, loss G: 7.4195\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [11/200] Batch 11/12                         Loss D: -52.6330, loss G: 6.8251\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [12/200] Batch 11/12                         Loss D: -58.3014, loss G: 6.2072\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [13/200] Batch 11/12                         Loss D: -67.6375, loss G: 5.5553\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [14/200] Batch 11/12                         Loss D: -76.3107, loss G: 4.8440\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [15/200] Batch 11/12                         Loss D: -85.0431, loss G: 4.8920\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [16/200] Batch 11/12                         Loss D: -92.2285, loss G: 5.3541\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [17/200] Batch 11/12                         Loss D: -100.0476, loss G: 5.7781\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [18/200] Batch 11/12                         Loss D: -106.3887, loss G: 6.0949\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [19/200] Batch 11/12                         Loss D: -112.7063, loss G: 6.6237\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [20/200] Batch 11/12                         Loss D: -118.9485, loss G: 6.9070\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [21/200] Batch 11/12                         Loss D: -127.1890, loss G: 7.2781\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [22/200] Batch 11/12                         Loss D: -133.4464, loss G: 7.6402\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [23/200] Batch 11/12                         Loss D: -140.0055, loss G: 7.9652\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [24/200] Batch 11/12                         Loss D: -148.0428, loss G: 8.1894\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [25/200] Batch 11/12                         Loss D: -153.7019, loss G: 8.7432\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [26/200] Batch 11/12                         Loss D: -157.1880, loss G: 9.0979\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [27/200] Batch 11/12                         Loss D: -164.4258, loss G: 9.4854\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [28/200] Batch 11/12                         Loss D: -169.5765, loss G: 9.9743\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [29/200] Batch 11/12                         Loss D: -172.5228, loss G: 10.3847\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [30/200] Batch 11/12                         Loss D: -177.1225, loss G: 10.7771\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [31/200] Batch 11/12                         Loss D: -177.5327, loss G: 11.3243\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [32/200] Batch 11/12                         Loss D: -178.7986, loss G: 11.7735\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [33/200] Batch 11/12                         Loss D: -177.5723, loss G: 12.2619\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [34/200] Batch 11/12                         Loss D: -172.6387, loss G: 12.7686\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [35/200] Batch 11/12                         Loss D: -171.3701, loss G: 13.1356\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [36/200] Batch 11/12                         Loss D: -162.0200, loss G: 13.6247\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [37/200] Batch 11/12                         Loss D: -158.1747, loss G: 13.9600\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [38/200] Batch 11/12                         Loss D: -147.7721, loss G: 14.3755\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [39/200] Batch 11/12                         Loss D: -143.6855, loss G: 14.6249\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [40/200] Batch 11/12                         Loss D: -138.5659, loss G: 14.9439\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [41/200] Batch 11/12                         Loss D: -139.0049, loss G: 15.2531\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [42/200] Batch 11/12                         Loss D: -140.0946, loss G: 15.5629\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [43/200] Batch 11/12                         Loss D: -143.7103, loss G: 15.8316\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [44/200] Batch 11/12                         Loss D: -146.7174, loss G: 16.1135\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [45/200] Batch 11/12                         Loss D: -150.1596, loss G: 16.4170\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [46/200] Batch 11/12                         Loss D: -155.8001, loss G: 16.7153\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [47/200] Batch 11/12                         Loss D: -156.9818, loss G: 17.0185\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [48/200] Batch 11/12                         Loss D: -176.7181, loss G: 17.3267\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [49/200] Batch 11/12                         Loss D: -195.9527, loss G: 17.8469\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [50/200] Batch 11/12                         Loss D: -195.4101, loss G: 18.1818\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [51/200] Batch 11/12                         Loss D: -188.5979, loss G: 18.4438\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [52/200] Batch 11/12                         Loss D: -184.8985, loss G: 18.7121\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [53/200] Batch 11/12                         Loss D: -177.5700, loss G: 18.9263\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [54/200] Batch 11/12                         Loss D: -166.1695, loss G: 19.0610\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [55/200] Batch 11/12                         Loss D: -153.2054, loss G: 19.1541\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [56/200] Batch 11/12                         Loss D: -135.2995, loss G: 19.1796\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [57/200] Batch 11/12                         Loss D: -106.2416, loss G: 19.0710\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [58/200] Batch 11/12                         Loss D: -114.5482, loss G: 19.3746\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [59/200] Batch 11/12                         Loss D: -119.2483, loss G: 19.3702\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [60/200] Batch 11/12                         Loss D: -117.2384, loss G: 19.4030\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [61/200] Batch 11/12                         Loss D: -111.2728, loss G: 19.2235\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [62/200] Batch 11/12                         Loss D: -98.7564, loss G: 18.9173\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [63/200] Batch 11/12                         Loss D: -86.1501, loss G: 17.8851\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [64/200] Batch 11/12                         Loss D: -58.9090, loss G: 16.3478\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [65/200] Batch 11/12                         Loss D: -53.0603, loss G: 16.1956\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [66/200] Batch 11/12                         Loss D: -54.1361, loss G: 16.4217\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [67/200] Batch 11/12                         Loss D: -48.5772, loss G: 16.5089\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [68/200] Batch 11/12                         Loss D: -37.4051, loss G: 16.5079\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [69/200] Batch 11/12                         Loss D: -22.2520, loss G: 16.3315\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [70/200] Batch 11/12                         Loss D: 0.6302, loss G: 16.1705\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [71/200] Batch 11/12                         Loss D: 1.1439, loss G: 16.2879\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [72/200] Batch 11/12                         Loss D: 0.4611, loss G: 16.3327\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [73/200] Batch 11/12                         Loss D: 0.9290, loss G: 16.4002\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [74/200] Batch 11/12                         Loss D: 0.6247, loss G: 16.4382\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [75/200] Batch 11/12                         Loss D: 0.7685, loss G: 16.4222\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [76/200] Batch 11/12                         Loss D: 0.8059, loss G: 16.4297\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [77/200] Batch 11/12                         Loss D: 0.5009, loss G: 16.4428\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [78/200] Batch 11/12                         Loss D: 0.4712, loss G: 16.4457\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [79/200] Batch 11/12                         Loss D: 0.5080, loss G: 16.4750\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [80/200] Batch 11/12                         Loss D: 0.5480, loss G: 16.4672\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [81/200] Batch 11/12                         Loss D: 0.4708, loss G: 16.4807\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [82/200] Batch 11/12                         Loss D: 0.7124, loss G: 16.4851\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [83/200] Batch 11/12                         Loss D: 0.5851, loss G: 16.4845\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [84/200] Batch 11/12                         Loss D: 0.5104, loss G: 16.4955\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [85/200] Batch 11/12                         Loss D: 0.8626, loss G: 16.5081\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [86/200] Batch 11/12                         Loss D: 0.3522, loss G: 16.5261\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [87/200] Batch 11/12                         Loss D: 0.6160, loss G: 16.5314\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [88/200] Batch 11/12                         Loss D: 0.7450, loss G: 16.5235\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [89/200] Batch 11/12                         Loss D: 0.5883, loss G: 16.5488\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [90/200] Batch 11/12                         Loss D: 0.8020, loss G: 16.5364\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [91/200] Batch 11/12                         Loss D: 0.7470, loss G: 16.5393\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [92/200] Batch 11/12                         Loss D: 0.6930, loss G: 16.5545\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [93/200] Batch 11/12                         Loss D: 1.3254, loss G: 16.5606\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [94/200] Batch 11/12                         Loss D: 1.3156, loss G: 16.5646\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [95/200] Batch 11/12                         Loss D: 1.3632, loss G: 16.5664\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [96/200] Batch 11/12                         Loss D: 1.3902, loss G: 16.5749\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [97/200] Batch 11/12                         Loss D: 1.3455, loss G: 16.5796\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [98/200] Batch 11/12                         Loss D: 1.4292, loss G: 16.5863\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [99/200] Batch 11/12                         Loss D: 0.7538, loss G: 16.5874\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [100/200] Batch 11/12                         Loss D: 0.2090, loss G: 16.5936\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [101/200] Batch 11/12                         Loss D: 1.1470, loss G: 16.5971\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [102/200] Batch 11/12                         Loss D: 1.0869, loss G: 16.6072\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [103/200] Batch 11/12                         Loss D: 0.4851, loss G: 16.6056\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [104/200] Batch 11/12                         Loss D: 0.8883, loss G: 16.6166\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [105/200] Batch 11/12                         Loss D: 0.9291, loss G: 16.6145\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [106/200] Batch 11/12                         Loss D: -0.0198, loss G: 16.6145\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [107/200] Batch 11/12                         Loss D: 0.6409, loss G: 16.6279\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [108/200] Batch 11/12                         Loss D: 0.7027, loss G: 16.6307\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [109/200] Batch 11/12                         Loss D: 0.4901, loss G: 16.6342\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [110/200] Batch 11/12                         Loss D: 0.1603, loss G: 16.6363\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [111/200] Batch 11/12                         Loss D: 0.0922, loss G: 16.6447\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [112/200] Batch 11/12                         Loss D: 0.1837, loss G: 16.6514\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [113/200] Batch 11/12                         Loss D: -0.0053, loss G: 16.6621\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [114/200] Batch 11/12                         Loss D: -0.5618, loss G: 16.6703\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [115/200] Batch 11/12                         Loss D: 0.0666, loss G: 16.6975\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [116/200] Batch 11/12                         Loss D: 0.5856, loss G: 16.7338\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [117/200] Batch 11/12                         Loss D: 0.9549, loss G: 16.7666\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [118/200] Batch 11/12                         Loss D: 1.4819, loss G: 16.8092\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [119/200] Batch 11/12                         Loss D: 1.4299, loss G: 16.8441\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [120/200] Batch 11/12                         Loss D: 1.3752, loss G: 16.8522\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [121/200] Batch 11/12                         Loss D: 1.5071, loss G: 16.8461\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [122/200] Batch 11/12                         Loss D: 1.8461, loss G: 16.8399\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [123/200] Batch 11/12                         Loss D: 1.9128, loss G: 16.8387\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [124/200] Batch 11/12                         Loss D: 1.9836, loss G: 16.8380\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [125/200] Batch 11/12                         Loss D: 2.0958, loss G: 16.8361\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [126/200] Batch 11/12                         Loss D: 2.0297, loss G: 16.8342\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [127/200] Batch 11/12                         Loss D: 2.0858, loss G: 16.8315\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [128/200] Batch 11/12                         Loss D: 2.3811, loss G: 16.8280\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [129/200] Batch 11/12                         Loss D: 2.6534, loss G: 16.8246\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [130/200] Batch 11/12                         Loss D: 2.7175, loss G: 16.8254\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [131/200] Batch 11/12                         Loss D: 1.5819, loss G: 16.8333\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [132/200] Batch 11/12                         Loss D: 2.5106, loss G: 16.8210\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [133/200] Batch 11/12                         Loss D: 2.7082, loss G: 16.8237\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [134/200] Batch 11/12                         Loss D: 3.0412, loss G: 16.8252\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [135/200] Batch 11/12                         Loss D: 2.0863, loss G: 16.8197\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [136/200] Batch 11/12                         Loss D: 2.1734, loss G: 16.8204\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [137/200] Batch 11/12                         Loss D: 2.2947, loss G: 16.8168\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [138/200] Batch 11/12                         Loss D: 3.6800, loss G: 16.8526\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [139/200] Batch 11/12                         Loss D: 2.3432, loss G: 16.8152\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [140/200] Batch 11/12                         Loss D: 1.1879, loss G: 16.8275\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [141/200] Batch 11/12                         Loss D: 2.0162, loss G: 16.8134\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [142/200] Batch 11/12                         Loss D: 1.9154, loss G: 16.8130\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [143/200] Batch 11/12                         Loss D: 1.7667, loss G: 16.8135\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [144/200] Batch 11/12                         Loss D: 2.6674, loss G: 16.8193\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [145/200] Batch 11/12                         Loss D: 1.8851, loss G: 16.8101\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [146/200] Batch 11/12                         Loss D: 2.4243, loss G: 16.8113\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [147/200] Batch 11/12                         Loss D: 2.1816, loss G: 16.8084\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [148/200] Batch 11/12                         Loss D: 1.6391, loss G: 16.8081\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [149/200] Batch 11/12                         Loss D: 2.5420, loss G: 16.8138\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [150/200] Batch 11/12                         Loss D: -0.6559, loss G: 16.8533\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [151/200] Batch 11/12                         Loss D: 1.5486, loss G: 16.8055\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [152/200] Batch 11/12                         Loss D: 0.2205, loss G: 16.8291\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [153/200] Batch 11/12                         Loss D: 2.2532, loss G: 16.8086\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [154/200] Batch 11/12                         Loss D: 2.0819, loss G: 16.8052\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [155/200] Batch 11/12                         Loss D: 1.4669, loss G: 16.8012\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [156/200] Batch 11/12                         Loss D: 1.7049, loss G: 16.8048\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [157/200] Batch 11/12                         Loss D: 1.2203, loss G: 16.8018\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [158/200] Batch 11/12                         Loss D: 1.7792, loss G: 16.8018\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [159/200] Batch 11/12                         Loss D: 2.9067, loss G: 16.8299\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [160/200] Batch 11/12                         Loss D: 1.3916, loss G: 16.7954\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [161/200] Batch 11/12                         Loss D: 1.3715, loss G: 16.7949\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [162/200] Batch 11/12                         Loss D: 1.0731, loss G: 16.7978\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [163/200] Batch 11/12                         Loss D: 0.8336, loss G: 16.8001\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [164/200] Batch 11/12                         Loss D: 1.6890, loss G: 16.7950\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [165/200] Batch 11/12                         Loss D: 1.0975, loss G: 16.7925\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [166/200] Batch 11/12                         Loss D: 0.6849, loss G: 16.7987\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [167/200] Batch 11/12                         Loss D: -0.3176, loss G: 16.8182\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [168/200] Batch 11/12                         Loss D: 1.7180, loss G: 16.8009\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [169/200] Batch 11/12                         Loss D: 0.4008, loss G: 16.8007\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [170/200] Batch 11/12                         Loss D: 0.6319, loss G: 16.7934\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [171/200] Batch 11/12                         Loss D: 2.1665, loss G: 16.8228\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [172/200] Batch 11/12                         Loss D: 1.1810, loss G: 16.7867\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [173/200] Batch 11/12                         Loss D: 1.1325, loss G: 16.7911\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [174/200] Batch 11/12                         Loss D: 0.7171, loss G: 16.7872\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [175/200] Batch 11/12                         Loss D: 1.2536, loss G: 16.7871\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [176/200] Batch 11/12                         Loss D: 1.6194, loss G: 16.7932\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [177/200] Batch 11/12                         Loss D: 0.3751, loss G: 16.7911\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [178/200] Batch 11/12                         Loss D: -0.0553, loss G: 16.7965\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [179/200] Batch 11/12                         Loss D: 0.4652, loss G: 16.7865\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [180/200] Batch 11/12                         Loss D: 0.7051, loss G: 16.7823\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [181/200] Batch 11/12                         Loss D: -0.7327, loss G: 16.8074\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [182/200] Batch 11/12                         Loss D: 0.4263, loss G: 16.7820\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [183/200] Batch 11/12                         Loss D: -0.6978, loss G: 16.8027\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [184/200] Batch 11/12                         Loss D: -0.8419, loss G: 16.8039\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [185/200] Batch 11/12                         Loss D: -0.4974, loss G: 16.7968\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [186/200] Batch 11/12                         Loss D: -0.1150, loss G: 16.7863\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [187/200] Batch 11/12                         Loss D: -0.6719, loss G: 16.7963\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [188/200] Batch 11/12                         Loss D: -0.2375, loss G: 16.7853\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [189/200] Batch 11/12                         Loss D: -0.6182, loss G: 16.7931\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [190/200] Batch 11/12                         Loss D: 0.0455, loss G: 16.7741\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [191/200] Batch 11/12                         Loss D: 0.2000, loss G: 16.7718\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [192/200] Batch 11/12                         Loss D: -0.0005, loss G: 16.7758\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [193/200] Batch 11/12                         Loss D: -0.8930, loss G: 16.7934\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [194/200] Batch 11/12                         Loss D: -0.1159, loss G: 16.7776\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [195/200] Batch 11/12                         Loss D: -0.5058, loss G: 16.7817\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [196/200] Batch 11/12                         Loss D: 0.3475, loss G: 16.7693\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [197/200] Batch 11/12                         Loss D: 0.8771, loss G: 16.7835\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [198/200] Batch 11/12                         Loss D: 0.9574, loss G: 16.7871\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [199/200] Batch 11/12                         Loss D: 0.7122, loss G: 16.7842\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [0/200] Batch 11/12                         Loss D: 1.2225, loss G: 3.6607\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [1/200] Batch 11/12                         Loss D: 1.1479, loss G: 3.6092\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [2/200] Batch 11/12                         Loss D: 0.9753, loss G: 3.5098\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [3/200] Batch 11/12                         Loss D: 0.6059, loss G: 3.3797\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [4/200] Batch 11/12                         Loss D: -0.0696, loss G: 3.2347\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [5/200] Batch 11/12                         Loss D: -1.0396, loss G: 3.1427\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [6/200] Batch 11/12                         Loss D: -2.1723, loss G: 3.1054\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [7/200] Batch 11/12                         Loss D: -3.6816, loss G: 3.0748\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [8/200] Batch 11/12                         Loss D: -5.5296, loss G: 3.0665\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [9/200] Batch 11/12                         Loss D: -8.0591, loss G: 3.0581\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [10/200] Batch 11/12                         Loss D: -12.2986, loss G: 3.0804\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [11/200] Batch 11/12                         Loss D: -17.8606, loss G: 3.1213\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [12/200] Batch 11/12                         Loss D: -23.1094, loss G: 3.1975\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [13/200] Batch 11/12                         Loss D: -29.0422, loss G: 3.2918\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [14/200] Batch 11/12                         Loss D: -32.8175, loss G: 3.4078\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [15/200] Batch 11/12                         Loss D: -35.0044, loss G: 3.5300\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [16/200] Batch 11/12                         Loss D: -35.7650, loss G: 3.6421\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [17/200] Batch 11/12                         Loss D: -34.9243, loss G: 3.7315\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [18/200] Batch 11/12                         Loss D: -33.1092, loss G: 3.7928\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [19/200] Batch 11/12                         Loss D: -31.2768, loss G: 3.8326\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [20/200] Batch 11/12                         Loss D: -27.6438, loss G: 3.8381\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [21/200] Batch 11/12                         Loss D: -24.0238, loss G: 3.8264\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [22/200] Batch 11/12                         Loss D: -20.6527, loss G: 3.8059\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [23/200] Batch 11/12                         Loss D: -17.2711, loss G: 3.7756\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [24/200] Batch 11/12                         Loss D: -13.9958, loss G: 3.7391\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [25/200] Batch 11/12                         Loss D: -11.0948, loss G: 3.7013\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [26/200] Batch 11/12                         Loss D: -8.6136, loss G: 3.6641\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [27/200] Batch 11/12                         Loss D: -6.3198, loss G: 3.6281\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [28/200] Batch 11/12                         Loss D: -4.7379, loss G: 3.6167\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [29/200] Batch 11/12                         Loss D: -3.6765, loss G: 3.6145\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [30/200] Batch 11/12                         Loss D: -2.6169, loss G: 3.6134\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [31/200] Batch 11/12                         Loss D: -2.2504, loss G: 3.6139\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [32/200] Batch 11/12                         Loss D: -1.8313, loss G: 3.6152\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [33/200] Batch 11/12                         Loss D: -1.6706, loss G: 3.6162\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [34/200] Batch 11/12                         Loss D: -1.6058, loss G: 3.6179\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [35/200] Batch 11/12                         Loss D: -1.5489, loss G: 3.6202\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [36/200] Batch 11/12                         Loss D: -1.4772, loss G: 3.6230\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [37/200] Batch 11/12                         Loss D: -1.4956, loss G: 3.6249\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [38/200] Batch 11/12                         Loss D: -1.5010, loss G: 3.6271\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [39/200] Batch 11/12                         Loss D: -1.4927, loss G: 3.6295\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [40/200] Batch 11/12                         Loss D: -1.5034, loss G: 3.6317\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [41/200] Batch 11/12                         Loss D: -1.5109, loss G: 3.6333\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [42/200] Batch 11/12                         Loss D: -1.5755, loss G: 3.6356\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [43/200] Batch 11/12                         Loss D: -1.5650, loss G: 3.6373\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [44/200] Batch 11/12                         Loss D: -1.7200, loss G: 3.6389\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [45/200] Batch 11/12                         Loss D: -1.9160, loss G: 3.6411\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [46/200] Batch 11/12                         Loss D: -2.1730, loss G: 3.6427\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [47/200] Batch 11/12                         Loss D: -2.3319, loss G: 3.6442\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [48/200] Batch 11/12                         Loss D: -2.5044, loss G: 3.6456\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [49/200] Batch 11/12                         Loss D: -2.6614, loss G: 3.6467\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [50/200] Batch 11/12                         Loss D: -2.8099, loss G: 3.6476\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [51/200] Batch 11/12                         Loss D: -2.8021, loss G: 3.6480\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [52/200] Batch 11/12                         Loss D: -2.7954, loss G: 3.6484\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [53/200] Batch 11/12                         Loss D: -2.7516, loss G: 3.6489\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [54/200] Batch 11/12                         Loss D: -2.7010, loss G: 3.6492\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [55/200] Batch 11/12                         Loss D: -2.6823, loss G: 3.6497\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [56/200] Batch 11/12                         Loss D: -2.6196, loss G: 3.6500\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [57/200] Batch 11/12                         Loss D: -2.6192, loss G: 3.6505\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [58/200] Batch 11/12                         Loss D: -2.5110, loss G: 3.6507\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [59/200] Batch 11/12                         Loss D: -2.3761, loss G: 3.6509\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [60/200] Batch 11/12                         Loss D: -1.7184, loss G: 3.6488\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [61/200] Batch 11/12                         Loss D: -1.5319, loss G: 3.6488\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [62/200] Batch 11/12                         Loss D: -1.5403, loss G: 3.6495\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [63/200] Batch 11/12                         Loss D: -1.6195, loss G: 3.6500\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [64/200] Batch 11/12                         Loss D: -1.6707, loss G: 3.6504\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [65/200] Batch 11/12                         Loss D: -1.6965, loss G: 3.6506\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [66/200] Batch 11/12                         Loss D: -1.7538, loss G: 3.6509\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [67/200] Batch 11/12                         Loss D: -1.7491, loss G: 3.6509\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [68/200] Batch 11/12                         Loss D: -1.7378, loss G: 3.6509\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [69/200] Batch 11/12                         Loss D: -1.7090, loss G: 3.6507\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [70/200] Batch 11/12                         Loss D: -1.7135, loss G: 3.6506\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [71/200] Batch 11/12                         Loss D: -1.6933, loss G: 3.6505\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [72/200] Batch 11/12                         Loss D: -1.6595, loss G: 3.6503\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [73/200] Batch 11/12                         Loss D: -1.6847, loss G: 3.6497\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [74/200] Batch 11/12                         Loss D: -1.7265, loss G: 3.6493\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [75/200] Batch 11/12                         Loss D: -1.6893, loss G: 3.6487\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [76/200] Batch 11/12                         Loss D: -1.7044, loss G: 3.6484\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [77/200] Batch 11/12                         Loss D: -1.7867, loss G: 3.6481\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [78/200] Batch 11/12                         Loss D: -1.6658, loss G: 3.6476\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [79/200] Batch 11/12                         Loss D: -1.7724, loss G: 3.6473\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [80/200] Batch 11/12                         Loss D: -1.7007, loss G: 3.6467\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [81/200] Batch 11/12                         Loss D: -1.7005, loss G: 3.6464\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [82/200] Batch 11/12                         Loss D: -1.6988, loss G: 3.6461\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [83/200] Batch 11/12                         Loss D: -1.6650, loss G: 3.6457\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [84/200] Batch 11/12                         Loss D: -1.6563, loss G: 3.6452\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [85/200] Batch 11/12                         Loss D: -1.6795, loss G: 3.6449\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [86/200] Batch 11/12                         Loss D: -1.7347, loss G: 3.6444\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [87/200] Batch 11/12                         Loss D: -1.7433, loss G: 3.6438\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [88/200] Batch 11/12                         Loss D: -1.7517, loss G: 3.6434\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [89/200] Batch 11/12                         Loss D: -1.6621, loss G: 3.6428\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [90/200] Batch 11/12                         Loss D: -1.6933, loss G: 3.6423\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [91/200] Batch 11/12                         Loss D: -1.6884, loss G: 3.6418\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [92/200] Batch 11/12                         Loss D: -1.6566, loss G: 3.6414\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [93/200] Batch 11/12                         Loss D: -1.6564, loss G: 3.6409\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [94/200] Batch 11/12                         Loss D: -1.6333, loss G: 3.6406\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [95/200] Batch 11/12                         Loss D: -1.7371, loss G: 3.6398\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [96/200] Batch 11/12                         Loss D: -1.8404, loss G: 3.6398\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [97/200] Batch 11/12                         Loss D: -1.6068, loss G: 3.6390\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [98/200] Batch 11/12                         Loss D: -1.7340, loss G: 3.6383\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [99/200] Batch 11/12                         Loss D: -1.6432, loss G: 3.6379\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [100/200] Batch 11/12                         Loss D: -1.7073, loss G: 3.6370\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [101/200] Batch 11/12                         Loss D: -1.7133, loss G: 3.6361\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [102/200] Batch 11/12                         Loss D: -1.6900, loss G: 3.6356\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [103/200] Batch 11/12                         Loss D: -1.6015, loss G: 3.6352\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [104/200] Batch 11/12                         Loss D: -1.6494, loss G: 3.6344\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [105/200] Batch 11/12                         Loss D: -1.7754, loss G: 3.6338\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [106/200] Batch 11/12                         Loss D: -1.7692, loss G: 3.6329\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [107/200] Batch 11/12                         Loss D: -1.7522, loss G: 3.6320\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [108/200] Batch 11/12                         Loss D: -1.7645, loss G: 3.6314\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [109/200] Batch 11/12                         Loss D: -1.5937, loss G: 3.6309\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [110/200] Batch 11/12                         Loss D: -1.7725, loss G: 3.6298\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [111/200] Batch 11/12                         Loss D: -1.7839, loss G: 3.6290\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [112/200] Batch 11/12                         Loss D: -1.8515, loss G: 3.6288\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [113/200] Batch 11/12                         Loss D: -1.6546, loss G: 3.6275\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [114/200] Batch 11/12                         Loss D: -1.7882, loss G: 3.6265\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [115/200] Batch 11/12                         Loss D: -1.4641, loss G: 3.6266\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [116/200] Batch 11/12                         Loss D: -1.7778, loss G: 3.6248\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [117/200] Batch 11/12                         Loss D: -1.7354, loss G: 3.6237\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [118/200] Batch 11/12                         Loss D: -1.8004, loss G: 3.6226\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [119/200] Batch 11/12                         Loss D: -1.7538, loss G: 3.6217\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [120/200] Batch 11/12                         Loss D: -1.7251, loss G: 3.6208\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [121/200] Batch 11/12                         Loss D: -1.5438, loss G: 3.6205\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [122/200] Batch 11/12                         Loss D: -1.7811, loss G: 3.6189\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [123/200] Batch 11/12                         Loss D: -1.7425, loss G: 3.6179\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [124/200] Batch 11/12                         Loss D: -1.7004, loss G: 3.6175\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [125/200] Batch 11/12                         Loss D: -1.6938, loss G: 3.6162\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [126/200] Batch 11/12                         Loss D: -1.6477, loss G: 3.6146\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [127/200] Batch 11/12                         Loss D: -1.7640, loss G: 3.6134\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [128/200] Batch 11/12                         Loss D: -1.7384, loss G: 3.6122\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [129/200] Batch 11/12                         Loss D: -1.8020, loss G: 3.6113\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [130/200] Batch 11/12                         Loss D: -1.7605, loss G: 3.6099\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [131/200] Batch 11/12                         Loss D: -1.8305, loss G: 3.6088\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [132/200] Batch 11/12                         Loss D: -1.8030, loss G: 3.6078\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [133/200] Batch 11/12                         Loss D: -1.7240, loss G: 3.6064\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [134/200] Batch 11/12                         Loss D: -1.7834, loss G: 3.6051\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [135/200] Batch 11/12                         Loss D: -1.7958, loss G: 3.6038\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [136/200] Batch 11/12                         Loss D: -1.7934, loss G: 3.6024\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [137/200] Batch 11/12                         Loss D: -1.8097, loss G: 3.6013\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [138/200] Batch 11/12                         Loss D: -1.6916, loss G: 3.5999\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [139/200] Batch 11/12                         Loss D: -1.8077, loss G: 3.5986\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [140/200] Batch 11/12                         Loss D: -1.7869, loss G: 3.5973\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [141/200] Batch 11/12                         Loss D: -1.7486, loss G: 3.5964\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [142/200] Batch 11/12                         Loss D: -1.6364, loss G: 3.5950\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [143/200] Batch 11/12                         Loss D: -1.4407, loss G: 3.5944\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [144/200] Batch 11/12                         Loss D: -1.0352, loss G: 3.5945\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [145/200] Batch 11/12                         Loss D: 2.6355, loss G: 3.5948\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [146/200] Batch 11/12                         Loss D: 1.9396, loss G: 3.5910\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [147/200] Batch 11/12                         Loss D: 1.6668, loss G: 3.5930\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [148/200] Batch 11/12                         Loss D: 1.2080, loss G: 3.5962\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [149/200] Batch 11/12                         Loss D: 0.4659, loss G: 3.5963\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [150/200] Batch 11/12                         Loss D: 0.3892, loss G: 3.5958\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [151/200] Batch 11/12                         Loss D: 0.3730, loss G: 3.5975\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [152/200] Batch 11/12                         Loss D: 0.5179, loss G: 3.5947\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [153/200] Batch 11/12                         Loss D: 0.5606, loss G: 3.5937\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [154/200] Batch 11/12                         Loss D: 0.5426, loss G: 3.5929\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [155/200] Batch 11/12                         Loss D: 0.5772, loss G: 3.5925\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [156/200] Batch 11/12                         Loss D: 0.2096, loss G: 3.5940\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [157/200] Batch 11/12                         Loss D: 0.4565, loss G: 3.5918\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [158/200] Batch 11/12                         Loss D: 0.5226, loss G: 3.5949\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [159/200] Batch 11/12                         Loss D: 0.4432, loss G: 3.5923\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [160/200] Batch 11/12                         Loss D: 1.5749, loss G: 3.5976\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [161/200] Batch 11/12                         Loss D: 0.7417, loss G: 3.5958\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [162/200] Batch 11/12                         Loss D: 0.9015, loss G: 3.5959\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [163/200] Batch 11/12                         Loss D: 0.4786, loss G: 3.5963\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [164/200] Batch 11/12                         Loss D: 0.5652, loss G: 3.5943\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [165/200] Batch 11/12                         Loss D: 0.5388, loss G: 3.5928\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [166/200] Batch 11/12                         Loss D: 0.4905, loss G: 3.5915\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [167/200] Batch 11/12                         Loss D: 0.4626, loss G: 3.5905\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [168/200] Batch 11/12                         Loss D: 0.9094, loss G: 3.5954\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [169/200] Batch 11/12                         Loss D: 0.8697, loss G: 3.5929\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [170/200] Batch 11/12                         Loss D: 0.5513, loss G: 3.5898\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [171/200] Batch 11/12                         Loss D: 1.0610, loss G: 3.6014\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [172/200] Batch 11/12                         Loss D: 0.4926, loss G: 3.5928\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [173/200] Batch 11/12                         Loss D: 0.4568, loss G: 3.5915\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [174/200] Batch 11/12                         Loss D: 0.0626, loss G: 3.5962\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [175/200] Batch 11/12                         Loss D: 0.3796, loss G: 3.5930\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [176/200] Batch 11/12                         Loss D: 0.6230, loss G: 3.5944\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [177/200] Batch 11/12                         Loss D: -0.3313, loss G: 3.6050\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [178/200] Batch 11/12                         Loss D: 0.2247, loss G: 3.5970\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [179/200] Batch 11/12                         Loss D: 0.4658, loss G: 3.5939\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [180/200] Batch 11/12                         Loss D: 0.3577, loss G: 3.5924\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [181/200] Batch 11/12                         Loss D: -0.0330, loss G: 3.6036\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [182/200] Batch 11/12                         Loss D: 0.8948, loss G: 3.6030\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [183/200] Batch 11/12                         Loss D: 0.2663, loss G: 3.6024\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [184/200] Batch 11/12                         Loss D: 0.2884, loss G: 3.5994\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [185/200] Batch 11/12                         Loss D: 0.2664, loss G: 3.6028\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [186/200] Batch 11/12                         Loss D: 0.3895, loss G: 3.5970\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [187/200] Batch 11/12                         Loss D: 0.4044, loss G: 3.5983\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [188/200] Batch 11/12                         Loss D: 0.2309, loss G: 3.5968\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [189/200] Batch 11/12                         Loss D: 0.1382, loss G: 3.5981\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [190/200] Batch 11/12                         Loss D: -0.0185, loss G: 3.6014\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [191/200] Batch 11/12                         Loss D: -0.0234, loss G: 3.6035\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [192/200] Batch 11/12                         Loss D: 0.3072, loss G: 3.6035\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [193/200] Batch 11/12                         Loss D: 0.0410, loss G: 3.6011\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [194/200] Batch 11/12                         Loss D: -0.0383, loss G: 3.5992\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [195/200] Batch 11/12                         Loss D: -0.2242, loss G: 3.6018\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [196/200] Batch 11/12                         Loss D: -0.3121, loss G: 3.6025\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [197/200] Batch 11/12                         Loss D: -0.3506, loss G: 3.5983\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [198/200] Batch 11/12                         Loss D: -0.5490, loss G: 3.5974\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [199/200] Batch 11/12                         Loss D: -0.8718, loss G: 3.5948\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [0/200] Batch 11/12                         Loss D: 0.5872, loss G: 33.9066\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [1/200] Batch 11/12                         Loss D: 1.2781, loss G: 32.9593\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [2/200] Batch 11/12                         Loss D: 1.7282, loss G: 31.4236\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [3/200] Batch 11/12                         Loss D: 1.3810, loss G: 29.4685\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [4/200] Batch 11/12                         Loss D: -1.8931, loss G: 28.4788\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [5/200] Batch 11/12                         Loss D: -6.8404, loss G: 27.3133\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [6/200] Batch 11/12                         Loss D: -14.4330, loss G: 25.7122\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [7/200] Batch 11/12                         Loss D: -25.3345, loss G: 23.7865\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [8/200] Batch 11/12                         Loss D: -40.3045, loss G: 21.4828\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [9/200] Batch 11/12                         Loss D: -61.3547, loss G: 18.9090\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [10/200] Batch 11/12                         Loss D: -91.3268, loss G: 16.0716\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [11/200] Batch 11/12                         Loss D: -107.6896, loss G: 15.7889\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [12/200] Batch 11/12                         Loss D: -131.7152, loss G: 15.0193\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [13/200] Batch 11/12                         Loss D: -152.3811, loss G: 14.4172\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [14/200] Batch 11/12                         Loss D: -175.0381, loss G: 13.6946\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [15/200] Batch 11/12                         Loss D: -201.4666, loss G: 13.0735\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [16/200] Batch 11/12                         Loss D: -226.1994, loss G: 12.9846\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [17/200] Batch 11/12                         Loss D: -246.0057, loss G: 13.9497\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [18/200] Batch 11/12                         Loss D: -259.8298, loss G: 14.8259\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [19/200] Batch 11/12                         Loss D: -271.1891, loss G: 15.7565\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [20/200] Batch 11/12                         Loss D: -289.3249, loss G: 16.5554\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [21/200] Batch 11/12                         Loss D: -302.9109, loss G: 17.5341\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [22/200] Batch 11/12                         Loss D: -322.6738, loss G: 18.2846\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [23/200] Batch 11/12                         Loss D: -335.9540, loss G: 19.2834\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [24/200] Batch 11/12                         Loss D: -353.3218, loss G: 20.2692\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [25/200] Batch 11/12                         Loss D: -368.0624, loss G: 21.2380\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [26/200] Batch 11/12                         Loss D: -382.2568, loss G: 22.2160\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [27/200] Batch 11/12                         Loss D: -398.9528, loss G: 23.2855\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [28/200] Batch 11/12                         Loss D: -420.3519, loss G: 24.1884\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [29/200] Batch 11/12                         Loss D: -440.3652, loss G: 25.2012\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [30/200] Batch 11/12                         Loss D: -452.4773, loss G: 26.3947\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [31/200] Batch 11/12                         Loss D: -472.3268, loss G: 27.4726\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [32/200] Batch 11/12                         Loss D: -490.7971, loss G: 28.6277\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [33/200] Batch 11/12                         Loss D: -503.1313, loss G: 29.7594\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [34/200] Batch 11/12                         Loss D: -523.0917, loss G: 30.8515\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [35/200] Batch 11/12                         Loss D: -544.9240, loss G: 32.2162\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [36/200] Batch 11/12                         Loss D: -534.9971, loss G: 33.0840\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [37/200] Batch 11/12                         Loss D: -550.4539, loss G: 34.1972\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [38/200] Batch 11/12                         Loss D: -561.5516, loss G: 35.1926\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [39/200] Batch 11/12                         Loss D: -556.1477, loss G: 36.1489\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [40/200] Batch 11/12                         Loss D: -545.8175, loss G: 36.9045\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [41/200] Batch 11/12                         Loss D: -521.5328, loss G: 37.4976\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [42/200] Batch 11/12                         Loss D: -492.3083, loss G: 37.9214\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [43/200] Batch 11/12                         Loss D: -451.2052, loss G: 38.0200\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [44/200] Batch 11/12                         Loss D: -395.6984, loss G: 37.7730\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [45/200] Batch 11/12                         Loss D: -327.2622, loss G: 37.2236\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [46/200] Batch 11/12                         Loss D: -237.0048, loss G: 36.1738\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [47/200] Batch 11/12                         Loss D: -114.4166, loss G: 34.0575\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [48/200] Batch 11/12                         Loss D: -43.4927, loss G: 33.2939\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [49/200] Batch 11/12                         Loss D: 25.6787, loss G: 32.5267\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [50/200] Batch 11/12                         Loss D: 34.9618, loss G: 32.4935\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [51/200] Batch 11/12                         Loss D: 31.9153, loss G: 32.5682\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [52/200] Batch 11/12                         Loss D: 30.9732, loss G: 32.7055\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [53/200] Batch 11/12                         Loss D: 29.4336, loss G: 32.7778\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [54/200] Batch 11/12                         Loss D: 26.7974, loss G: 32.8806\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [55/200] Batch 11/12                         Loss D: 24.9771, loss G: 32.9461\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [56/200] Batch 11/12                         Loss D: 23.4882, loss G: 33.0382\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [57/200] Batch 11/12                         Loss D: 22.4972, loss G: 33.1018\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [58/200] Batch 11/12                         Loss D: 22.1755, loss G: 33.2318\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [59/200] Batch 11/12                         Loss D: 21.1141, loss G: 33.2630\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [60/200] Batch 11/12                         Loss D: 19.5386, loss G: 33.2665\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [61/200] Batch 11/12                         Loss D: 19.1562, loss G: 33.3235\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [62/200] Batch 11/12                         Loss D: 19.5164, loss G: 33.3745\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [63/200] Batch 11/12                         Loss D: 18.2177, loss G: 33.3432\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [64/200] Batch 11/12                         Loss D: 17.7015, loss G: 33.3295\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [65/200] Batch 11/12                         Loss D: 17.6342, loss G: 33.3232\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [66/200] Batch 11/12                         Loss D: 16.1721, loss G: 33.3644\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [67/200] Batch 11/12                         Loss D: 14.0390, loss G: 33.3709\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [68/200] Batch 11/12                         Loss D: 12.7229, loss G: 33.3684\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [69/200] Batch 11/12                         Loss D: 10.2504, loss G: 33.3913\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [70/200] Batch 11/12                         Loss D: 7.4994, loss G: 33.4189\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [71/200] Batch 11/12                         Loss D: 3.9880, loss G: 33.4758\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [72/200] Batch 11/12                         Loss D: 4.9714, loss G: 33.4743\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [73/200] Batch 11/12                         Loss D: 3.0302, loss G: 33.5020\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [74/200] Batch 11/12                         Loss D: 1.6619, loss G: 33.5279\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [75/200] Batch 11/12                         Loss D: -0.0286, loss G: 33.5657\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [76/200] Batch 11/12                         Loss D: -1.1746, loss G: 33.6163\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [77/200] Batch 11/12                         Loss D: -3.2285, loss G: 33.6232\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [78/200] Batch 11/12                         Loss D: -5.6949, loss G: 33.6261\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [79/200] Batch 11/12                         Loss D: -7.0213, loss G: 33.6474\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [80/200] Batch 11/12                         Loss D: -9.4809, loss G: 33.6491\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [81/200] Batch 11/12                         Loss D: -11.5720, loss G: 33.6189\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [82/200] Batch 11/12                         Loss D: -13.5305, loss G: 33.6013\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [83/200] Batch 11/12                         Loss D: -14.1443, loss G: 33.5283\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [84/200] Batch 11/12                         Loss D: -13.8590, loss G: 33.5643\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [85/200] Batch 11/12                         Loss D: -16.9283, loss G: 33.5457\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [86/200] Batch 11/12                         Loss D: -16.3595, loss G: 33.5609\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [87/200] Batch 11/12                         Loss D: -16.0498, loss G: 33.5575\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [88/200] Batch 11/12                         Loss D: -14.0961, loss G: 33.6106\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [89/200] Batch 11/12                         Loss D: -17.1933, loss G: 33.5861\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [90/200] Batch 11/12                         Loss D: -15.9850, loss G: 33.5943\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [91/200] Batch 11/12                         Loss D: -17.6499, loss G: 33.6348\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [92/200] Batch 11/12                         Loss D: -17.0222, loss G: 33.6611\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [93/200] Batch 11/12                         Loss D: -18.4804, loss G: 33.6594\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [94/200] Batch 11/12                         Loss D: -18.5976, loss G: 33.6565\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [95/200] Batch 11/12                         Loss D: -23.4670, loss G: 33.7463\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [96/200] Batch 11/12                         Loss D: -21.6870, loss G: 33.6907\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [97/200] Batch 11/12                         Loss D: -23.0082, loss G: 33.7267\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [98/200] Batch 11/12                         Loss D: -23.1045, loss G: 33.7353\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [99/200] Batch 11/12                         Loss D: -21.1716, loss G: 33.7783\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [100/200] Batch 11/12                         Loss D: -20.5676, loss G: 33.8455\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [101/200] Batch 11/12                         Loss D: -23.4631, loss G: 33.8380\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [102/200] Batch 11/12                         Loss D: -23.7438, loss G: 33.8710\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [103/200] Batch 11/12                         Loss D: -24.7948, loss G: 33.9026\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [104/200] Batch 11/12                         Loss D: -28.5327, loss G: 33.9252\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [105/200] Batch 11/12                         Loss D: -30.3641, loss G: 33.9843\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [106/200] Batch 11/12                         Loss D: -30.3392, loss G: 34.0413\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [107/200] Batch 11/12                         Loss D: -30.7664, loss G: 34.0793\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [108/200] Batch 11/12                         Loss D: -33.5336, loss G: 34.1386\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [109/200] Batch 11/12                         Loss D: -30.8145, loss G: 34.1933\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [110/200] Batch 11/12                         Loss D: -34.7603, loss G: 34.2352\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [111/200] Batch 11/12                         Loss D: -35.5982, loss G: 34.2923\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [112/200] Batch 11/12                         Loss D: -35.9551, loss G: 34.3508\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [113/200] Batch 11/12                         Loss D: -36.2440, loss G: 34.3961\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [114/200] Batch 11/12                         Loss D: -34.5894, loss G: 34.4541\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [115/200] Batch 11/12                         Loss D: -32.4030, loss G: 34.4960\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [116/200] Batch 11/12                         Loss D: -29.5493, loss G: 34.5394\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [117/200] Batch 11/12                         Loss D: -25.1663, loss G: 34.5667\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [118/200] Batch 11/12                         Loss D: -20.5630, loss G: 34.5860\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [119/200] Batch 11/12                         Loss D: -15.0047, loss G: 34.5965\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [120/200] Batch 11/12                         Loss D: -9.3132, loss G: 34.5986\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [121/200] Batch 11/12                         Loss D: -3.2857, loss G: 34.5944\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [122/200] Batch 11/12                         Loss D: 0.4016, loss G: 34.5947\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [123/200] Batch 11/12                         Loss D: 3.7211, loss G: 34.5994\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [124/200] Batch 11/12                         Loss D: 6.1657, loss G: 34.6002\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [125/200] Batch 11/12                         Loss D: 8.8064, loss G: 34.5970\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [126/200] Batch 11/12                         Loss D: 11.3868, loss G: 34.5894\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [127/200] Batch 11/12                         Loss D: 16.6065, loss G: 34.5678\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [128/200] Batch 11/12                         Loss D: 24.3469, loss G: 34.4730\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [129/200] Batch 11/12                         Loss D: 27.9657, loss G: 34.5888\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [130/200] Batch 11/12                         Loss D: 13.3209, loss G: 34.5116\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [131/200] Batch 11/12                         Loss D: 14.0803, loss G: 34.4681\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [132/200] Batch 11/12                         Loss D: 16.1260, loss G: 34.4150\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [133/200] Batch 11/12                         Loss D: 16.4194, loss G: 34.4340\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [134/200] Batch 11/12                         Loss D: 19.9344, loss G: 34.5531\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [135/200] Batch 11/12                         Loss D: 10.9457, loss G: 34.4433\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [136/200] Batch 11/12                         Loss D: 12.1837, loss G: 34.4129\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [137/200] Batch 11/12                         Loss D: 12.5628, loss G: 34.4140\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [138/200] Batch 11/12                         Loss D: 13.0321, loss G: 34.4307\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [139/200] Batch 11/12                         Loss D: 12.5609, loss G: 34.4294\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [140/200] Batch 11/12                         Loss D: 15.4766, loss G: 34.5169\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [141/200] Batch 11/12                         Loss D: 6.2438, loss G: 34.4800\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [142/200] Batch 11/12                         Loss D: 12.3601, loss G: 34.4497\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [143/200] Batch 11/12                         Loss D: 11.1566, loss G: 34.4276\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [144/200] Batch 11/12                         Loss D: 13.6491, loss G: 34.4916\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [145/200] Batch 11/12                         Loss D: 6.4972, loss G: 34.4556\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [146/200] Batch 11/12                         Loss D: 10.4328, loss G: 34.4300\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [147/200] Batch 11/12                         Loss D: 10.8847, loss G: 34.4410\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [148/200] Batch 11/12                         Loss D: 8.3327, loss G: 34.4176\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [149/200] Batch 11/12                         Loss D: 8.4608, loss G: 34.4148\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [150/200] Batch 11/12                         Loss D: 11.9021, loss G: 34.4830\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [151/200] Batch 11/12                         Loss D: 8.0833, loss G: 34.4157\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [152/200] Batch 11/12                         Loss D: 7.5289, loss G: 34.4182\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [153/200] Batch 11/12                         Loss D: 7.8575, loss G: 34.4154\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [154/200] Batch 11/12                         Loss D: 10.6008, loss G: 34.4603\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [155/200] Batch 11/12                         Loss D: 5.7071, loss G: 34.4391\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [156/200] Batch 11/12                         Loss D: 7.7429, loss G: 34.4169\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [157/200] Batch 11/12                         Loss D: 7.2439, loss G: 34.4159\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [158/200] Batch 11/12                         Loss D: 4.6423, loss G: 34.4569\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [159/200] Batch 11/12                         Loss D: 8.8559, loss G: 34.4329\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [160/200] Batch 11/12                         Loss D: 4.9134, loss G: 34.4434\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [161/200] Batch 11/12                         Loss D: 7.1114, loss G: 34.4161\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [162/200] Batch 11/12                         Loss D: 7.8122, loss G: 34.4221\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [163/200] Batch 11/12                         Loss D: 7.9401, loss G: 34.4257\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [164/200] Batch 11/12                         Loss D: 7.8190, loss G: 34.4257\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [165/200] Batch 11/12                         Loss D: 7.5835, loss G: 34.4239\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [166/200] Batch 11/12                         Loss D: 7.6376, loss G: 34.4245\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [167/200] Batch 11/12                         Loss D: 7.3489, loss G: 34.4256\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [168/200] Batch 11/12                         Loss D: 7.2084, loss G: 34.4232\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [169/200] Batch 11/12                         Loss D: 7.2536, loss G: 34.4249\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [170/200] Batch 11/12                         Loss D: 6.9656, loss G: 34.4232\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [171/200] Batch 11/12                         Loss D: 6.8752, loss G: 34.4216\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [172/200] Batch 11/12                         Loss D: 3.8631, loss G: 34.4401\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [173/200] Batch 11/12                         Loss D: 6.5521, loss G: 34.4203\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [174/200] Batch 11/12                         Loss D: 6.6338, loss G: 34.4218\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [175/200] Batch 11/12                         Loss D: 6.4259, loss G: 34.4202\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [176/200] Batch 11/12                         Loss D: 6.6021, loss G: 34.4214\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [177/200] Batch 11/12                         Loss D: 6.4522, loss G: 34.4216\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [178/200] Batch 11/12                         Loss D: 6.4631, loss G: 34.4214\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [179/200] Batch 11/12                         Loss D: 6.1640, loss G: 34.4200\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [180/200] Batch 11/12                         Loss D: 6.0764, loss G: 34.4198\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [181/200] Batch 11/12                         Loss D: 6.0822, loss G: 34.4205\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [182/200] Batch 11/12                         Loss D: 6.0234, loss G: 34.4205\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [183/200] Batch 11/12                         Loss D: 5.8048, loss G: 34.4189\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [184/200] Batch 11/12                         Loss D: 5.5008, loss G: 34.4177\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [185/200] Batch 11/12                         Loss D: 5.5624, loss G: 34.4189\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [186/200] Batch 11/12                         Loss D: 5.1867, loss G: 34.4173\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [187/200] Batch 11/12                         Loss D: 5.0422, loss G: 34.4166\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [188/200] Batch 11/12                         Loss D: 4.9909, loss G: 34.4169\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [189/200] Batch 11/12                         Loss D: 4.6452, loss G: 34.4161\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [190/200] Batch 11/12                         Loss D: 4.5273, loss G: 34.4157\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [191/200] Batch 11/12                         Loss D: 4.2692, loss G: 34.4158\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [192/200] Batch 11/12                         Loss D: 3.7195, loss G: 34.4140\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [193/200] Batch 11/12                         Loss D: 2.9541, loss G: 34.4130\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [194/200] Batch 11/12                         Loss D: 0.5751, loss G: 34.4016\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [195/200] Batch 11/12                         Loss D: 0.3732, loss G: 34.4033\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [196/200] Batch 11/12                         Loss D: 0.4210, loss G: 34.4150\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [197/200] Batch 11/12                         Loss D: 0.8202, loss G: 34.4322\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [198/200] Batch 11/12                         Loss D: -0.0837, loss G: 34.4065\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [199/200] Batch 11/12                         Loss D: 1.7281, loss G: 34.4718\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [0/200] Batch 11/12                         Loss D: -0.0887, loss G: 17.2427\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [1/200] Batch 11/12                         Loss D: -0.4791, loss G: 16.9504\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [2/200] Batch 11/12                         Loss D: -1.0472, loss G: 16.4327\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [3/200] Batch 11/12                         Loss D: -2.1747, loss G: 15.5485\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [4/200] Batch 11/12                         Loss D: -3.8090, loss G: 14.6637\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [5/200] Batch 11/12                         Loss D: -5.7632, loss G: 13.8015\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [6/200] Batch 11/12                         Loss D: -7.9338, loss G: 12.7405\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [7/200] Batch 11/12                         Loss D: -10.3763, loss G: 11.3286\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [8/200] Batch 11/12                         Loss D: -13.7769, loss G: 9.6029\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [9/200] Batch 11/12                         Loss D: -16.4516, loss G: 7.3830\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [10/200] Batch 11/12                         Loss D: -13.5897, loss G: 4.9711\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [11/200] Batch 11/12                         Loss D: -7.0100, loss G: 3.0637\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [12/200] Batch 11/12                         Loss D: -3.1142, loss G: 0.9353\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [13/200] Batch 11/12                         Loss D: -5.0608, loss G: 0.2775\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [14/200] Batch 11/12                         Loss D: -16.5863, loss G: 0.9132\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [15/200] Batch 11/12                         Loss D: -25.6309, loss G: 1.5891\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [16/200] Batch 11/12                         Loss D: -34.4406, loss G: 2.1261\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [17/200] Batch 11/12                         Loss D: -42.9095, loss G: 2.6052\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [18/200] Batch 11/12                         Loss D: -51.1123, loss G: 3.1382\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [19/200] Batch 11/12                         Loss D: -59.4565, loss G: 3.7578\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [20/200] Batch 11/12                         Loss D: -63.6381, loss G: 4.2988\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [21/200] Batch 11/12                         Loss D: -71.3478, loss G: 4.5401\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [22/200] Batch 11/12                         Loss D: -77.6761, loss G: 4.9599\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [23/200] Batch 11/12                         Loss D: -84.2931, loss G: 5.2294\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [24/200] Batch 11/12                         Loss D: -89.2360, loss G: 5.6242\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [25/200] Batch 11/12                         Loss D: -95.1371, loss G: 6.0791\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [26/200] Batch 11/12                         Loss D: -98.5863, loss G: 6.3183\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [27/200] Batch 11/12                         Loss D: -105.5047, loss G: 6.7597\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [28/200] Batch 11/12                         Loss D: -109.4005, loss G: 6.9615\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [29/200] Batch 11/12                         Loss D: -114.4740, loss G: 7.3454\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [30/200] Batch 11/12                         Loss D: -119.2074, loss G: 7.8139\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [31/200] Batch 11/12                         Loss D: -127.8765, loss G: 8.2617\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [32/200] Batch 11/12                         Loss D: -132.4005, loss G: 8.4419\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [33/200] Batch 11/12                         Loss D: -138.2661, loss G: 8.8131\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [34/200] Batch 11/12                         Loss D: -142.4073, loss G: 9.2463\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [35/200] Batch 11/12                         Loss D: -150.0667, loss G: 9.5737\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [36/200] Batch 11/12                         Loss D: -153.9691, loss G: 9.9944\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [37/200] Batch 11/12                         Loss D: -159.8454, loss G: 10.3745\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [38/200] Batch 11/12                         Loss D: -165.7589, loss G: 10.7649\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [39/200] Batch 11/12                         Loss D: -173.6118, loss G: 11.0942\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [40/200] Batch 11/12                         Loss D: -181.7274, loss G: 11.6607\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [41/200] Batch 11/12                         Loss D: -187.2837, loss G: 11.9390\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [42/200] Batch 11/12                         Loss D: -189.7371, loss G: 12.4032\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [43/200] Batch 11/12                         Loss D: -199.9833, loss G: 12.8133\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [44/200] Batch 11/12                         Loss D: -204.1380, loss G: 13.3242\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [45/200] Batch 11/12                         Loss D: -211.2935, loss G: 13.7049\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [46/200] Batch 11/12                         Loss D: -216.3363, loss G: 14.1978\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [47/200] Batch 11/12                         Loss D: -225.3524, loss G: 14.7216\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [48/200] Batch 11/12                         Loss D: -226.1507, loss G: 15.1004\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [49/200] Batch 11/12                         Loss D: -231.2270, loss G: 15.5035\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [50/200] Batch 11/12                         Loss D: -234.8988, loss G: 15.9554\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [51/200] Batch 11/12                         Loss D: -239.8328, loss G: 16.3405\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [52/200] Batch 11/12                         Loss D: -238.3107, loss G: 16.6779\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [53/200] Batch 11/12                         Loss D: -238.5814, loss G: 16.9912\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [54/200] Batch 11/12                         Loss D: -240.0173, loss G: 17.4008\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [55/200] Batch 11/12                         Loss D: -235.8754, loss G: 17.5273\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [56/200] Batch 11/12                         Loss D: -232.0075, loss G: 17.6695\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [57/200] Batch 11/12                         Loss D: -225.3292, loss G: 17.7499\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [58/200] Batch 11/12                         Loss D: -213.1922, loss G: 17.7665\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [59/200] Batch 11/12                         Loss D: -204.8959, loss G: 17.6256\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [60/200] Batch 11/12                         Loss D: -187.5422, loss G: 17.4029\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [61/200] Batch 11/12                         Loss D: -171.1134, loss G: 17.1362\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [62/200] Batch 11/12                         Loss D: -145.5412, loss G: 16.6018\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [63/200] Batch 11/12                         Loss D: -112.8133, loss G: 16.0265\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [64/200] Batch 11/12                         Loss D: -81.1143, loss G: 15.2611\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [65/200] Batch 11/12                         Loss D: -58.1459, loss G: 14.6986\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [66/200] Batch 11/12                         Loss D: -60.3894, loss G: 14.7369\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [67/200] Batch 11/12                         Loss D: -60.6956, loss G: 14.8047\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [68/200] Batch 11/12                         Loss D: -61.5815, loss G: 14.8883\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [69/200] Batch 11/12                         Loss D: -62.4839, loss G: 14.9205\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [70/200] Batch 11/12                         Loss D: -62.8757, loss G: 14.9894\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [71/200] Batch 11/12                         Loss D: -65.7392, loss G: 15.1038\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [72/200] Batch 11/12                         Loss D: -64.6773, loss G: 15.1221\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [73/200] Batch 11/12                         Loss D: -66.8236, loss G: 15.1727\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [74/200] Batch 11/12                         Loss D: -65.8730, loss G: 15.2506\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [75/200] Batch 11/12                         Loss D: -67.5439, loss G: 15.2776\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [76/200] Batch 11/12                         Loss D: -66.7937, loss G: 15.3602\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [77/200] Batch 11/12                         Loss D: -68.3030, loss G: 15.4533\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [78/200] Batch 11/12                         Loss D: -68.4896, loss G: 15.4599\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [79/200] Batch 11/12                         Loss D: -69.1488, loss G: 15.5574\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [80/200] Batch 11/12                         Loss D: -69.2017, loss G: 15.6284\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [81/200] Batch 11/12                         Loss D: -69.7938, loss G: 15.6533\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [82/200] Batch 11/12                         Loss D: -69.9333, loss G: 15.6970\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [83/200] Batch 11/12                         Loss D: -70.7438, loss G: 15.7501\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [84/200] Batch 11/12                         Loss D: -70.0038, loss G: 15.8229\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [85/200] Batch 11/12                         Loss D: -69.3034, loss G: 15.9009\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [86/200] Batch 11/12                         Loss D: -68.6076, loss G: 15.9796\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [87/200] Batch 11/12                         Loss D: -70.2397, loss G: 15.9772\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [88/200] Batch 11/12                         Loss D: -70.1929, loss G: 16.0243\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [89/200] Batch 11/12                         Loss D: -70.9594, loss G: 16.1267\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [90/200] Batch 11/12                         Loss D: -68.4440, loss G: 16.1403\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [91/200] Batch 11/12                         Loss D: -69.4832, loss G: 16.1414\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [92/200] Batch 11/12                         Loss D: -69.3038, loss G: 16.1912\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [93/200] Batch 11/12                         Loss D: -70.5472, loss G: 16.2928\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [94/200] Batch 11/12                         Loss D: -70.3815, loss G: 16.3185\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [95/200] Batch 11/12                         Loss D: -68.2533, loss G: 16.3573\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [96/200] Batch 11/12                         Loss D: -64.9110, loss G: 16.3754\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [97/200] Batch 11/12                         Loss D: -61.4602, loss G: 16.3818\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [98/200] Batch 11/12                         Loss D: -54.2601, loss G: 16.2864\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [99/200] Batch 11/12                         Loss D: -52.5820, loss G: 15.9861\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [100/200] Batch 11/12                         Loss D: -47.9823, loss G: 15.7773\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [101/200] Batch 11/12                         Loss D: -40.3284, loss G: 15.1651\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [102/200] Batch 11/12                         Loss D: -44.5979, loss G: 15.0650\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [103/200] Batch 11/12                         Loss D: -47.9364, loss G: 15.4510\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [104/200] Batch 11/12                         Loss D: -50.9104, loss G: 15.9334\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [105/200] Batch 11/12                         Loss D: -56.7461, loss G: 16.6564\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [106/200] Batch 11/12                         Loss D: -68.8084, loss G: 17.5471\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [107/200] Batch 11/12                         Loss D: -75.6904, loss G: 18.3403\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [108/200] Batch 11/12                         Loss D: -85.5423, loss G: 19.0865\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [109/200] Batch 11/12                         Loss D: -86.8723, loss G: 19.6402\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [110/200] Batch 11/12                         Loss D: -88.3828, loss G: 20.0684\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [111/200] Batch 11/12                         Loss D: -85.9619, loss G: 20.2696\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [112/200] Batch 11/12                         Loss D: -80.7478, loss G: 20.2173\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [113/200] Batch 11/12                         Loss D: -69.6633, loss G: 19.8170\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [114/200] Batch 11/12                         Loss D: -57.3813, loss G: 18.8424\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [115/200] Batch 11/12                         Loss D: -63.6892, loss G: 18.1134\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [116/200] Batch 11/12                         Loss D: -48.8374, loss G: 17.9642\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [117/200] Batch 11/12                         Loss D: -36.8550, loss G: 17.8048\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [118/200] Batch 11/12                         Loss D: -22.0940, loss G: 17.5975\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [119/200] Batch 11/12                         Loss D: -9.1275, loss G: 17.4012\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [120/200] Batch 11/12                         Loss D: 1.5549, loss G: 17.2801\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [121/200] Batch 11/12                         Loss D: 9.1412, loss G: 17.1134\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [122/200] Batch 11/12                         Loss D: 9.5292, loss G: 17.1246\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [123/200] Batch 11/12                         Loss D: 10.0149, loss G: 17.1603\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [124/200] Batch 11/12                         Loss D: 9.3942, loss G: 17.1668\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [125/200] Batch 11/12                         Loss D: 8.1780, loss G: 17.1546\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [126/200] Batch 11/12                         Loss D: 6.1562, loss G: 17.1835\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [127/200] Batch 11/12                         Loss D: 7.0522, loss G: 17.1769\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [128/200] Batch 11/12                         Loss D: 7.4111, loss G: 17.1998\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [129/200] Batch 11/12                         Loss D: 6.3157, loss G: 17.2065\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [130/200] Batch 11/12                         Loss D: 4.7105, loss G: 17.2199\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [131/200] Batch 11/12                         Loss D: 4.2610, loss G: 17.2270\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [132/200] Batch 11/12                         Loss D: 6.1582, loss G: 17.2171\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [133/200] Batch 11/12                         Loss D: 5.5920, loss G: 17.2172\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [134/200] Batch 11/12                         Loss D: 4.8983, loss G: 17.2275\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [135/200] Batch 11/12                         Loss D: 4.3116, loss G: 17.2450\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [136/200] Batch 11/12                         Loss D: 5.1015, loss G: 17.2394\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [137/200] Batch 11/12                         Loss D: 3.8045, loss G: 17.2578\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [138/200] Batch 11/12                         Loss D: 4.5207, loss G: 17.2546\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [139/200] Batch 11/12                         Loss D: 4.8537, loss G: 17.2599\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [140/200] Batch 11/12                         Loss D: 3.2580, loss G: 17.2724\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [141/200] Batch 11/12                         Loss D: 3.7192, loss G: 17.2774\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [142/200] Batch 11/12                         Loss D: 3.7789, loss G: 17.2840\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [143/200] Batch 11/12                         Loss D: 3.7323, loss G: 17.2921\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [144/200] Batch 11/12                         Loss D: 3.3254, loss G: 17.3006\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [145/200] Batch 11/12                         Loss D: 3.1558, loss G: 17.3081\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [146/200] Batch 11/12                         Loss D: 2.6924, loss G: 17.3152\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [147/200] Batch 11/12                         Loss D: 2.1556, loss G: 17.3223\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [148/200] Batch 11/12                         Loss D: 1.0811, loss G: 17.3268\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [149/200] Batch 11/12                         Loss D: 0.0249, loss G: 17.3309\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [150/200] Batch 11/12                         Loss D: -0.3206, loss G: 17.3352\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [151/200] Batch 11/12                         Loss D: -0.8075, loss G: 17.3382\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [152/200] Batch 11/12                         Loss D: -1.1547, loss G: 17.3423\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [153/200] Batch 11/12                         Loss D: -1.5416, loss G: 17.3451\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [154/200] Batch 11/12                         Loss D: -1.8668, loss G: 17.3485\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [155/200] Batch 11/12                         Loss D: -2.2514, loss G: 17.3512\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [156/200] Batch 11/12                         Loss D: -2.4955, loss G: 17.3537\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [157/200] Batch 11/12                         Loss D: -2.6363, loss G: 17.3555\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [158/200] Batch 11/12                         Loss D: -2.7784, loss G: 17.3576\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [159/200] Batch 11/12                         Loss D: -3.0356, loss G: 17.3593\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [160/200] Batch 11/12                         Loss D: -3.1488, loss G: 17.3612\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [161/200] Batch 11/12                         Loss D: -3.2751, loss G: 17.3630\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [162/200] Batch 11/12                         Loss D: -3.4562, loss G: 17.3650\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [163/200] Batch 11/12                         Loss D: -3.3937, loss G: 17.3666\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [164/200] Batch 11/12                         Loss D: -3.6361, loss G: 17.3687\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [165/200] Batch 11/12                         Loss D: -3.6046, loss G: 17.3703\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [166/200] Batch 11/12                         Loss D: -3.9070, loss G: 17.3713\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [167/200] Batch 11/12                         Loss D: -4.3118, loss G: 17.3729\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [168/200] Batch 11/12                         Loss D: -4.6517, loss G: 17.3740\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [169/200] Batch 11/12                         Loss D: -4.8267, loss G: 17.3749\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [170/200] Batch 11/12                         Loss D: -4.9114, loss G: 17.3763\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [171/200] Batch 11/12                         Loss D: -4.8795, loss G: 17.3776\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [172/200] Batch 11/12                         Loss D: -4.9836, loss G: 17.3784\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [173/200] Batch 11/12                         Loss D: -5.1057, loss G: 17.3795\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [174/200] Batch 11/12                         Loss D: -5.3022, loss G: 17.3806\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [175/200] Batch 11/12                         Loss D: -5.3259, loss G: 17.3815\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [176/200] Batch 11/12                         Loss D: -5.3357, loss G: 17.3824\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [177/200] Batch 11/12                         Loss D: -5.1831, loss G: 17.3831\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [178/200] Batch 11/12                         Loss D: -4.8262, loss G: 17.3833\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [179/200] Batch 11/12                         Loss D: -2.9532, loss G: 17.3757\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [180/200] Batch 11/12                         Loss D: -3.3734, loss G: 17.3747\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [181/200] Batch 11/12                         Loss D: -3.7920, loss G: 17.3738\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [182/200] Batch 11/12                         Loss D: -5.0121, loss G: 17.3795\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [183/200] Batch 11/12                         Loss D: -3.9209, loss G: 17.3738\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [184/200] Batch 11/12                         Loss D: -4.0426, loss G: 17.3738\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [185/200] Batch 11/12                         Loss D: -4.9689, loss G: 17.3809\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [186/200] Batch 11/12                         Loss D: -4.9322, loss G: 17.3801\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [187/200] Batch 11/12                         Loss D: -4.8650, loss G: 17.3798\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [188/200] Batch 11/12                         Loss D: -3.7425, loss G: 17.3757\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [189/200] Batch 11/12                         Loss D: -4.9206, loss G: 17.3791\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [190/200] Batch 11/12                         Loss D: -3.8970, loss G: 17.3754\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [191/200] Batch 11/12                         Loss D: -4.2826, loss G: 17.3750\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [192/200] Batch 11/12                         Loss D: -5.0008, loss G: 17.3806\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [193/200] Batch 11/12                         Loss D: -4.8045, loss G: 17.3808\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [194/200] Batch 11/12                         Loss D: -4.5763, loss G: 17.3783\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [195/200] Batch 11/12                         Loss D: -4.9150, loss G: 17.3827\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [196/200] Batch 11/12                         Loss D: -4.8574, loss G: 17.3811\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [197/200] Batch 11/12                         Loss D: -5.2341, loss G: 17.3845\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [198/200] Batch 11/12                         Loss D: -4.9553, loss G: 17.3831\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [199/200] Batch 11/12                         Loss D: -5.1698, loss G: 17.3840\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [0/200] Batch 11/12                         Loss D: 1.1830, loss G: 3.4124\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [1/200] Batch 11/12                         Loss D: 1.5769, loss G: 3.3670\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [2/200] Batch 11/12                         Loss D: 2.0843, loss G: 3.3010\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [3/200] Batch 11/12                         Loss D: 1.6557, loss G: 3.2031\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [4/200] Batch 11/12                         Loss D: 0.8719, loss G: 3.0599\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [5/200] Batch 11/12                         Loss D: -2.5258, loss G: 2.9654\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [6/200] Batch 11/12                         Loss D: -5.5496, loss G: 2.9238\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [7/200] Batch 11/12                         Loss D: -8.1289, loss G: 2.8863\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [8/200] Batch 11/12                         Loss D: -11.3121, loss G: 2.8547\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [9/200] Batch 11/12                         Loss D: -15.6492, loss G: 2.8107\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [10/200] Batch 11/12                         Loss D: -20.7542, loss G: 2.7615\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [11/200] Batch 11/12                         Loss D: -25.0364, loss G: 2.6636\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [12/200] Batch 11/12                         Loss D: -33.2278, loss G: 2.5771\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [13/200] Batch 11/12                         Loss D: -41.2673, loss G: 2.4943\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [14/200] Batch 11/12                         Loss D: -51.9427, loss G: 2.3970\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [15/200] Batch 11/12                         Loss D: -57.8268, loss G: 2.3673\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [16/200] Batch 11/12                         Loss D: -61.4001, loss G: 2.3626\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [17/200] Batch 11/12                         Loss D: -66.7089, loss G: 2.3408\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [18/200] Batch 11/12                         Loss D: -69.7031, loss G: 2.3574\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [19/200] Batch 11/12                         Loss D: -74.0871, loss G: 2.3539\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [20/200] Batch 11/12                         Loss D: -77.2095, loss G: 2.3591\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [21/200] Batch 11/12                         Loss D: -82.9439, loss G: 2.3443\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [22/200] Batch 11/12                         Loss D: -88.0218, loss G: 2.3640\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [23/200] Batch 11/12                         Loss D: -91.3018, loss G: 2.3592\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [24/200] Batch 11/12                         Loss D: -95.3367, loss G: 2.3733\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [25/200] Batch 11/12                         Loss D: -99.9267, loss G: 2.3605\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [26/200] Batch 11/12                         Loss D: -106.2428, loss G: 2.3717\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [27/200] Batch 11/12                         Loss D: -110.5079, loss G: 2.3880\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [28/200] Batch 11/12                         Loss D: -114.9212, loss G: 2.3743\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [29/200] Batch 11/12                         Loss D: -120.6696, loss G: 2.3994\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [30/200] Batch 11/12                         Loss D: -124.8022, loss G: 2.4100\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [31/200] Batch 11/12                         Loss D: -130.1637, loss G: 2.4116\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [32/200] Batch 11/12                         Loss D: -136.9445, loss G: 2.4686\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [33/200] Batch 11/12                         Loss D: -140.0865, loss G: 2.5768\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [34/200] Batch 11/12                         Loss D: -147.1213, loss G: 2.6479\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [35/200] Batch 11/12                         Loss D: -151.6319, loss G: 2.7575\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [36/200] Batch 11/12                         Loss D: -156.7296, loss G: 2.9191\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [37/200] Batch 11/12                         Loss D: -161.8100, loss G: 3.0334\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [38/200] Batch 11/12                         Loss D: -167.5854, loss G: 3.2143\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [39/200] Batch 11/12                         Loss D: -173.8433, loss G: 3.3331\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [40/200] Batch 11/12                         Loss D: -177.7334, loss G: 3.4714\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [41/200] Batch 11/12                         Loss D: -174.1279, loss G: 3.6644\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [42/200] Batch 11/12                         Loss D: -178.9378, loss G: 3.7341\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [43/200] Batch 11/12                         Loss D: -176.1223, loss G: 3.8440\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [44/200] Batch 11/12                         Loss D: -156.3467, loss G: 3.7152\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [45/200] Batch 11/12                         Loss D: -132.2245, loss G: 3.7283\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [46/200] Batch 11/12                         Loss D: -108.0939, loss G: 3.7800\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [47/200] Batch 11/12                         Loss D: -101.9947, loss G: 3.8392\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [48/200] Batch 11/12                         Loss D: -91.8956, loss G: 3.9034\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [49/200] Batch 11/12                         Loss D: -84.3780, loss G: 3.9616\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [50/200] Batch 11/12                         Loss D: -75.1414, loss G: 3.9651\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [51/200] Batch 11/12                         Loss D: -64.4764, loss G: 3.9506\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [52/200] Batch 11/12                         Loss D: -55.0585, loss G: 3.9233\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [53/200] Batch 11/12                         Loss D: -46.7298, loss G: 3.8919\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [54/200] Batch 11/12                         Loss D: -39.3603, loss G: 3.8561\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [55/200] Batch 11/12                         Loss D: -32.2138, loss G: 3.8082\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [56/200] Batch 11/12                         Loss D: -25.8996, loss G: 3.7582\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [57/200] Batch 11/12                         Loss D: -20.0433, loss G: 3.7054\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [58/200] Batch 11/12                         Loss D: -14.5057, loss G: 3.6491\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [59/200] Batch 11/12                         Loss D: -10.0025, loss G: 3.5956\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [60/200] Batch 11/12                         Loss D: -6.1906, loss G: 3.5378\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [61/200] Batch 11/12                         Loss D: -2.9043, loss G: 3.4786\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [62/200] Batch 11/12                         Loss D: -0.9797, loss G: 3.4287\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [63/200] Batch 11/12                         Loss D: -0.2012, loss G: 3.3633\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [64/200] Batch 11/12                         Loss D: 0.4864, loss G: 3.3200\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [65/200] Batch 11/12                         Loss D: 0.8791, loss G: 3.3146\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [66/200] Batch 11/12                         Loss D: 0.9046, loss G: 3.3080\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [67/200] Batch 11/12                         Loss D: 1.0369, loss G: 3.3064\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [68/200] Batch 11/12                         Loss D: 0.7703, loss G: 3.3026\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [69/200] Batch 11/12                         Loss D: 0.1527, loss G: 3.2931\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [70/200] Batch 11/12                         Loss D: 1.1240, loss G: 3.2881\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [71/200] Batch 11/12                         Loss D: 0.5577, loss G: 3.2850\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [72/200] Batch 11/12                         Loss D: 0.0674, loss G: 3.2765\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [73/200] Batch 11/12                         Loss D: 1.1131, loss G: 3.2683\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [74/200] Batch 11/12                         Loss D: 0.7702, loss G: 3.2632\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [75/200] Batch 11/12                         Loss D: 1.0183, loss G: 3.2566\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [76/200] Batch 11/12                         Loss D: 0.1866, loss G: 3.2580\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [77/200] Batch 11/12                         Loss D: 0.9817, loss G: 3.2470\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [78/200] Batch 11/12                         Loss D: 0.5987, loss G: 3.2405\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [79/200] Batch 11/12                         Loss D: 1.2856, loss G: 3.2325\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [80/200] Batch 11/12                         Loss D: 1.9064, loss G: 3.2326\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [81/200] Batch 11/12                         Loss D: 1.4931, loss G: 3.2210\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [82/200] Batch 11/12                         Loss D: 1.2501, loss G: 3.2127\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [83/200] Batch 11/12                         Loss D: 1.1987, loss G: 3.2063\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [84/200] Batch 11/12                         Loss D: 1.1642, loss G: 3.1993\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [85/200] Batch 11/12                         Loss D: 0.9591, loss G: 3.1924\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [86/200] Batch 11/12                         Loss D: 1.2342, loss G: 3.1841\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [87/200] Batch 11/12                         Loss D: 1.3992, loss G: 3.1778\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [88/200] Batch 11/12                         Loss D: 0.2978, loss G: 3.1703\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [89/200] Batch 11/12                         Loss D: 0.5565, loss G: 3.1626\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [90/200] Batch 11/12                         Loss D: 0.7176, loss G: 3.1544\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [91/200] Batch 11/12                         Loss D: 0.4428, loss G: 3.1467\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [92/200] Batch 11/12                         Loss D: 0.0902, loss G: 3.1387\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [93/200] Batch 11/12                         Loss D: 0.5106, loss G: 3.1309\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [94/200] Batch 11/12                         Loss D: 0.2510, loss G: 3.1209\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [95/200] Batch 11/12                         Loss D: 0.8982, loss G: 3.1115\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [96/200] Batch 11/12                         Loss D: -0.2836, loss G: 3.1023\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [97/200] Batch 11/12                         Loss D: 0.2703, loss G: 3.0943\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [98/200] Batch 11/12                         Loss D: -0.1792, loss G: 3.0824\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [99/200] Batch 11/12                         Loss D: -0.7249, loss G: 3.0734\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [100/200] Batch 11/12                         Loss D: -1.4258, loss G: 3.0616\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [101/200] Batch 11/12                         Loss D: -2.2152, loss G: 3.0499\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [102/200] Batch 11/12                         Loss D: -3.0202, loss G: 3.0358\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [103/200] Batch 11/12                         Loss D: -3.9826, loss G: 3.0209\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [104/200] Batch 11/12                         Loss D: -5.1443, loss G: 3.0039\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [105/200] Batch 11/12                         Loss D: -6.7679, loss G: 2.9828\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [106/200] Batch 11/12                         Loss D: -9.0122, loss G: 2.9592\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [107/200] Batch 11/12                         Loss D: -11.6723, loss G: 2.9354\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [108/200] Batch 11/12                         Loss D: -13.7912, loss G: 2.9176\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [109/200] Batch 11/12                         Loss D: -14.6946, loss G: 2.9286\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [110/200] Batch 11/12                         Loss D: -15.9076, loss G: 2.9342\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [111/200] Batch 11/12                         Loss D: -19.1861, loss G: 2.9346\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [112/200] Batch 11/12                         Loss D: -19.4690, loss G: 2.9372\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [113/200] Batch 11/12                         Loss D: -19.7490, loss G: 2.9491\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [114/200] Batch 11/12                         Loss D: -21.2603, loss G: 2.9556\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [115/200] Batch 11/12                         Loss D: -22.4819, loss G: 2.9547\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [116/200] Batch 11/12                         Loss D: -23.0405, loss G: 2.9613\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [117/200] Batch 11/12                         Loss D: -23.6337, loss G: 2.9599\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [118/200] Batch 11/12                         Loss D: -23.8677, loss G: 2.9490\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [119/200] Batch 11/12                         Loss D: -23.9039, loss G: 2.9380\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [120/200] Batch 11/12                         Loss D: -25.0228, loss G: 2.9113\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [121/200] Batch 11/12                         Loss D: -26.1914, loss G: 2.8928\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [122/200] Batch 11/12                         Loss D: -27.6312, loss G: 2.8821\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [123/200] Batch 11/12                         Loss D: -28.6192, loss G: 2.8729\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [124/200] Batch 11/12                         Loss D: -30.5270, loss G: 2.8607\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [125/200] Batch 11/12                         Loss D: -31.8142, loss G: 2.8745\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [126/200] Batch 11/12                         Loss D: -35.4830, loss G: 2.8753\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [127/200] Batch 11/12                         Loss D: -53.0616, loss G: 2.7348\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [128/200] Batch 11/12                         Loss D: -75.6560, loss G: 2.6170\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [129/200] Batch 11/12                         Loss D: -87.6883, loss G: 2.7365\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [130/200] Batch 11/12                         Loss D: -64.8313, loss G: 3.2723\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [131/200] Batch 11/12                         Loss D: -32.3877, loss G: 3.5419\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [132/200] Batch 11/12                         Loss D: -5.5245, loss G: 3.5188\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [133/200] Batch 11/12                         Loss D: 1.6157, loss G: 3.5627\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [134/200] Batch 11/12                         Loss D: -1.8400, loss G: 3.6447\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [135/200] Batch 11/12                         Loss D: -5.5330, loss G: 3.6649\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [136/200] Batch 11/12                         Loss D: -6.9039, loss G: 3.6318\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [137/200] Batch 11/12                         Loss D: 5.1482, loss G: 3.5513\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [138/200] Batch 11/12                         Loss D: 3.4343, loss G: 3.6251\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [139/200] Batch 11/12                         Loss D: -2.2708, loss G: 3.5804\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [140/200] Batch 11/12                         Loss D: -6.8922, loss G: 3.5379\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [141/200] Batch 11/12                         Loss D: -10.5235, loss G: 3.4984\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [142/200] Batch 11/12                         Loss D: -8.0522, loss G: 3.4610\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [143/200] Batch 11/12                         Loss D: 1.5690, loss G: 3.3692\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [144/200] Batch 11/12                         Loss D: 21.9719, loss G: 2.9703\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [145/200] Batch 11/12                         Loss D: 25.3681, loss G: 2.8758\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [146/200] Batch 11/12                         Loss D: 25.9372, loss G: 2.9246\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [147/200] Batch 11/12                         Loss D: 23.5920, loss G: 3.1243\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [148/200] Batch 11/12                         Loss D: 19.4255, loss G: 3.3634\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [149/200] Batch 11/12                         Loss D: 15.3849, loss G: 3.5103\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [150/200] Batch 11/12                         Loss D: 12.4403, loss G: 3.5577\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [151/200] Batch 11/12                         Loss D: 10.3329, loss G: 3.5174\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [152/200] Batch 11/12                         Loss D: 9.0804, loss G: 3.4393\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [153/200] Batch 11/12                         Loss D: 9.3841, loss G: 3.3544\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [154/200] Batch 11/12                         Loss D: 7.7994, loss G: 3.2965\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [155/200] Batch 11/12                         Loss D: 7.2061, loss G: 3.2938\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [156/200] Batch 11/12                         Loss D: 7.3292, loss G: 3.2936\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [157/200] Batch 11/12                         Loss D: 7.2608, loss G: 3.2955\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [158/200] Batch 11/12                         Loss D: 7.1059, loss G: 3.2965\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [159/200] Batch 11/12                         Loss D: 6.8532, loss G: 3.2972\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [160/200] Batch 11/12                         Loss D: 6.4454, loss G: 3.2997\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [161/200] Batch 11/12                         Loss D: 6.4330, loss G: 3.2995\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [162/200] Batch 11/12                         Loss D: 6.6958, loss G: 3.3047\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [163/200] Batch 11/12                         Loss D: 5.8802, loss G: 3.3035\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [164/200] Batch 11/12                         Loss D: 5.8254, loss G: 3.3031\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [165/200] Batch 11/12                         Loss D: 6.3371, loss G: 3.3090\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [166/200] Batch 11/12                         Loss D: 6.1489, loss G: 3.3093\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [167/200] Batch 11/12                         Loss D: 5.3207, loss G: 3.3091\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [168/200] Batch 11/12                         Loss D: 5.3169, loss G: 3.3096\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [169/200] Batch 11/12                         Loss D: 5.1304, loss G: 3.3100\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [170/200] Batch 11/12                         Loss D: 5.1489, loss G: 3.3102\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [171/200] Batch 11/12                         Loss D: 5.1980, loss G: 3.3124\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [172/200] Batch 11/12                         Loss D: 5.3630, loss G: 3.3132\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [173/200] Batch 11/12                         Loss D: 4.7996, loss G: 3.3135\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [174/200] Batch 11/12                         Loss D: 4.8341, loss G: 3.3166\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [175/200] Batch 11/12                         Loss D: 4.8262, loss G: 3.3137\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [176/200] Batch 11/12                         Loss D: 4.6051, loss G: 3.3158\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [177/200] Batch 11/12                         Loss D: 4.8373, loss G: 3.3178\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [178/200] Batch 11/12                         Loss D: 4.5142, loss G: 3.3168\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [179/200] Batch 11/12                         Loss D: 4.5196, loss G: 3.3211\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [180/200] Batch 11/12                         Loss D: 4.4469, loss G: 3.3191\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [181/200] Batch 11/12                         Loss D: 4.3708, loss G: 3.3201\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [182/200] Batch 11/12                         Loss D: 4.0750, loss G: 3.3229\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [183/200] Batch 11/12                         Loss D: 4.3502, loss G: 3.3261\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [184/200] Batch 11/12                         Loss D: 4.1836, loss G: 3.3233\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [185/200] Batch 11/12                         Loss D: 4.2765, loss G: 3.3285\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [186/200] Batch 11/12                         Loss D: 4.1521, loss G: 3.3260\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [187/200] Batch 11/12                         Loss D: 3.6534, loss G: 3.3321\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [188/200] Batch 11/12                         Loss D: 3.7832, loss G: 3.3277\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [189/200] Batch 11/12                         Loss D: 4.0648, loss G: 3.3326\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [190/200] Batch 11/12                         Loss D: 3.9361, loss G: 3.3313\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [191/200] Batch 11/12                         Loss D: 3.7702, loss G: 3.3302\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [192/200] Batch 11/12                         Loss D: 3.8412, loss G: 3.3315\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [193/200] Batch 11/12                         Loss D: 4.0037, loss G: 3.3320\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [194/200] Batch 11/12                         Loss D: 3.8017, loss G: 3.3341\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [195/200] Batch 11/12                         Loss D: 3.7094, loss G: 3.3325\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [196/200] Batch 11/12                         Loss D: 3.7158, loss G: 3.3349\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [197/200] Batch 11/12                         Loss D: 3.8109, loss G: 3.3382\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [198/200] Batch 11/12                         Loss D: 3.6759, loss G: 3.3360\n",
      "[lr_G=0.0002, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [199/200] Batch 11/12                         Loss D: 3.7980, loss G: 3.3384\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [0/200] Batch 11/12                         Loss D: 8.5526, loss G: 34.2947\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [1/200] Batch 11/12                         Loss D: 9.0894, loss G: 33.6187\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [2/200] Batch 11/12                         Loss D: 9.6099, loss G: 32.4477\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [3/200] Batch 11/12                         Loss D: 10.0575, loss G: 30.6357\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [4/200] Batch 11/12                         Loss D: 10.3824, loss G: 28.5091\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [5/200] Batch 11/12                         Loss D: 10.8091, loss G: 26.5961\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [6/200] Batch 11/12                         Loss D: 10.8631, loss G: 24.1966\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [7/200] Batch 11/12                         Loss D: 10.0445, loss G: 21.2755\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [8/200] Batch 11/12                         Loss D: 7.0544, loss G: 17.6172\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [9/200] Batch 11/12                         Loss D: 1.2983, loss G: 12.9906\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [10/200] Batch 11/12                         Loss D: -12.1398, loss G: 10.7885\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [11/200] Batch 11/12                         Loss D: -19.3911, loss G: 9.0026\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [12/200] Batch 11/12                         Loss D: -26.9503, loss G: 7.1916\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [13/200] Batch 11/12                         Loss D: -33.8706, loss G: 5.2224\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [14/200] Batch 11/12                         Loss D: -42.9418, loss G: 3.4600\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [15/200] Batch 11/12                         Loss D: -50.2868, loss G: 3.8623\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [16/200] Batch 11/12                         Loss D: -59.2965, loss G: 4.1889\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [17/200] Batch 11/12                         Loss D: -65.6340, loss G: 4.7392\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [18/200] Batch 11/12                         Loss D: -72.7912, loss G: 5.1571\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [19/200] Batch 11/12                         Loss D: -80.6432, loss G: 5.3721\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [20/200] Batch 11/12                         Loss D: -89.1846, loss G: 6.2951\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [21/200] Batch 11/12                         Loss D: -94.3399, loss G: 6.2932\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [22/200] Batch 11/12                         Loss D: -100.8482, loss G: 6.7851\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [23/200] Batch 11/12                         Loss D: -108.5502, loss G: 7.0662\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [24/200] Batch 11/12                         Loss D: -114.4473, loss G: 7.7557\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [25/200] Batch 11/12                         Loss D: -123.7155, loss G: 7.9596\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [26/200] Batch 11/12                         Loss D: -130.8327, loss G: 8.3152\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [27/200] Batch 11/12                         Loss D: -136.2378, loss G: 9.0422\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [28/200] Batch 11/12                         Loss D: -143.0855, loss G: 9.4815\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [29/200] Batch 11/12                         Loss D: -152.8498, loss G: 9.6949\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [30/200] Batch 11/12                         Loss D: -160.8537, loss G: 10.1611\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [31/200] Batch 11/12                         Loss D: -168.7849, loss G: 10.6961\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [32/200] Batch 11/12                         Loss D: -176.3204, loss G: 11.0567\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [33/200] Batch 11/12                         Loss D: -180.3097, loss G: 11.8092\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [34/200] Batch 11/12                         Loss D: -192.5916, loss G: 12.0680\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [35/200] Batch 11/12                         Loss D: -198.9803, loss G: 12.4609\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [36/200] Batch 11/12                         Loss D: -204.3298, loss G: 13.2845\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [37/200] Batch 11/12                         Loss D: -215.0656, loss G: 13.5316\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [38/200] Batch 11/12                         Loss D: -224.2569, loss G: 13.9632\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [39/200] Batch 11/12                         Loss D: -237.5563, loss G: 14.9971\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [40/200] Batch 11/12                         Loss D: -241.4393, loss G: 15.0802\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [41/200] Batch 11/12                         Loss D: -250.4191, loss G: 15.6118\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [42/200] Batch 11/12                         Loss D: -258.9832, loss G: 16.1767\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [43/200] Batch 11/12                         Loss D: -269.7332, loss G: 16.6614\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [44/200] Batch 11/12                         Loss D: -276.7209, loss G: 17.3440\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [45/200] Batch 11/12                         Loss D: -290.6258, loss G: 17.7180\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [46/200] Batch 11/12                         Loss D: -298.6306, loss G: 18.3877\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [47/200] Batch 11/12                         Loss D: -312.1019, loss G: 19.0827\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [48/200] Batch 11/12                         Loss D: -317.1121, loss G: 19.6082\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [49/200] Batch 11/12                         Loss D: -325.0829, loss G: 20.2489\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [50/200] Batch 11/12                         Loss D: -335.5307, loss G: 20.9120\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [51/200] Batch 11/12                         Loss D: -353.1147, loss G: 21.4283\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [52/200] Batch 11/12                         Loss D: -365.5782, loss G: 22.3217\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [53/200] Batch 11/12                         Loss D: -372.5457, loss G: 22.6374\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [54/200] Batch 11/12                         Loss D: -376.1286, loss G: 23.5294\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [55/200] Batch 11/12                         Loss D: -393.8458, loss G: 23.9691\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [56/200] Batch 11/12                         Loss D: -405.6021, loss G: 24.6806\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [57/200] Batch 11/12                         Loss D: -413.8188, loss G: 25.4080\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [58/200] Batch 11/12                         Loss D: -426.4537, loss G: 26.0861\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [59/200] Batch 11/12                         Loss D: -441.2841, loss G: 26.7516\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [60/200] Batch 11/12                         Loss D: -453.2309, loss G: 27.4991\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [61/200] Batch 11/12                         Loss D: -457.4528, loss G: 28.3059\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [62/200] Batch 11/12                         Loss D: -475.5451, loss G: 29.0032\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [63/200] Batch 11/12                         Loss D: -485.8860, loss G: 29.7631\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [64/200] Batch 11/12                         Loss D: -507.9399, loss G: 30.6033\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [65/200] Batch 11/12                         Loss D: -515.5331, loss G: 31.2574\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [66/200] Batch 11/12                         Loss D: -519.5978, loss G: 32.0417\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [67/200] Batch 11/12                         Loss D: -535.8076, loss G: 32.7619\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [68/200] Batch 11/12                         Loss D: -546.0049, loss G: 33.5685\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [69/200] Batch 11/12                         Loss D: -563.8183, loss G: 34.3199\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [70/200] Batch 11/12                         Loss D: -560.9763, loss G: 35.1250\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [71/200] Batch 11/12                         Loss D: -574.1396, loss G: 35.8687\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [72/200] Batch 11/12                         Loss D: -578.7493, loss G: 36.5397\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [73/200] Batch 11/12                         Loss D: -581.6979, loss G: 37.2439\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [74/200] Batch 11/12                         Loss D: -581.4307, loss G: 37.8713\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [75/200] Batch 11/12                         Loss D: -581.7139, loss G: 38.4967\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [76/200] Batch 11/12                         Loss D: -580.4286, loss G: 39.0346\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [77/200] Batch 11/12                         Loss D: -568.7748, loss G: 39.4606\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [78/200] Batch 11/12                         Loss D: -562.0347, loss G: 39.8928\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [79/200] Batch 11/12                         Loss D: -547.5208, loss G: 40.1992\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [80/200] Batch 11/12                         Loss D: -533.1791, loss G: 40.4493\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [81/200] Batch 11/12                         Loss D: -521.2493, loss G: 40.7479\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [82/200] Batch 11/12                         Loss D: -492.9268, loss G: 40.6444\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [83/200] Batch 11/12                         Loss D: -456.7465, loss G: 40.4359\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [84/200] Batch 11/12                         Loss D: -404.1356, loss G: 39.9140\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [85/200] Batch 11/12                         Loss D: -319.7786, loss G: 38.8173\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [86/200] Batch 11/12                         Loss D: -207.1782, loss G: 37.1676\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [87/200] Batch 11/12                         Loss D: -118.2451, loss G: 35.8499\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [88/200] Batch 11/12                         Loss D: -55.5409, loss G: 34.5451\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [89/200] Batch 11/12                         Loss D: -5.8449, loss G: 33.5634\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [90/200] Batch 11/12                         Loss D: -5.2125, loss G: 33.4074\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [91/200] Batch 11/12                         Loss D: -2.9035, loss G: 33.4324\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [92/200] Batch 11/12                         Loss D: -4.1734, loss G: 33.4519\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [93/200] Batch 11/12                         Loss D: -5.8234, loss G: 33.4531\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [94/200] Batch 11/12                         Loss D: -4.5065, loss G: 33.4897\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [95/200] Batch 11/12                         Loss D: -4.9561, loss G: 33.4836\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [96/200] Batch 11/12                         Loss D: -4.1887, loss G: 33.5055\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [97/200] Batch 11/12                         Loss D: -6.9658, loss G: 33.5634\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [98/200] Batch 11/12                         Loss D: -3.6282, loss G: 33.5336\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [99/200] Batch 11/12                         Loss D: -5.3762, loss G: 33.5416\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [100/200] Batch 11/12                         Loss D: -4.5072, loss G: 33.5893\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [101/200] Batch 11/12                         Loss D: -5.9400, loss G: 33.5767\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [102/200] Batch 11/12                         Loss D: -5.3216, loss G: 33.5796\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [103/200] Batch 11/12                         Loss D: -5.4106, loss G: 33.5913\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [104/200] Batch 11/12                         Loss D: -3.6836, loss G: 33.6241\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [105/200] Batch 11/12                         Loss D: -3.8804, loss G: 33.6446\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [106/200] Batch 11/12                         Loss D: -3.4205, loss G: 33.6694\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [107/200] Batch 11/12                         Loss D: -4.1900, loss G: 33.6548\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [108/200] Batch 11/12                         Loss D: -4.7997, loss G: 33.6600\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [109/200] Batch 11/12                         Loss D: -5.3022, loss G: 33.6939\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [110/200] Batch 11/12                         Loss D: -4.8275, loss G: 33.6947\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [111/200] Batch 11/12                         Loss D: -3.4030, loss G: 33.7168\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [112/200] Batch 11/12                         Loss D: -4.1573, loss G: 33.7280\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [113/200] Batch 11/12                         Loss D: -5.2739, loss G: 33.7286\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [114/200] Batch 11/12                         Loss D: -4.7083, loss G: 33.7509\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [115/200] Batch 11/12                         Loss D: -4.7605, loss G: 33.7532\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [116/200] Batch 11/12                         Loss D: -5.4728, loss G: 33.7870\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [117/200] Batch 11/12                         Loss D: -5.2197, loss G: 33.7894\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [118/200] Batch 11/12                         Loss D: -5.1754, loss G: 33.7871\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [119/200] Batch 11/12                         Loss D: -5.3061, loss G: 33.7933\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [120/200] Batch 11/12                         Loss D: -5.0983, loss G: 33.8152\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [121/200] Batch 11/12                         Loss D: -4.9521, loss G: 33.8176\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [122/200] Batch 11/12                         Loss D: -3.9263, loss G: 33.8452\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [123/200] Batch 11/12                         Loss D: -3.9415, loss G: 33.8525\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [124/200] Batch 11/12                         Loss D: -4.1756, loss G: 33.8728\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [125/200] Batch 11/12                         Loss D: -4.8840, loss G: 33.8638\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [126/200] Batch 11/12                         Loss D: -5.6458, loss G: 33.8827\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [127/200] Batch 11/12                         Loss D: -3.9364, loss G: 33.8971\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [128/200] Batch 11/12                         Loss D: -4.1227, loss G: 33.9089\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [129/200] Batch 11/12                         Loss D: -4.0565, loss G: 33.9296\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [130/200] Batch 11/12                         Loss D: -4.3206, loss G: 33.9138\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [131/200] Batch 11/12                         Loss D: -4.6897, loss G: 33.9474\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [132/200] Batch 11/12                         Loss D: -3.3503, loss G: 33.9801\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [133/200] Batch 11/12                         Loss D: -4.4055, loss G: 34.0077\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [134/200] Batch 11/12                         Loss D: -4.9966, loss G: 33.9662\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [135/200] Batch 11/12                         Loss D: -3.6714, loss G: 33.9744\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [136/200] Batch 11/12                         Loss D: -3.8150, loss G: 34.0025\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [137/200] Batch 11/12                         Loss D: -4.1084, loss G: 34.0090\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [138/200] Batch 11/12                         Loss D: -3.6433, loss G: 34.0393\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [139/200] Batch 11/12                         Loss D: -3.9973, loss G: 34.0296\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [140/200] Batch 11/12                         Loss D: -3.8741, loss G: 34.0377\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [141/200] Batch 11/12                         Loss D: -4.0210, loss G: 34.0429\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [142/200] Batch 11/12                         Loss D: -4.0189, loss G: 34.0487\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [143/200] Batch 11/12                         Loss D: -4.3980, loss G: 34.0728\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [144/200] Batch 11/12                         Loss D: -4.9993, loss G: 34.1206\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [145/200] Batch 11/12                         Loss D: -4.0840, loss G: 34.0963\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [146/200] Batch 11/12                         Loss D: -4.0435, loss G: 34.0883\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [147/200] Batch 11/12                         Loss D: -3.9320, loss G: 34.0988\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [148/200] Batch 11/12                         Loss D: -4.2592, loss G: 34.1187\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [149/200] Batch 11/12                         Loss D: -3.9050, loss G: 34.1318\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [150/200] Batch 11/12                         Loss D: -3.8844, loss G: 34.1236\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [151/200] Batch 11/12                         Loss D: -5.2775, loss G: 34.1562\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [152/200] Batch 11/12                         Loss D: -5.2098, loss G: 34.1489\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [153/200] Batch 11/12                         Loss D: -4.7062, loss G: 34.1574\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [154/200] Batch 11/12                         Loss D: -4.1320, loss G: 34.1691\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [155/200] Batch 11/12                         Loss D: -3.6063, loss G: 34.1822\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [156/200] Batch 11/12                         Loss D: -4.6015, loss G: 34.1835\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [157/200] Batch 11/12                         Loss D: -3.5863, loss G: 34.2076\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [158/200] Batch 11/12                         Loss D: -3.5066, loss G: 34.2110\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [159/200] Batch 11/12                         Loss D: -5.0297, loss G: 34.2431\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [160/200] Batch 11/12                         Loss D: -5.1576, loss G: 34.2442\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [161/200] Batch 11/12                         Loss D: -4.9815, loss G: 34.2428\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [162/200] Batch 11/12                         Loss D: -4.0197, loss G: 34.2461\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [163/200] Batch 11/12                         Loss D: -4.6545, loss G: 34.2747\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [164/200] Batch 11/12                         Loss D: -3.5335, loss G: 34.2943\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [165/200] Batch 11/12                         Loss D: -4.9366, loss G: 34.2997\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [166/200] Batch 11/12                         Loss D: -4.8999, loss G: 34.3055\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [167/200] Batch 11/12                         Loss D: -3.3330, loss G: 34.3106\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [168/200] Batch 11/12                         Loss D: -4.2531, loss G: 34.3224\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [169/200] Batch 11/12                         Loss D: -3.1942, loss G: 34.3302\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [170/200] Batch 11/12                         Loss D: -3.1140, loss G: 34.3439\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [171/200] Batch 11/12                         Loss D: -3.6038, loss G: 34.3533\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [172/200] Batch 11/12                         Loss D: -3.8220, loss G: 34.3583\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [173/200] Batch 11/12                         Loss D: -5.2263, loss G: 34.3639\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [174/200] Batch 11/12                         Loss D: -4.4575, loss G: 34.3736\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [175/200] Batch 11/12                         Loss D: -4.0489, loss G: 34.3956\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [176/200] Batch 11/12                         Loss D: -3.8643, loss G: 34.3989\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [177/200] Batch 11/12                         Loss D: -4.7107, loss G: 34.4000\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [178/200] Batch 11/12                         Loss D: -3.5980, loss G: 34.4241\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [179/200] Batch 11/12                         Loss D: -4.8367, loss G: 34.4205\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [180/200] Batch 11/12                         Loss D: -4.4687, loss G: 34.4426\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [181/200] Batch 11/12                         Loss D: -5.6544, loss G: 34.4494\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [182/200] Batch 11/12                         Loss D: -5.2883, loss G: 34.4588\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [183/200] Batch 11/12                         Loss D: -5.8945, loss G: 34.4609\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [184/200] Batch 11/12                         Loss D: -5.3325, loss G: 34.4721\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [185/200] Batch 11/12                         Loss D: -4.2684, loss G: 34.4791\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [186/200] Batch 11/12                         Loss D: -5.4216, loss G: 34.4874\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [187/200] Batch 11/12                         Loss D: -4.3909, loss G: 34.4944\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [188/200] Batch 11/12                         Loss D: -6.1934, loss G: 34.5045\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [189/200] Batch 11/12                         Loss D: -4.4936, loss G: 34.5174\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [190/200] Batch 11/12                         Loss D: -5.4920, loss G: 34.5265\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [191/200] Batch 11/12                         Loss D: -6.2816, loss G: 34.5378\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [192/200] Batch 11/12                         Loss D: -5.8488, loss G: 34.5494\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [193/200] Batch 11/12                         Loss D: -5.6325, loss G: 34.5603\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [194/200] Batch 11/12                         Loss D: -5.6400, loss G: 34.5582\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [195/200] Batch 11/12                         Loss D: -6.1966, loss G: 34.5717\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [196/200] Batch 11/12                         Loss D: -6.1648, loss G: 34.5851\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [197/200] Batch 11/12                         Loss D: -6.6386, loss G: 34.5846\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [198/200] Batch 11/12                         Loss D: -6.6670, loss G: 34.5974\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [199/200] Batch 11/12                         Loss D: -3.7804, loss G: 34.6126\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [0/200] Batch 11/12                         Loss D: 8.2824, loss G: 16.9339\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [1/200] Batch 11/12                         Loss D: 8.3052, loss G: 16.5214\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [2/200] Batch 11/12                         Loss D: 8.1238, loss G: 15.9519\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [3/200] Batch 11/12                         Loss D: 7.6431, loss G: 15.0453\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [4/200] Batch 11/12                         Loss D: 5.5550, loss G: 14.6438\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [5/200] Batch 11/12                         Loss D: 2.1989, loss G: 14.1027\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [6/200] Batch 11/12                         Loss D: -2.4012, loss G: 13.5590\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [7/200] Batch 11/12                         Loss D: -9.1728, loss G: 12.8739\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [8/200] Batch 11/12                         Loss D: -18.4442, loss G: 12.0862\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [9/200] Batch 11/12                         Loss D: -30.9399, loss G: 11.1914\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [10/200] Batch 11/12                         Loss D: -47.2430, loss G: 10.2041\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [11/200] Batch 11/12                         Loss D: -67.0308, loss G: 9.2597\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [12/200] Batch 11/12                         Loss D: -77.4321, loss G: 9.1231\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [13/200] Batch 11/12                         Loss D: -88.8496, loss G: 8.9261\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [14/200] Batch 11/12                         Loss D: -102.1357, loss G: 8.7844\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [15/200] Batch 11/12                         Loss D: -112.9858, loss G: 8.5069\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [16/200] Batch 11/12                         Loss D: -128.1111, loss G: 8.2320\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [17/200] Batch 11/12                         Loss D: -140.7764, loss G: 8.2250\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [18/200] Batch 11/12                         Loss D: -144.8794, loss G: 8.4334\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [19/200] Batch 11/12                         Loss D: -149.3746, loss G: 8.8175\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [20/200] Batch 11/12                         Loss D: -156.1304, loss G: 9.0597\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [21/200] Batch 11/12                         Loss D: -158.7463, loss G: 9.4836\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [22/200] Batch 11/12                         Loss D: -167.6617, loss G: 9.6063\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [23/200] Batch 11/12                         Loss D: -173.4212, loss G: 9.9071\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [24/200] Batch 11/12                         Loss D: -177.2931, loss G: 10.1534\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [25/200] Batch 11/12                         Loss D: -179.0402, loss G: 10.5178\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [26/200] Batch 11/12                         Loss D: -182.7722, loss G: 10.7230\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [27/200] Batch 11/12                         Loss D: -185.3595, loss G: 11.0137\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [28/200] Batch 11/12                         Loss D: -187.7671, loss G: 11.3544\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [29/200] Batch 11/12                         Loss D: -188.1486, loss G: 11.6909\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [30/200] Batch 11/12                         Loss D: -183.6959, loss G: 11.8343\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [31/200] Batch 11/12                         Loss D: -182.4262, loss G: 12.0746\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [32/200] Batch 11/12                         Loss D: -175.7844, loss G: 12.1337\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [33/200] Batch 11/12                         Loss D: -167.7854, loss G: 12.2429\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [34/200] Batch 11/12                         Loss D: -158.7085, loss G: 12.2887\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [35/200] Batch 11/12                         Loss D: -150.6316, loss G: 12.4315\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [36/200] Batch 11/12                         Loss D: -150.4828, loss G: 12.6438\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [37/200] Batch 11/12                         Loss D: -150.7271, loss G: 12.8425\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [38/200] Batch 11/12                         Loss D: -151.4902, loss G: 12.9919\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [39/200] Batch 11/12                         Loss D: -150.1576, loss G: 13.1955\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [40/200] Batch 11/12                         Loss D: -148.2669, loss G: 13.3621\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [41/200] Batch 11/12                         Loss D: -149.0401, loss G: 13.4557\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [42/200] Batch 11/12                         Loss D: -145.2257, loss G: 13.6582\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [43/200] Batch 11/12                         Loss D: -142.9429, loss G: 13.7707\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [44/200] Batch 11/12                         Loss D: -141.2435, loss G: 13.8910\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [45/200] Batch 11/12                         Loss D: -138.1454, loss G: 14.0089\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [46/200] Batch 11/12                         Loss D: -131.6605, loss G: 14.1545\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [47/200] Batch 11/12                         Loss D: -128.9830, loss G: 14.2361\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [48/200] Batch 11/12                         Loss D: -120.7141, loss G: 14.3636\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [49/200] Batch 11/12                         Loss D: -122.6239, loss G: 14.5340\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [50/200] Batch 11/12                         Loss D: -124.6140, loss G: 14.7169\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [51/200] Batch 11/12                         Loss D: -125.9245, loss G: 14.9119\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [52/200] Batch 11/12                         Loss D: -127.6318, loss G: 15.0752\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [53/200] Batch 11/12                         Loss D: -132.5692, loss G: 15.2163\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [54/200] Batch 11/12                         Loss D: -135.7034, loss G: 15.3824\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [55/200] Batch 11/12                         Loss D: -136.8309, loss G: 15.5522\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [56/200] Batch 11/12                         Loss D: -143.3360, loss G: 15.6988\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [57/200] Batch 11/12                         Loss D: -147.3359, loss G: 15.8790\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [58/200] Batch 11/12                         Loss D: -152.3910, loss G: 16.1494\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [59/200] Batch 11/12                         Loss D: -147.4684, loss G: 16.1998\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [60/200] Batch 11/12                         Loss D: -149.0682, loss G: 16.3619\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [61/200] Batch 11/12                         Loss D: -149.7861, loss G: 16.5185\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [62/200] Batch 11/12                         Loss D: -151.1974, loss G: 16.6969\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [63/200] Batch 11/12                         Loss D: -151.0454, loss G: 16.8362\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [64/200] Batch 11/12                         Loss D: -152.1183, loss G: 17.0027\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [65/200] Batch 11/12                         Loss D: -148.4476, loss G: 17.1190\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [66/200] Batch 11/12                         Loss D: -146.1500, loss G: 17.2568\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [67/200] Batch 11/12                         Loss D: -144.1252, loss G: 17.3986\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [68/200] Batch 11/12                         Loss D: -137.3622, loss G: 17.4602\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [69/200] Batch 11/12                         Loss D: -132.4708, loss G: 17.5527\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [70/200] Batch 11/12                         Loss D: -126.6322, loss G: 17.6354\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [71/200] Batch 11/12                         Loss D: -118.2971, loss G: 17.6795\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [72/200] Batch 11/12                         Loss D: -108.3555, loss G: 17.6968\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [73/200] Batch 11/12                         Loss D: -94.5719, loss G: 17.6989\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [74/200] Batch 11/12                         Loss D: -78.1607, loss G: 17.6293\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [75/200] Batch 11/12                         Loss D: -57.4158, loss G: 17.5521\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [76/200] Batch 11/12                         Loss D: -24.6669, loss G: 17.2954\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [77/200] Batch 11/12                         Loss D: -22.1176, loss G: 17.2992\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [78/200] Batch 11/12                         Loss D: -18.0882, loss G: 17.1834\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [79/200] Batch 11/12                         Loss D: -11.1610, loss G: 17.0130\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [80/200] Batch 11/12                         Loss D: -2.8906, loss G: 16.7991\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [81/200] Batch 11/12                         Loss D: 0.5255, loss G: 16.5556\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [82/200] Batch 11/12                         Loss D: -0.2812, loss G: 16.3615\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [83/200] Batch 11/12                         Loss D: -3.0558, loss G: 16.3320\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [84/200] Batch 11/12                         Loss D: -2.6151, loss G: 16.3299\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [85/200] Batch 11/12                         Loss D: -1.8869, loss G: 16.3279\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [86/200] Batch 11/12                         Loss D: -2.0448, loss G: 16.3537\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [87/200] Batch 11/12                         Loss D: -1.7905, loss G: 16.3624\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [88/200] Batch 11/12                         Loss D: -4.4941, loss G: 16.3934\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [89/200] Batch 11/12                         Loss D: -1.6069, loss G: 16.3738\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [90/200] Batch 11/12                         Loss D: -1.7592, loss G: 16.3753\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [91/200] Batch 11/12                         Loss D: -4.1221, loss G: 16.3943\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [92/200] Batch 11/12                         Loss D: -4.9471, loss G: 16.4165\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [93/200] Batch 11/12                         Loss D: -4.1541, loss G: 16.4222\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [94/200] Batch 11/12                         Loss D: -3.1227, loss G: 16.4240\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [95/200] Batch 11/12                         Loss D: -0.8486, loss G: 16.4118\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [96/200] Batch 11/12                         Loss D: -3.5673, loss G: 16.4360\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [97/200] Batch 11/12                         Loss D: -1.4551, loss G: 16.4343\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [98/200] Batch 11/12                         Loss D: -0.3847, loss G: 16.4946\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [99/200] Batch 11/12                         Loss D: -0.9313, loss G: 16.4487\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [100/200] Batch 11/12                         Loss D: -0.3207, loss G: 16.4903\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [101/200] Batch 11/12                         Loss D: -4.6524, loss G: 16.5119\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [102/200] Batch 11/12                         Loss D: -0.5992, loss G: 16.5021\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [103/200] Batch 11/12                         Loss D: -2.4119, loss G: 16.5093\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [104/200] Batch 11/12                         Loss D: -1.1085, loss G: 16.5299\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [105/200] Batch 11/12                         Loss D: 0.5709, loss G: 16.5250\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [106/200] Batch 11/12                         Loss D: -1.8958, loss G: 16.5428\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [107/200] Batch 11/12                         Loss D: -0.8585, loss G: 16.5402\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [108/200] Batch 11/12                         Loss D: -1.5409, loss G: 16.5677\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [109/200] Batch 11/12                         Loss D: 1.0650, loss G: 16.5797\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [110/200] Batch 11/12                         Loss D: -2.2721, loss G: 16.6131\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [111/200] Batch 11/12                         Loss D: 0.1643, loss G: 16.5712\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [112/200] Batch 11/12                         Loss D: -1.6570, loss G: 16.6085\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [113/200] Batch 11/12                         Loss D: -1.0520, loss G: 16.6187\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [114/200] Batch 11/12                         Loss D: 1.2813, loss G: 16.6373\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [115/200] Batch 11/12                         Loss D: 0.4913, loss G: 16.6374\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [116/200] Batch 11/12                         Loss D: 0.7026, loss G: 16.6487\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [117/200] Batch 11/12                         Loss D: -1.2296, loss G: 16.6729\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [118/200] Batch 11/12                         Loss D: -2.2424, loss G: 16.6812\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [119/200] Batch 11/12                         Loss D: -1.3471, loss G: 16.6830\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [120/200] Batch 11/12                         Loss D: -1.6331, loss G: 16.7025\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [121/200] Batch 11/12                         Loss D: -1.1706, loss G: 16.7101\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [122/200] Batch 11/12                         Loss D: -0.4723, loss G: 16.7098\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [123/200] Batch 11/12                         Loss D: -0.2811, loss G: 16.7316\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [124/200] Batch 11/12                         Loss D: -1.5191, loss G: 16.7855\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [125/200] Batch 11/12                         Loss D: -0.7759, loss G: 16.7601\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [126/200] Batch 11/12                         Loss D: -1.7355, loss G: 16.7967\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [127/200] Batch 11/12                         Loss D: -1.0395, loss G: 16.7904\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [128/200] Batch 11/12                         Loss D: -1.3039, loss G: 16.8077\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [129/200] Batch 11/12                         Loss D: -2.0379, loss G: 16.8451\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [130/200] Batch 11/12                         Loss D: -3.0905, loss G: 16.8708\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [131/200] Batch 11/12                         Loss D: -3.2445, loss G: 16.8793\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [132/200] Batch 11/12                         Loss D: -2.3950, loss G: 16.8813\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [133/200] Batch 11/12                         Loss D: -1.3466, loss G: 16.9096\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [134/200] Batch 11/12                         Loss D: -3.3322, loss G: 16.9340\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [135/200] Batch 11/12                         Loss D: -2.8793, loss G: 16.9450\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [136/200] Batch 11/12                         Loss D: -2.6339, loss G: 16.9554\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [137/200] Batch 11/12                         Loss D: -3.2008, loss G: 16.9787\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [138/200] Batch 11/12                         Loss D: -2.2088, loss G: 17.0035\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [139/200] Batch 11/12                         Loss D: -3.1489, loss G: 17.0100\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [140/200] Batch 11/12                         Loss D: -3.1129, loss G: 17.0369\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [141/200] Batch 11/12                         Loss D: -2.6816, loss G: 17.0611\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [142/200] Batch 11/12                         Loss D: -3.5045, loss G: 17.0682\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [143/200] Batch 11/12                         Loss D: -3.8518, loss G: 17.0892\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [144/200] Batch 11/12                         Loss D: -3.8552, loss G: 17.1130\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [145/200] Batch 11/12                         Loss D: -3.5483, loss G: 17.1389\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [146/200] Batch 11/12                         Loss D: -4.1499, loss G: 17.1533\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [147/200] Batch 11/12                         Loss D: -5.4085, loss G: 17.1667\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [148/200] Batch 11/12                         Loss D: -6.3588, loss G: 17.1936\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [149/200] Batch 11/12                         Loss D: -4.9839, loss G: 17.2086\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [150/200] Batch 11/12                         Loss D: -4.6493, loss G: 17.2264\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [151/200] Batch 11/12                         Loss D: -5.7313, loss G: 17.2451\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [152/200] Batch 11/12                         Loss D: -7.2452, loss G: 17.2722\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [153/200] Batch 11/12                         Loss D: -6.1603, loss G: 17.2834\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [154/200] Batch 11/12                         Loss D: -7.2099, loss G: 17.3078\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [155/200] Batch 11/12                         Loss D: -5.9453, loss G: 17.3158\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [156/200] Batch 11/12                         Loss D: -6.4435, loss G: 17.3329\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [157/200] Batch 11/12                         Loss D: -5.7373, loss G: 17.3392\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [158/200] Batch 11/12                         Loss D: -5.0705, loss G: 17.3420\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [159/200] Batch 11/12                         Loss D: -4.2511, loss G: 17.2526\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [160/200] Batch 11/12                         Loss D: -6.3191, loss G: 17.1782\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [161/200] Batch 11/12                         Loss D: -8.3278, loss G: 17.1500\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [162/200] Batch 11/12                         Loss D: -6.6933, loss G: 17.1479\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [163/200] Batch 11/12                         Loss D: -7.1730, loss G: 17.1515\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [164/200] Batch 11/12                         Loss D: -7.6946, loss G: 17.1749\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [165/200] Batch 11/12                         Loss D: -5.2520, loss G: 17.1821\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [166/200] Batch 11/12                         Loss D: -4.6234, loss G: 17.1694\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [167/200] Batch 11/12                         Loss D: -5.6006, loss G: 17.2047\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [168/200] Batch 11/12                         Loss D: -6.0404, loss G: 17.2220\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [169/200] Batch 11/12                         Loss D: -5.8999, loss G: 17.2253\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [170/200] Batch 11/12                         Loss D: -5.1678, loss G: 17.2126\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [171/200] Batch 11/12                         Loss D: -5.4315, loss G: 17.2260\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [172/200] Batch 11/12                         Loss D: -4.8150, loss G: 17.2159\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [173/200] Batch 11/12                         Loss D: -3.8076, loss G: 17.1950\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [174/200] Batch 11/12                         Loss D: -5.3811, loss G: 17.2391\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [175/200] Batch 11/12                         Loss D: -1.7358, loss G: 17.2299\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [176/200] Batch 11/12                         Loss D: -3.8039, loss G: 17.2057\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [177/200] Batch 11/12                         Loss D: -5.2680, loss G: 17.2540\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [178/200] Batch 11/12                         Loss D: -2.5901, loss G: 17.2087\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [179/200] Batch 11/12                         Loss D: -2.8777, loss G: 17.2045\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [180/200] Batch 11/12                         Loss D: -3.0642, loss G: 17.2115\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [181/200] Batch 11/12                         Loss D: -0.9859, loss G: 17.2335\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [182/200] Batch 11/12                         Loss D: -1.7805, loss G: 17.2123\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [183/200] Batch 11/12                         Loss D: 0.9361, loss G: 17.2688\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [184/200] Batch 11/12                         Loss D: -1.3133, loss G: 17.2164\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [185/200] Batch 11/12                         Loss D: -1.2739, loss G: 17.2134\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [186/200] Batch 11/12                         Loss D: 1.5790, loss G: 17.2778\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [187/200] Batch 11/12                         Loss D: -1.1263, loss G: 17.2159\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [188/200] Batch 11/12                         Loss D: -1.0991, loss G: 17.2147\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [189/200] Batch 11/12                         Loss D: 0.2828, loss G: 17.2422\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [190/200] Batch 11/12                         Loss D: -0.3918, loss G: 17.2221\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [191/200] Batch 11/12                         Loss D: -1.0325, loss G: 17.2163\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [192/200] Batch 11/12                         Loss D: 1.7969, loss G: 17.2812\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [193/200] Batch 11/12                         Loss D: -0.8682, loss G: 17.2218\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [194/200] Batch 11/12                         Loss D: -0.9490, loss G: 17.2186\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [195/200] Batch 11/12                         Loss D: 1.9714, loss G: 17.2867\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [196/200] Batch 11/12                         Loss D: -1.1994, loss G: 17.2127\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [197/200] Batch 11/12                         Loss D: -0.9477, loss G: 17.2198\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [198/200] Batch 11/12                         Loss D: -1.5688, loss G: 17.2191\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [199/200] Batch 11/12                         Loss D: -2.0812, loss G: 17.2304\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [0/200] Batch 11/12                         Loss D: 7.7228, loss G: 3.5639\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [1/200] Batch 11/12                         Loss D: 10.2880, loss G: 3.3406\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [2/200] Batch 11/12                         Loss D: 14.3738, loss G: 2.9780\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [3/200] Batch 11/12                         Loss D: 20.1598, loss G: 2.4546\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [4/200] Batch 11/12                         Loss D: 27.5098, loss G: 1.7843\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [5/200] Batch 11/12                         Loss D: 35.9206, loss G: 1.0142\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [6/200] Batch 11/12                         Loss D: 47.2761, loss G: -0.0210\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [7/200] Batch 11/12                         Loss D: 58.9109, loss G: -1.1015\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [8/200] Batch 11/12                         Loss D: 71.1385, loss G: -2.2668\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [9/200] Batch 11/12                         Loss D: 84.3930, loss G: -3.5581\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [10/200] Batch 11/12                         Loss D: 100.2813, loss G: -5.0913\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [11/200] Batch 11/12                         Loss D: 107.8941, loss G: -6.0035\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [12/200] Batch 11/12                         Loss D: 113.5421, loss G: -6.6399\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [13/200] Batch 11/12                         Loss D: 115.6319, loss G: -6.6378\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [14/200] Batch 11/12                         Loss D: 119.1757, loss G: -6.6019\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [15/200] Batch 11/12                         Loss D: 119.9232, loss G: -6.3504\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [16/200] Batch 11/12                         Loss D: 123.9545, loss G: -6.1399\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [17/200] Batch 11/12                         Loss D: 125.9311, loss G: -5.7713\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [18/200] Batch 11/12                         Loss D: 124.4610, loss G: -5.2533\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [19/200] Batch 11/12                         Loss D: 124.2026, loss G: -4.7470\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [20/200] Batch 11/12                         Loss D: 120.3065, loss G: -4.0817\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [21/200] Batch 11/12                         Loss D: 116.3610, loss G: -3.4183\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [22/200] Batch 11/12                         Loss D: 112.8369, loss G: -2.7294\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [23/200] Batch 11/12                         Loss D: 104.6229, loss G: -1.9754\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [24/200] Batch 11/12                         Loss D: 98.6763, loss G: -1.2580\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [25/200] Batch 11/12                         Loss D: 89.5724, loss G: -0.5588\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [26/200] Batch 11/12                         Loss D: 80.9015, loss G: 0.0697\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [27/200] Batch 11/12                         Loss D: 72.1865, loss G: 0.6299\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [28/200] Batch 11/12                         Loss D: 63.9683, loss G: 1.1179\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [29/200] Batch 11/12                         Loss D: 55.7676, loss G: 1.5155\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [30/200] Batch 11/12                         Loss D: 48.2929, loss G: 1.8054\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [31/200] Batch 11/12                         Loss D: 42.0773, loss G: 2.0157\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [32/200] Batch 11/12                         Loss D: 36.3797, loss G: 2.1575\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [33/200] Batch 11/12                         Loss D: 31.3129, loss G: 2.2455\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [34/200] Batch 11/12                         Loss D: 26.4406, loss G: 2.2316\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [35/200] Batch 11/12                         Loss D: 22.4805, loss G: 2.2151\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [36/200] Batch 11/12                         Loss D: 19.5511, loss G: 2.1553\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [37/200] Batch 11/12                         Loss D: 17.9784, loss G: 2.0076\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [38/200] Batch 11/12                         Loss D: 16.3714, loss G: 1.8621\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [39/200] Batch 11/12                         Loss D: 15.0318, loss G: 1.6390\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [40/200] Batch 11/12                         Loss D: 14.3335, loss G: 1.4285\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [41/200] Batch 11/12                         Loss D: 14.2943, loss G: 1.1594\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [42/200] Batch 11/12                         Loss D: 12.9959, loss G: 1.1180\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [43/200] Batch 11/12                         Loss D: 11.3309, loss G: 1.0425\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [44/200] Batch 11/12                         Loss D: 10.0346, loss G: 0.9661\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [45/200] Batch 11/12                         Loss D: 9.0004, loss G: 0.6222\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [46/200] Batch 11/12                         Loss D: 8.5283, loss G: 0.2790\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [47/200] Batch 11/12                         Loss D: 7.0006, loss G: 0.3819\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [48/200] Batch 11/12                         Loss D: 5.3414, loss G: 0.4827\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [49/200] Batch 11/12                         Loss D: 3.8477, loss G: 0.5619\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [50/200] Batch 11/12                         Loss D: 2.9120, loss G: 0.5082\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [51/200] Batch 11/12                         Loss D: 5.8462, loss G: 0.4194\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [52/200] Batch 11/12                         Loss D: 10.7753, loss G: 0.3278\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [53/200] Batch 11/12                         Loss D: 23.3021, loss G: -0.1875\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [54/200] Batch 11/12                         Loss D: 33.2608, loss G: -0.2629\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [55/200] Batch 11/12                         Loss D: 41.3795, loss G: -0.3047\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [56/200] Batch 11/12                         Loss D: 43.0420, loss G: -0.2628\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [57/200] Batch 11/12                         Loss D: 42.6943, loss G: -0.2143\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [58/200] Batch 11/12                         Loss D: 42.3380, loss G: -0.1615\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [59/200] Batch 11/12                         Loss D: 41.9330, loss G: -0.1057\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [60/200] Batch 11/12                         Loss D: 41.9044, loss G: -0.0321\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [61/200] Batch 11/12                         Loss D: 41.6300, loss G: 0.0432\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [62/200] Batch 11/12                         Loss D: 40.1557, loss G: 0.1056\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [63/200] Batch 11/12                         Loss D: 36.3968, loss G: 0.3517\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [64/200] Batch 11/12                         Loss D: 31.7191, loss G: 0.4928\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [65/200] Batch 11/12                         Loss D: 27.6792, loss G: 0.5787\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [66/200] Batch 11/12                         Loss D: 26.0873, loss G: 0.6762\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [67/200] Batch 11/12                         Loss D: 24.4680, loss G: 0.7674\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [68/200] Batch 11/12                         Loss D: 22.0502, loss G: 0.8925\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [69/200] Batch 11/12                         Loss D: 20.5759, loss G: 0.9763\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [70/200] Batch 11/12                         Loss D: 18.9867, loss G: 1.0963\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [71/200] Batch 11/12                         Loss D: 16.7284, loss G: 1.2247\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [72/200] Batch 11/12                         Loss D: 15.0936, loss G: 1.3258\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [73/200] Batch 11/12                         Loss D: 13.0730, loss G: 1.4503\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [74/200] Batch 11/12                         Loss D: 11.3137, loss G: 1.5540\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [75/200] Batch 11/12                         Loss D: 9.1455, loss G: 1.6723\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [76/200] Batch 11/12                         Loss D: 7.4006, loss G: 1.7814\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [77/200] Batch 11/12                         Loss D: 5.5740, loss G: 1.8844\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [78/200] Batch 11/12                         Loss D: 3.7938, loss G: 1.9794\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [79/200] Batch 11/12                         Loss D: 2.0769, loss G: 2.1148\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [80/200] Batch 11/12                         Loss D: 0.1537, loss G: 2.1923\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [81/200] Batch 11/12                         Loss D: -1.7628, loss G: 2.2913\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [82/200] Batch 11/12                         Loss D: -3.4006, loss G: 2.3863\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [83/200] Batch 11/12                         Loss D: -5.3191, loss G: 2.4854\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [84/200] Batch 11/12                         Loss D: -7.6208, loss G: 2.6044\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [85/200] Batch 11/12                         Loss D: -9.4707, loss G: 2.6462\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [86/200] Batch 11/12                         Loss D: -11.1207, loss G: 2.7327\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [87/200] Batch 11/12                         Loss D: -13.1854, loss G: 2.8003\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [88/200] Batch 11/12                         Loss D: -15.2666, loss G: 2.9015\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [89/200] Batch 11/12                         Loss D: -16.9561, loss G: 2.9347\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [90/200] Batch 11/12                         Loss D: -18.5267, loss G: 2.9995\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [91/200] Batch 11/12                         Loss D: -20.6980, loss G: 3.0496\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [92/200] Batch 11/12                         Loss D: -22.4071, loss G: 3.1004\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [93/200] Batch 11/12                         Loss D: -23.9196, loss G: 3.1515\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [94/200] Batch 11/12                         Loss D: -25.8206, loss G: 3.1881\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [95/200] Batch 11/12                         Loss D: -27.9622, loss G: 3.2241\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [96/200] Batch 11/12                         Loss D: -29.0193, loss G: 3.2468\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [97/200] Batch 11/12                         Loss D: -30.4002, loss G: 3.2663\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [98/200] Batch 11/12                         Loss D: -31.8582, loss G: 3.2716\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [99/200] Batch 11/12                         Loss D: -13.7847, loss G: 0.6915\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [100/200] Batch 11/12                         Loss D: 31.7279, loss G: -1.7451\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [101/200] Batch 11/12                         Loss D: 47.1589, loss G: -1.9877\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [102/200] Batch 11/12                         Loss D: 62.1800, loss G: -2.1414\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [103/200] Batch 11/12                         Loss D: 72.9305, loss G: -2.1772\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [104/200] Batch 11/12                         Loss D: 80.2583, loss G: -2.0261\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [105/200] Batch 11/12                         Loss D: 83.7029, loss G: -1.7200\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [106/200] Batch 11/12                         Loss D: 84.5484, loss G: -1.3118\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [107/200] Batch 11/12                         Loss D: 80.6975, loss G: -0.7757\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [108/200] Batch 11/12                         Loss D: 73.3235, loss G: -0.1204\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [109/200] Batch 11/12                         Loss D: 63.8697, loss G: 0.5699\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [110/200] Batch 11/12                         Loss D: 53.5565, loss G: 1.2490\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [111/200] Batch 11/12                         Loss D: 41.7583, loss G: 1.8805\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [112/200] Batch 11/12                         Loss D: 30.3700, loss G: 2.4310\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [113/200] Batch 11/12                         Loss D: 19.5603, loss G: 2.8596\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [114/200] Batch 11/12                         Loss D: 10.0688, loss G: 3.1704\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [115/200] Batch 11/12                         Loss D: 2.2450, loss G: 3.3877\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [116/200] Batch 11/12                         Loss D: -3.8948, loss G: 3.4896\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [117/200] Batch 11/12                         Loss D: -8.9546, loss G: 3.5512\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [118/200] Batch 11/12                         Loss D: -13.6000, loss G: 3.5167\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [119/200] Batch 11/12                         Loss D: -20.0004, loss G: 3.4256\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [120/200] Batch 11/12                         Loss D: -25.2716, loss G: 3.2906\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [121/200] Batch 11/12                         Loss D: -29.4240, loss G: 3.1425\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [122/200] Batch 11/12                         Loss D: -32.1104, loss G: 2.9724\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [123/200] Batch 11/12                         Loss D: -35.2389, loss G: 2.8163\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [124/200] Batch 11/12                         Loss D: -36.9124, loss G: 2.6309\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [125/200] Batch 11/12                         Loss D: -38.2026, loss G: 2.4693\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [126/200] Batch 11/12                         Loss D: -39.7880, loss G: 2.4962\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [127/200] Batch 11/12                         Loss D: -40.5718, loss G: 2.5242\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [128/200] Batch 11/12                         Loss D: -42.2306, loss G: 2.5882\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [129/200] Batch 11/12                         Loss D: -42.9713, loss G: 2.6054\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [130/200] Batch 11/12                         Loss D: -43.8233, loss G: 2.6532\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [131/200] Batch 11/12                         Loss D: -44.5578, loss G: 2.6758\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [132/200] Batch 11/12                         Loss D: -45.5940, loss G: 2.7198\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [133/200] Batch 11/12                         Loss D: -45.7249, loss G: 2.7630\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [134/200] Batch 11/12                         Loss D: -45.3634, loss G: 2.8068\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [135/200] Batch 11/12                         Loss D: -46.2411, loss G: 2.8414\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [136/200] Batch 11/12                         Loss D: -49.2153, loss G: 2.9083\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [137/200] Batch 11/12                         Loss D: -48.4096, loss G: 2.9042\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [138/200] Batch 11/12                         Loss D: -48.8227, loss G: 2.9489\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [139/200] Batch 11/12                         Loss D: -49.8111, loss G: 2.9896\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [140/200] Batch 11/12                         Loss D: -49.7088, loss G: 3.0369\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [141/200] Batch 11/12                         Loss D: -51.1679, loss G: 3.0731\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [142/200] Batch 11/12                         Loss D: -50.2971, loss G: 3.1181\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [143/200] Batch 11/12                         Loss D: -52.0290, loss G: 3.1511\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [144/200] Batch 11/12                         Loss D: -53.0036, loss G: 3.1966\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [145/200] Batch 11/12                         Loss D: -51.8956, loss G: 3.2410\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [146/200] Batch 11/12                         Loss D: -53.3909, loss G: 3.2746\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [147/200] Batch 11/12                         Loss D: -53.7829, loss G: 3.3159\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [148/200] Batch 11/12                         Loss D: -54.1029, loss G: 3.3561\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [149/200] Batch 11/12                         Loss D: -54.9557, loss G: 3.4030\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [150/200] Batch 11/12                         Loss D: -54.2368, loss G: 3.4425\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [151/200] Batch 11/12                         Loss D: -55.4098, loss G: 3.4823\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [152/200] Batch 11/12                         Loss D: -55.6758, loss G: 3.5277\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [153/200] Batch 11/12                         Loss D: -56.1196, loss G: 3.5678\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [154/200] Batch 11/12                         Loss D: -57.0294, loss G: 3.6105\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [155/200] Batch 11/12                         Loss D: -57.2455, loss G: 3.6520\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [156/200] Batch 11/12                         Loss D: -57.3221, loss G: 3.6938\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [157/200] Batch 11/12                         Loss D: -57.4668, loss G: 3.7341\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [158/200] Batch 11/12                         Loss D: -57.3470, loss G: 3.7752\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [159/200] Batch 11/12                         Loss D: -57.0776, loss G: 3.8078\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [160/200] Batch 11/12                         Loss D: -55.4407, loss G: 3.8347\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [161/200] Batch 11/12                         Loss D: -54.7066, loss G: 3.8705\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [162/200] Batch 11/12                         Loss D: -54.1375, loss G: 3.8900\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [163/200] Batch 11/12                         Loss D: -53.6461, loss G: 3.9148\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [164/200] Batch 11/12                         Loss D: -52.6639, loss G: 3.9340\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [165/200] Batch 11/12                         Loss D: -50.9594, loss G: 3.9425\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [166/200] Batch 11/12                         Loss D: -48.8037, loss G: 3.9506\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [167/200] Batch 11/12                         Loss D: -48.0458, loss G: 3.9618\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [168/200] Batch 11/12                         Loss D: -47.1202, loss G: 3.9603\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [169/200] Batch 11/12                         Loss D: -44.6118, loss G: 3.9551\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [170/200] Batch 11/12                         Loss D: -42.6762, loss G: 3.9513\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [171/200] Batch 11/12                         Loss D: -41.0198, loss G: 3.9366\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [172/200] Batch 11/12                         Loss D: -38.9721, loss G: 3.9234\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [173/200] Batch 11/12                         Loss D: -36.2508, loss G: 3.9111\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [174/200] Batch 11/12                         Loss D: -33.1572, loss G: 3.8964\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [175/200] Batch 11/12                         Loss D: -30.1600, loss G: 3.8756\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [176/200] Batch 11/12                         Loss D: -26.1357, loss G: 3.8481\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [177/200] Batch 11/12                         Loss D: -22.6932, loss G: 3.8154\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [178/200] Batch 11/12                         Loss D: -20.6019, loss G: 3.8088\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [179/200] Batch 11/12                         Loss D: -19.5676, loss G: 3.7930\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [180/200] Batch 11/12                         Loss D: -19.5654, loss G: 3.7978\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [181/200] Batch 11/12                         Loss D: -18.9001, loss G: 3.8002\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [182/200] Batch 11/12                         Loss D: -18.3661, loss G: 3.8060\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [183/200] Batch 11/12                         Loss D: -17.7884, loss G: 3.8111\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [184/200] Batch 11/12                         Loss D: -17.1752, loss G: 3.8137\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [185/200] Batch 11/12                         Loss D: -16.3364, loss G: 3.8145\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [186/200] Batch 11/12                         Loss D: -15.1039, loss G: 3.8070\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [187/200] Batch 11/12                         Loss D: -14.8899, loss G: 3.8072\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [188/200] Batch 11/12                         Loss D: -13.5286, loss G: 3.7880\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [189/200] Batch 11/12                         Loss D: -11.8639, loss G: 3.7652\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [190/200] Batch 11/12                         Loss D: -10.2388, loss G: 3.7422\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [191/200] Batch 11/12                         Loss D: -8.1062, loss G: 3.7310\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [192/200] Batch 11/12                         Loss D: -7.7822, loss G: 3.6941\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [193/200] Batch 11/12                         Loss D: -5.3123, loss G: 3.6617\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [194/200] Batch 11/12                         Loss D: -4.1161, loss G: 3.6444\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [195/200] Batch 11/12                         Loss D: -0.5270, loss G: 3.6001\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [196/200] Batch 11/12                         Loss D: 0.0711, loss G: 3.5731\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [197/200] Batch 11/12                         Loss D: 3.3168, loss G: 3.5252\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [198/200] Batch 11/12                         Loss D: 2.5647, loss G: 3.5189\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [199/200] Batch 11/12                         Loss D: 2.6387, loss G: 3.5201\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [0/200] Batch 11/12                         Loss D: 0.7278, loss G: 33.9158\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [1/200] Batch 11/12                         Loss D: 0.7480, loss G: 33.2378\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [2/200] Batch 11/12                         Loss D: 0.9556, loss G: 32.0023\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [3/200] Batch 11/12                         Loss D: 1.2970, loss G: 30.1502\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [4/200] Batch 11/12                         Loss D: 1.6798, loss G: 28.3316\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [5/200] Batch 11/12                         Loss D: 2.2077, loss G: 26.3181\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [6/200] Batch 11/12                         Loss D: 2.6575, loss G: 23.8840\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [7/200] Batch 11/12                         Loss D: 3.0442, loss G: 20.5351\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [8/200] Batch 11/12                         Loss D: 3.2506, loss G: 16.9334\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [9/200] Batch 11/12                         Loss D: 3.4468, loss G: 12.3076\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [10/200] Batch 11/12                         Loss D: 4.3037, loss G: 8.2664\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [11/200] Batch 11/12                         Loss D: 6.4316, loss G: 6.2701\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [12/200] Batch 11/12                         Loss D: 7.8065, loss G: 3.8297\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [13/200] Batch 11/12                         Loss D: 7.8705, loss G: 1.1161\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [14/200] Batch 11/12                         Loss D: 6.8196, loss G: -0.2138\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [15/200] Batch 11/12                         Loss D: 4.7983, loss G: -0.1882\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [16/200] Batch 11/12                         Loss D: 3.1645, loss G: -0.3197\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [17/200] Batch 11/12                         Loss D: 1.6671, loss G: 0.0726\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [18/200] Batch 11/12                         Loss D: 0.2305, loss G: 0.1040\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [19/200] Batch 11/12                         Loss D: -1.0821, loss G: 0.5507\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [20/200] Batch 11/12                         Loss D: -2.3098, loss G: 0.5034\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [21/200] Batch 11/12                         Loss D: -3.6250, loss G: 0.1684\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [22/200] Batch 11/12                         Loss D: -4.7578, loss G: 0.6847\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [23/200] Batch 11/12                         Loss D: -6.0986, loss G: 0.4261\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [24/200] Batch 11/12                         Loss D: -7.1669, loss G: 0.7034\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [25/200] Batch 11/12                         Loss D: -8.6081, loss G: 0.6927\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [26/200] Batch 11/12                         Loss D: -9.9118, loss G: 0.6306\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [27/200] Batch 11/12                         Loss D: -11.0240, loss G: 1.0032\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [28/200] Batch 11/12                         Loss D: -12.5074, loss G: 0.8956\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [29/200] Batch 11/12                         Loss D: -13.7603, loss G: 1.2043\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [30/200] Batch 11/12                         Loss D: -14.9522, loss G: 1.4305\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [31/200] Batch 11/12                         Loss D: -16.5898, loss G: 1.1297\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [32/200] Batch 11/12                         Loss D: -18.2979, loss G: 1.2517\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [33/200] Batch 11/12                         Loss D: -19.4109, loss G: 1.7719\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [34/200] Batch 11/12                         Loss D: -21.1011, loss G: 1.6679\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [35/200] Batch 11/12                         Loss D: -22.8945, loss G: 1.5270\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [36/200] Batch 11/12                         Loss D: -24.5148, loss G: 1.6669\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [37/200] Batch 11/12                         Loss D: -26.1652, loss G: 1.7528\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [38/200] Batch 11/12                         Loss D: -27.6665, loss G: 1.8392\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [39/200] Batch 11/12                         Loss D: -29.7004, loss G: 2.2508\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [40/200] Batch 11/12                         Loss D: -31.0551, loss G: 2.2048\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [41/200] Batch 11/12                         Loss D: -32.8356, loss G: 2.3046\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [42/200] Batch 11/12                         Loss D: -34.5234, loss G: 2.4023\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [43/200] Batch 11/12                         Loss D: -36.6718, loss G: 2.4843\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [44/200] Batch 11/12                         Loss D: -39.0917, loss G: 2.9444\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [45/200] Batch 11/12                         Loss D: -40.1014, loss G: 3.1040\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [46/200] Batch 11/12                         Loss D: -42.1105, loss G: 2.9542\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [47/200] Batch 11/12                         Loss D: -44.3177, loss G: 3.0506\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [48/200] Batch 11/12                         Loss D: -46.4414, loss G: 3.2636\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [49/200] Batch 11/12                         Loss D: -47.7725, loss G: 3.8070\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [50/200] Batch 11/12                         Loss D: -50.2964, loss G: 3.6822\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [51/200] Batch 11/12                         Loss D: -52.1718, loss G: 3.8773\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [52/200] Batch 11/12                         Loss D: -54.8070, loss G: 3.9229\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [53/200] Batch 11/12                         Loss D: -57.2825, loss G: 3.8960\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [54/200] Batch 11/12                         Loss D: -59.7008, loss G: 4.0221\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [55/200] Batch 11/12                         Loss D: -61.5764, loss G: 4.5602\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [56/200] Batch 11/12                         Loss D: -64.2643, loss G: 4.4469\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [57/200] Batch 11/12                         Loss D: -65.6062, loss G: 4.7964\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [58/200] Batch 11/12                         Loss D: -69.6412, loss G: 5.1923\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [59/200] Batch 11/12                         Loss D: -71.1013, loss G: 4.9663\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [60/200] Batch 11/12                         Loss D: -74.2458, loss G: 5.0389\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [61/200] Batch 11/12                         Loss D: -76.0543, loss G: 5.4390\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [62/200] Batch 11/12                         Loss D: -79.5971, loss G: 5.5210\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [63/200] Batch 11/12                         Loss D: -82.0115, loss G: 5.8149\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [64/200] Batch 11/12                         Loss D: -83.1873, loss G: 5.7587\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [65/200] Batch 11/12                         Loss D: -87.5372, loss G: 6.4549\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [66/200] Batch 11/12                         Loss D: -89.0740, loss G: 5.9712\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [67/200] Batch 11/12                         Loss D: -90.9792, loss G: 6.1315\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [68/200] Batch 11/12                         Loss D: -93.6967, loss G: 6.3861\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [69/200] Batch 11/12                         Loss D: -95.8631, loss G: 6.5735\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [70/200] Batch 11/12                         Loss D: -98.7767, loss G: 6.6618\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [71/200] Batch 11/12                         Loss D: -101.0128, loss G: 6.8943\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [72/200] Batch 11/12                         Loss D: -103.1438, loss G: 7.1187\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [73/200] Batch 11/12                         Loss D: -105.6003, loss G: 7.2522\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [74/200] Batch 11/12                         Loss D: -110.4584, loss G: 7.5254\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [75/200] Batch 11/12                         Loss D: -112.0954, loss G: 7.7079\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [76/200] Batch 11/12                         Loss D: -113.5128, loss G: 7.8706\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [77/200] Batch 11/12                         Loss D: -116.6383, loss G: 8.1035\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [78/200] Batch 11/12                         Loss D: -122.3608, loss G: 8.3616\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [79/200] Batch 11/12                         Loss D: -124.0371, loss G: 8.3204\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [80/200] Batch 11/12                         Loss D: -128.3545, loss G: 8.8158\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [81/200] Batch 11/12                         Loss D: -130.5187, loss G: 8.7994\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [82/200] Batch 11/12                         Loss D: -134.2693, loss G: 9.0833\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [83/200] Batch 11/12                         Loss D: -137.3430, loss G: 9.1420\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [84/200] Batch 11/12                         Loss D: -138.1080, loss G: 9.4387\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [85/200] Batch 11/12                         Loss D: -142.7077, loss G: 9.5419\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [86/200] Batch 11/12                         Loss D: -146.7593, loss G: 9.5795\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [87/200] Batch 11/12                         Loss D: -147.5559, loss G: 9.9509\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [88/200] Batch 11/12                         Loss D: -152.6762, loss G: 10.1173\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [89/200] Batch 11/12                         Loss D: -157.6052, loss G: 10.2427\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [90/200] Batch 11/12                         Loss D: -160.0077, loss G: 10.5465\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [91/200] Batch 11/12                         Loss D: -164.7480, loss G: 10.7388\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [92/200] Batch 11/12                         Loss D: -166.6184, loss G: 11.1396\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [93/200] Batch 11/12                         Loss D: -170.0411, loss G: 11.4874\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [94/200] Batch 11/12                         Loss D: -175.0529, loss G: 11.5490\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [95/200] Batch 11/12                         Loss D: -180.2782, loss G: 11.6985\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [96/200] Batch 11/12                         Loss D: -183.6928, loss G: 11.9690\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [97/200] Batch 11/12                         Loss D: -187.8382, loss G: 12.2981\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [98/200] Batch 11/12                         Loss D: -192.4068, loss G: 12.5945\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [99/200] Batch 11/12                         Loss D: -196.0074, loss G: 12.8998\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [100/200] Batch 11/12                         Loss D: -200.8023, loss G: 13.1494\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [101/200] Batch 11/12                         Loss D: -208.1591, loss G: 13.6292\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [102/200] Batch 11/12                         Loss D: -209.8331, loss G: 13.7439\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [103/200] Batch 11/12                         Loss D: -214.3141, loss G: 14.1223\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [104/200] Batch 11/12                         Loss D: -220.6624, loss G: 14.3712\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [105/200] Batch 11/12                         Loss D: -226.6387, loss G: 14.7456\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [106/200] Batch 11/12                         Loss D: -231.4358, loss G: 15.0523\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [107/200] Batch 11/12                         Loss D: -234.3782, loss G: 15.4528\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [108/200] Batch 11/12                         Loss D: -243.6971, loss G: 15.6588\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [109/200] Batch 11/12                         Loss D: -251.6611, loss G: 16.3089\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [110/200] Batch 11/12                         Loss D: -248.7833, loss G: 16.7462\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [111/200] Batch 11/12                         Loss D: -260.8952, loss G: 16.7668\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [112/200] Batch 11/12                         Loss D: -266.9598, loss G: 17.1676\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [113/200] Batch 11/12                         Loss D: -272.3064, loss G: 17.7168\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [114/200] Batch 11/12                         Loss D: -280.0748, loss G: 17.9237\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [115/200] Batch 11/12                         Loss D: -284.3408, loss G: 18.3415\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [116/200] Batch 11/12                         Loss D: -291.8657, loss G: 18.7569\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [117/200] Batch 11/12                         Loss D: -300.6250, loss G: 19.4440\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [118/200] Batch 11/12                         Loss D: -300.6064, loss G: 19.5134\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [119/200] Batch 11/12                         Loss D: -307.9921, loss G: 19.9365\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [120/200] Batch 11/12                         Loss D: -314.7851, loss G: 20.3615\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [121/200] Batch 11/12                         Loss D: -322.4624, loss G: 20.7424\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [122/200] Batch 11/12                         Loss D: -323.9504, loss G: 21.2417\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [123/200] Batch 11/12                         Loss D: -329.8322, loss G: 21.6214\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [124/200] Batch 11/12                         Loss D: -337.7660, loss G: 22.0003\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [125/200] Batch 11/12                         Loss D: -340.5363, loss G: 22.4438\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [126/200] Batch 11/12                         Loss D: -342.7905, loss G: 22.8437\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [127/200] Batch 11/12                         Loss D: -348.2657, loss G: 23.2739\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [128/200] Batch 11/12                         Loss D: -347.7464, loss G: 23.6595\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [129/200] Batch 11/12                         Loss D: -349.8273, loss G: 24.0453\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [130/200] Batch 11/12                         Loss D: -350.9725, loss G: 24.4145\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [131/200] Batch 11/12                         Loss D: -350.7325, loss G: 24.7788\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [132/200] Batch 11/12                         Loss D: -349.7180, loss G: 25.0450\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [133/200] Batch 11/12                         Loss D: -347.5214, loss G: 25.3939\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [134/200] Batch 11/12                         Loss D: -344.5728, loss G: 25.6267\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [135/200] Batch 11/12                         Loss D: -338.2287, loss G: 25.9936\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [136/200] Batch 11/12                         Loss D: -333.8887, loss G: 26.2961\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [137/200] Batch 11/12                         Loss D: -311.2061, loss G: 26.2756\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [138/200] Batch 11/12                         Loss D: -215.9275, loss G: 23.0702\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [139/200] Batch 11/12                         Loss D: -48.5113, loss G: 16.6563\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [140/200] Batch 11/12                         Loss D: 132.9986, loss G: 10.3503\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [141/200] Batch 11/12                         Loss D: 246.2110, loss G: 8.6445\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [142/200] Batch 11/12                         Loss D: 237.1503, loss G: 9.9670\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [143/200] Batch 11/12                         Loss D: 232.5363, loss G: 11.2522\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [144/200] Batch 11/12                         Loss D: 226.5426, loss G: 12.5353\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [145/200] Batch 11/12                         Loss D: 211.3857, loss G: 13.8456\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [146/200] Batch 11/12                         Loss D: 199.0637, loss G: 14.6965\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [147/200] Batch 11/12                         Loss D: 183.9372, loss G: 15.5612\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [148/200] Batch 11/12                         Loss D: 170.5307, loss G: 16.2934\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [149/200] Batch 11/12                         Loss D: 155.3190, loss G: 16.8577\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [150/200] Batch 11/12                         Loss D: 142.0868, loss G: 17.3959\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [151/200] Batch 11/12                         Loss D: 126.0434, loss G: 17.7257\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [152/200] Batch 11/12                         Loss D: 117.2005, loss G: 18.0090\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [153/200] Batch 11/12                         Loss D: 106.5156, loss G: 18.4903\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [154/200] Batch 11/12                         Loss D: 96.8370, loss G: 18.6124\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [155/200] Batch 11/12                         Loss D: 86.3452, loss G: 18.8722\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [156/200] Batch 11/12                         Loss D: 72.8229, loss G: 18.9412\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [157/200] Batch 11/12                         Loss D: 61.2646, loss G: 18.9843\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [158/200] Batch 11/12                         Loss D: 47.5700, loss G: 18.9550\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [159/200] Batch 11/12                         Loss D: 34.6549, loss G: 18.8331\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [160/200] Batch 11/12                         Loss D: 26.1168, loss G: 18.8940\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [161/200] Batch 11/12                         Loss D: 17.4668, loss G: 19.1142\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [162/200] Batch 11/12                         Loss D: 15.7485, loss G: 19.2584\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [163/200] Batch 11/12                         Loss D: 13.6648, loss G: 19.4530\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [164/200] Batch 11/12                         Loss D: 11.9187, loss G: 19.5474\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [165/200] Batch 11/12                         Loss D: 7.8545, loss G: 19.8669\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [166/200] Batch 11/12                         Loss D: 4.7519, loss G: 19.8882\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [167/200] Batch 11/12                         Loss D: 1.4827, loss G: 20.1430\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [168/200] Batch 11/12                         Loss D: -1.5856, loss G: 20.2566\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [169/200] Batch 11/12                         Loss D: -3.2166, loss G: 20.4178\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [170/200] Batch 11/12                         Loss D: -5.4378, loss G: 20.6325\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [171/200] Batch 11/12                         Loss D: -9.2692, loss G: 20.7792\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [172/200] Batch 11/12                         Loss D: -11.0829, loss G: 20.9593\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [173/200] Batch 11/12                         Loss D: -13.8820, loss G: 21.1195\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [174/200] Batch 11/12                         Loss D: -17.9686, loss G: 21.3063\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [175/200] Batch 11/12                         Loss D: -20.2068, loss G: 21.5342\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [176/200] Batch 11/12                         Loss D: -21.5563, loss G: 21.6060\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [177/200] Batch 11/12                         Loss D: -25.2352, loss G: 21.8618\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [178/200] Batch 11/12                         Loss D: -26.6863, loss G: 22.0193\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [179/200] Batch 11/12                         Loss D: -30.0862, loss G: 22.2020\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [180/200] Batch 11/12                         Loss D: -33.3946, loss G: 22.3649\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [181/200] Batch 11/12                         Loss D: -33.6639, loss G: 22.4704\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [182/200] Batch 11/12                         Loss D: -37.3745, loss G: 22.6351\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [183/200] Batch 11/12                         Loss D: -40.1221, loss G: 22.8936\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [184/200] Batch 11/12                         Loss D: -42.8660, loss G: 22.9266\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [185/200] Batch 11/12                         Loss D: -45.2449, loss G: 23.0646\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [186/200] Batch 11/12                         Loss D: -46.3377, loss G: 23.2606\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [187/200] Batch 11/12                         Loss D: -49.4379, loss G: 23.5096\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [188/200] Batch 11/12                         Loss D: -51.1423, loss G: 23.4672\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [189/200] Batch 11/12                         Loss D: -52.5267, loss G: 23.5644\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [190/200] Batch 11/12                         Loss D: -54.1722, loss G: 23.6506\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [191/200] Batch 11/12                         Loss D: -57.0721, loss G: 23.8556\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [192/200] Batch 11/12                         Loss D: -58.3057, loss G: 23.9181\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [193/200] Batch 11/12                         Loss D: -59.7161, loss G: 24.1093\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [194/200] Batch 11/12                         Loss D: -61.2951, loss G: 24.2290\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [195/200] Batch 11/12                         Loss D: -64.2535, loss G: 24.3087\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [196/200] Batch 11/12                         Loss D: -64.0453, loss G: 24.4711\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [197/200] Batch 11/12                         Loss D: -67.3281, loss G: 24.6287\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [198/200] Batch 11/12                         Loss D: -67.7150, loss G: 24.7121\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [199/200] Batch 11/12                         Loss D: -70.5178, loss G: 24.8151\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [0/200] Batch 11/12                         Loss D: 0.8644, loss G: 17.4006\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [1/200] Batch 11/12                         Loss D: 0.4263, loss G: 17.0970\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [2/200] Batch 11/12                         Loss D: -0.7836, loss G: 16.5997\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [3/200] Batch 11/12                         Loss D: -2.9728, loss G: 15.8715\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [4/200] Batch 11/12                         Loss D: -5.8331, loss G: 15.2901\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [5/200] Batch 11/12                         Loss D: -9.5258, loss G: 14.7383\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [6/200] Batch 11/12                         Loss D: -15.0025, loss G: 14.0296\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [7/200] Batch 11/12                         Loss D: -22.2965, loss G: 13.2703\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [8/200] Batch 11/12                         Loss D: -32.5455, loss G: 12.3036\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [9/200] Batch 11/12                         Loss D: -46.2334, loss G: 11.2144\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [10/200] Batch 11/12                         Loss D: -63.9300, loss G: 10.0006\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [11/200] Batch 11/12                         Loss D: -74.5090, loss G: 9.8375\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [12/200] Batch 11/12                         Loss D: -85.9202, loss G: 9.6461\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [13/200] Batch 11/12                         Loss D: -95.9667, loss G: 9.5051\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [14/200] Batch 11/12                         Loss D: -107.5445, loss G: 9.3665\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [15/200] Batch 11/12                         Loss D: -119.9417, loss G: 9.1839\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [16/200] Batch 11/12                         Loss D: -134.1087, loss G: 9.0672\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [17/200] Batch 11/12                         Loss D: -145.5542, loss G: 9.3888\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [18/200] Batch 11/12                         Loss D: -150.9710, loss G: 9.8656\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [19/200] Batch 11/12                         Loss D: -161.5444, loss G: 10.2289\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [20/200] Batch 11/12                         Loss D: -164.7560, loss G: 10.6001\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [21/200] Batch 11/12                         Loss D: -174.3283, loss G: 10.8781\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [22/200] Batch 11/12                         Loss D: -180.1800, loss G: 11.2635\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [23/200] Batch 11/12                         Loss D: -185.2565, loss G: 11.6515\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [24/200] Batch 11/12                         Loss D: -190.0372, loss G: 12.0664\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [25/200] Batch 11/12                         Loss D: -197.6147, loss G: 12.3883\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [26/200] Batch 11/12                         Loss D: -202.5502, loss G: 12.8044\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [27/200] Batch 11/12                         Loss D: -211.6989, loss G: 13.1116\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [28/200] Batch 11/12                         Loss D: -219.5609, loss G: 13.4957\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [29/200] Batch 11/12                         Loss D: -220.9786, loss G: 13.9597\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [30/200] Batch 11/12                         Loss D: -228.2198, loss G: 14.3141\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [31/200] Batch 11/12                         Loss D: -236.4523, loss G: 14.6555\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [32/200] Batch 11/12                         Loss D: -243.9757, loss G: 15.0432\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [33/200] Batch 11/12                         Loss D: -251.6773, loss G: 15.4156\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [34/200] Batch 11/12                         Loss D: -256.0328, loss G: 15.8142\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [35/200] Batch 11/12                         Loss D: -266.7181, loss G: 16.1766\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [36/200] Batch 11/12                         Loss D: -271.6525, loss G: 16.5660\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [37/200] Batch 11/12                         Loss D: -273.0882, loss G: 16.8952\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [38/200] Batch 11/12                         Loss D: -276.3525, loss G: 17.2026\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [39/200] Batch 11/12                         Loss D: -280.9462, loss G: 17.5529\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [40/200] Batch 11/12                         Loss D: -283.8647, loss G: 17.9225\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [41/200] Batch 11/12                         Loss D: -282.7367, loss G: 18.2877\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [42/200] Batch 11/12                         Loss D: -282.3616, loss G: 18.5964\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [43/200] Batch 11/12                         Loss D: -275.4353, loss G: 18.8519\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [44/200] Batch 11/12                         Loss D: -268.4753, loss G: 19.0906\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [45/200] Batch 11/12                         Loss D: -260.1814, loss G: 19.2671\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [46/200] Batch 11/12                         Loss D: -248.2232, loss G: 19.3800\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [47/200] Batch 11/12                         Loss D: -234.3796, loss G: 19.4495\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [48/200] Batch 11/12                         Loss D: -218.3017, loss G: 19.4314\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [49/200] Batch 11/12                         Loss D: -199.9747, loss G: 19.3813\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [50/200] Batch 11/12                         Loss D: -181.2200, loss G: 19.2611\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [51/200] Batch 11/12                         Loss D: -158.3597, loss G: 19.0588\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [52/200] Batch 11/12                         Loss D: -133.7836, loss G: 18.8142\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [53/200] Batch 11/12                         Loss D: -100.1619, loss G: 18.3760\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [54/200] Batch 11/12                         Loss D: -65.2329, loss G: 17.8551\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [55/200] Batch 11/12                         Loss D: -34.9294, loss G: 17.4321\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [56/200] Batch 11/12                         Loss D: -19.7190, loss G: 17.2559\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [57/200] Batch 11/12                         Loss D: -19.0782, loss G: 17.2528\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [58/200] Batch 11/12                         Loss D: -19.7465, loss G: 17.2583\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [59/200] Batch 11/12                         Loss D: -20.4860, loss G: 17.2785\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [60/200] Batch 11/12                         Loss D: -20.1243, loss G: 17.2547\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [61/200] Batch 11/12                         Loss D: -19.8613, loss G: 17.2650\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [62/200] Batch 11/12                         Loss D: -20.2682, loss G: 17.2685\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [63/200] Batch 11/12                         Loss D: -19.2536, loss G: 17.2821\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [64/200] Batch 11/12                         Loss D: -21.0116, loss G: 17.2911\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [65/200] Batch 11/12                         Loss D: -19.7506, loss G: 17.2842\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [66/200] Batch 11/12                         Loss D: -21.3834, loss G: 17.2904\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [67/200] Batch 11/12                         Loss D: -21.0452, loss G: 17.3051\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [68/200] Batch 11/12                         Loss D: -20.0926, loss G: 17.2948\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [69/200] Batch 11/12                         Loss D: -20.7168, loss G: 17.2992\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [70/200] Batch 11/12                         Loss D: -20.4233, loss G: 17.3099\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [71/200] Batch 11/12                         Loss D: -20.7380, loss G: 17.3049\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [72/200] Batch 11/12                         Loss D: -20.3368, loss G: 17.3059\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [73/200] Batch 11/12                         Loss D: -21.6472, loss G: 17.3200\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [74/200] Batch 11/12                         Loss D: -19.7995, loss G: 17.3156\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [75/200] Batch 11/12                         Loss D: -19.8676, loss G: 17.3195\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [76/200] Batch 11/12                         Loss D: -20.3586, loss G: 17.3261\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [77/200] Batch 11/12                         Loss D: -19.7527, loss G: 17.3465\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [78/200] Batch 11/12                         Loss D: -19.6607, loss G: 17.3525\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [79/200] Batch 11/12                         Loss D: -19.1910, loss G: 17.3645\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [80/200] Batch 11/12                         Loss D: -18.1846, loss G: 17.3591\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [81/200] Batch 11/12                         Loss D: -16.3913, loss G: 17.3484\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [82/200] Batch 11/12                         Loss D: -5.7963, loss G: 17.1667\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [83/200] Batch 11/12                         Loss D: 4.1232, loss G: 16.6798\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [84/200] Batch 11/12                         Loss D: -2.7635, loss G: 16.7169\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [85/200] Batch 11/12                         Loss D: -7.9362, loss G: 16.8273\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [86/200] Batch 11/12                         Loss D: -11.1015, loss G: 16.9694\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [87/200] Batch 11/12                         Loss D: -12.8097, loss G: 17.0659\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [88/200] Batch 11/12                         Loss D: -12.5947, loss G: 17.1703\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [89/200] Batch 11/12                         Loss D: -10.9203, loss G: 17.2133\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [90/200] Batch 11/12                         Loss D: -6.8149, loss G: 17.2622\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [91/200] Batch 11/12                         Loss D: -5.6870, loss G: 17.2964\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [92/200] Batch 11/12                         Loss D: -6.4577, loss G: 17.3380\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [93/200] Batch 11/12                         Loss D: -7.1368, loss G: 17.3997\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [94/200] Batch 11/12                         Loss D: -7.4670, loss G: 17.4461\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [95/200] Batch 11/12                         Loss D: -8.2378, loss G: 17.4988\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [96/200] Batch 11/12                         Loss D: -8.7439, loss G: 17.5269\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [97/200] Batch 11/12                         Loss D: -9.1674, loss G: 17.5717\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [98/200] Batch 11/12                         Loss D: -9.7808, loss G: 17.6147\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [99/200] Batch 11/12                         Loss D: -10.9676, loss G: 17.6549\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [100/200] Batch 11/12                         Loss D: -11.2349, loss G: 17.6965\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [101/200] Batch 11/12                         Loss D: -11.1224, loss G: 17.7324\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [102/200] Batch 11/12                         Loss D: -11.0013, loss G: 17.7441\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [103/200] Batch 11/12                         Loss D: -11.7624, loss G: 17.7337\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [104/200] Batch 11/12                         Loss D: -12.1034, loss G: 17.7072\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [105/200] Batch 11/12                         Loss D: -13.3716, loss G: 17.6769\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [106/200] Batch 11/12                         Loss D: -12.9281, loss G: 17.6503\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [107/200] Batch 11/12                         Loss D: -10.9314, loss G: 17.6427\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [108/200] Batch 11/12                         Loss D: -8.3822, loss G: 17.6320\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [109/200] Batch 11/12                         Loss D: -5.8155, loss G: 17.6143\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [110/200] Batch 11/12                         Loss D: -2.4354, loss G: 17.5914\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [111/200] Batch 11/12                         Loss D: -1.1310, loss G: 17.5818\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [112/200] Batch 11/12                         Loss D: -1.1968, loss G: 17.5777\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [113/200] Batch 11/12                         Loss D: -2.4769, loss G: 17.5717\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [114/200] Batch 11/12                         Loss D: -3.5762, loss G: 17.5697\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [115/200] Batch 11/12                         Loss D: -4.4864, loss G: 17.5706\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [116/200] Batch 11/12                         Loss D: -5.5720, loss G: 17.5678\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [117/200] Batch 11/12                         Loss D: -6.2397, loss G: 17.5699\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [118/200] Batch 11/12                         Loss D: -7.2391, loss G: 17.5730\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [119/200] Batch 11/12                         Loss D: -7.7209, loss G: 17.5744\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [120/200] Batch 11/12                         Loss D: -8.6312, loss G: 17.5752\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [121/200] Batch 11/12                         Loss D: -8.8621, loss G: 17.5813\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [122/200] Batch 11/12                         Loss D: -9.3409, loss G: 17.5864\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [123/200] Batch 11/12                         Loss D: -9.6287, loss G: 17.5917\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [124/200] Batch 11/12                         Loss D: -9.9090, loss G: 17.5953\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [125/200] Batch 11/12                         Loss D: -9.8177, loss G: 17.5995\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [126/200] Batch 11/12                         Loss D: -9.8747, loss G: 17.6056\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [127/200] Batch 11/12                         Loss D: -9.6177, loss G: 17.6103\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [128/200] Batch 11/12                         Loss D: -9.2685, loss G: 17.6151\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [129/200] Batch 11/12                         Loss D: -8.8626, loss G: 17.6212\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [130/200] Batch 11/12                         Loss D: -8.5347, loss G: 17.6205\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [131/200] Batch 11/12                         Loss D: -7.6043, loss G: 17.6264\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [132/200] Batch 11/12                         Loss D: -6.8352, loss G: 17.6283\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [133/200] Batch 11/12                         Loss D: -5.9560, loss G: 17.6277\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [134/200] Batch 11/12                         Loss D: -5.0443, loss G: 17.6290\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [135/200] Batch 11/12                         Loss D: -3.9533, loss G: 17.6286\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [136/200] Batch 11/12                         Loss D: -2.8391, loss G: 17.6257\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [137/200] Batch 11/12                         Loss D: -1.6471, loss G: 17.6182\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [138/200] Batch 11/12                         Loss D: -1.1329, loss G: 17.6128\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [139/200] Batch 11/12                         Loss D: -0.9761, loss G: 17.6127\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [140/200] Batch 11/12                         Loss D: -0.8517, loss G: 17.6128\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [141/200] Batch 11/12                         Loss D: -0.9087, loss G: 17.6133\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [142/200] Batch 11/12                         Loss D: -1.0296, loss G: 17.6140\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [143/200] Batch 11/12                         Loss D: -0.9880, loss G: 17.6148\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [144/200] Batch 11/12                         Loss D: -0.9939, loss G: 17.6153\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [145/200] Batch 11/12                         Loss D: -1.0248, loss G: 17.6161\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [146/200] Batch 11/12                         Loss D: -1.0648, loss G: 17.6168\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [147/200] Batch 11/12                         Loss D: -0.9131, loss G: 17.6173\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [148/200] Batch 11/12                         Loss D: -0.8694, loss G: 17.6180\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [149/200] Batch 11/12                         Loss D: -0.7710, loss G: 17.6185\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [150/200] Batch 11/12                         Loss D: -0.6723, loss G: 17.6191\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [151/200] Batch 11/12                         Loss D: -0.5370, loss G: 17.6195\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [152/200] Batch 11/12                         Loss D: -0.3357, loss G: 17.6199\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [153/200] Batch 11/12                         Loss D: -0.0664, loss G: 17.6202\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [154/200] Batch 11/12                         Loss D: -0.1174, loss G: 17.6207\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [155/200] Batch 11/12                         Loss D: -0.0340, loss G: 17.6211\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [156/200] Batch 11/12                         Loss D: -0.0436, loss G: 17.6214\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [157/200] Batch 11/12                         Loss D: -0.0253, loss G: 17.6219\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [158/200] Batch 11/12                         Loss D: -0.0302, loss G: 17.6223\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [159/200] Batch 11/12                         Loss D: -0.0324, loss G: 17.6228\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [160/200] Batch 11/12                         Loss D: -0.0071, loss G: 17.6233\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [161/200] Batch 11/12                         Loss D: -0.0072, loss G: 17.6236\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [162/200] Batch 11/12                         Loss D: -0.0124, loss G: 17.6240\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [163/200] Batch 11/12                         Loss D: -0.0322, loss G: 17.6243\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [164/200] Batch 11/12                         Loss D: -0.0217, loss G: 17.6248\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [165/200] Batch 11/12                         Loss D: -0.0134, loss G: 17.6251\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [166/200] Batch 11/12                         Loss D: -0.0361, loss G: 17.6254\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [167/200] Batch 11/12                         Loss D: 0.0136, loss G: 17.6259\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [168/200] Batch 11/12                         Loss D: 0.0027, loss G: 17.6264\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [169/200] Batch 11/12                         Loss D: -0.0095, loss G: 17.6267\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [170/200] Batch 11/12                         Loss D: -0.1036, loss G: 17.6270\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [171/200] Batch 11/12                         Loss D: -0.0948, loss G: 17.6273\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [172/200] Batch 11/12                         Loss D: -0.1333, loss G: 17.6276\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [173/200] Batch 11/12                         Loss D: -0.2295, loss G: 17.6280\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [174/200] Batch 11/12                         Loss D: -0.3686, loss G: 17.6282\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [175/200] Batch 11/12                         Loss D: -0.5427, loss G: 17.6286\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [176/200] Batch 11/12                         Loss D: -0.7361, loss G: 17.6289\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [177/200] Batch 11/12                         Loss D: -0.9889, loss G: 17.6291\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [178/200] Batch 11/12                         Loss D: -1.2728, loss G: 17.6292\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [179/200] Batch 11/12                         Loss D: -1.3798, loss G: 17.6294\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [180/200] Batch 11/12                         Loss D: -1.4083, loss G: 17.6296\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [181/200] Batch 11/12                         Loss D: -1.3825, loss G: 17.6298\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [182/200] Batch 11/12                         Loss D: -1.4091, loss G: 17.6302\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [183/200] Batch 11/12                         Loss D: -1.4142, loss G: 17.6304\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [184/200] Batch 11/12                         Loss D: -1.4295, loss G: 17.6305\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [185/200] Batch 11/12                         Loss D: -1.5379, loss G: 17.6309\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [186/200] Batch 11/12                         Loss D: -1.5244, loss G: 17.6310\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [187/200] Batch 11/12                         Loss D: -1.5248, loss G: 17.6311\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [188/200] Batch 11/12                         Loss D: -1.5218, loss G: 17.6314\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [189/200] Batch 11/12                         Loss D: -1.5768, loss G: 17.6314\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [190/200] Batch 11/12                         Loss D: -1.6039, loss G: 17.6317\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [191/200] Batch 11/12                         Loss D: -1.5709, loss G: 17.6318\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [192/200] Batch 11/12                         Loss D: -1.6661, loss G: 17.6319\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [193/200] Batch 11/12                         Loss D: -1.6407, loss G: 17.6320\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [194/200] Batch 11/12                         Loss D: -1.5724, loss G: 17.6321\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [195/200] Batch 11/12                         Loss D: -1.6995, loss G: 17.6322\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [196/200] Batch 11/12                         Loss D: -1.7407, loss G: 17.6323\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [197/200] Batch 11/12                         Loss D: -1.5013, loss G: 17.6325\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [198/200] Batch 11/12                         Loss D: -1.5305, loss G: 17.6326\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [199/200] Batch 11/12                         Loss D: -1.6052, loss G: 17.6326\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [0/200] Batch 11/12                         Loss D: 0.8078, loss G: 3.1833\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [1/200] Batch 11/12                         Loss D: 0.7686, loss G: 3.1678\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [2/200] Batch 11/12                         Loss D: 0.6798, loss G: 3.1596\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [3/200] Batch 11/12                         Loss D: 0.4452, loss G: 3.1254\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [4/200] Batch 11/12                         Loss D: -0.1470, loss G: 3.0396\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [5/200] Batch 11/12                         Loss D: -1.3117, loss G: 2.9264\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [6/200] Batch 11/12                         Loss D: -2.5871, loss G: 2.9068\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [7/200] Batch 11/12                         Loss D: -4.1591, loss G: 2.8980\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [8/200] Batch 11/12                         Loss D: -5.9668, loss G: 2.8971\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [9/200] Batch 11/12                         Loss D: -7.9825, loss G: 2.9188\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [10/200] Batch 11/12                         Loss D: -10.1291, loss G: 2.9535\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [11/200] Batch 11/12                         Loss D: -12.5093, loss G: 2.9986\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [12/200] Batch 11/12                         Loss D: -14.6044, loss G: 3.0558\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [13/200] Batch 11/12                         Loss D: -15.8039, loss G: 3.1168\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [14/200] Batch 11/12                         Loss D: -16.9332, loss G: 3.1643\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [15/200] Batch 11/12                         Loss D: -16.9614, loss G: 3.2070\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [16/200] Batch 11/12                         Loss D: -16.1867, loss G: 3.2376\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [17/200] Batch 11/12                         Loss D: -14.8008, loss G: 3.2543\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [18/200] Batch 11/12                         Loss D: -13.1564, loss G: 3.2570\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [19/200] Batch 11/12                         Loss D: -11.2383, loss G: 3.2495\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [20/200] Batch 11/12                         Loss D: -9.2773, loss G: 3.2357\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [21/200] Batch 11/12                         Loss D: -7.2922, loss G: 3.2134\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [22/200] Batch 11/12                         Loss D: -5.0725, loss G: 3.1896\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [23/200] Batch 11/12                         Loss D: -4.7123, loss G: 3.1948\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [24/200] Batch 11/12                         Loss D: -4.8353, loss G: 3.2046\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [25/200] Batch 11/12                         Loss D: -4.8000, loss G: 3.2136\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [26/200] Batch 11/12                         Loss D: -4.8440, loss G: 3.2218\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [27/200] Batch 11/12                         Loss D: -4.6261, loss G: 3.2298\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [28/200] Batch 11/12                         Loss D: -4.3263, loss G: 3.2364\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [29/200] Batch 11/12                         Loss D: -3.6914, loss G: 3.2416\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [30/200] Batch 11/12                         Loss D: -2.7967, loss G: 3.2455\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [31/200] Batch 11/12                         Loss D: -1.5502, loss G: 3.2460\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [32/200] Batch 11/12                         Loss D: 2.7070, loss G: 3.1378\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [33/200] Batch 11/12                         Loss D: 8.6340, loss G: 3.0601\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [34/200] Batch 11/12                         Loss D: 8.4736, loss G: 3.1092\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [35/200] Batch 11/12                         Loss D: 6.7238, loss G: 3.1254\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [36/200] Batch 11/12                         Loss D: 5.8644, loss G: 3.1322\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [37/200] Batch 11/12                         Loss D: 5.0688, loss G: 3.1383\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [38/200] Batch 11/12                         Loss D: 4.6133, loss G: 3.1363\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [39/200] Batch 11/12                         Loss D: 4.2082, loss G: 3.1386\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [40/200] Batch 11/12                         Loss D: 4.1142, loss G: 3.1387\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [41/200] Batch 11/12                         Loss D: 4.0463, loss G: 3.1397\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [42/200] Batch 11/12                         Loss D: 4.0488, loss G: 3.1419\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [43/200] Batch 11/12                         Loss D: 3.8989, loss G: 3.1420\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [44/200] Batch 11/12                         Loss D: 3.9216, loss G: 3.1446\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [45/200] Batch 11/12                         Loss D: 3.8383, loss G: 3.1434\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [46/200] Batch 11/12                         Loss D: 3.7828, loss G: 3.1470\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [47/200] Batch 11/12                         Loss D: 3.7464, loss G: 3.1471\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [48/200] Batch 11/12                         Loss D: 3.7175, loss G: 3.1477\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [49/200] Batch 11/12                         Loss D: 3.6202, loss G: 3.1489\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [50/200] Batch 11/12                         Loss D: 3.6111, loss G: 3.1502\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [51/200] Batch 11/12                         Loss D: 3.5503, loss G: 3.1508\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [52/200] Batch 11/12                         Loss D: 3.4855, loss G: 3.1538\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [53/200] Batch 11/12                         Loss D: 3.4787, loss G: 3.1528\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [54/200] Batch 11/12                         Loss D: 3.4271, loss G: 3.1560\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [55/200] Batch 11/12                         Loss D: 3.4292, loss G: 3.1594\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [56/200] Batch 11/12                         Loss D: 3.3173, loss G: 3.1581\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [57/200] Batch 11/12                         Loss D: 3.3154, loss G: 3.1577\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [58/200] Batch 11/12                         Loss D: 3.2076, loss G: 3.1601\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [59/200] Batch 11/12                         Loss D: 3.2106, loss G: 3.1600\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [60/200] Batch 11/12                         Loss D: 3.1559, loss G: 3.1609\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [61/200] Batch 11/12                         Loss D: 3.1139, loss G: 3.1630\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [62/200] Batch 11/12                         Loss D: 3.1116, loss G: 3.1633\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [63/200] Batch 11/12                         Loss D: 3.0236, loss G: 3.1643\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [64/200] Batch 11/12                         Loss D: 2.9577, loss G: 3.1662\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [65/200] Batch 11/12                         Loss D: 2.9208, loss G: 3.1672\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [66/200] Batch 11/12                         Loss D: 2.8891, loss G: 3.1682\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [67/200] Batch 11/12                         Loss D: 2.8132, loss G: 3.1696\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [68/200] Batch 11/12                         Loss D: 2.8241, loss G: 3.1727\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [69/200] Batch 11/12                         Loss D: 2.7556, loss G: 3.1709\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [70/200] Batch 11/12                         Loss D: 2.7260, loss G: 3.1724\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [71/200] Batch 11/12                         Loss D: 2.6911, loss G: 3.1735\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [72/200] Batch 11/12                         Loss D: 2.6476, loss G: 3.1784\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [73/200] Batch 11/12                         Loss D: 2.5167, loss G: 3.1752\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [74/200] Batch 11/12                         Loss D: 2.5230, loss G: 3.1761\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [75/200] Batch 11/12                         Loss D: 2.4857, loss G: 3.1785\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [76/200] Batch 11/12                         Loss D: 2.4178, loss G: 3.1788\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [77/200] Batch 11/12                         Loss D: 2.3903, loss G: 3.1826\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [78/200] Batch 11/12                         Loss D: 2.3440, loss G: 3.1824\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [79/200] Batch 11/12                         Loss D: 2.2138, loss G: 3.1812\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [80/200] Batch 11/12                         Loss D: 2.2891, loss G: 3.1832\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [81/200] Batch 11/12                         Loss D: 2.1586, loss G: 3.1828\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [82/200] Batch 11/12                         Loss D: 2.0658, loss G: 3.1837\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [83/200] Batch 11/12                         Loss D: 2.0789, loss G: 3.1844\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [84/200] Batch 11/12                         Loss D: 1.9905, loss G: 3.1867\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [85/200] Batch 11/12                         Loss D: 1.9408, loss G: 3.1865\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [86/200] Batch 11/12                         Loss D: 1.9078, loss G: 3.1890\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [87/200] Batch 11/12                         Loss D: 1.8400, loss G: 3.1893\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [88/200] Batch 11/12                         Loss D: 1.7560, loss G: 3.1907\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [89/200] Batch 11/12                         Loss D: 1.7579, loss G: 3.1899\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [90/200] Batch 11/12                         Loss D: 1.6790, loss G: 3.1912\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [91/200] Batch 11/12                         Loss D: 1.6288, loss G: 3.1944\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [92/200] Batch 11/12                         Loss D: 1.5370, loss G: 3.1921\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [93/200] Batch 11/12                         Loss D: 1.4902, loss G: 3.1968\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [94/200] Batch 11/12                         Loss D: 1.3398, loss G: 3.1934\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [95/200] Batch 11/12                         Loss D: 1.2866, loss G: 3.1942\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [96/200] Batch 11/12                         Loss D: 1.2108, loss G: 3.1949\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [97/200] Batch 11/12                         Loss D: 1.0973, loss G: 3.1958\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [98/200] Batch 11/12                         Loss D: 0.9166, loss G: 3.1963\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [99/200] Batch 11/12                         Loss D: 0.7783, loss G: 3.1971\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [100/200] Batch 11/12                         Loss D: 0.5859, loss G: 3.1981\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [101/200] Batch 11/12                         Loss D: 0.4969, loss G: 3.2018\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [102/200] Batch 11/12                         Loss D: 0.3118, loss G: 3.2002\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [103/200] Batch 11/12                         Loss D: 0.0985, loss G: 3.2021\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [104/200] Batch 11/12                         Loss D: -0.0883, loss G: 3.2028\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [105/200] Batch 11/12                         Loss D: -0.2632, loss G: 3.2036\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [106/200] Batch 11/12                         Loss D: -0.4639, loss G: 3.2076\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [107/200] Batch 11/12                         Loss D: -0.6021, loss G: 3.2043\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [108/200] Batch 11/12                         Loss D: -0.7959, loss G: 3.2054\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [109/200] Batch 11/12                         Loss D: -1.0030, loss G: 3.2043\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [110/200] Batch 11/12                         Loss D: -1.1817, loss G: 3.2047\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [111/200] Batch 11/12                         Loss D: -1.3480, loss G: 3.2033\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [112/200] Batch 11/12                         Loss D: -1.5147, loss G: 3.2015\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [113/200] Batch 11/12                         Loss D: -1.5915, loss G: 3.1978\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [114/200] Batch 11/12                         Loss D: -1.3911, loss G: 3.1953\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [115/200] Batch 11/12                         Loss D: -1.5924, loss G: 3.1910\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [116/200] Batch 11/12                         Loss D: -1.8296, loss G: 3.1848\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [117/200] Batch 11/12                         Loss D: -2.0535, loss G: 3.1808\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [118/200] Batch 11/12                         Loss D: -2.2908, loss G: 3.1812\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [119/200] Batch 11/12                         Loss D: -2.5686, loss G: 3.1785\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [120/200] Batch 11/12                         Loss D: -2.8158, loss G: 3.1777\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [121/200] Batch 11/12                         Loss D: -3.1269, loss G: 3.1777\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [122/200] Batch 11/12                         Loss D: -3.4518, loss G: 3.1783\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [123/200] Batch 11/12                         Loss D: -3.8432, loss G: 3.1770\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [124/200] Batch 11/12                         Loss D: -4.2050, loss G: 3.1760\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [125/200] Batch 11/12                         Loss D: -4.5025, loss G: 3.1742\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [126/200] Batch 11/12                         Loss D: -4.7735, loss G: 3.1725\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [127/200] Batch 11/12                         Loss D: -5.0450, loss G: 3.1750\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [128/200] Batch 11/12                         Loss D: -5.3582, loss G: 3.1719\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [129/200] Batch 11/12                         Loss D: -5.5994, loss G: 3.1719\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [130/200] Batch 11/12                         Loss D: -5.8196, loss G: 3.1779\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [131/200] Batch 11/12                         Loss D: -6.1666, loss G: 3.1794\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [132/200] Batch 11/12                         Loss D: -6.5166, loss G: 3.1851\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [133/200] Batch 11/12                         Loss D: -6.8799, loss G: 3.1872\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [134/200] Batch 11/12                         Loss D: -7.2333, loss G: 3.1945\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [135/200] Batch 11/12                         Loss D: -7.5466, loss G: 3.1965\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [136/200] Batch 11/12                         Loss D: -7.8551, loss G: 3.2003\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [137/200] Batch 11/12                         Loss D: -8.1401, loss G: 3.2088\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [138/200] Batch 11/12                         Loss D: -8.5385, loss G: 3.2189\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [139/200] Batch 11/12                         Loss D: -8.8890, loss G: 3.2300\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [140/200] Batch 11/12                         Loss D: -9.2292, loss G: 3.2419\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [141/200] Batch 11/12                         Loss D: -9.6274, loss G: 3.2519\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [142/200] Batch 11/12                         Loss D: -9.9539, loss G: 3.2554\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [143/200] Batch 11/12                         Loss D: -10.0925, loss G: 3.2560\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [144/200] Batch 11/12                         Loss D: -10.1859, loss G: 3.2534\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [145/200] Batch 11/12                         Loss D: -10.0766, loss G: 3.2509\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [146/200] Batch 11/12                         Loss D: -10.0525, loss G: 3.2478\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [147/200] Batch 11/12                         Loss D: -10.0444, loss G: 3.2438\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [148/200] Batch 11/12                         Loss D: -10.1391, loss G: 3.2413\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [149/200] Batch 11/12                         Loss D: -10.2114, loss G: 3.2396\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [150/200] Batch 11/12                         Loss D: -10.1980, loss G: 3.2378\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [151/200] Batch 11/12                         Loss D: -10.4329, loss G: 3.2371\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [152/200] Batch 11/12                         Loss D: -10.5035, loss G: 3.2364\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [153/200] Batch 11/12                         Loss D: -10.8884, loss G: 3.2347\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [154/200] Batch 11/12                         Loss D: -11.9572, loss G: 3.2301\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [155/200] Batch 11/12                         Loss D: -12.5831, loss G: 3.2273\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [156/200] Batch 11/12                         Loss D: -12.9524, loss G: 3.2272\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [157/200] Batch 11/12                         Loss D: -13.6158, loss G: 3.2235\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [158/200] Batch 11/12                         Loss D: -14.6786, loss G: 3.2233\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [159/200] Batch 11/12                         Loss D: -15.7521, loss G: 3.2293\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [160/200] Batch 11/12                         Loss D: -16.3369, loss G: 3.2419\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [161/200] Batch 11/12                         Loss D: -16.7349, loss G: 3.2533\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [162/200] Batch 11/12                         Loss D: -17.0052, loss G: 3.2599\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [163/200] Batch 11/12                         Loss D: -17.0662, loss G: 3.2635\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [164/200] Batch 11/12                         Loss D: -17.0568, loss G: 3.2643\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [165/200] Batch 11/12                         Loss D: -17.0914, loss G: 3.2647\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [166/200] Batch 11/12                         Loss D: -17.1225, loss G: 3.2638\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [167/200] Batch 11/12                         Loss D: -17.3135, loss G: 3.2638\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [168/200] Batch 11/12                         Loss D: -17.4324, loss G: 3.2622\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [169/200] Batch 11/12                         Loss D: -17.5013, loss G: 3.2620\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [170/200] Batch 11/12                         Loss D: -17.7811, loss G: 3.2616\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [171/200] Batch 11/12                         Loss D: -17.8861, loss G: 3.2613\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [172/200] Batch 11/12                         Loss D: -17.8001, loss G: 3.2609\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [173/200] Batch 11/12                         Loss D: -17.5597, loss G: 3.2607\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [174/200] Batch 11/12                         Loss D: -16.9265, loss G: 3.2606\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [175/200] Batch 11/12                         Loss D: -15.7984, loss G: 3.2590\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [176/200] Batch 11/12                         Loss D: -5.9366, loss G: 3.2103\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [177/200] Batch 11/12                         Loss D: 134.5929, loss G: -5.7377\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [178/200] Batch 11/12                         Loss D: 502.6358, loss G: -28.2920\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [179/200] Batch 11/12                         Loss D: 950.7246, loss G: -51.2144\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [180/200] Batch 11/12                         Loss D: 1394.5093, loss G: -72.6478\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [181/200] Batch 11/12                         Loss D: 1813.0516, loss G: -91.9973\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [182/200] Batch 11/12                         Loss D: 2167.2991, loss G: -107.3936\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [183/200] Batch 11/12                         Loss D: 2424.7554, loss G: -117.2888\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [184/200] Batch 11/12                         Loss D: 2605.8867, loss G: -122.7327\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [185/200] Batch 11/12                         Loss D: 2664.0850, loss G: -121.8148\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [186/200] Batch 11/12                         Loss D: 2696.8804, loss G: -119.2279\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [187/200] Batch 11/12                         Loss D: 2599.1309, loss G: -110.5428\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [188/200] Batch 11/12                         Loss D: 2475.7498, loss G: -100.4109\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [189/200] Batch 11/12                         Loss D: 2305.9031, loss G: -88.2269\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [190/200] Batch 11/12                         Loss D: 2115.6885, loss G: -75.4002\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [191/200] Batch 11/12                         Loss D: 1917.1135, loss G: -62.6677\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [192/200] Batch 11/12                         Loss D: 1710.1830, loss G: -50.4661\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [193/200] Batch 11/12                         Loss D: 1492.7407, loss G: -39.0886\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [194/200] Batch 11/12                         Loss D: 1329.9164, loss G: -30.2173\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [195/200] Batch 11/12                         Loss D: 1096.3320, loss G: -20.7804\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [196/200] Batch 11/12                         Loss D: 874.1958, loss G: -11.6070\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [197/200] Batch 11/12                         Loss D: 670.0706, loss G: -1.7921\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [198/200] Batch 11/12                         Loss D: 465.5500, loss G: 7.1712\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [199/200] Batch 11/12                         Loss D: 273.0082, loss G: 14.6992\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [0/200] Batch 11/12                         Loss D: -0.2640, loss G: 34.1647\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [1/200] Batch 11/12                         Loss D: 0.8437, loss G: 33.4624\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [2/200] Batch 11/12                         Loss D: 2.3481, loss G: 32.2560\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [3/200] Batch 11/12                         Loss D: 4.2421, loss G: 30.3407\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [4/200] Batch 11/12                         Loss D: 7.2026, loss G: 28.7364\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [5/200] Batch 11/12                         Loss D: 10.9397, loss G: 26.9554\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [6/200] Batch 11/12                         Loss D: 15.2582, loss G: 24.5542\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [7/200] Batch 11/12                         Loss D: 20.5540, loss G: 21.4014\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [8/200] Batch 11/12                         Loss D: 25.6790, loss G: 17.6740\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [9/200] Batch 11/12                         Loss D: 31.5070, loss G: 12.7884\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [10/200] Batch 11/12                         Loss D: 36.5921, loss G: 7.3781\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [11/200] Batch 11/12                         Loss D: 39.7779, loss G: 4.4472\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [12/200] Batch 11/12                         Loss D: 44.3436, loss G: 1.5042\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [13/200] Batch 11/12                         Loss D: 48.7802, loss G: -2.0677\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [14/200] Batch 11/12                         Loss D: 45.5114, loss G: -3.3955\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [15/200] Batch 11/12                         Loss D: 37.7323, loss G: -3.0359\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [16/200] Batch 11/12                         Loss D: 30.0717, loss G: -2.2789\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [17/200] Batch 11/12                         Loss D: 24.8118, loss G: -2.1104\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [18/200] Batch 11/12                         Loss D: 18.2694, loss G: -1.9165\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [19/200] Batch 11/12                         Loss D: 13.0818, loss G: -1.1093\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [20/200] Batch 11/12                         Loss D: 7.7972, loss G: -1.1959\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [21/200] Batch 11/12                         Loss D: 2.5702, loss G: -0.9111\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [22/200] Batch 11/12                         Loss D: -2.8439, loss G: -0.6385\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [23/200] Batch 11/12                         Loss D: -7.5525, loss G: -0.0480\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [24/200] Batch 11/12                         Loss D: -12.6575, loss G: 0.2479\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [25/200] Batch 11/12                         Loss D: -17.7434, loss G: 0.4862\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [26/200] Batch 11/12                         Loss D: -22.8906, loss G: 0.7258\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [27/200] Batch 11/12                         Loss D: -28.0951, loss G: 1.1233\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [28/200] Batch 11/12                         Loss D: -33.1744, loss G: 1.7275\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [29/200] Batch 11/12                         Loss D: -38.9926, loss G: 1.4656\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [30/200] Batch 11/12                         Loss D: -44.3651, loss G: 2.0315\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [31/200] Batch 11/12                         Loss D: -50.0043, loss G: 2.2082\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [32/200] Batch 11/12                         Loss D: -55.5033, loss G: 2.5632\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [33/200] Batch 11/12                         Loss D: -62.1176, loss G: 3.0741\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [34/200] Batch 11/12                         Loss D: -67.4216, loss G: 3.2582\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [35/200] Batch 11/12                         Loss D: -73.2957, loss G: 3.6355\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [36/200] Batch 11/12                         Loss D: -79.2841, loss G: 4.0971\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [37/200] Batch 11/12                         Loss D: -86.1218, loss G: 4.2808\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [38/200] Batch 11/12                         Loss D: -91.1647, loss G: 5.0368\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [39/200] Batch 11/12                         Loss D: -97.7386, loss G: 5.1940\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [40/200] Batch 11/12                         Loss D: -105.2941, loss G: 5.5412\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [41/200] Batch 11/12                         Loss D: -110.5251, loss G: 5.8934\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [42/200] Batch 11/12                         Loss D: -115.7757, loss G: 6.4188\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [43/200] Batch 11/12                         Loss D: -124.2779, loss G: 6.6127\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [44/200] Batch 11/12                         Loss D: -131.7989, loss G: 7.1698\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [45/200] Batch 11/12                         Loss D: -138.0581, loss G: 7.4214\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [46/200] Batch 11/12                         Loss D: -144.3072, loss G: 7.7783\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [47/200] Batch 11/12                         Loss D: -151.9369, loss G: 8.2156\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [48/200] Batch 11/12                         Loss D: -158.1235, loss G: 8.7752\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [49/200] Batch 11/12                         Loss D: -167.2937, loss G: 9.1159\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [50/200] Batch 11/12                         Loss D: -175.2057, loss G: 9.5612\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [51/200] Batch 11/12                         Loss D: -181.7970, loss G: 9.9748\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [52/200] Batch 11/12                         Loss D: -189.7651, loss G: 10.4816\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [53/200] Batch 11/12                         Loss D: -197.5445, loss G: 11.0454\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [54/200] Batch 11/12                         Loss D: -207.1321, loss G: 11.4259\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [55/200] Batch 11/12                         Loss D: -216.2367, loss G: 12.0491\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [56/200] Batch 11/12                         Loss D: -223.2118, loss G: 12.6082\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [57/200] Batch 11/12                         Loss D: -231.3090, loss G: 13.1673\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [58/200] Batch 11/12                         Loss D: -241.6853, loss G: 13.5695\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [59/200] Batch 11/12                         Loss D: -252.3403, loss G: 14.1411\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [60/200] Batch 11/12                         Loss D: -260.0873, loss G: 14.7046\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [61/200] Batch 11/12                         Loss D: -270.7229, loss G: 15.2710\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [62/200] Batch 11/12                         Loss D: -282.1151, loss G: 15.9251\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [63/200] Batch 11/12                         Loss D: -291.3829, loss G: 16.4349\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [64/200] Batch 11/12                         Loss D: -298.2610, loss G: 17.1994\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [65/200] Batch 11/12                         Loss D: -313.4279, loss G: 17.7527\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [66/200] Batch 11/12                         Loss D: -320.9486, loss G: 18.3848\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [67/200] Batch 11/12                         Loss D: -333.0944, loss G: 18.9938\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [68/200] Batch 11/12                         Loss D: -344.2303, loss G: 19.6303\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [69/200] Batch 11/12                         Loss D: -353.3955, loss G: 20.3586\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [70/200] Batch 11/12                         Loss D: -367.1368, loss G: 21.0251\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [71/200] Batch 11/12                         Loss D: -381.4928, loss G: 21.8970\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [72/200] Batch 11/12                         Loss D: -384.9807, loss G: 22.5682\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [73/200] Batch 11/12                         Loss D: -402.5873, loss G: 23.1426\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [74/200] Batch 11/12                         Loss D: -411.9629, loss G: 23.9552\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [75/200] Batch 11/12                         Loss D: -422.0990, loss G: 24.7274\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [76/200] Batch 11/12                         Loss D: -432.7631, loss G: 25.5513\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [77/200] Batch 11/12                         Loss D: -447.4590, loss G: 26.3151\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [78/200] Batch 11/12                         Loss D: -458.5303, loss G: 27.1400\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [79/200] Batch 11/12                         Loss D: -463.8055, loss G: 28.0537\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [80/200] Batch 11/12                         Loss D: -478.7644, loss G: 28.9187\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [81/200] Batch 11/12                         Loss D: -493.8375, loss G: 29.8548\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [82/200] Batch 11/12                         Loss D: -499.7589, loss G: 30.8690\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [83/200] Batch 11/12                         Loss D: -498.5525, loss G: 31.8602\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [84/200] Batch 11/12                         Loss D: -510.9460, loss G: 32.9064\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [85/200] Batch 11/12                         Loss D: -513.3134, loss G: 34.0081\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [86/200] Batch 11/12                         Loss D: -507.8048, loss G: 34.9861\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [87/200] Batch 11/12                         Loss D: -497.8986, loss G: 35.8934\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [88/200] Batch 11/12                         Loss D: -469.4268, loss G: 36.5499\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [89/200] Batch 11/12                         Loss D: -431.3308, loss G: 36.9870\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [90/200] Batch 11/12                         Loss D: -378.0631, loss G: 37.1384\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [91/200] Batch 11/12                         Loss D: -372.4782, loss G: 37.7258\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [92/200] Batch 11/12                         Loss D: -353.3798, loss G: 37.9800\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [93/200] Batch 11/12                         Loss D: -330.9913, loss G: 37.9901\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [94/200] Batch 11/12                         Loss D: -300.3063, loss G: 37.7607\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [95/200] Batch 11/12                         Loss D: -261.9310, loss G: 37.2975\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [96/200] Batch 11/12                         Loss D: -216.8320, loss G: 36.6112\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [97/200] Batch 11/12                         Loss D: -157.2814, loss G: 35.6186\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [98/200] Batch 11/12                         Loss D: -87.1935, loss G: 34.2438\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [99/200] Batch 11/12                         Loss D: -30.6168, loss G: 32.9861\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [100/200] Batch 11/12                         Loss D: -39.1408, loss G: 32.5901\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [101/200] Batch 11/12                         Loss D: -55.8698, loss G: 32.5338\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [102/200] Batch 11/12                         Loss D: -71.3601, loss G: 32.4759\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [103/200] Batch 11/12                         Loss D: -87.7813, loss G: 32.5048\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [104/200] Batch 11/12                         Loss D: -102.9369, loss G: 32.4948\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [105/200] Batch 11/12                         Loss D: -114.4739, loss G: 32.5396\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [106/200] Batch 11/12                         Loss D: -126.2516, loss G: 32.6782\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [107/200] Batch 11/12                         Loss D: -132.5601, loss G: 32.7562\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [108/200] Batch 11/12                         Loss D: -140.4194, loss G: 32.8924\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [109/200] Batch 11/12                         Loss D: -143.5476, loss G: 33.0214\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [110/200] Batch 11/12                         Loss D: -146.4606, loss G: 33.2108\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [111/200] Batch 11/12                         Loss D: -143.7947, loss G: 33.2678\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [112/200] Batch 11/12                         Loss D: -138.9347, loss G: 33.4144\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [113/200] Batch 11/12                         Loss D: -130.2484, loss G: 33.4926\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [114/200] Batch 11/12                         Loss D: -119.3431, loss G: 33.5683\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [115/200] Batch 11/12                         Loss D: -106.2959, loss G: 33.6182\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [116/200] Batch 11/12                         Loss D: -94.6154, loss G: 33.6036\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [117/200] Batch 11/12                         Loss D: -73.9536, loss G: 33.5269\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [118/200] Batch 11/12                         Loss D: -55.0908, loss G: 33.4194\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [119/200] Batch 11/12                         Loss D: -33.5682, loss G: 33.3941\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [120/200] Batch 11/12                         Loss D: -15.3980, loss G: 33.2321\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [121/200] Batch 11/12                         Loss D: -12.5173, loss G: 33.2307\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [122/200] Batch 11/12                         Loss D: -10.6992, loss G: 33.2161\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [123/200] Batch 11/12                         Loss D: -13.5154, loss G: 33.2771\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [124/200] Batch 11/12                         Loss D: -11.6586, loss G: 33.2589\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [125/200] Batch 11/12                         Loss D: -11.2269, loss G: 33.2923\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [126/200] Batch 11/12                         Loss D: -10.8540, loss G: 33.3215\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [127/200] Batch 11/12                         Loss D: -9.8829, loss G: 33.2967\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [128/200] Batch 11/12                         Loss D: -11.0896, loss G: 33.3175\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [129/200] Batch 11/12                         Loss D: -8.9878, loss G: 33.3677\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [130/200] Batch 11/12                         Loss D: -10.9498, loss G: 33.3378\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [131/200] Batch 11/12                         Loss D: -11.2671, loss G: 33.3688\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [132/200] Batch 11/12                         Loss D: -9.6678, loss G: 33.4399\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [133/200] Batch 11/12                         Loss D: -9.7283, loss G: 33.4533\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [134/200] Batch 11/12                         Loss D: -12.2627, loss G: 33.4307\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [135/200] Batch 11/12                         Loss D: -12.4392, loss G: 33.4548\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [136/200] Batch 11/12                         Loss D: -10.4779, loss G: 33.4197\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [137/200] Batch 11/12                         Loss D: -11.1993, loss G: 33.4349\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [138/200] Batch 11/12                         Loss D: -10.3918, loss G: 33.4427\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [139/200] Batch 11/12                         Loss D: -10.7659, loss G: 33.5498\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [140/200] Batch 11/12                         Loss D: -10.7046, loss G: 33.5012\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [141/200] Batch 11/12                         Loss D: -10.9582, loss G: 33.5155\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [142/200] Batch 11/12                         Loss D: -9.7933, loss G: 33.5491\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [143/200] Batch 11/12                         Loss D: -10.0526, loss G: 33.5535\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [144/200] Batch 11/12                         Loss D: -10.2851, loss G: 33.5988\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [145/200] Batch 11/12                         Loss D: -9.8471, loss G: 33.5534\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [146/200] Batch 11/12                         Loss D: -9.3005, loss G: 33.5665\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [147/200] Batch 11/12                         Loss D: -9.4922, loss G: 33.5500\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [148/200] Batch 11/12                         Loss D: -9.8484, loss G: 33.6152\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [149/200] Batch 11/12                         Loss D: -10.3106, loss G: 33.6609\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [150/200] Batch 11/12                         Loss D: -8.9878, loss G: 33.6184\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [151/200] Batch 11/12                         Loss D: -9.4448, loss G: 33.6296\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [152/200] Batch 11/12                         Loss D: -8.7433, loss G: 33.6253\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [153/200] Batch 11/12                         Loss D: -7.8743, loss G: 33.7523\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [154/200] Batch 11/12                         Loss D: -9.8033, loss G: 33.7029\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [155/200] Batch 11/12                         Loss D: -9.2070, loss G: 33.6673\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [156/200] Batch 11/12                         Loss D: -7.6020, loss G: 33.7060\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [157/200] Batch 11/12                         Loss D: -8.1169, loss G: 33.7331\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [158/200] Batch 11/12                         Loss D: -9.1122, loss G: 33.7318\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [159/200] Batch 11/12                         Loss D: -9.3796, loss G: 33.7369\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [160/200] Batch 11/12                         Loss D: -9.9788, loss G: 33.8155\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [161/200] Batch 11/12                         Loss D: -9.6571, loss G: 33.7686\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [162/200] Batch 11/12                         Loss D: -9.3861, loss G: 33.7798\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [163/200] Batch 11/12                         Loss D: -10.6414, loss G: 33.8372\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [164/200] Batch 11/12                         Loss D: -8.7657, loss G: 33.8181\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [165/200] Batch 11/12                         Loss D: -8.1748, loss G: 33.8183\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [166/200] Batch 11/12                         Loss D: -8.2041, loss G: 33.8611\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [167/200] Batch 11/12                         Loss D: -9.6148, loss G: 33.8609\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [168/200] Batch 11/12                         Loss D: -10.4556, loss G: 33.9285\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [169/200] Batch 11/12                         Loss D: -9.7648, loss G: 33.9308\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [170/200] Batch 11/12                         Loss D: -9.9934, loss G: 33.8885\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [171/200] Batch 11/12                         Loss D: -7.7343, loss G: 33.8912\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [172/200] Batch 11/12                         Loss D: -9.3793, loss G: 33.9247\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [173/200] Batch 11/12                         Loss D: -10.6159, loss G: 33.9837\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [174/200] Batch 11/12                         Loss D: -9.7856, loss G: 34.0052\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [175/200] Batch 11/12                         Loss D: -8.8733, loss G: 33.9615\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [176/200] Batch 11/12                         Loss D: -9.2403, loss G: 33.9986\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [177/200] Batch 11/12                         Loss D: -7.7555, loss G: 33.9728\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [178/200] Batch 11/12                         Loss D: -8.5816, loss G: 33.9878\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [179/200] Batch 11/12                         Loss D: -7.6003, loss G: 34.0767\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [180/200] Batch 11/12                         Loss D: -6.7968, loss G: 34.0568\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [181/200] Batch 11/12                         Loss D: -7.9784, loss G: 34.0966\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [182/200] Batch 11/12                         Loss D: -9.2297, loss G: 34.0386\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [183/200] Batch 11/12                         Loss D: -7.6412, loss G: 34.1441\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [184/200] Batch 11/12                         Loss D: -8.6412, loss G: 34.0911\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [185/200] Batch 11/12                         Loss D: -8.0710, loss G: 34.1021\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [186/200] Batch 11/12                         Loss D: -9.6910, loss G: 34.1061\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [187/200] Batch 11/12                         Loss D: -7.9997, loss G: 34.1727\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [188/200] Batch 11/12                         Loss D: -8.0786, loss G: 34.1949\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [189/200] Batch 11/12                         Loss D: -8.1708, loss G: 34.1550\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [190/200] Batch 11/12                         Loss D: -10.1657, loss G: 34.1961\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [191/200] Batch 11/12                         Loss D: -8.5264, loss G: 34.1790\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [192/200] Batch 11/12                         Loss D: -10.6876, loss G: 34.3178\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [193/200] Batch 11/12                         Loss D: -7.6451, loss G: 34.2135\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [194/200] Batch 11/12                         Loss D: -7.7006, loss G: 34.2583\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [195/200] Batch 11/12                         Loss D: -8.1041, loss G: 34.2786\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [196/200] Batch 11/12                         Loss D: -9.1844, loss G: 34.2664\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [197/200] Batch 11/12                         Loss D: -8.1749, loss G: 34.2881\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [198/200] Batch 11/12                         Loss D: -9.9555, loss G: 34.2939\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [199/200] Batch 11/12                         Loss D: -9.6068, loss G: 34.3328\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [0/200] Batch 11/12                         Loss D: 0.0028, loss G: 17.0872\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [1/200] Batch 11/12                         Loss D: -0.1483, loss G: 16.7553\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [2/200] Batch 11/12                         Loss D: -0.1738, loss G: 16.1386\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [3/200] Batch 11/12                         Loss D: 0.0026, loss G: 15.1993\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [4/200] Batch 11/12                         Loss D: -0.1508, loss G: 14.1133\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [5/200] Batch 11/12                         Loss D: -0.7630, loss G: 13.3230\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [6/200] Batch 11/12                         Loss D: -1.7128, loss G: 12.3608\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [7/200] Batch 11/12                         Loss D: -3.0529, loss G: 11.1514\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [8/200] Batch 11/12                         Loss D: -5.2716, loss G: 9.4712\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [9/200] Batch 11/12                         Loss D: -8.3921, loss G: 7.4950\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [10/200] Batch 11/12                         Loss D: -12.1782, loss G: 6.0042\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [11/200] Batch 11/12                         Loss D: -14.9476, loss G: 5.0084\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [12/200] Batch 11/12                         Loss D: -16.2865, loss G: 3.9335\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [13/200] Batch 11/12                         Loss D: -16.4774, loss G: 2.6706\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [14/200] Batch 11/12                         Loss D: -16.5286, loss G: 1.4535\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [15/200] Batch 11/12                         Loss D: -18.0997, loss G: 1.0570\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [16/200] Batch 11/12                         Loss D: -18.9150, loss G: 0.9008\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [17/200] Batch 11/12                         Loss D: -20.4192, loss G: 0.9200\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [18/200] Batch 11/12                         Loss D: -21.3664, loss G: 1.0761\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [19/200] Batch 11/12                         Loss D: -23.2128, loss G: 1.0939\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [20/200] Batch 11/12                         Loss D: -24.3823, loss G: 1.1620\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [21/200] Batch 11/12                         Loss D: -24.9992, loss G: 1.1722\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [22/200] Batch 11/12                         Loss D: -26.7561, loss G: 1.2959\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [23/200] Batch 11/12                         Loss D: -27.5194, loss G: 1.2556\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [24/200] Batch 11/12                         Loss D: -28.2625, loss G: 1.4333\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [25/200] Batch 11/12                         Loss D: -29.9448, loss G: 1.4199\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [26/200] Batch 11/12                         Loss D: -31.2439, loss G: 1.5088\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [27/200] Batch 11/12                         Loss D: -31.8504, loss G: 1.4451\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [28/200] Batch 11/12                         Loss D: -32.8106, loss G: 1.6367\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [29/200] Batch 11/12                         Loss D: -34.2138, loss G: 1.5800\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [30/200] Batch 11/12                         Loss D: -35.2437, loss G: 1.6454\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [31/200] Batch 11/12                         Loss D: -37.0318, loss G: 1.7618\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [32/200] Batch 11/12                         Loss D: -37.4111, loss G: 1.8667\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [33/200] Batch 11/12                         Loss D: -38.4957, loss G: 1.8427\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [34/200] Batch 11/12                         Loss D: -40.4858, loss G: 2.1868\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [35/200] Batch 11/12                         Loss D: -40.7088, loss G: 2.0013\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [36/200] Batch 11/12                         Loss D: -40.5616, loss G: 2.2648\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [37/200] Batch 11/12                         Loss D: -42.4061, loss G: 2.0070\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [38/200] Batch 11/12                         Loss D: -43.3260, loss G: 2.1009\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [39/200] Batch 11/12                         Loss D: -44.7897, loss G: 2.1337\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [40/200] Batch 11/12                         Loss D: -45.4288, loss G: 2.1916\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [41/200] Batch 11/12                         Loss D: -46.1922, loss G: 2.2481\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [42/200] Batch 11/12                         Loss D: -46.8336, loss G: 2.4730\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [43/200] Batch 11/12                         Loss D: -48.4274, loss G: 2.3959\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [44/200] Batch 11/12                         Loss D: -50.3470, loss G: 2.6079\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [45/200] Batch 11/12                         Loss D: -50.8351, loss G: 2.4479\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [46/200] Batch 11/12                         Loss D: -51.5196, loss G: 2.6300\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [47/200] Batch 11/12                         Loss D: -53.7304, loss G: 2.7578\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [48/200] Batch 11/12                         Loss D: -54.0561, loss G: 2.6407\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [49/200] Batch 11/12                         Loss D: -54.8124, loss G: 2.7124\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [50/200] Batch 11/12                         Loss D: -56.0757, loss G: 2.8479\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [51/200] Batch 11/12                         Loss D: -57.5446, loss G: 2.8153\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [52/200] Batch 11/12                         Loss D: -59.2891, loss G: 3.0144\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [53/200] Batch 11/12                         Loss D: -59.1907, loss G: 3.1046\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [54/200] Batch 11/12                         Loss D: -61.0586, loss G: 3.0483\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [55/200] Batch 11/12                         Loss D: -61.1538, loss G: 3.3355\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [56/200] Batch 11/12                         Loss D: -63.7824, loss G: 3.2606\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [57/200] Batch 11/12                         Loss D: -64.8877, loss G: 3.2683\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [58/200] Batch 11/12                         Loss D: -65.7821, loss G: 3.3680\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [59/200] Batch 11/12                         Loss D: -66.8770, loss G: 3.5042\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [60/200] Batch 11/12                         Loss D: -69.0810, loss G: 3.4955\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [61/200] Batch 11/12                         Loss D: -70.2561, loss G: 3.5438\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [62/200] Batch 11/12                         Loss D: -71.2889, loss G: 3.7004\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [63/200] Batch 11/12                         Loss D: -72.5382, loss G: 3.7569\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [64/200] Batch 11/12                         Loss D: -75.9714, loss G: 4.0817\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [65/200] Batch 11/12                         Loss D: -74.1218, loss G: 4.0807\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [66/200] Batch 11/12                         Loss D: -77.3651, loss G: 3.9503\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [67/200] Batch 11/12                         Loss D: -79.3192, loss G: 4.0602\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [68/200] Batch 11/12                         Loss D: -79.7453, loss G: 4.1693\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [69/200] Batch 11/12                         Loss D: -81.6323, loss G: 4.1903\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [70/200] Batch 11/12                         Loss D: -83.1689, loss G: 4.3032\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [71/200] Batch 11/12                         Loss D: -83.8416, loss G: 4.4634\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [72/200] Batch 11/12                         Loss D: -86.7527, loss G: 4.4385\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [73/200] Batch 11/12                         Loss D: -86.8649, loss G: 4.6597\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [74/200] Batch 11/12                         Loss D: -89.6908, loss G: 4.6233\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [75/200] Batch 11/12                         Loss D: -90.0958, loss G: 4.8585\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [76/200] Batch 11/12                         Loss D: -92.7679, loss G: 4.8506\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [77/200] Batch 11/12                         Loss D: -95.0206, loss G: 4.9058\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [78/200] Batch 11/12                         Loss D: -97.7987, loss G: 5.1970\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [79/200] Batch 11/12                         Loss D: -99.6636, loss G: 5.3475\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [80/200] Batch 11/12                         Loss D: -98.5983, loss G: 5.2638\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [81/200] Batch 11/12                         Loss D: -101.9660, loss G: 5.2881\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [82/200] Batch 11/12                         Loss D: -103.3190, loss G: 5.3808\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [83/200] Batch 11/12                         Loss D: -105.3981, loss G: 5.5412\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [84/200] Batch 11/12                         Loss D: -106.1158, loss G: 5.6518\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [85/200] Batch 11/12                         Loss D: -108.7882, loss G: 5.7056\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [86/200] Batch 11/12                         Loss D: -109.5466, loss G: 5.8945\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [87/200] Batch 11/12                         Loss D: -113.2792, loss G: 5.9200\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [88/200] Batch 11/12                         Loss D: -115.5298, loss G: 6.0557\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [89/200] Batch 11/12                         Loss D: -116.4177, loss G: 6.1058\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [90/200] Batch 11/12                         Loss D: -118.4525, loss G: 6.2513\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [91/200] Batch 11/12                         Loss D: -119.3888, loss G: 6.3911\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [92/200] Batch 11/12                         Loss D: -121.1482, loss G: 6.5185\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [93/200] Batch 11/12                         Loss D: -126.1732, loss G: 6.7670\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [94/200] Batch 11/12                         Loss D: -124.8425, loss G: 6.7533\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [95/200] Batch 11/12                         Loss D: -127.7550, loss G: 6.8010\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [96/200] Batch 11/12                         Loss D: -129.6491, loss G: 6.9432\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [97/200] Batch 11/12                         Loss D: -131.1229, loss G: 7.0801\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [98/200] Batch 11/12                         Loss D: -132.5927, loss G: 7.2864\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [99/200] Batch 11/12                         Loss D: -137.6320, loss G: 7.3240\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [100/200] Batch 11/12                         Loss D: -138.3312, loss G: 7.3688\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [101/200] Batch 11/12                         Loss D: -139.9536, loss G: 7.5912\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [102/200] Batch 11/12                         Loss D: -141.4658, loss G: 7.7340\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [103/200] Batch 11/12                         Loss D: -147.2114, loss G: 7.9067\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [104/200] Batch 11/12                         Loss D: -149.1106, loss G: 7.9097\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [105/200] Batch 11/12                         Loss D: -151.7392, loss G: 8.0897\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [106/200] Batch 11/12                         Loss D: -150.4084, loss G: 8.2189\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [107/200] Batch 11/12                         Loss D: -154.4728, loss G: 8.2845\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [108/200] Batch 11/12                         Loss D: -156.5379, loss G: 8.4031\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [109/200] Batch 11/12                         Loss D: -160.3690, loss G: 8.6756\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [110/200] Batch 11/12                         Loss D: -160.4857, loss G: 8.6765\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [111/200] Batch 11/12                         Loss D: -162.1238, loss G: 8.8498\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [112/200] Batch 11/12                         Loss D: -163.3029, loss G: 9.0343\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [113/200] Batch 11/12                         Loss D: -164.0299, loss G: 9.1807\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [114/200] Batch 11/12                         Loss D: -167.3741, loss G: 9.2723\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [115/200] Batch 11/12                         Loss D: -167.3254, loss G: 9.4012\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [116/200] Batch 11/12                         Loss D: -167.9182, loss G: 9.5188\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [117/200] Batch 11/12                         Loss D: -168.1236, loss G: 9.6219\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [118/200] Batch 11/12                         Loss D: -165.8204, loss G: 9.8281\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [119/200] Batch 11/12                         Loss D: -165.8507, loss G: 9.9035\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [120/200] Batch 11/12                         Loss D: -165.6822, loss G: 9.9972\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [121/200] Batch 11/12                         Loss D: -160.1745, loss G: 10.1145\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [122/200] Batch 11/12                         Loss D: -152.9360, loss G: 10.1647\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [123/200] Batch 11/12                         Loss D: -140.4920, loss G: 10.1249\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [124/200] Batch 11/12                         Loss D: -122.5182, loss G: 10.1176\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [125/200] Batch 11/12                         Loss D: -94.6373, loss G: 9.9019\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [126/200] Batch 11/12                         Loss D: -78.3584, loss G: 9.7340\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [127/200] Batch 11/12                         Loss D: -80.3489, loss G: 9.8760\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [128/200] Batch 11/12                         Loss D: -81.2701, loss G: 10.0264\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [129/200] Batch 11/12                         Loss D: -82.2382, loss G: 10.1248\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [130/200] Batch 11/12                         Loss D: -80.4052, loss G: 10.3778\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [131/200] Batch 11/12                         Loss D: -83.0169, loss G: 10.3071\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [132/200] Batch 11/12                         Loss D: -84.1220, loss G: 10.4319\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [133/200] Batch 11/12                         Loss D: -85.4593, loss G: 10.5485\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [134/200] Batch 11/12                         Loss D: -86.6880, loss G: 10.6797\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [135/200] Batch 11/12                         Loss D: -89.0805, loss G: 10.8165\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [136/200] Batch 11/12                         Loss D: -89.8513, loss G: 10.8531\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [137/200] Batch 11/12                         Loss D: -90.2243, loss G: 11.0124\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [138/200] Batch 11/12                         Loss D: -91.9956, loss G: 11.0490\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [139/200] Batch 11/12                         Loss D: -94.2750, loss G: 11.1647\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [140/200] Batch 11/12                         Loss D: -94.0414, loss G: 11.2862\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [141/200] Batch 11/12                         Loss D: -95.0647, loss G: 11.4020\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [142/200] Batch 11/12                         Loss D: -96.0362, loss G: 11.5292\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [143/200] Batch 11/12                         Loss D: -98.6473, loss G: 11.5815\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [144/200] Batch 11/12                         Loss D: -98.9430, loss G: 11.6989\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [145/200] Batch 11/12                         Loss D: -100.5761, loss G: 11.8136\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [146/200] Batch 11/12                         Loss D: -103.3550, loss G: 11.8468\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [147/200] Batch 11/12                         Loss D: -102.6224, loss G: 11.9765\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [148/200] Batch 11/12                         Loss D: -105.5040, loss G: 12.0256\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [149/200] Batch 11/12                         Loss D: -107.1409, loss G: 12.1016\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [150/200] Batch 11/12                         Loss D: -107.5305, loss G: 12.2273\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [151/200] Batch 11/12                         Loss D: -108.5740, loss G: 12.3252\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [152/200] Batch 11/12                         Loss D: -110.9632, loss G: 12.3708\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [153/200] Batch 11/12                         Loss D: -111.2483, loss G: 12.5372\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [154/200] Batch 11/12                         Loss D: -113.9480, loss G: 12.5688\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [155/200] Batch 11/12                         Loss D: -114.0780, loss G: 12.6737\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [156/200] Batch 11/12                         Loss D: -115.1207, loss G: 12.7711\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [157/200] Batch 11/12                         Loss D: -118.6024, loss G: 12.8336\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [158/200] Batch 11/12                         Loss D: -120.1847, loss G: 12.9055\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [159/200] Batch 11/12                         Loss D: -122.2054, loss G: 12.9862\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [160/200] Batch 11/12                         Loss D: -120.4430, loss G: 13.1689\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [161/200] Batch 11/12                         Loss D: -126.2564, loss G: 13.2935\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [162/200] Batch 11/12                         Loss D: -126.9518, loss G: 13.2985\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [163/200] Batch 11/12                         Loss D: -129.7051, loss G: 13.3864\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [164/200] Batch 11/12                         Loss D: -138.9222, loss G: 13.3670\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [165/200] Batch 11/12                         Loss D: -151.9465, loss G: 13.1255\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [166/200] Batch 11/12                         Loss D: -91.1897, loss G: 6.1081\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [167/200] Batch 11/12                         Loss D: -55.3142, loss G: 1.9675\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [168/200] Batch 11/12                         Loss D: -52.2390, loss G: 1.1500\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [169/200] Batch 11/12                         Loss D: -31.8731, loss G: -0.0330\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [170/200] Batch 11/12                         Loss D: -5.1070, loss G: -1.1739\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [171/200] Batch 11/12                         Loss D: 28.2836, loss G: -2.7274\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [172/200] Batch 11/12                         Loss D: 66.6293, loss G: -3.9399\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [173/200] Batch 11/12                         Loss D: 111.0865, loss G: -5.1453\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [174/200] Batch 11/12                         Loss D: 159.5605, loss G: -6.2315\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [175/200] Batch 11/12                         Loss D: 167.5735, loss G: -5.6254\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [176/200] Batch 11/12                         Loss D: 152.9195, loss G: -4.4909\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [177/200] Batch 11/12                         Loss D: 141.0174, loss G: -3.1797\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [178/200] Batch 11/12                         Loss D: 130.6907, loss G: -1.8784\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [179/200] Batch 11/12                         Loss D: 120.5452, loss G: -0.1368\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [180/200] Batch 11/12                         Loss D: 106.6569, loss G: 1.7096\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [181/200] Batch 11/12                         Loss D: 93.3734, loss G: 3.6784\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [182/200] Batch 11/12                         Loss D: 81.2966, loss G: 6.1533\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [183/200] Batch 11/12                         Loss D: 60.7001, loss G: 8.4815\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [184/200] Batch 11/12                         Loss D: 46.9649, loss G: 10.8023\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [185/200] Batch 11/12                         Loss D: 32.8188, loss G: 13.1900\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [186/200] Batch 11/12                         Loss D: 10.3027, loss G: 15.6139\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [187/200] Batch 11/12                         Loss D: 2.6510, loss G: 17.7676\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [188/200] Batch 11/12                         Loss D: -15.4928, loss G: 19.8522\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [189/200] Batch 11/12                         Loss D: -24.5693, loss G: 21.6614\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [190/200] Batch 11/12                         Loss D: -35.9348, loss G: 23.3105\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [191/200] Batch 11/12                         Loss D: -45.8007, loss G: 24.6015\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [192/200] Batch 11/12                         Loss D: -54.0594, loss G: 25.7456\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [193/200] Batch 11/12                         Loss D: -59.5164, loss G: 26.3896\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [194/200] Batch 11/12                         Loss D: -63.6857, loss G: 26.8665\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [195/200] Batch 11/12                         Loss D: -66.6981, loss G: 27.1955\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [196/200] Batch 11/12                         Loss D: -66.7322, loss G: 27.1233\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [197/200] Batch 11/12                         Loss D: -64.9175, loss G: 26.9100\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [198/200] Batch 11/12                         Loss D: -62.5346, loss G: 26.7067\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [199/200] Batch 11/12                         Loss D: -58.1448, loss G: 26.2639\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [0/200] Batch 11/12                         Loss D: -0.1395, loss G: 3.1670\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [1/200] Batch 11/12                         Loss D: -1.5315, loss G: 3.0651\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [2/200] Batch 11/12                         Loss D: -1.8037, loss G: 2.8827\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [3/200] Batch 11/12                         Loss D: -0.5414, loss G: 2.6792\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [4/200] Batch 11/12                         Loss D: 1.8626, loss G: 2.6106\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [5/200] Batch 11/12                         Loss D: 4.5991, loss G: 2.5476\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [6/200] Batch 11/12                         Loss D: 7.7193, loss G: 2.4822\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [7/200] Batch 11/12                         Loss D: 10.7674, loss G: 2.4313\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [8/200] Batch 11/12                         Loss D: 14.2420, loss G: 2.3892\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [9/200] Batch 11/12                         Loss D: 17.5673, loss G: 2.3750\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [10/200] Batch 11/12                         Loss D: 20.1003, loss G: 2.3944\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [11/200] Batch 11/12                         Loss D: 23.1100, loss G: 2.4234\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [12/200] Batch 11/12                         Loss D: 24.6748, loss G: 2.4959\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [13/200] Batch 11/12                         Loss D: 24.5748, loss G: 2.5368\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [14/200] Batch 11/12                         Loss D: 24.7941, loss G: 2.3854\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [15/200] Batch 11/12                         Loss D: 23.5987, loss G: 2.3385\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [16/200] Batch 11/12                         Loss D: 22.0456, loss G: 2.3175\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [17/200] Batch 11/12                         Loss D: 19.2377, loss G: 2.3278\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [18/200] Batch 11/12                         Loss D: 18.8696, loss G: 1.9702\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [19/200] Batch 11/12                         Loss D: 17.7363, loss G: 1.4328\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [20/200] Batch 11/12                         Loss D: 16.5543, loss G: 1.2269\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [21/200] Batch 11/12                         Loss D: 29.1153, loss G: -0.5627\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [22/200] Batch 11/12                         Loss D: 72.5994, loss G: -3.3378\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [23/200] Batch 11/12                         Loss D: 125.0946, loss G: -6.4427\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [24/200] Batch 11/12                         Loss D: 148.7126, loss G: -7.3344\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [25/200] Batch 11/12                         Loss D: 166.1356, loss G: -7.5309\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [26/200] Batch 11/12                         Loss D: 177.9234, loss G: -7.4509\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [27/200] Batch 11/12                         Loss D: 193.9303, loss G: -7.3653\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [28/200] Batch 11/12                         Loss D: 198.0564, loss G: -6.9778\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [29/200] Batch 11/12                         Loss D: 206.9328, loss G: -6.5900\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [30/200] Batch 11/12                         Loss D: 203.5918, loss G: -5.9549\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [31/200] Batch 11/12                         Loss D: 200.4095, loss G: -5.3020\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [32/200] Batch 11/12                         Loss D: 192.3882, loss G: -4.6075\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [33/200] Batch 11/12                         Loss D: 179.5165, loss G: -3.8876\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [34/200] Batch 11/12                         Loss D: 169.7345, loss G: -3.2044\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [35/200] Batch 11/12                         Loss D: 150.7040, loss G: -2.6196\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [36/200] Batch 11/12                         Loss D: 124.6557, loss G: -2.0036\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [37/200] Batch 11/12                         Loss D: 106.1180, loss G: -1.2452\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [38/200] Batch 11/12                         Loss D: 88.1314, loss G: -0.7520\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [39/200] Batch 11/12                         Loss D: 72.5524, loss G: -0.4511\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [40/200] Batch 11/12                         Loss D: 58.8971, loss G: -0.3195\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [41/200] Batch 11/12                         Loss D: 47.4999, loss G: -0.3270\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [42/200] Batch 11/12                         Loss D: 38.8304, loss G: -0.3840\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [43/200] Batch 11/12                         Loss D: 31.5233, loss G: -0.5731\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [44/200] Batch 11/12                         Loss D: 27.9008, loss G: -1.0222\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [45/200] Batch 11/12                         Loss D: 22.5143, loss G: -1.1880\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [46/200] Batch 11/12                         Loss D: 17.9299, loss G: -1.3132\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [47/200] Batch 11/12                         Loss D: 14.3229, loss G: -1.2938\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [48/200] Batch 11/12                         Loss D: 12.4657, loss G: -1.1881\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [49/200] Batch 11/12                         Loss D: 10.1225, loss G: -1.1012\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [50/200] Batch 11/12                         Loss D: 8.0070, loss G: -1.0126\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [51/200] Batch 11/12                         Loss D: 5.9160, loss G: -0.9397\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [52/200] Batch 11/12                         Loss D: 4.0220, loss G: -0.8812\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [53/200] Batch 11/12                         Loss D: 2.1197, loss G: -0.8291\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [54/200] Batch 11/12                         Loss D: 0.6706, loss G: -0.7358\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [55/200] Batch 11/12                         Loss D: -0.9735, loss G: -0.6888\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [56/200] Batch 11/12                         Loss D: -2.4420, loss G: -0.6235\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [57/200] Batch 11/12                         Loss D: -3.4504, loss G: -0.5251\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [58/200] Batch 11/12                         Loss D: -4.3711, loss G: -0.4490\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [59/200] Batch 11/12                         Loss D: -4.4884, loss G: -0.3173\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [60/200] Batch 11/12                         Loss D: -5.5250, loss G: -0.2603\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [61/200] Batch 11/12                         Loss D: -6.0424, loss G: -0.1964\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [62/200] Batch 11/12                         Loss D: -6.5463, loss G: -0.0996\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [63/200] Batch 11/12                         Loss D: -7.2895, loss G: -0.0353\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [64/200] Batch 11/12                         Loss D: -7.6929, loss G: 0.0562\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [65/200] Batch 11/12                         Loss D: -8.3935, loss G: 0.1559\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [66/200] Batch 11/12                         Loss D: -9.1018, loss G: 0.2002\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [67/200] Batch 11/12                         Loss D: -9.0415, loss G: 0.2840\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [68/200] Batch 11/12                         Loss D: -10.2437, loss G: 0.3510\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [69/200] Batch 11/12                         Loss D: -10.4373, loss G: 0.4443\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [70/200] Batch 11/12                         Loss D: -11.0625, loss G: 0.5134\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [71/200] Batch 11/12                         Loss D: -11.4908, loss G: 0.5590\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [72/200] Batch 11/12                         Loss D: -11.1006, loss G: 0.6102\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [73/200] Batch 11/12                         Loss D: -10.9525, loss G: 0.6602\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [74/200] Batch 11/12                         Loss D: -10.3432, loss G: 0.6992\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [75/200] Batch 11/12                         Loss D: -9.7725, loss G: 0.7521\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [76/200] Batch 11/12                         Loss D: -8.2601, loss G: 0.7693\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [77/200] Batch 11/12                         Loss D: -6.3054, loss G: 0.8142\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [78/200] Batch 11/12                         Loss D: -4.0244, loss G: 0.8475\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [79/200] Batch 11/12                         Loss D: -3.1988, loss G: 0.8951\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [80/200] Batch 11/12                         Loss D: -3.8106, loss G: 0.9202\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [81/200] Batch 11/12                         Loss D: -4.4938, loss G: 0.9674\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [82/200] Batch 11/12                         Loss D: -5.1429, loss G: 1.0059\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [83/200] Batch 11/12                         Loss D: -5.9998, loss G: 1.0411\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [84/200] Batch 11/12                         Loss D: -7.2205, loss G: 1.1104\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [85/200] Batch 11/12                         Loss D: -8.5743, loss G: 1.1329\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [86/200] Batch 11/12                         Loss D: -9.8715, loss G: 1.1803\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [87/200] Batch 11/12                         Loss D: -10.6637, loss G: 1.2360\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [88/200] Batch 11/12                         Loss D: -11.9791, loss G: 1.2557\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [89/200] Batch 11/12                         Loss D: -13.3384, loss G: 1.2996\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [90/200] Batch 11/12                         Loss D: -14.5508, loss G: 1.3430\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [91/200] Batch 11/12                         Loss D: -15.6354, loss G: 1.4014\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [92/200] Batch 11/12                         Loss D: -16.7920, loss G: 1.4364\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [93/200] Batch 11/12                         Loss D: -17.9364, loss G: 1.4729\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [94/200] Batch 11/12                         Loss D: -18.6686, loss G: 1.5170\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [95/200] Batch 11/12                         Loss D: -18.6234, loss G: 1.5630\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [96/200] Batch 11/12                         Loss D: -18.8073, loss G: 1.6110\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [97/200] Batch 11/12                         Loss D: -19.1731, loss G: 1.7030\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [98/200] Batch 11/12                         Loss D: -18.9082, loss G: 1.7455\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [99/200] Batch 11/12                         Loss D: -18.6822, loss G: 1.7452\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [100/200] Batch 11/12                         Loss D: -18.4474, loss G: 1.7982\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [101/200] Batch 11/12                         Loss D: -18.2767, loss G: 1.8606\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [102/200] Batch 11/12                         Loss D: -17.9808, loss G: 1.9151\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [103/200] Batch 11/12                         Loss D: -17.1359, loss G: 1.9749\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [104/200] Batch 11/12                         Loss D: -16.4777, loss G: 2.0331\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [105/200] Batch 11/12                         Loss D: -16.0721, loss G: 2.0834\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [106/200] Batch 11/12                         Loss D: -15.9478, loss G: 2.1566\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [107/200] Batch 11/12                         Loss D: -19.3464, loss G: 2.2171\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [108/200] Batch 11/12                         Loss D: -21.6931, loss G: 2.2773\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [109/200] Batch 11/12                         Loss D: -23.0734, loss G: 2.3355\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [110/200] Batch 11/12                         Loss D: -24.0143, loss G: 2.3921\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [111/200] Batch 11/12                         Loss D: -24.8347, loss G: 2.4532\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [112/200] Batch 11/12                         Loss D: -25.9741, loss G: 2.5170\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [113/200] Batch 11/12                         Loss D: -27.7355, loss G: 2.5940\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [114/200] Batch 11/12                         Loss D: -28.6214, loss G: 2.7687\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [115/200] Batch 11/12                         Loss D: -33.6166, loss G: 3.1244\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [116/200] Batch 11/12                         Loss D: -37.8445, loss G: 3.3888\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [117/200] Batch 11/12                         Loss D: -40.0459, loss G: 3.6069\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [118/200] Batch 11/12                         Loss D: -41.2534, loss G: 3.7736\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [119/200] Batch 11/12                         Loss D: -41.7495, loss G: 3.9107\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [120/200] Batch 11/12                         Loss D: -34.4329, loss G: 3.9217\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [121/200] Batch 11/12                         Loss D: -31.5276, loss G: 3.9418\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [122/200] Batch 11/12                         Loss D: -31.7520, loss G: 4.0002\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [123/200] Batch 11/12                         Loss D: -30.7530, loss G: 3.9963\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [124/200] Batch 11/12                         Loss D: -29.2395, loss G: 3.9680\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [125/200] Batch 11/12                         Loss D: -26.3895, loss G: 3.8817\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [126/200] Batch 11/12                         Loss D: -23.0294, loss G: 3.7569\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [127/200] Batch 11/12                         Loss D: -18.8513, loss G: 3.6086\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [128/200] Batch 11/12                         Loss D: 44.5305, loss G: 0.1794\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [129/200] Batch 11/12                         Loss D: 100.2603, loss G: -3.1006\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [130/200] Batch 11/12                         Loss D: 117.6728, loss G: -3.5133\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [131/200] Batch 11/12                         Loss D: 126.7655, loss G: -3.5279\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [132/200] Batch 11/12                         Loss D: 127.3434, loss G: -3.1317\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [133/200] Batch 11/12                         Loss D: 118.7526, loss G: -2.3247\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [134/200] Batch 11/12                         Loss D: 105.9419, loss G: -1.3433\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [135/200] Batch 11/12                         Loss D: 87.3436, loss G: -0.1971\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [136/200] Batch 11/12                         Loss D: 67.4410, loss G: 0.9242\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [137/200] Batch 11/12                         Loss D: 50.9694, loss G: 1.7510\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [138/200] Batch 11/12                         Loss D: 44.4104, loss G: 2.1392\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [139/200] Batch 11/12                         Loss D: 41.9594, loss G: 2.0809\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [140/200] Batch 11/12                         Loss D: 46.6246, loss G: 1.7795\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [141/200] Batch 11/12                         Loss D: 52.9280, loss G: 1.4240\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [142/200] Batch 11/12                         Loss D: 59.9932, loss G: 0.8687\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [143/200] Batch 11/12                         Loss D: 76.9460, loss G: -0.3831\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [144/200] Batch 11/12                         Loss D: 71.5079, loss G: -0.0051\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [145/200] Batch 11/12                         Loss D: 66.2857, loss G: 0.3320\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [146/200] Batch 11/12                         Loss D: 60.9508, loss G: 0.6429\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [147/200] Batch 11/12                         Loss D: 54.9035, loss G: 0.9371\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [148/200] Batch 11/12                         Loss D: 48.3301, loss G: 1.2068\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [149/200] Batch 11/12                         Loss D: 42.4682, loss G: 1.4539\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [150/200] Batch 11/12                         Loss D: 36.3070, loss G: 1.6625\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [151/200] Batch 11/12                         Loss D: 30.6839, loss G: 1.8360\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [152/200] Batch 11/12                         Loss D: 25.5921, loss G: 1.9776\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [153/200] Batch 11/12                         Loss D: 21.0427, loss G: 2.0834\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [154/200] Batch 11/12                         Loss D: 16.7485, loss G: 2.1517\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [155/200] Batch 11/12                         Loss D: 13.1206, loss G: 2.1828\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [156/200] Batch 11/12                         Loss D: 9.9561, loss G: 2.1878\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [157/200] Batch 11/12                         Loss D: 7.3614, loss G: 2.1778\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [158/200] Batch 11/12                         Loss D: 5.2050, loss G: 2.1826\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [159/200] Batch 11/12                         Loss D: 3.9077, loss G: 2.2725\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [160/200] Batch 11/12                         Loss D: 1.5756, loss G: 2.3521\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [161/200] Batch 11/12                         Loss D: -0.0693, loss G: 2.4402\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [162/200] Batch 11/12                         Loss D: -0.8074, loss G: 2.5279\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [163/200] Batch 11/12                         Loss D: -2.8286, loss G: 2.6018\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [164/200] Batch 11/12                         Loss D: -4.6669, loss G: 2.6875\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [165/200] Batch 11/12                         Loss D: -6.2585, loss G: 2.7799\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [166/200] Batch 11/12                         Loss D: -8.3115, loss G: 2.8588\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [167/200] Batch 11/12                         Loss D: -10.1578, loss G: 2.9440\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [168/200] Batch 11/12                         Loss D: -2.3108, loss G: 2.8215\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [169/200] Batch 11/12                         Loss D: 19.5506, loss G: 2.3976\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [170/200] Batch 11/12                         Loss D: 29.1692, loss G: 2.3733\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [171/200] Batch 11/12                         Loss D: 34.4351, loss G: 2.4823\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [172/200] Batch 11/12                         Loss D: 36.9178, loss G: 2.6249\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [173/200] Batch 11/12                         Loss D: 36.0024, loss G: 2.7837\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [174/200] Batch 11/12                         Loss D: 34.9356, loss G: 2.9331\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [175/200] Batch 11/12                         Loss D: 34.1360, loss G: 3.0685\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [176/200] Batch 11/12                         Loss D: 32.1617, loss G: 3.1976\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [177/200] Batch 11/12                         Loss D: 31.1062, loss G: 3.3058\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [178/200] Batch 11/12                         Loss D: 29.7245, loss G: 3.3932\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [179/200] Batch 11/12                         Loss D: 28.1095, loss G: 3.4715\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [180/200] Batch 11/12                         Loss D: 26.5515, loss G: 3.5359\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [181/200] Batch 11/12                         Loss D: 25.3163, loss G: 3.5926\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [182/200] Batch 11/12                         Loss D: 23.7984, loss G: 3.6356\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [183/200] Batch 11/12                         Loss D: 22.4613, loss G: 3.6745\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [184/200] Batch 11/12                         Loss D: 20.9017, loss G: 3.6904\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [185/200] Batch 11/12                         Loss D: 19.6466, loss G: 3.7030\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [186/200] Batch 11/12                         Loss D: 18.3966, loss G: 3.7094\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [187/200] Batch 11/12                         Loss D: 17.3517, loss G: 3.7154\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [188/200] Batch 11/12                         Loss D: 16.1810, loss G: 3.7034\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [189/200] Batch 11/12                         Loss D: 15.1078, loss G: 3.6928\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [190/200] Batch 11/12                         Loss D: 13.9492, loss G: 3.6585\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [191/200] Batch 11/12                         Loss D: 13.0758, loss G: 3.6380\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [192/200] Batch 11/12                         Loss D: 12.1891, loss G: 3.6133\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [193/200] Batch 11/12                         Loss D: 11.2836, loss G: 3.5796\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [194/200] Batch 11/12                         Loss D: 10.6165, loss G: 3.5510\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [195/200] Batch 11/12                         Loss D: 9.7628, loss G: 3.5051\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [196/200] Batch 11/12                         Loss D: 8.9949, loss G: 3.4624\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [197/200] Batch 11/12                         Loss D: 8.2907, loss G: 3.4254\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [198/200] Batch 11/12                         Loss D: 7.5548, loss G: 3.3801\n",
      "[lr_G=0.0002, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [199/200] Batch 11/12                         Loss D: 6.7913, loss G: 3.3289\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [0/200] Batch 11/12                         Loss D: 7.7236, loss G: 33.8301\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [1/200] Batch 11/12                         Loss D: 8.2063, loss G: 33.0267\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [2/200] Batch 11/12                         Loss D: 9.1492, loss G: 31.6298\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [3/200] Batch 11/12                         Loss D: 10.5662, loss G: 29.5371\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [4/200] Batch 11/12                         Loss D: 12.0178, loss G: 27.9038\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [5/200] Batch 11/12                         Loss D: 13.2291, loss G: 26.1168\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [6/200] Batch 11/12                         Loss D: 13.5977, loss G: 23.8805\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [7/200] Batch 11/12                         Loss D: 13.0051, loss G: 20.8798\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [8/200] Batch 11/12                         Loss D: 12.3163, loss G: 17.2594\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [9/200] Batch 11/12                         Loss D: 11.3227, loss G: 12.5087\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [10/200] Batch 11/12                         Loss D: 12.0314, loss G: 8.3679\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [11/200] Batch 11/12                         Loss D: 19.6222, loss G: 6.1398\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [12/200] Batch 11/12                         Loss D: 25.8391, loss G: 3.8387\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [13/200] Batch 11/12                         Loss D: 28.9134, loss G: 0.8457\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [14/200] Batch 11/12                         Loss D: 31.9268, loss G: -1.9254\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [15/200] Batch 11/12                         Loss D: 30.3523, loss G: -2.1734\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [16/200] Batch 11/12                         Loss D: 28.8244, loss G: -2.1554\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [17/200] Batch 11/12                         Loss D: 27.3057, loss G: -1.8511\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [18/200] Batch 11/12                         Loss D: 26.3843, loss G: -1.5979\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [19/200] Batch 11/12                         Loss D: 24.5599, loss G: -1.6611\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [20/200] Batch 11/12                         Loss D: 23.6987, loss G: -1.6474\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [21/200] Batch 11/12                         Loss D: 22.2697, loss G: -1.4100\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [22/200] Batch 11/12                         Loss D: 21.2102, loss G: -1.6450\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [23/200] Batch 11/12                         Loss D: 20.2077, loss G: -1.6032\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [24/200] Batch 11/12                         Loss D: 18.9953, loss G: -1.4814\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [25/200] Batch 11/12                         Loss D: 17.8026, loss G: -1.1865\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [26/200] Batch 11/12                         Loss D: 16.7931, loss G: -1.3881\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [27/200] Batch 11/12                         Loss D: 15.6913, loss G: -1.3078\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [28/200] Batch 11/12                         Loss D: 14.8166, loss G: -1.1873\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [29/200] Batch 11/12                         Loss D: 13.6146, loss G: -1.1889\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [30/200] Batch 11/12                         Loss D: 12.5628, loss G: -1.1397\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [31/200] Batch 11/12                         Loss D: 11.5654, loss G: -1.0883\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [32/200] Batch 11/12                         Loss D: 10.5615, loss G: -0.9476\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [33/200] Batch 11/12                         Loss D: 9.4408, loss G: -0.9627\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [34/200] Batch 11/12                         Loss D: 8.4089, loss G: -0.6266\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [35/200] Batch 11/12                         Loss D: 7.4267, loss G: -0.8179\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [36/200] Batch 11/12                         Loss D: 6.3264, loss G: -0.3644\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [37/200] Batch 11/12                         Loss D: 5.3695, loss G: -0.6326\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [38/200] Batch 11/12                         Loss D: 4.2789, loss G: -0.6519\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [39/200] Batch 11/12                         Loss D: 3.1305, loss G: -0.2929\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [40/200] Batch 11/12                         Loss D: 2.2134, loss G: -0.3351\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [41/200] Batch 11/12                         Loss D: 1.1016, loss G: -0.4497\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [42/200] Batch 11/12                         Loss D: 0.1807, loss G: -0.3044\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [43/200] Batch 11/12                         Loss D: -0.6811, loss G: 0.1377\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [44/200] Batch 11/12                         Loss D: -1.8966, loss G: -0.0953\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [45/200] Batch 11/12                         Loss D: -2.9351, loss G: -0.1320\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [46/200] Batch 11/12                         Loss D: -4.1378, loss G: 0.0249\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [47/200] Batch 11/12                         Loss D: -5.2777, loss G: 0.1047\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [48/200] Batch 11/12                         Loss D: -6.1121, loss G: 0.0209\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [49/200] Batch 11/12                         Loss D: -7.3077, loss G: 0.1879\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [50/200] Batch 11/12                         Loss D: -8.3399, loss G: 0.3504\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [51/200] Batch 11/12                         Loss D: -9.3468, loss G: 0.1008\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [52/200] Batch 11/12                         Loss D: -10.4434, loss G: 0.2009\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [53/200] Batch 11/12                         Loss D: -11.4972, loss G: 0.2385\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [54/200] Batch 11/12                         Loss D: -12.5117, loss G: 0.2878\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [55/200] Batch 11/12                         Loss D: -13.6690, loss G: 0.3417\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [56/200] Batch 11/12                         Loss D: -14.5327, loss G: 0.5419\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [57/200] Batch 11/12                         Loss D: -15.4698, loss G: 0.8296\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [58/200] Batch 11/12                         Loss D: -17.1318, loss G: 0.9307\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [59/200] Batch 11/12                         Loss D: -17.5396, loss G: 0.9838\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [60/200] Batch 11/12                         Loss D: -19.1637, loss G: 0.7134\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [61/200] Batch 11/12                         Loss D: -19.8921, loss G: 0.9127\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [62/200] Batch 11/12                         Loss D: -20.7782, loss G: 1.1278\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [63/200] Batch 11/12                         Loss D: -22.4536, loss G: 1.1382\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [64/200] Batch 11/12                         Loss D: -23.1218, loss G: 1.2087\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [65/200] Batch 11/12                         Loss D: -24.7196, loss G: 1.1401\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [66/200] Batch 11/12                         Loss D: -25.9457, loss G: 1.2402\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [67/200] Batch 11/12                         Loss D: -26.9438, loss G: 1.1882\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [68/200] Batch 11/12                         Loss D: -27.7007, loss G: 1.2942\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [69/200] Batch 11/12                         Loss D: -29.2056, loss G: 1.3685\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [70/200] Batch 11/12                         Loss D: -30.0992, loss G: 1.4481\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [71/200] Batch 11/12                         Loss D: -31.5005, loss G: 1.4285\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [72/200] Batch 11/12                         Loss D: -32.7656, loss G: 1.6848\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [73/200] Batch 11/12                         Loss D: -33.3794, loss G: 1.7762\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [74/200] Batch 11/12                         Loss D: -35.1801, loss G: 1.7237\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [75/200] Batch 11/12                         Loss D: -35.9203, loss G: 1.6871\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [76/200] Batch 11/12                         Loss D: -37.1327, loss G: 1.8661\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [77/200] Batch 11/12                         Loss D: -38.3648, loss G: 1.9304\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [78/200] Batch 11/12                         Loss D: -39.4584, loss G: 1.9924\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [79/200] Batch 11/12                         Loss D: -40.4873, loss G: 2.2555\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [80/200] Batch 11/12                         Loss D: -41.9787, loss G: 2.1477\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [81/200] Batch 11/12                         Loss D: -43.6101, loss G: 2.1885\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [82/200] Batch 11/12                         Loss D: -44.3898, loss G: 2.3454\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [83/200] Batch 11/12                         Loss D: -47.0364, loss G: 2.8295\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [84/200] Batch 11/12                         Loss D: -48.1750, loss G: 2.6869\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [85/200] Batch 11/12                         Loss D: -48.5942, loss G: 2.4220\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [86/200] Batch 11/12                         Loss D: -49.8593, loss G: 2.4793\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [87/200] Batch 11/12                         Loss D: -51.2911, loss G: 2.5800\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [88/200] Batch 11/12                         Loss D: -52.5293, loss G: 2.7483\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [89/200] Batch 11/12                         Loss D: -53.5554, loss G: 2.9798\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [90/200] Batch 11/12                         Loss D: -55.8349, loss G: 2.9503\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [91/200] Batch 11/12                         Loss D: -56.8361, loss G: 2.9361\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [92/200] Batch 11/12                         Loss D: -59.0839, loss G: 3.3415\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [93/200] Batch 11/12                         Loss D: -59.8260, loss G: 3.1122\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [94/200] Batch 11/12                         Loss D: -61.6966, loss G: 3.4324\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [95/200] Batch 11/12                         Loss D: -62.8183, loss G: 3.3304\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [96/200] Batch 11/12                         Loss D: -64.5619, loss G: 3.4776\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [97/200] Batch 11/12                         Loss D: -66.4171, loss G: 3.7301\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [98/200] Batch 11/12                         Loss D: -66.5401, loss G: 3.7628\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [99/200] Batch 11/12                         Loss D: -68.2210, loss G: 3.7861\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [100/200] Batch 11/12                         Loss D: -70.7683, loss G: 3.8491\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [101/200] Batch 11/12                         Loss D: -71.4685, loss G: 3.9137\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [102/200] Batch 11/12                         Loss D: -74.0421, loss G: 3.9974\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [103/200] Batch 11/12                         Loss D: -75.1101, loss G: 4.0317\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [104/200] Batch 11/12                         Loss D: -75.7409, loss G: 4.3783\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [105/200] Batch 11/12                         Loss D: -78.9997, loss G: 4.4129\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [106/200] Batch 11/12                         Loss D: -79.2559, loss G: 4.4591\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [107/200] Batch 11/12                         Loss D: -82.5844, loss G: 4.5895\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [108/200] Batch 11/12                         Loss D: -82.2025, loss G: 4.7215\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [109/200] Batch 11/12                         Loss D: -85.4742, loss G: 4.7766\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [110/200] Batch 11/12                         Loss D: -85.6836, loss G: 4.8255\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [111/200] Batch 11/12                         Loss D: -87.8223, loss G: 4.7345\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [112/200] Batch 11/12                         Loss D: -88.8313, loss G: 5.1141\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [113/200] Batch 11/12                         Loss D: -90.9910, loss G: 4.9650\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [114/200] Batch 11/12                         Loss D: -93.0924, loss G: 4.9330\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [115/200] Batch 11/12                         Loss D: -95.0399, loss G: 5.1294\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [116/200] Batch 11/12                         Loss D: -97.1337, loss G: 5.3645\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [117/200] Batch 11/12                         Loss D: -98.9727, loss G: 5.3846\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [118/200] Batch 11/12                         Loss D: -98.6192, loss G: 5.5391\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [119/200] Batch 11/12                         Loss D: -100.7648, loss G: 5.4445\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [120/200] Batch 11/12                         Loss D: -104.3849, loss G: 5.5159\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [121/200] Batch 11/12                         Loss D: -105.7968, loss G: 5.4122\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [122/200] Batch 11/12                         Loss D: -108.3734, loss G: 5.6730\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [123/200] Batch 11/12                         Loss D: -108.0416, loss G: 5.4860\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [124/200] Batch 11/12                         Loss D: -111.0390, loss G: 5.5468\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [125/200] Batch 11/12                         Loss D: -111.7434, loss G: 5.5564\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [126/200] Batch 11/12                         Loss D: -114.6187, loss G: 5.4822\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [127/200] Batch 11/12                         Loss D: -115.3118, loss G: 5.6488\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [128/200] Batch 11/12                         Loss D: -116.8179, loss G: 5.8711\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [129/200] Batch 11/12                         Loss D: -119.6461, loss G: 5.8383\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [130/200] Batch 11/12                         Loss D: -122.6070, loss G: 5.8059\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [131/200] Batch 11/12                         Loss D: -123.6112, loss G: 5.8322\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [132/200] Batch 11/12                         Loss D: -125.1291, loss G: 6.0565\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [133/200] Batch 11/12                         Loss D: -127.8535, loss G: 6.1230\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [134/200] Batch 11/12                         Loss D: -130.2217, loss G: 6.2609\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [135/200] Batch 11/12                         Loss D: -132.5681, loss G: 6.3336\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [136/200] Batch 11/12                         Loss D: -132.5959, loss G: 6.4675\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [137/200] Batch 11/12                         Loss D: -135.8830, loss G: 6.4184\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [138/200] Batch 11/12                         Loss D: -137.7190, loss G: 6.6400\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [139/200] Batch 11/12                         Loss D: -139.1940, loss G: 6.6327\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [140/200] Batch 11/12                         Loss D: -142.6022, loss G: 7.0218\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [141/200] Batch 11/12                         Loss D: -142.5042, loss G: 6.9378\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [142/200] Batch 11/12                         Loss D: -144.6091, loss G: 7.0919\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [143/200] Batch 11/12                         Loss D: -144.9630, loss G: 7.4229\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [144/200] Batch 11/12                         Loss D: -150.8969, loss G: 7.4624\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [145/200] Batch 11/12                         Loss D: -150.0876, loss G: 7.4628\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [146/200] Batch 11/12                         Loss D: -155.0092, loss G: 7.6375\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [147/200] Batch 11/12                         Loss D: -155.0226, loss G: 7.5936\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [148/200] Batch 11/12                         Loss D: -157.0709, loss G: 7.6428\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [149/200] Batch 11/12                         Loss D: -158.2323, loss G: 7.9166\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [150/200] Batch 11/12                         Loss D: -162.0147, loss G: 7.9936\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [151/200] Batch 11/12                         Loss D: -164.7821, loss G: 8.2393\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [152/200] Batch 11/12                         Loss D: -167.0023, loss G: 8.3560\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [153/200] Batch 11/12                         Loss D: -167.6127, loss G: 8.2772\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [154/200] Batch 11/12                         Loss D: -169.1830, loss G: 8.4951\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [155/200] Batch 11/12                         Loss D: -172.1946, loss G: 8.5361\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [156/200] Batch 11/12                         Loss D: -175.1236, loss G: 8.7072\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [157/200] Batch 11/12                         Loss D: -176.7426, loss G: 8.7556\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [158/200] Batch 11/12                         Loss D: -180.7613, loss G: 9.2550\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [159/200] Batch 11/12                         Loss D: -179.1820, loss G: 9.2154\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [160/200] Batch 11/12                         Loss D: -183.4705, loss G: 9.2192\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [161/200] Batch 11/12                         Loss D: -185.4383, loss G: 9.2725\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [162/200] Batch 11/12                         Loss D: -187.6810, loss G: 9.3935\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [163/200] Batch 11/12                         Loss D: -187.6207, loss G: 9.7797\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [164/200] Batch 11/12                         Loss D: -191.6519, loss G: 9.6787\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [165/200] Batch 11/12                         Loss D: -194.4765, loss G: 9.7623\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [166/200] Batch 11/12                         Loss D: -195.1340, loss G: 10.1541\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [167/200] Batch 11/12                         Loss D: -198.0963, loss G: 10.1852\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [168/200] Batch 11/12                         Loss D: -198.3968, loss G: 10.4796\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [169/200] Batch 11/12                         Loss D: -201.2682, loss G: 10.5982\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [170/200] Batch 11/12                         Loss D: -204.7509, loss G: 10.6082\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [171/200] Batch 11/12                         Loss D: -211.4342, loss G: 10.9744\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [172/200] Batch 11/12                         Loss D: -210.6219, loss G: 10.7767\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [173/200] Batch 11/12                         Loss D: -212.3080, loss G: 10.9858\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [174/200] Batch 11/12                         Loss D: -214.0608, loss G: 11.1630\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [175/200] Batch 11/12                         Loss D: -217.0021, loss G: 11.2492\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [176/200] Batch 11/12                         Loss D: -219.8828, loss G: 11.3990\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [177/200] Batch 11/12                         Loss D: -221.4580, loss G: 11.6275\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [178/200] Batch 11/12                         Loss D: -222.9048, loss G: 11.8477\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [179/200] Batch 11/12                         Loss D: -225.0911, loss G: 12.0425\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [180/200] Batch 11/12                         Loss D: -230.6540, loss G: 11.9979\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [181/200] Batch 11/12                         Loss D: -233.2842, loss G: 12.0744\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [182/200] Batch 11/12                         Loss D: -235.1616, loss G: 12.2703\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [183/200] Batch 11/12                         Loss D: -235.4814, loss G: 12.5718\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [184/200] Batch 11/12                         Loss D: -242.3361, loss G: 12.6181\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [185/200] Batch 11/12                         Loss D: -244.3196, loss G: 12.6459\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [186/200] Batch 11/12                         Loss D: -245.0699, loss G: 12.9110\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [187/200] Batch 11/12                         Loss D: -246.5750, loss G: 13.1153\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [188/200] Batch 11/12                         Loss D: -252.0201, loss G: 13.1688\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [189/200] Batch 11/12                         Loss D: -252.9855, loss G: 13.3676\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [190/200] Batch 11/12                         Loss D: -257.5149, loss G: 13.5231\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [191/200] Batch 11/12                         Loss D: -258.3180, loss G: 13.6583\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [192/200] Batch 11/12                         Loss D: -260.7863, loss G: 13.8594\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [193/200] Batch 11/12                         Loss D: -260.2907, loss G: 14.3027\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [194/200] Batch 11/12                         Loss D: -268.6780, loss G: 14.1040\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [195/200] Batch 11/12                         Loss D: -269.4986, loss G: 14.2928\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [196/200] Batch 11/12                         Loss D: -274.3443, loss G: 14.5350\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [197/200] Batch 11/12                         Loss D: -273.9915, loss G: 14.6738\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [198/200] Batch 11/12                         Loss D: -279.7274, loss G: 14.8101\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [199/200] Batch 11/12                         Loss D: -280.3104, loss G: 14.9849\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [0/200] Batch 11/12                         Loss D: 7.2390, loss G: 17.0297\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [1/200] Batch 11/12                         Loss D: 8.9855, loss G: 16.5958\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [2/200] Batch 11/12                         Loss D: 14.0619, loss G: 15.8361\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [3/200] Batch 11/12                         Loss D: 21.0934, loss G: 14.7530\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [4/200] Batch 11/12                         Loss D: 30.4266, loss G: 13.2473\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [5/200] Batch 11/12                         Loss D: 40.8862, loss G: 11.6264\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [6/200] Batch 11/12                         Loss D: 53.5542, loss G: 9.6556\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [7/200] Batch 11/12                         Loss D: 67.7296, loss G: 7.3550\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [8/200] Batch 11/12                         Loss D: 85.0638, loss G: 4.8321\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [9/200] Batch 11/12                         Loss D: 104.1642, loss G: 1.9835\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [10/200] Batch 11/12                         Loss D: 103.1074, loss G: 1.7187\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [11/200] Batch 11/12                         Loss D: 103.9056, loss G: 1.3094\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [12/200] Batch 11/12                         Loss D: 101.9310, loss G: 0.9304\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [13/200] Batch 11/12                         Loss D: 99.3297, loss G: 0.4431\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [14/200] Batch 11/12                         Loss D: 95.3798, loss G: -0.0813\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [15/200] Batch 11/12                         Loss D: 91.0353, loss G: -0.6440\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [16/200] Batch 11/12                         Loss D: 83.4291, loss G: -2.9007\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [17/200] Batch 11/12                         Loss D: 74.6002, loss G: -4.2526\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [18/200] Batch 11/12                         Loss D: 72.1208, loss G: -4.1054\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [19/200] Batch 11/12                         Loss D: 68.9101, loss G: -3.9618\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [20/200] Batch 11/12                         Loss D: 66.0341, loss G: -3.7752\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [21/200] Batch 11/12                         Loss D: 62.5293, loss G: -3.5511\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [22/200] Batch 11/12                         Loss D: 60.7911, loss G: -3.5357\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [23/200] Batch 11/12                         Loss D: 59.0390, loss G: -3.4081\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [24/200] Batch 11/12                         Loss D: 58.5488, loss G: -2.9695\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [25/200] Batch 11/12                         Loss D: 54.7350, loss G: -2.9821\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [26/200] Batch 11/12                         Loss D: 52.9706, loss G: -2.9467\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [27/200] Batch 11/12                         Loss D: 51.4711, loss G: -2.9211\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [28/200] Batch 11/12                         Loss D: 50.0449, loss G: -2.7704\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [29/200] Batch 11/12                         Loss D: 47.5365, loss G: -2.5194\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [30/200] Batch 11/12                         Loss D: 46.6222, loss G: -2.5550\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [31/200] Batch 11/12                         Loss D: 44.9111, loss G: -2.4602\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [32/200] Batch 11/12                         Loss D: 42.6535, loss G: -2.2741\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [33/200] Batch 11/12                         Loss D: 41.5054, loss G: -2.2600\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [34/200] Batch 11/12                         Loss D: 39.6305, loss G: -2.0933\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [35/200] Batch 11/12                         Loss D: 38.7327, loss G: -1.9601\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [36/200] Batch 11/12                         Loss D: 36.6214, loss G: -1.9771\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [37/200] Batch 11/12                         Loss D: 35.3662, loss G: -1.9345\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [38/200] Batch 11/12                         Loss D: 33.6724, loss G: -1.8215\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [39/200] Batch 11/12                         Loss D: 32.2998, loss G: -1.7123\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [40/200] Batch 11/12                         Loss D: 30.8296, loss G: -1.6935\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [41/200] Batch 11/12                         Loss D: 29.8171, loss G: -1.2983\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [42/200] Batch 11/12                         Loss D: 27.8002, loss G: -1.4088\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [43/200] Batch 11/12                         Loss D: 26.8165, loss G: -1.2928\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [44/200] Batch 11/12                         Loss D: 25.1205, loss G: -1.2593\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [45/200] Batch 11/12                         Loss D: 23.5617, loss G: -1.2016\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [46/200] Batch 11/12                         Loss D: 22.3572, loss G: -1.1295\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [47/200] Batch 11/12                         Loss D: 20.9111, loss G: -1.0606\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [48/200] Batch 11/12                         Loss D: 19.5552, loss G: -0.9067\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [49/200] Batch 11/12                         Loss D: 18.0499, loss G: -0.8037\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [50/200] Batch 11/12                         Loss D: 16.7773, loss G: -0.6897\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [51/200] Batch 11/12                         Loss D: 15.3644, loss G: -0.5909\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [52/200] Batch 11/12                         Loss D: 13.8478, loss G: -0.4167\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [53/200] Batch 11/12                         Loss D: 12.6898, loss G: -0.5437\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [54/200] Batch 11/12                         Loss D: 11.3293, loss G: -0.3269\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [55/200] Batch 11/12                         Loss D: 9.9225, loss G: -0.3557\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [56/200] Batch 11/12                         Loss D: 8.4687, loss G: -0.2632\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [57/200] Batch 11/12                         Loss D: 7.2322, loss G: -0.2017\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [58/200] Batch 11/12                         Loss D: 5.8892, loss G: -0.1792\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [59/200] Batch 11/12                         Loss D: 4.5857, loss G: 0.1625\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [60/200] Batch 11/12                         Loss D: 3.1603, loss G: 0.0023\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [61/200] Batch 11/12                         Loss D: 1.6790, loss G: 0.1745\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [62/200] Batch 11/12                         Loss D: 0.3312, loss G: 0.1168\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [63/200] Batch 11/12                         Loss D: -0.8863, loss G: 0.3775\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [64/200] Batch 11/12                         Loss D: -2.2840, loss G: 0.3030\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [65/200] Batch 11/12                         Loss D: -3.8529, loss G: 0.5756\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [66/200] Batch 11/12                         Loss D: -5.1020, loss G: 0.4648\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [67/200] Batch 11/12                         Loss D: -6.4977, loss G: 0.6092\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [68/200] Batch 11/12                         Loss D: -7.7713, loss G: 0.5978\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [69/200] Batch 11/12                         Loss D: -9.1130, loss G: 0.7814\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [70/200] Batch 11/12                         Loss D: -10.7987, loss G: 0.7744\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [71/200] Batch 11/12                         Loss D: -12.1265, loss G: 0.8201\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [72/200] Batch 11/12                         Loss D: -13.5216, loss G: 0.8829\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [73/200] Batch 11/12                         Loss D: -14.6780, loss G: 1.0620\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [74/200] Batch 11/12                         Loss D: -16.2222, loss G: 1.0794\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [75/200] Batch 11/12                         Loss D: -17.5478, loss G: 1.1719\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [76/200] Batch 11/12                         Loss D: -19.5595, loss G: 1.4630\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [77/200] Batch 11/12                         Loss D: -20.4436, loss G: 1.3001\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [78/200] Batch 11/12                         Loss D: -22.1404, loss G: 1.4148\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [79/200] Batch 11/12                         Loss D: -23.3370, loss G: 1.4404\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [80/200] Batch 11/12                         Loss D: -25.0375, loss G: 1.5811\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [81/200] Batch 11/12                         Loss D: -26.1820, loss G: 1.6815\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [82/200] Batch 11/12                         Loss D: -28.0205, loss G: 1.7990\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [83/200] Batch 11/12                         Loss D: -29.5617, loss G: 1.8846\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [84/200] Batch 11/12                         Loss D: -30.7568, loss G: 1.8758\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [85/200] Batch 11/12                         Loss D: -31.9830, loss G: 2.0048\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [86/200] Batch 11/12                         Loss D: -34.1200, loss G: 2.1702\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [87/200] Batch 11/12                         Loss D: -35.3279, loss G: 2.1421\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [88/200] Batch 11/12                         Loss D: -37.2523, loss G: 2.3397\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [89/200] Batch 11/12                         Loss D: -38.3793, loss G: 2.3053\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [90/200] Batch 11/12                         Loss D: -39.4865, loss G: 2.5171\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [91/200] Batch 11/12                         Loss D: -41.0755, loss G: 2.5362\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [92/200] Batch 11/12                         Loss D: -43.3301, loss G: 2.6771\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [93/200] Batch 11/12                         Loss D: -43.9387, loss G: 2.7984\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [94/200] Batch 11/12                         Loss D: -45.8043, loss G: 2.8182\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [95/200] Batch 11/12                         Loss D: -47.9744, loss G: 2.9960\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [96/200] Batch 11/12                         Loss D: -48.9524, loss G: 3.0046\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [97/200] Batch 11/12                         Loss D: -51.2182, loss G: 3.1825\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [98/200] Batch 11/12                         Loss D: -52.3722, loss G: 3.1308\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [99/200] Batch 11/12                         Loss D: -53.9452, loss G: 3.2688\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [100/200] Batch 11/12                         Loss D: -56.1799, loss G: 3.4697\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [101/200] Batch 11/12                         Loss D: -57.3985, loss G: 3.4201\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [102/200] Batch 11/12                         Loss D: -59.2477, loss G: 3.5566\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [103/200] Batch 11/12                         Loss D: -60.8103, loss G: 3.5963\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [104/200] Batch 11/12                         Loss D: -62.0926, loss G: 3.7583\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [105/200] Batch 11/12                         Loss D: -64.6167, loss G: 3.9332\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [106/200] Batch 11/12                         Loss D: -66.0259, loss G: 3.9627\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [107/200] Batch 11/12                         Loss D: -67.9002, loss G: 4.0470\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [108/200] Batch 11/12                         Loss D: -68.5991, loss G: 4.2520\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [109/200] Batch 11/12                         Loss D: -70.9146, loss G: 4.2386\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [110/200] Batch 11/12                         Loss D: -72.1590, loss G: 4.4151\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [111/200] Batch 11/12                         Loss D: -74.2045, loss G: 4.4820\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [112/200] Batch 11/12                         Loss D: -76.5455, loss G: 4.5382\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [113/200] Batch 11/12                         Loss D: -77.6828, loss G: 4.7334\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [114/200] Batch 11/12                         Loss D: -80.4035, loss G: 4.7465\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [115/200] Batch 11/12                         Loss D: -82.7522, loss G: 4.9481\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [116/200] Batch 11/12                         Loss D: -83.3385, loss G: 5.0361\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [117/200] Batch 11/12                         Loss D: -86.0180, loss G: 5.0653\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [118/200] Batch 11/12                         Loss D: -88.3998, loss G: 5.3195\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [119/200] Batch 11/12                         Loss D: -88.4901, loss G: 5.4413\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [120/200] Batch 11/12                         Loss D: -90.8245, loss G: 5.5098\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [121/200] Batch 11/12                         Loss D: -93.5027, loss G: 5.5605\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [122/200] Batch 11/12                         Loss D: -95.9180, loss G: 5.6596\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [123/200] Batch 11/12                         Loss D: -97.4523, loss G: 5.7767\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [124/200] Batch 11/12                         Loss D: -100.0490, loss G: 5.9596\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [125/200] Batch 11/12                         Loss D: -100.8826, loss G: 6.0878\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [126/200] Batch 11/12                         Loss D: -103.8606, loss G: 6.1572\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [127/200] Batch 11/12                         Loss D: -105.2651, loss G: 6.2862\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [128/200] Batch 11/12                         Loss D: -107.4706, loss G: 6.3963\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [129/200] Batch 11/12                         Loss D: -108.4071, loss G: 6.6220\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [130/200] Batch 11/12                         Loss D: -111.3592, loss G: 6.6931\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [131/200] Batch 11/12                         Loss D: -113.7674, loss G: 6.7720\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [132/200] Batch 11/12                         Loss D: -115.2562, loss G: 6.9558\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [133/200] Batch 11/12                         Loss D: -118.2105, loss G: 7.0026\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [134/200] Batch 11/12                         Loss D: -120.8945, loss G: 7.1422\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [135/200] Batch 11/12                         Loss D: -122.5020, loss G: 7.2659\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [136/200] Batch 11/12                         Loss D: -125.4613, loss G: 7.4461\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [137/200] Batch 11/12                         Loss D: -126.0084, loss G: 7.6000\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [138/200] Batch 11/12                         Loss D: -129.4738, loss G: 7.6480\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [139/200] Batch 11/12                         Loss D: -132.3488, loss G: 7.8745\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [140/200] Batch 11/12                         Loss D: -134.8354, loss G: 8.0393\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [141/200] Batch 11/12                         Loss D: -136.7345, loss G: 8.1038\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [142/200] Batch 11/12                         Loss D: -138.6647, loss G: 8.2023\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [143/200] Batch 11/12                         Loss D: -139.5898, loss G: 8.3689\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [144/200] Batch 11/12                         Loss D: -143.8696, loss G: 8.5269\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [145/200] Batch 11/12                         Loss D: -143.7833, loss G: 8.6656\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [146/200] Batch 11/12                         Loss D: -148.8769, loss G: 8.8791\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [147/200] Batch 11/12                         Loss D: -148.8654, loss G: 8.9174\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [148/200] Batch 11/12                         Loss D: -150.0329, loss G: 9.1208\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [149/200] Batch 11/12                         Loss D: -154.6929, loss G: 9.1486\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [150/200] Batch 11/12                         Loss D: -157.1984, loss G: 9.3104\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [151/200] Batch 11/12                         Loss D: -158.6982, loss G: 9.4713\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [152/200] Batch 11/12                         Loss D: -159.3700, loss G: 9.6925\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [153/200] Batch 11/12                         Loss D: -166.7521, loss G: 9.9695\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [154/200] Batch 11/12                         Loss D: -167.6111, loss G: 9.9010\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [155/200] Batch 11/12                         Loss D: -167.9753, loss G: 10.0715\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [156/200] Batch 11/12                         Loss D: -171.5004, loss G: 10.1835\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [157/200] Batch 11/12                         Loss D: -175.7106, loss G: 10.4300\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [158/200] Batch 11/12                         Loss D: -174.6649, loss G: 10.5466\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [159/200] Batch 11/12                         Loss D: -178.0974, loss G: 10.6602\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [160/200] Batch 11/12                         Loss D: -180.8040, loss G: 10.8088\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [161/200] Batch 11/12                         Loss D: -183.7693, loss G: 10.9556\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [162/200] Batch 11/12                         Loss D: -187.4281, loss G: 11.0787\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [163/200] Batch 11/12                         Loss D: -189.3294, loss G: 11.2448\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [164/200] Batch 11/12                         Loss D: -189.9944, loss G: 11.4495\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [165/200] Batch 11/12                         Loss D: -192.9437, loss G: 11.6088\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [166/200] Batch 11/12                         Loss D: -200.4312, loss G: 11.9745\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [167/200] Batch 11/12                         Loss D: -200.6830, loss G: 11.8680\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [168/200] Batch 11/12                         Loss D: -203.1310, loss G: 12.0411\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [169/200] Batch 11/12                         Loss D: -202.8374, loss G: 12.2441\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [170/200] Batch 11/12                         Loss D: -205.1513, loss G: 12.4018\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [171/200] Batch 11/12                         Loss D: -208.3891, loss G: 12.5522\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [172/200] Batch 11/12                         Loss D: -214.9546, loss G: 12.6966\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [173/200] Batch 11/12                         Loss D: -215.1352, loss G: 12.8723\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [174/200] Batch 11/12                         Loss D: -218.5870, loss G: 13.0105\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [175/200] Batch 11/12                         Loss D: -219.8549, loss G: 13.1832\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [176/200] Batch 11/12                         Loss D: -221.3771, loss G: 13.3748\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [177/200] Batch 11/12                         Loss D: -225.2987, loss G: 13.5476\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [178/200] Batch 11/12                         Loss D: -231.7486, loss G: 13.7000\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [179/200] Batch 11/12                         Loss D: -234.0002, loss G: 13.9017\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [180/200] Batch 11/12                         Loss D: -232.6486, loss G: 14.0452\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [181/200] Batch 11/12                         Loss D: -236.3482, loss G: 14.2009\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [182/200] Batch 11/12                         Loss D: -239.0762, loss G: 14.3764\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [183/200] Batch 11/12                         Loss D: -243.3162, loss G: 14.5284\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [184/200] Batch 11/12                         Loss D: -245.9157, loss G: 14.7109\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [185/200] Batch 11/12                         Loss D: -246.7102, loss G: 14.9032\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [186/200] Batch 11/12                         Loss D: -250.4422, loss G: 15.0996\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [187/200] Batch 11/12                         Loss D: -254.0296, loss G: 15.2413\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [188/200] Batch 11/12                         Loss D: -259.2634, loss G: 15.4193\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [189/200] Batch 11/12                         Loss D: -259.5576, loss G: 15.5964\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [190/200] Batch 11/12                         Loss D: -261.1885, loss G: 15.7436\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [191/200] Batch 11/12                         Loss D: -263.0255, loss G: 15.9205\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [192/200] Batch 11/12                         Loss D: -266.5816, loss G: 16.1129\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [193/200] Batch 11/12                         Loss D: -268.0326, loss G: 16.2585\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [194/200] Batch 11/12                         Loss D: -267.3472, loss G: 16.4323\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [195/200] Batch 11/12                         Loss D: -269.8372, loss G: 16.5806\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [196/200] Batch 11/12                         Loss D: -270.2986, loss G: 16.7420\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [197/200] Batch 11/12                         Loss D: -271.6197, loss G: 16.8748\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [198/200] Batch 11/12                         Loss D: -273.9937, loss G: 17.0403\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [199/200] Batch 11/12                         Loss D: -272.9868, loss G: 17.1676\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [0/200] Batch 11/12                         Loss D: 8.4431, loss G: 3.0851\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [1/200] Batch 11/12                         Loss D: 7.8660, loss G: 3.0068\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [2/200] Batch 11/12                         Loss D: 7.1082, loss G: 2.9752\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [3/200] Batch 11/12                         Loss D: 6.1607, loss G: 2.9574\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [4/200] Batch 11/12                         Loss D: 4.9645, loss G: 2.9404\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [5/200] Batch 11/12                         Loss D: 3.4968, loss G: 2.9273\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [6/200] Batch 11/12                         Loss D: 1.7792, loss G: 2.9251\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [7/200] Batch 11/12                         Loss D: 0.0203, loss G: 2.9355\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [8/200] Batch 11/12                         Loss D: -1.9248, loss G: 2.9547\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [9/200] Batch 11/12                         Loss D: -3.5644, loss G: 2.9841\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [10/200] Batch 11/12                         Loss D: -4.7361, loss G: 3.0180\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [11/200] Batch 11/12                         Loss D: -5.0736, loss G: 3.0503\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [12/200] Batch 11/12                         Loss D: -4.5612, loss G: 3.0749\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [13/200] Batch 11/12                         Loss D: -3.2709, loss G: 3.0875\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [14/200] Batch 11/12                         Loss D: -1.7943, loss G: 3.0912\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [15/200] Batch 11/12                         Loss D: -0.2513, loss G: 3.0876\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [16/200] Batch 11/12                         Loss D: 1.3411, loss G: 3.0792\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [17/200] Batch 11/12                         Loss D: 2.6284, loss G: 3.0717\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [18/200] Batch 11/12                         Loss D: 3.7143, loss G: 3.0656\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [19/200] Batch 11/12                         Loss D: 4.7929, loss G: 3.0586\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [20/200] Batch 11/12                         Loss D: 5.4731, loss G: 3.0555\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [21/200] Batch 11/12                         Loss D: 5.6448, loss G: 3.0554\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [22/200] Batch 11/12                         Loss D: 5.6606, loss G: 3.0558\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [23/200] Batch 11/12                         Loss D: 5.6716, loss G: 3.0556\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [24/200] Batch 11/12                         Loss D: 5.6229, loss G: 3.0562\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [25/200] Batch 11/12                         Loss D: 5.6311, loss G: 3.0564\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [26/200] Batch 11/12                         Loss D: 5.5561, loss G: 3.0568\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [27/200] Batch 11/12                         Loss D: 5.5556, loss G: 3.0570\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [28/200] Batch 11/12                         Loss D: 5.4851, loss G: 3.0574\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [29/200] Batch 11/12                         Loss D: 5.4984, loss G: 3.0578\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [30/200] Batch 11/12                         Loss D: 5.4512, loss G: 3.0584\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [31/200] Batch 11/12                         Loss D: 5.3967, loss G: 3.0590\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [32/200] Batch 11/12                         Loss D: 5.3962, loss G: 3.0592\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [33/200] Batch 11/12                         Loss D: 5.3839, loss G: 3.0599\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [34/200] Batch 11/12                         Loss D: 5.3594, loss G: 3.0606\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [35/200] Batch 11/12                         Loss D: 5.3451, loss G: 3.0612\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [36/200] Batch 11/12                         Loss D: 5.2773, loss G: 3.0616\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [37/200] Batch 11/12                         Loss D: 5.2826, loss G: 3.0622\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [38/200] Batch 11/12                         Loss D: 5.2595, loss G: 3.0628\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [39/200] Batch 11/12                         Loss D: 5.2464, loss G: 3.0631\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [40/200] Batch 11/12                         Loss D: 5.2406, loss G: 3.0637\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [41/200] Batch 11/12                         Loss D: 5.2970, loss G: 3.0643\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [42/200] Batch 11/12                         Loss D: 5.2483, loss G: 3.0648\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [43/200] Batch 11/12                         Loss D: 5.2104, loss G: 3.0655\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [44/200] Batch 11/12                         Loss D: 5.2510, loss G: 3.0659\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [45/200] Batch 11/12                         Loss D: 5.1912, loss G: 3.0664\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [46/200] Batch 11/12                         Loss D: 5.2207, loss G: 3.0670\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [47/200] Batch 11/12                         Loss D: 5.1708, loss G: 3.0675\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [48/200] Batch 11/12                         Loss D: 5.1497, loss G: 3.0679\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [49/200] Batch 11/12                         Loss D: 5.1551, loss G: 3.0684\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [50/200] Batch 11/12                         Loss D: 5.1036, loss G: 3.0691\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [51/200] Batch 11/12                         Loss D: 5.0996, loss G: 3.0702\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [52/200] Batch 11/12                         Loss D: 5.0332, loss G: 3.0703\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [53/200] Batch 11/12                         Loss D: 5.0542, loss G: 3.0709\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [54/200] Batch 11/12                         Loss D: 5.0259, loss G: 3.0716\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [55/200] Batch 11/12                         Loss D: 5.0119, loss G: 3.0719\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [56/200] Batch 11/12                         Loss D: 5.0154, loss G: 3.0730\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [57/200] Batch 11/12                         Loss D: 4.9282, loss G: 3.0734\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [58/200] Batch 11/12                         Loss D: 4.8671, loss G: 3.0747\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [59/200] Batch 11/12                         Loss D: 4.9077, loss G: 3.0746\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [60/200] Batch 11/12                         Loss D: 4.8626, loss G: 3.0753\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [61/200] Batch 11/12                         Loss D: 4.8121, loss G: 3.0767\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [62/200] Batch 11/12                         Loss D: 4.8261, loss G: 3.0765\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [63/200] Batch 11/12                         Loss D: 4.8229, loss G: 3.0773\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [64/200] Batch 11/12                         Loss D: 4.7947, loss G: 3.0778\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [65/200] Batch 11/12                         Loss D: 4.7708, loss G: 3.0787\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [66/200] Batch 11/12                         Loss D: 4.7807, loss G: 3.0791\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [67/200] Batch 11/12                         Loss D: 4.7672, loss G: 3.0800\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [68/200] Batch 11/12                         Loss D: 4.6778, loss G: 3.0805\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [69/200] Batch 11/12                         Loss D: 4.7255, loss G: 3.0814\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [70/200] Batch 11/12                         Loss D: 4.6589, loss G: 3.0817\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [71/200] Batch 11/12                         Loss D: 4.6441, loss G: 3.0823\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [72/200] Batch 11/12                         Loss D: 4.7021, loss G: 3.0852\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [73/200] Batch 11/12                         Loss D: 4.6388, loss G: 3.0851\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [74/200] Batch 11/12                         Loss D: 4.6205, loss G: 3.0854\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [75/200] Batch 11/12                         Loss D: 4.5970, loss G: 3.0863\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [76/200] Batch 11/12                         Loss D: 4.5617, loss G: 3.0864\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [77/200] Batch 11/12                         Loss D: 4.4932, loss G: 3.0863\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [78/200] Batch 11/12                         Loss D: 4.4246, loss G: 3.0872\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [79/200] Batch 11/12                         Loss D: 4.4624, loss G: 3.0877\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [80/200] Batch 11/12                         Loss D: 4.4179, loss G: 3.0882\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [81/200] Batch 11/12                         Loss D: 4.4171, loss G: 3.0889\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [82/200] Batch 11/12                         Loss D: 4.2922, loss G: 3.0900\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [83/200] Batch 11/12                         Loss D: 4.3297, loss G: 3.0901\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [84/200] Batch 11/12                         Loss D: 4.2590, loss G: 3.0909\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [85/200] Batch 11/12                         Loss D: 4.2941, loss G: 3.0918\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [86/200] Batch 11/12                         Loss D: 4.1930, loss G: 3.0923\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [87/200] Batch 11/12                         Loss D: 4.1437, loss G: 3.0934\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [88/200] Batch 11/12                         Loss D: 4.1827, loss G: 3.0938\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [89/200] Batch 11/12                         Loss D: 4.1539, loss G: 3.0941\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [90/200] Batch 11/12                         Loss D: 4.0276, loss G: 3.0956\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [91/200] Batch 11/12                         Loss D: 4.0633, loss G: 3.0952\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [92/200] Batch 11/12                         Loss D: 4.0065, loss G: 3.0958\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [93/200] Batch 11/12                         Loss D: 4.0043, loss G: 3.0969\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [94/200] Batch 11/12                         Loss D: 3.9563, loss G: 3.0971\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [95/200] Batch 11/12                         Loss D: 3.9351, loss G: 3.0978\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [96/200] Batch 11/12                         Loss D: 3.9605, loss G: 3.0988\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [97/200] Batch 11/12                         Loss D: 3.8310, loss G: 3.0991\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [98/200] Batch 11/12                         Loss D: 3.7971, loss G: 3.0996\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [99/200] Batch 11/12                         Loss D: 3.8258, loss G: 3.1004\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [100/200] Batch 11/12                         Loss D: 3.7621, loss G: 3.1011\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [101/200] Batch 11/12                         Loss D: 3.7408, loss G: 3.1018\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [102/200] Batch 11/12                         Loss D: 3.5884, loss G: 3.1026\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [103/200] Batch 11/12                         Loss D: 3.6501, loss G: 3.1031\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [104/200] Batch 11/12                         Loss D: 3.6351, loss G: 3.1037\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [105/200] Batch 11/12                         Loss D: 3.5029, loss G: 3.1039\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [106/200] Batch 11/12                         Loss D: 3.4977, loss G: 3.1048\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [107/200] Batch 11/12                         Loss D: 3.4857, loss G: 3.1054\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [108/200] Batch 11/12                         Loss D: 3.4738, loss G: 3.1064\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [109/200] Batch 11/12                         Loss D: 3.3132, loss G: 3.1067\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [110/200] Batch 11/12                         Loss D: 3.2655, loss G: 3.1076\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [111/200] Batch 11/12                         Loss D: 3.2380, loss G: 3.1080\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [112/200] Batch 11/12                         Loss D: 3.1906, loss G: 3.1087\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [113/200] Batch 11/12                         Loss D: 3.1151, loss G: 3.1093\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [114/200] Batch 11/12                         Loss D: 3.1250, loss G: 3.1106\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [115/200] Batch 11/12                         Loss D: 3.0675, loss G: 3.1102\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [116/200] Batch 11/12                         Loss D: 2.9688, loss G: 3.1117\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [117/200] Batch 11/12                         Loss D: 2.9363, loss G: 3.1119\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [118/200] Batch 11/12                         Loss D: 2.8625, loss G: 3.1130\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [119/200] Batch 11/12                         Loss D: 2.8190, loss G: 3.1132\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [120/200] Batch 11/12                         Loss D: 2.7651, loss G: 3.1138\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [121/200] Batch 11/12                         Loss D: 2.8072, loss G: 3.1146\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [122/200] Batch 11/12                         Loss D: 2.7616, loss G: 3.1153\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [123/200] Batch 11/12                         Loss D: 2.6727, loss G: 3.1155\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [124/200] Batch 11/12                         Loss D: 2.6762, loss G: 3.1167\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [125/200] Batch 11/12                         Loss D: 2.5781, loss G: 3.1173\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [126/200] Batch 11/12                         Loss D: 2.5431, loss G: 3.1181\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [127/200] Batch 11/12                         Loss D: 2.4364, loss G: 3.1184\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [128/200] Batch 11/12                         Loss D: 2.4253, loss G: 3.1191\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [129/200] Batch 11/12                         Loss D: 2.4317, loss G: 3.1202\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [130/200] Batch 11/12                         Loss D: 2.3257, loss G: 3.1206\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [131/200] Batch 11/12                         Loss D: 2.3038, loss G: 3.1216\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [132/200] Batch 11/12                         Loss D: 2.2964, loss G: 3.1227\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [133/200] Batch 11/12                         Loss D: 2.1224, loss G: 3.1228\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [134/200] Batch 11/12                         Loss D: 2.0987, loss G: 3.1232\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [135/200] Batch 11/12                         Loss D: 1.9613, loss G: 3.1243\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [136/200] Batch 11/12                         Loss D: 1.9356, loss G: 3.1247\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [137/200] Batch 11/12                         Loss D: 1.9841, loss G: 3.1256\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [138/200] Batch 11/12                         Loss D: 1.9369, loss G: 3.1262\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [139/200] Batch 11/12                         Loss D: 1.7668, loss G: 3.1267\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [140/200] Batch 11/12                         Loss D: 1.6815, loss G: 3.1277\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [141/200] Batch 11/12                         Loss D: 1.6427, loss G: 3.1282\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [142/200] Batch 11/12                         Loss D: 1.5782, loss G: 3.1290\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [143/200] Batch 11/12                         Loss D: 1.5292, loss G: 3.1297\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [144/200] Batch 11/12                         Loss D: 1.5023, loss G: 3.1302\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [145/200] Batch 11/12                         Loss D: 1.5711, loss G: 3.1312\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [146/200] Batch 11/12                         Loss D: 1.3584, loss G: 3.1317\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [147/200] Batch 11/12                         Loss D: 1.2929, loss G: 3.1326\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [148/200] Batch 11/12                         Loss D: 1.3526, loss G: 3.1329\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [149/200] Batch 11/12                         Loss D: 1.3585, loss G: 3.1345\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [150/200] Batch 11/12                         Loss D: 1.2060, loss G: 3.1343\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [151/200] Batch 11/12                         Loss D: 1.2099, loss G: 3.1354\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [152/200] Batch 11/12                         Loss D: 1.0972, loss G: 3.1357\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [153/200] Batch 11/12                         Loss D: 0.9991, loss G: 3.1363\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [154/200] Batch 11/12                         Loss D: 0.8910, loss G: 3.1373\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [155/200] Batch 11/12                         Loss D: 0.8478, loss G: 3.1379\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [156/200] Batch 11/12                         Loss D: 0.8005, loss G: 3.1385\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [157/200] Batch 11/12                         Loss D: 0.8247, loss G: 3.1393\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [158/200] Batch 11/12                         Loss D: 0.8759, loss G: 3.1404\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [159/200] Batch 11/12                         Loss D: 1.0952, loss G: 3.1404\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [160/200] Batch 11/12                         Loss D: 1.0821, loss G: 3.1418\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [161/200] Batch 11/12                         Loss D: 0.9467, loss G: 3.1411\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [162/200] Batch 11/12                         Loss D: 0.9282, loss G: 3.1418\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [163/200] Batch 11/12                         Loss D: 1.0412, loss G: 3.1424\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [164/200] Batch 11/12                         Loss D: 1.0057, loss G: 3.1430\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [165/200] Batch 11/12                         Loss D: 0.8619, loss G: 3.1435\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [166/200] Batch 11/12                         Loss D: 0.7658, loss G: 3.1439\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [167/200] Batch 11/12                         Loss D: 0.7406, loss G: 3.1444\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [168/200] Batch 11/12                         Loss D: 0.4978, loss G: 3.1454\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [169/200] Batch 11/12                         Loss D: 0.4421, loss G: 3.1466\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [170/200] Batch 11/12                         Loss D: 0.3800, loss G: 3.1472\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [171/200] Batch 11/12                         Loss D: 0.2916, loss G: 3.1480\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [172/200] Batch 11/12                         Loss D: 0.3264, loss G: 3.1473\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [173/200] Batch 11/12                         Loss D: 0.2389, loss G: 3.1478\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [174/200] Batch 11/12                         Loss D: 0.1924, loss G: 3.1484\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [175/200] Batch 11/12                         Loss D: 0.1229, loss G: 3.1490\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [176/200] Batch 11/12                         Loss D: 0.0921, loss G: 3.1497\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [177/200] Batch 11/12                         Loss D: 0.0633, loss G: 3.1502\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [178/200] Batch 11/12                         Loss D: 0.1622, loss G: 3.1505\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [179/200] Batch 11/12                         Loss D: 0.3062, loss G: 3.1508\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [180/200] Batch 11/12                         Loss D: 0.5575, loss G: 3.1508\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [181/200] Batch 11/12                         Loss D: 1.4573, loss G: 3.1337\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [182/200] Batch 11/12                         Loss D: 18.3951, loss G: 2.7001\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [183/200] Batch 11/12                         Loss D: 35.6688, loss G: 1.6922\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [184/200] Batch 11/12                         Loss D: 55.0832, loss G: -0.1585\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [185/200] Batch 11/12                         Loss D: 59.7746, loss G: -0.9932\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [186/200] Batch 11/12                         Loss D: 49.0750, loss G: -0.3541\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [187/200] Batch 11/12                         Loss D: 41.4835, loss G: 0.1337\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [188/200] Batch 11/12                         Loss D: 34.2782, loss G: 0.5662\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [189/200] Batch 11/12                         Loss D: 28.4394, loss G: 1.0028\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [190/200] Batch 11/12                         Loss D: 22.5601, loss G: 1.3421\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [191/200] Batch 11/12                         Loss D: 17.2201, loss G: 1.7300\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [192/200] Batch 11/12                         Loss D: 11.6771, loss G: 2.0483\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [193/200] Batch 11/12                         Loss D: 6.6296, loss G: 2.3729\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [194/200] Batch 11/12                         Loss D: 2.1925, loss G: 2.7011\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [195/200] Batch 11/12                         Loss D: -2.6883, loss G: 3.0042\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [196/200] Batch 11/12                         Loss D: -7.3324, loss G: 3.2992\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [197/200] Batch 11/12                         Loss D: -10.3401, loss G: 3.5614\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [198/200] Batch 11/12                         Loss D: -11.7411, loss G: 3.7744\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [199/200] Batch 11/12                         Loss D: -12.3371, loss G: 3.9243\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [0/200] Batch 11/12                         Loss D: 1.1549, loss G: 33.9771\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [1/200] Batch 11/12                         Loss D: 1.0959, loss G: 33.2180\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [2/200] Batch 11/12                         Loss D: 0.6404, loss G: 31.9712\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [3/200] Batch 11/12                         Loss D: -0.0661, loss G: 30.1037\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [4/200] Batch 11/12                         Loss D: -0.7110, loss G: 28.5248\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [5/200] Batch 11/12                         Loss D: -1.4019, loss G: 26.7498\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [6/200] Batch 11/12                         Loss D: -2.3679, loss G: 24.3027\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [7/200] Batch 11/12                         Loss D: -3.5272, loss G: 21.5430\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [8/200] Batch 11/12                         Loss D: -5.4177, loss G: 17.3933\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [9/200] Batch 11/12                         Loss D: -7.9290, loss G: 12.3005\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [10/200] Batch 11/12                         Loss D: -8.7414, loss G: 8.7575\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [11/200] Batch 11/12                         Loss D: -6.8515, loss G: 6.2979\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [12/200] Batch 11/12                         Loss D: -4.7938, loss G: 3.8934\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [13/200] Batch 11/12                         Loss D: -2.8294, loss G: 0.9357\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [14/200] Batch 11/12                         Loss D: -2.0891, loss G: 0.0884\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [15/200] Batch 11/12                         Loss D: -2.5065, loss G: 0.4664\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [16/200] Batch 11/12                         Loss D: -2.7211, loss G: -0.0268\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [17/200] Batch 11/12                         Loss D: -3.0350, loss G: 0.1565\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [18/200] Batch 11/12                         Loss D: -3.2335, loss G: 0.0239\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [19/200] Batch 11/12                         Loss D: -3.3306, loss G: 0.0068\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [20/200] Batch 11/12                         Loss D: -3.6466, loss G: 0.1427\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [21/200] Batch 11/12                         Loss D: -3.5020, loss G: 0.0303\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [22/200] Batch 11/12                         Loss D: -4.2588, loss G: 0.1717\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [23/200] Batch 11/12                         Loss D: -4.2344, loss G: 0.0469\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [24/200] Batch 11/12                         Loss D: -4.2851, loss G: -0.0300\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [25/200] Batch 11/12                         Loss D: -4.4787, loss G: 0.4306\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [26/200] Batch 11/12                         Loss D: -4.5624, loss G: 0.6829\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [27/200] Batch 11/12                         Loss D: -4.8732, loss G: 0.0693\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [28/200] Batch 11/12                         Loss D: -5.3257, loss G: -0.0228\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [29/200] Batch 11/12                         Loss D: -5.4612, loss G: 0.0035\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [30/200] Batch 11/12                         Loss D: -5.8201, loss G: 0.3362\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [31/200] Batch 11/12                         Loss D: -6.0522, loss G: 0.2416\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [32/200] Batch 11/12                         Loss D: -6.2464, loss G: 0.0893\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [33/200] Batch 11/12                         Loss D: -6.4375, loss G: 0.0641\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [34/200] Batch 11/12                         Loss D: -6.4810, loss G: 0.1449\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [35/200] Batch 11/12                         Loss D: -6.9947, loss G: 0.4948\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [36/200] Batch 11/12                         Loss D: -6.9597, loss G: 0.4512\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [37/200] Batch 11/12                         Loss D: -7.6856, loss G: 0.2689\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [38/200] Batch 11/12                         Loss D: -7.3706, loss G: 0.3131\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [39/200] Batch 11/12                         Loss D: -7.9720, loss G: 0.2735\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [40/200] Batch 11/12                         Loss D: -8.1369, loss G: 0.3889\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [41/200] Batch 11/12                         Loss D: -8.5080, loss G: 0.4380\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [42/200] Batch 11/12                         Loss D: -8.4697, loss G: 0.5398\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [43/200] Batch 11/12                         Loss D: -8.9959, loss G: 0.4659\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [44/200] Batch 11/12                         Loss D: -9.2721, loss G: 0.2431\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [45/200] Batch 11/12                         Loss D: -9.6189, loss G: 0.1671\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [46/200] Batch 11/12                         Loss D: -10.1279, loss G: 0.2930\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [47/200] Batch 11/12                         Loss D: -10.0105, loss G: 0.2732\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [48/200] Batch 11/12                         Loss D: -10.4719, loss G: 0.5303\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [49/200] Batch 11/12                         Loss D: -10.7151, loss G: 0.4853\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [50/200] Batch 11/12                         Loss D: -11.1095, loss G: 0.4068\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [51/200] Batch 11/12                         Loss D: -11.0108, loss G: 0.5103\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [52/200] Batch 11/12                         Loss D: -11.6215, loss G: 0.3969\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [53/200] Batch 11/12                         Loss D: -11.8506, loss G: 0.4846\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [54/200] Batch 11/12                         Loss D: -12.0448, loss G: 0.4707\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [55/200] Batch 11/12                         Loss D: -11.9441, loss G: 0.3783\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [56/200] Batch 11/12                         Loss D: -12.8838, loss G: 0.6122\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [57/200] Batch 11/12                         Loss D: -12.3852, loss G: 0.4662\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [58/200] Batch 11/12                         Loss D: -13.0880, loss G: 0.3795\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [59/200] Batch 11/12                         Loss D: -13.2361, loss G: 0.4114\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [60/200] Batch 11/12                         Loss D: -13.2624, loss G: 0.7541\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [61/200] Batch 11/12                         Loss D: -13.5553, loss G: 0.4850\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [62/200] Batch 11/12                         Loss D: -13.8634, loss G: 0.6144\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [63/200] Batch 11/12                         Loss D: -13.9312, loss G: 0.9680\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [64/200] Batch 11/12                         Loss D: -14.9253, loss G: 0.5464\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [65/200] Batch 11/12                         Loss D: -15.1248, loss G: 0.5389\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [66/200] Batch 11/12                         Loss D: -15.1394, loss G: 0.8694\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [67/200] Batch 11/12                         Loss D: -15.4083, loss G: 0.6182\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [68/200] Batch 11/12                         Loss D: -16.3675, loss G: 0.9275\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [69/200] Batch 11/12                         Loss D: -16.6231, loss G: 0.7687\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [70/200] Batch 11/12                         Loss D: -16.6488, loss G: 0.6869\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [71/200] Batch 11/12                         Loss D: -17.0745, loss G: 0.7341\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [72/200] Batch 11/12                         Loss D: -17.2333, loss G: 0.7385\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [73/200] Batch 11/12                         Loss D: -17.6642, loss G: 0.6392\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [74/200] Batch 11/12                         Loss D: -17.7437, loss G: 0.9364\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [75/200] Batch 11/12                         Loss D: -18.3244, loss G: 0.6061\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [76/200] Batch 11/12                         Loss D: -18.2088, loss G: 0.9855\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [77/200] Batch 11/12                         Loss D: -19.2169, loss G: 1.0129\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [78/200] Batch 11/12                         Loss D: -19.5776, loss G: 0.8767\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [79/200] Batch 11/12                         Loss D: -20.0478, loss G: 0.7357\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [80/200] Batch 11/12                         Loss D: -20.5439, loss G: 0.8089\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [81/200] Batch 11/12                         Loss D: -20.3635, loss G: 1.0281\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [82/200] Batch 11/12                         Loss D: -21.2185, loss G: 0.8745\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [83/200] Batch 11/12                         Loss D: -21.2849, loss G: 0.8541\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [84/200] Batch 11/12                         Loss D: -21.2284, loss G: 0.8325\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [85/200] Batch 11/12                         Loss D: -22.0255, loss G: 0.7743\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [86/200] Batch 11/12                         Loss D: -22.6632, loss G: 0.8290\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [87/200] Batch 11/12                         Loss D: -22.7793, loss G: 0.8739\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [88/200] Batch 11/12                         Loss D: -23.4004, loss G: 0.8974\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [89/200] Batch 11/12                         Loss D: -23.5362, loss G: 0.8841\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [90/200] Batch 11/12                         Loss D: -24.2790, loss G: 0.8161\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [91/200] Batch 11/12                         Loss D: -24.4293, loss G: 0.9621\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [92/200] Batch 11/12                         Loss D: -25.3307, loss G: 0.9335\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [93/200] Batch 11/12                         Loss D: -25.4693, loss G: 0.9083\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [94/200] Batch 11/12                         Loss D: -25.9233, loss G: 0.9485\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [95/200] Batch 11/12                         Loss D: -26.0318, loss G: 1.2736\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [96/200] Batch 11/12                         Loss D: -26.5334, loss G: 1.1164\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [97/200] Batch 11/12                         Loss D: -27.9664, loss G: 1.5040\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [98/200] Batch 11/12                         Loss D: -27.7021, loss G: 1.0838\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [99/200] Batch 11/12                         Loss D: -28.3907, loss G: 1.0685\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [100/200] Batch 11/12                         Loss D: -28.5426, loss G: 1.2065\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [101/200] Batch 11/12                         Loss D: -29.3713, loss G: 1.0941\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [102/200] Batch 11/12                         Loss D: -29.2325, loss G: 1.3016\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [103/200] Batch 11/12                         Loss D: -29.9170, loss G: 1.2587\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [104/200] Batch 11/12                         Loss D: -31.4935, loss G: 1.5681\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [105/200] Batch 11/12                         Loss D: -31.0577, loss G: 1.2281\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [106/200] Batch 11/12                         Loss D: -31.8915, loss G: 1.1892\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [107/200] Batch 11/12                         Loss D: -32.6259, loss G: 1.6535\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [108/200] Batch 11/12                         Loss D: -32.9176, loss G: 1.5717\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [109/200] Batch 11/12                         Loss D: -32.8883, loss G: 1.3002\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [110/200] Batch 11/12                         Loss D: -34.1411, loss G: 1.5750\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [111/200] Batch 11/12                         Loss D: -34.6640, loss G: 1.6072\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [112/200] Batch 11/12                         Loss D: -34.7284, loss G: 1.3809\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [113/200] Batch 11/12                         Loss D: -34.8873, loss G: 1.5448\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [114/200] Batch 11/12                         Loss D: -36.0179, loss G: 1.6601\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [115/200] Batch 11/12                         Loss D: -36.1164, loss G: 1.6533\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [116/200] Batch 11/12                         Loss D: -37.2008, loss G: 1.4610\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [117/200] Batch 11/12                         Loss D: -36.7669, loss G: 1.8669\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [118/200] Batch 11/12                         Loss D: -38.1384, loss G: 1.5503\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [119/200] Batch 11/12                         Loss D: -38.7446, loss G: 1.5645\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [120/200] Batch 11/12                         Loss D: -38.9792, loss G: 1.6299\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [121/200] Batch 11/12                         Loss D: -39.6958, loss G: 1.6323\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [122/200] Batch 11/12                         Loss D: -40.1893, loss G: 1.9806\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [123/200] Batch 11/12                         Loss D: -41.2341, loss G: 1.7117\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [124/200] Batch 11/12                         Loss D: -42.3147, loss G: 1.8898\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [125/200] Batch 11/12                         Loss D: -41.9991, loss G: 1.8858\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [126/200] Batch 11/12                         Loss D: -43.0836, loss G: 1.7836\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [127/200] Batch 11/12                         Loss D: -43.8655, loss G: 1.7719\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [128/200] Batch 11/12                         Loss D: -44.4539, loss G: 1.9398\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [129/200] Batch 11/12                         Loss D: -44.5661, loss G: 2.2660\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [130/200] Batch 11/12                         Loss D: -45.5572, loss G: 1.8652\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [131/200] Batch 11/12                         Loss D: -45.1303, loss G: 2.0427\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [132/200] Batch 11/12                         Loss D: -46.8285, loss G: 2.1608\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [133/200] Batch 11/12                         Loss D: -47.0264, loss G: 2.0195\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [134/200] Batch 11/12                         Loss D: -48.3176, loss G: 2.0932\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [135/200] Batch 11/12                         Loss D: -48.6959, loss G: 2.1211\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [136/200] Batch 11/12                         Loss D: -49.0580, loss G: 2.2147\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [137/200] Batch 11/12                         Loss D: -49.7793, loss G: 2.4626\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [138/200] Batch 11/12                         Loss D: -50.7252, loss G: 2.2505\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [139/200] Batch 11/12                         Loss D: -51.7975, loss G: 2.1738\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [140/200] Batch 11/12                         Loss D: -52.4501, loss G: 2.2136\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [141/200] Batch 11/12                         Loss D: -52.4721, loss G: 2.4047\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [142/200] Batch 11/12                         Loss D: -53.9229, loss G: 2.2779\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [143/200] Batch 11/12                         Loss D: -52.5378, loss G: 2.7044\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [144/200] Batch 11/12                         Loss D: -55.6653, loss G: 2.3919\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [145/200] Batch 11/12                         Loss D: -55.3469, loss G: 2.4630\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [146/200] Batch 11/12                         Loss D: -57.0130, loss G: 2.3968\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [147/200] Batch 11/12                         Loss D: -55.8614, loss G: 2.8745\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [148/200] Batch 11/12                         Loss D: -57.5673, loss G: 2.8685\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [149/200] Batch 11/12                         Loss D: -58.5039, loss G: 2.6438\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [150/200] Batch 11/12                         Loss D: -59.7235, loss G: 2.5634\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [151/200] Batch 11/12                         Loss D: -59.7088, loss G: 2.6530\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [152/200] Batch 11/12                         Loss D: -61.7350, loss G: 3.0638\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [153/200] Batch 11/12                         Loss D: -62.3045, loss G: 2.7073\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [154/200] Batch 11/12                         Loss D: -62.2461, loss G: 2.9036\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [155/200] Batch 11/12                         Loss D: -63.2019, loss G: 2.9153\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [156/200] Batch 11/12                         Loss D: -64.7409, loss G: 2.8379\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [157/200] Batch 11/12                         Loss D: -64.5640, loss G: 2.8292\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [158/200] Batch 11/12                         Loss D: -66.4383, loss G: 2.7274\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [159/200] Batch 11/12                         Loss D: -67.5546, loss G: 2.9033\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [160/200] Batch 11/12                         Loss D: -68.7617, loss G: 2.9789\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [161/200] Batch 11/12                         Loss D: -67.9044, loss G: 2.8645\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [162/200] Batch 11/12                         Loss D: -68.9369, loss G: 2.8241\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [163/200] Batch 11/12                         Loss D: -70.4706, loss G: 2.7079\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [164/200] Batch 11/12                         Loss D: -71.5287, loss G: 2.7448\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [165/200] Batch 11/12                         Loss D: -71.1935, loss G: 2.7658\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [166/200] Batch 11/12                         Loss D: -73.3751, loss G: 2.8091\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [167/200] Batch 11/12                         Loss D: -75.0839, loss G: 2.8932\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [168/200] Batch 11/12                         Loss D: -74.1856, loss G: 2.7298\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [169/200] Batch 11/12                         Loss D: -74.6214, loss G: 2.8933\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [170/200] Batch 11/12                         Loss D: -77.5399, loss G: 3.0835\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [171/200] Batch 11/12                         Loss D: -76.9862, loss G: 2.8748\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [172/200] Batch 11/12                         Loss D: -77.3070, loss G: 2.8616\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [173/200] Batch 11/12                         Loss D: -77.7774, loss G: 2.9237\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [174/200] Batch 11/12                         Loss D: -80.3010, loss G: 2.9643\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [175/200] Batch 11/12                         Loss D: -80.2334, loss G: 3.0813\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [176/200] Batch 11/12                         Loss D: -81.4829, loss G: 3.0336\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [177/200] Batch 11/12                         Loss D: -83.2743, loss G: 3.0260\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [178/200] Batch 11/12                         Loss D: -84.3842, loss G: 3.0229\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [179/200] Batch 11/12                         Loss D: -84.4983, loss G: 3.2675\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [180/200] Batch 11/12                         Loss D: -84.2818, loss G: 3.4644\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [181/200] Batch 11/12                         Loss D: -85.9348, loss G: 3.3232\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [182/200] Batch 11/12                         Loss D: -87.6131, loss G: 3.3835\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [183/200] Batch 11/12                         Loss D: -88.6113, loss G: 3.4051\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [184/200] Batch 11/12                         Loss D: -88.3931, loss G: 3.4568\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [185/200] Batch 11/12                         Loss D: -90.3780, loss G: 3.4107\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [186/200] Batch 11/12                         Loss D: -91.4702, loss G: 3.3208\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [187/200] Batch 11/12                         Loss D: -90.9256, loss G: 3.5267\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [188/200] Batch 11/12                         Loss D: -92.8891, loss G: 3.5111\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [189/200] Batch 11/12                         Loss D: -95.0154, loss G: 3.6682\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [190/200] Batch 11/12                         Loss D: -96.5651, loss G: 3.7436\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [191/200] Batch 11/12                         Loss D: -96.5003, loss G: 3.7125\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [192/200] Batch 11/12                         Loss D: -96.2415, loss G: 3.7300\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [193/200] Batch 11/12                         Loss D: -98.4503, loss G: 3.8294\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [194/200] Batch 11/12                         Loss D: -99.6345, loss G: 3.8067\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [195/200] Batch 11/12                         Loss D: -99.4708, loss G: 3.8803\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [196/200] Batch 11/12                         Loss D: -100.6945, loss G: 3.9273\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [197/200] Batch 11/12                         Loss D: -102.7457, loss G: 3.9928\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [198/200] Batch 11/12                         Loss D: -103.6659, loss G: 4.0207\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [199/200] Batch 11/12                         Loss D: -104.6376, loss G: 4.0366\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [0/200] Batch 11/12                         Loss D: 0.6459, loss G: 16.9350\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [1/200] Batch 11/12                         Loss D: 0.9088, loss G: 16.5619\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [2/200] Batch 11/12                         Loss D: 1.5574, loss G: 15.9491\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [3/200] Batch 11/12                         Loss D: 2.6966, loss G: 15.0022\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [4/200] Batch 11/12                         Loss D: 4.1968, loss G: 13.9907\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [5/200] Batch 11/12                         Loss D: 6.2283, loss G: 12.9344\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [6/200] Batch 11/12                         Loss D: 8.7539, loss G: 11.4705\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [7/200] Batch 11/12                         Loss D: 12.0682, loss G: 9.5997\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [8/200] Batch 11/12                         Loss D: 15.9616, loss G: 7.3731\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [9/200] Batch 11/12                         Loss D: 20.2240, loss G: 4.8118\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [10/200] Batch 11/12                         Loss D: 21.2935, loss G: 3.4777\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [11/200] Batch 11/12                         Loss D: 22.1916, loss G: 2.0374\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [12/200] Batch 11/12                         Loss D: 27.9337, loss G: 0.4184\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [13/200] Batch 11/12                         Loss D: 32.4507, loss G: -1.3558\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [14/200] Batch 11/12                         Loss D: 35.1805, loss G: -2.1141\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [15/200] Batch 11/12                         Loss D: 33.2556, loss G: -2.2025\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [16/200] Batch 11/12                         Loss D: 32.5203, loss G: -2.0450\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [17/200] Batch 11/12                         Loss D: 30.7387, loss G: -2.0397\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [18/200] Batch 11/12                         Loss D: 30.1781, loss G: -1.8298\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [19/200] Batch 11/12                         Loss D: 29.0111, loss G: -1.8545\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [20/200] Batch 11/12                         Loss D: 28.4180, loss G: -1.8382\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [21/200] Batch 11/12                         Loss D: 27.2585, loss G: -1.7590\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [22/200] Batch 11/12                         Loss D: 26.5721, loss G: -1.6896\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [23/200] Batch 11/12                         Loss D: 25.9911, loss G: -1.5707\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [24/200] Batch 11/12                         Loss D: 24.9505, loss G: -1.6936\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [25/200] Batch 11/12                         Loss D: 24.2102, loss G: -1.6426\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [26/200] Batch 11/12                         Loss D: 23.9076, loss G: -1.3205\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [27/200] Batch 11/12                         Loss D: 22.6899, loss G: -1.5533\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [28/200] Batch 11/12                         Loss D: 22.2190, loss G: -1.4856\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [29/200] Batch 11/12                         Loss D: 21.3423, loss G: -1.4984\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [30/200] Batch 11/12                         Loss D: 20.4223, loss G: -1.2372\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [31/200] Batch 11/12                         Loss D: 20.2827, loss G: -1.2912\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [32/200] Batch 11/12                         Loss D: 19.2464, loss G: -1.1969\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [33/200] Batch 11/12                         Loss D: 18.7971, loss G: -1.2579\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [34/200] Batch 11/12                         Loss D: 18.4792, loss G: -1.2419\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [35/200] Batch 11/12                         Loss D: 17.5917, loss G: -1.1287\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [36/200] Batch 11/12                         Loss D: 17.2694, loss G: -1.1619\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [37/200] Batch 11/12                         Loss D: 16.4249, loss G: -1.1817\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [38/200] Batch 11/12                         Loss D: 16.0147, loss G: -1.1333\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [39/200] Batch 11/12                         Loss D: 15.1381, loss G: -0.8943\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [40/200] Batch 11/12                         Loss D: 14.5535, loss G: -0.8489\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [41/200] Batch 11/12                         Loss D: 14.1460, loss G: -1.0824\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [42/200] Batch 11/12                         Loss D: 13.6408, loss G: -0.9985\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [43/200] Batch 11/12                         Loss D: 13.1190, loss G: -1.0213\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [44/200] Batch 11/12                         Loss D: 12.5554, loss G: -0.8546\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [45/200] Batch 11/12                         Loss D: 12.2591, loss G: -0.8227\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [46/200] Batch 11/12                         Loss D: 11.4798, loss G: -0.9236\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [47/200] Batch 11/12                         Loss D: 11.0429, loss G: -0.8400\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [48/200] Batch 11/12                         Loss D: 10.4517, loss G: -0.7477\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [49/200] Batch 11/12                         Loss D: 10.1720, loss G: -0.6274\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [50/200] Batch 11/12                         Loss D: 9.4997, loss G: -0.7188\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [51/200] Batch 11/12                         Loss D: 8.9561, loss G: -0.7626\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [52/200] Batch 11/12                         Loss D: 8.5213, loss G: -0.7033\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [53/200] Batch 11/12                         Loss D: 7.9543, loss G: -0.6350\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [54/200] Batch 11/12                         Loss D: 7.4464, loss G: -0.6070\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [55/200] Batch 11/12                         Loss D: 7.0773, loss G: -0.5767\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [56/200] Batch 11/12                         Loss D: 6.5473, loss G: -0.6303\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [57/200] Batch 11/12                         Loss D: 6.0763, loss G: -0.5912\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [58/200] Batch 11/12                         Loss D: 5.5556, loss G: -0.4556\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [59/200] Batch 11/12                         Loss D: 5.0212, loss G: -0.1980\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [60/200] Batch 11/12                         Loss D: 4.7164, loss G: -0.4042\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [61/200] Batch 11/12                         Loss D: 4.1755, loss G: -0.3849\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [62/200] Batch 11/12                         Loss D: 3.7019, loss G: -0.3255\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [63/200] Batch 11/12                         Loss D: 3.2780, loss G: -0.3639\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [64/200] Batch 11/12                         Loss D: 2.7971, loss G: -0.3807\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [65/200] Batch 11/12                         Loss D: 2.3338, loss G: -0.3477\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [66/200] Batch 11/12                         Loss D: 1.8593, loss G: -0.1464\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [67/200] Batch 11/12                         Loss D: 1.4119, loss G: -0.2545\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [68/200] Batch 11/12                         Loss D: 0.9681, loss G: -0.1965\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [69/200] Batch 11/12                         Loss D: 0.5120, loss G: -0.2254\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [70/200] Batch 11/12                         Loss D: 0.0533, loss G: -0.1669\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [71/200] Batch 11/12                         Loss D: -0.3957, loss G: -0.0805\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [72/200] Batch 11/12                         Loss D: -0.8485, loss G: -0.1531\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [73/200] Batch 11/12                         Loss D: -1.3477, loss G: 0.0278\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [74/200] Batch 11/12                         Loss D: -1.7853, loss G: -0.0800\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [75/200] Batch 11/12                         Loss D: -2.2246, loss G: -0.0017\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [76/200] Batch 11/12                         Loss D: -2.6896, loss G: 0.0302\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [77/200] Batch 11/12                         Loss D: -3.0796, loss G: 0.2084\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [78/200] Batch 11/12                         Loss D: -3.6285, loss G: 0.1464\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [79/200] Batch 11/12                         Loss D: -3.9997, loss G: 0.2125\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [80/200] Batch 11/12                         Loss D: -4.5009, loss G: 0.0855\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [81/200] Batch 11/12                         Loss D: -4.9875, loss G: 0.1089\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [82/200] Batch 11/12                         Loss D: -5.5352, loss G: 0.2691\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [83/200] Batch 11/12                         Loss D: -5.9883, loss G: 0.3612\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [84/200] Batch 11/12                         Loss D: -6.4626, loss G: 0.3468\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [85/200] Batch 11/12                         Loss D: -6.8575, loss G: 0.2310\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [86/200] Batch 11/12                         Loss D: -7.3042, loss G: 0.2609\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [87/200] Batch 11/12                         Loss D: -7.8827, loss G: 0.4924\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [88/200] Batch 11/12                         Loss D: -8.2849, loss G: 0.3526\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [89/200] Batch 11/12                         Loss D: -8.7956, loss G: 0.4394\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [90/200] Batch 11/12                         Loss D: -9.2066, loss G: 0.3854\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [91/200] Batch 11/12                         Loss D: -9.7431, loss G: 0.4220\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [92/200] Batch 11/12                         Loss D: -10.1430, loss G: 0.5766\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [93/200] Batch 11/12                         Loss D: -10.7130, loss G: 0.4868\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [94/200] Batch 11/12                         Loss D: -11.1617, loss G: 0.5728\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [95/200] Batch 11/12                         Loss D: -11.5770, loss G: 0.6929\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [96/200] Batch 11/12                         Loss D: -12.2081, loss G: 0.6398\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [97/200] Batch 11/12                         Loss D: -12.4560, loss G: 0.9731\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [98/200] Batch 11/12                         Loss D: -13.1512, loss G: 0.7526\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [99/200] Batch 11/12                         Loss D: -13.8457, loss G: 0.7145\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [100/200] Batch 11/12                         Loss D: -14.1937, loss G: 0.8023\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [101/200] Batch 11/12                         Loss D: -14.8642, loss G: 0.7857\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [102/200] Batch 11/12                         Loss D: -15.5378, loss G: 0.9059\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [103/200] Batch 11/12                         Loss D: -15.7503, loss G: 0.9539\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [104/200] Batch 11/12                         Loss D: -16.6206, loss G: 0.9306\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [105/200] Batch 11/12                         Loss D: -17.2733, loss G: 1.1247\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [106/200] Batch 11/12                         Loss D: -17.3815, loss G: 1.0379\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [107/200] Batch 11/12                         Loss D: -18.3274, loss G: 1.1424\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [108/200] Batch 11/12                         Loss D: -18.6145, loss G: 1.0245\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [109/200] Batch 11/12                         Loss D: -19.2397, loss G: 1.0661\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [110/200] Batch 11/12                         Loss D: -19.7298, loss G: 1.1040\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [111/200] Batch 11/12                         Loss D: -20.5514, loss G: 1.2314\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [112/200] Batch 11/12                         Loss D: -20.9819, loss G: 1.1549\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [113/200] Batch 11/12                         Loss D: -21.8259, loss G: 1.3330\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [114/200] Batch 11/12                         Loss D: -22.2583, loss G: 1.2063\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [115/200] Batch 11/12                         Loss D: -22.9425, loss G: 1.2843\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [116/200] Batch 11/12                         Loss D: -23.6027, loss G: 1.3231\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [117/200] Batch 11/12                         Loss D: -24.3664, loss G: 1.4065\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [118/200] Batch 11/12                         Loss D: -24.7791, loss G: 1.3859\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [119/200] Batch 11/12                         Loss D: -25.4138, loss G: 1.4252\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [120/200] Batch 11/12                         Loss D: -26.0720, loss G: 1.4441\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [121/200] Batch 11/12                         Loss D: -26.4290, loss G: 1.5915\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [122/200] Batch 11/12                         Loss D: -27.1633, loss G: 1.6864\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [123/200] Batch 11/12                         Loss D: -28.2368, loss G: 1.7783\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [124/200] Batch 11/12                         Loss D: -28.6003, loss G: 1.6833\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [125/200] Batch 11/12                         Loss D: -29.2441, loss G: 1.7254\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [126/200] Batch 11/12                         Loss D: -30.7123, loss G: 2.0051\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [127/200] Batch 11/12                         Loss D: -30.4519, loss G: 1.8297\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [128/200] Batch 11/12                         Loss D: -31.4215, loss G: 1.8142\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [129/200] Batch 11/12                         Loss D: -32.2843, loss G: 1.8472\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [130/200] Batch 11/12                         Loss D: -33.1204, loss G: 1.9805\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [131/200] Batch 11/12                         Loss D: -33.7571, loss G: 2.0171\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [132/200] Batch 11/12                         Loss D: -34.5175, loss G: 2.0290\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [133/200] Batch 11/12                         Loss D: -35.1160, loss G: 2.0234\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [134/200] Batch 11/12                         Loss D: -35.8372, loss G: 2.0750\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [135/200] Batch 11/12                         Loss D: -36.6128, loss G: 2.1233\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [136/200] Batch 11/12                         Loss D: -36.9632, loss G: 2.2713\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [137/200] Batch 11/12                         Loss D: -38.2360, loss G: 2.2902\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [138/200] Batch 11/12                         Loss D: -38.9640, loss G: 2.3105\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [139/200] Batch 11/12                         Loss D: -40.0771, loss G: 2.4225\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [140/200] Batch 11/12                         Loss D: -39.7084, loss G: 2.5061\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [141/200] Batch 11/12                         Loss D: -40.8329, loss G: 2.5657\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [142/200] Batch 11/12                         Loss D: -41.4927, loss G: 2.5620\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [143/200] Batch 11/12                         Loss D: -42.5004, loss G: 2.5389\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [144/200] Batch 11/12                         Loss D: -42.8922, loss G: 2.7212\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [145/200] Batch 11/12                         Loss D: -44.3004, loss G: 2.5550\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [146/200] Batch 11/12                         Loss D: -45.1226, loss G: 2.5695\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [147/200] Batch 11/12                         Loss D: -46.1170, loss G: 2.5340\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [148/200] Batch 11/12                         Loss D: -46.6184, loss G: 2.5990\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [149/200] Batch 11/12                         Loss D: -47.9432, loss G: 2.5832\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [150/200] Batch 11/12                         Loss D: -48.4927, loss G: 2.6063\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [151/200] Batch 11/12                         Loss D: -48.6845, loss G: 2.8289\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [152/200] Batch 11/12                         Loss D: -49.4429, loss G: 2.8689\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [153/200] Batch 11/12                         Loss D: -51.6093, loss G: 2.8526\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [154/200] Batch 11/12                         Loss D: -51.9079, loss G: 2.8215\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [155/200] Batch 11/12                         Loss D: -53.3783, loss G: 2.8731\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [156/200] Batch 11/12                         Loss D: -53.3605, loss G: 2.9284\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [157/200] Batch 11/12                         Loss D: -54.4264, loss G: 2.9616\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [158/200] Batch 11/12                         Loss D: -55.5345, loss G: 2.9738\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [159/200] Batch 11/12                         Loss D: -55.7741, loss G: 3.1278\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [160/200] Batch 11/12                         Loss D: -57.3325, loss G: 3.0493\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [161/200] Batch 11/12                         Loss D: -58.8101, loss G: 3.2004\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [162/200] Batch 11/12                         Loss D: -58.8129, loss G: 3.2632\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [163/200] Batch 11/12                         Loss D: -60.3285, loss G: 3.2092\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [164/200] Batch 11/12                         Loss D: -61.0699, loss G: 3.2295\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [165/200] Batch 11/12                         Loss D: -61.1991, loss G: 3.4064\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [166/200] Batch 11/12                         Loss D: -62.7233, loss G: 3.3353\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [167/200] Batch 11/12                         Loss D: -63.6959, loss G: 3.3882\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [168/200] Batch 11/12                         Loss D: -63.4203, loss G: 3.6152\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [169/200] Batch 11/12                         Loss D: -64.6331, loss G: 3.6066\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [170/200] Batch 11/12                         Loss D: -66.4302, loss G: 3.6049\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [171/200] Batch 11/12                         Loss D: -67.6786, loss G: 3.8076\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [172/200] Batch 11/12                         Loss D: -67.5204, loss G: 3.7620\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [173/200] Batch 11/12                         Loss D: -68.6836, loss G: 3.7498\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [174/200] Batch 11/12                         Loss D: -68.4264, loss G: 3.9925\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [175/200] Batch 11/12                         Loss D: -70.5807, loss G: 3.9009\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [176/200] Batch 11/12                         Loss D: -71.2465, loss G: 3.9546\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [177/200] Batch 11/12                         Loss D: -72.1763, loss G: 4.1083\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [178/200] Batch 11/12                         Loss D: -72.3804, loss G: 4.0651\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [179/200] Batch 11/12                         Loss D: -72.7105, loss G: 4.2343\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [180/200] Batch 11/12                         Loss D: -73.3926, loss G: 4.2287\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [181/200] Batch 11/12                         Loss D: -74.6745, loss G: 4.2350\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [182/200] Batch 11/12                         Loss D: -74.6567, loss G: 4.3886\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [183/200] Batch 11/12                         Loss D: -75.2953, loss G: 4.4460\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [184/200] Batch 11/12                         Loss D: -75.8133, loss G: 4.5029\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [185/200] Batch 11/12                         Loss D: -74.8725, loss G: 4.5750\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [186/200] Batch 11/12                         Loss D: -72.6116, loss G: 4.5435\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [187/200] Batch 11/12                         Loss D: -68.5910, loss G: 4.4195\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [188/200] Batch 11/12                         Loss D: -59.1855, loss G: 3.8583\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [189/200] Batch 11/12                         Loss D: -47.2189, loss G: 3.2697\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [190/200] Batch 11/12                         Loss D: -36.7544, loss G: 2.8893\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [191/200] Batch 11/12                         Loss D: -25.9409, loss G: 2.7228\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [192/200] Batch 11/12                         Loss D: -27.3246, loss G: 2.9692\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [193/200] Batch 11/12                         Loss D: -28.7519, loss G: 3.3624\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [194/200] Batch 11/12                         Loss D: -31.0983, loss G: 3.5807\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [195/200] Batch 11/12                         Loss D: -31.7496, loss G: 3.9499\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [196/200] Batch 11/12                         Loss D: -33.5851, loss G: 4.1598\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [197/200] Batch 11/12                         Loss D: -35.3079, loss G: 4.2875\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [198/200] Batch 11/12                         Loss D: -36.4604, loss G: 4.5801\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [199/200] Batch 11/12                         Loss D: -38.4397, loss G: 4.7148\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [0/200] Batch 11/12                         Loss D: 1.0594, loss G: 2.9608\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [1/200] Batch 11/12                         Loss D: 2.1929, loss G: 2.8153\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [2/200] Batch 11/12                         Loss D: 4.2838, loss G: 2.5707\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [3/200] Batch 11/12                         Loss D: 7.3044, loss G: 2.1518\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [4/200] Batch 11/12                         Loss D: 10.7074, loss G: 1.7700\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [5/200] Batch 11/12                         Loss D: 14.7468, loss G: 1.3464\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [6/200] Batch 11/12                         Loss D: 19.8078, loss G: 0.8024\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [7/200] Batch 11/12                         Loss D: 26.1955, loss G: 0.1055\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [8/200] Batch 11/12                         Loss D: 34.4050, loss G: -0.8076\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [9/200] Batch 11/12                         Loss D: 43.3525, loss G: -1.8337\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [10/200] Batch 11/12                         Loss D: 54.6688, loss G: -3.1677\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [11/200] Batch 11/12                         Loss D: 64.7071, loss G: -4.2851\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [12/200] Batch 11/12                         Loss D: 72.0962, loss G: -5.2040\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [13/200] Batch 11/12                         Loss D: 79.2066, loss G: -6.0924\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [14/200] Batch 11/12                         Loss D: 80.8419, loss G: -6.4844\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [15/200] Batch 11/12                         Loss D: 81.6619, loss G: -6.7649\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [16/200] Batch 11/12                         Loss D: 87.3859, loss G: -7.2779\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [17/200] Batch 11/12                         Loss D: 90.7198, loss G: -7.6825\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [18/200] Batch 11/12                         Loss D: 95.0264, loss G: -7.9584\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [19/200] Batch 11/12                         Loss D: 98.5660, loss G: -8.0468\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [20/200] Batch 11/12                         Loss D: 104.4039, loss G: -8.2284\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [21/200] Batch 11/12                         Loss D: 108.3436, loss G: -8.3233\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [22/200] Batch 11/12                         Loss D: 111.8463, loss G: -8.3936\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [23/200] Batch 11/12                         Loss D: 116.0191, loss G: -8.4871\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [24/200] Batch 11/12                         Loss D: 120.6937, loss G: -8.5867\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [25/200] Batch 11/12                         Loss D: 123.9582, loss G: -8.6149\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [26/200] Batch 11/12                         Loss D: 128.4934, loss G: -8.6931\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [27/200] Batch 11/12                         Loss D: 129.9146, loss G: -8.6316\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [28/200] Batch 11/12                         Loss D: 131.7906, loss G: -8.5895\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [29/200] Batch 11/12                         Loss D: 134.4240, loss G: -8.5551\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [30/200] Batch 11/12                         Loss D: 136.8194, loss G: -8.4897\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [31/200] Batch 11/12                         Loss D: 138.4823, loss G: -8.3748\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [32/200] Batch 11/12                         Loss D: 136.1572, loss G: -8.1584\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [33/200] Batch 11/12                         Loss D: 137.0849, loss G: -8.0270\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [34/200] Batch 11/12                         Loss D: 134.9167, loss G: -7.7820\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [35/200] Batch 11/12                         Loss D: 133.3930, loss G: -7.5198\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [36/200] Batch 11/12                         Loss D: 132.2796, loss G: -7.2883\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [37/200] Batch 11/12                         Loss D: 129.5107, loss G: -6.9943\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [38/200] Batch 11/12                         Loss D: 126.7265, loss G: -6.7380\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [39/200] Batch 11/12                         Loss D: 121.8878, loss G: -6.3757\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [40/200] Batch 11/12                         Loss D: 119.4948, loss G: -6.1051\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [41/200] Batch 11/12                         Loss D: 115.4603, loss G: -5.7743\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [42/200] Batch 11/12                         Loss D: 110.5575, loss G: -5.4094\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [43/200] Batch 11/12                         Loss D: 106.5881, loss G: -5.0133\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [44/200] Batch 11/12                         Loss D: 101.1443, loss G: -4.6635\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [45/200] Batch 11/12                         Loss D: 96.0217, loss G: -4.2953\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [46/200] Batch 11/12                         Loss D: 89.7429, loss G: -3.9585\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [47/200] Batch 11/12                         Loss D: 85.8614, loss G: -3.5798\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [48/200] Batch 11/12                         Loss D: 78.1185, loss G: -3.2566\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [49/200] Batch 11/12                         Loss D: 72.4443, loss G: -2.9178\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [50/200] Batch 11/12                         Loss D: 66.5817, loss G: -2.5797\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [51/200] Batch 11/12                         Loss D: 59.9196, loss G: -2.2986\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [52/200] Batch 11/12                         Loss D: 54.3511, loss G: -1.9791\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [53/200] Batch 11/12                         Loss D: 48.1054, loss G: -1.6926\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [54/200] Batch 11/12                         Loss D: 42.7651, loss G: -1.5053\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [55/200] Batch 11/12                         Loss D: 37.1633, loss G: -1.2668\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [56/200] Batch 11/12                         Loss D: 31.3411, loss G: -1.0513\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [57/200] Batch 11/12                         Loss D: 26.8414, loss G: -0.8860\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [58/200] Batch 11/12                         Loss D: 22.0634, loss G: -0.7052\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [59/200] Batch 11/12                         Loss D: 17.5870, loss G: -0.5353\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [60/200] Batch 11/12                         Loss D: 12.6570, loss G: -0.4157\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [61/200] Batch 11/12                         Loss D: 8.3875, loss G: -0.2653\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [62/200] Batch 11/12                         Loss D: 4.8914, loss G: -0.2465\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [63/200] Batch 11/12                         Loss D: 1.4429, loss G: -0.1234\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [64/200] Batch 11/12                         Loss D: -2.0559, loss G: -0.1154\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [65/200] Batch 11/12                         Loss D: -5.2880, loss G: -0.0831\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [66/200] Batch 11/12                         Loss D: -8.1930, loss G: -0.0440\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [67/200] Batch 11/12                         Loss D: -11.1949, loss G: -0.0063\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [68/200] Batch 11/12                         Loss D: -13.6401, loss G: -0.0183\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [69/200] Batch 11/12                         Loss D: -15.4217, loss G: -0.0540\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [70/200] Batch 11/12                         Loss D: -18.1398, loss G: -0.0086\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [71/200] Batch 11/12                         Loss D: -19.5578, loss G: -0.0958\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [72/200] Batch 11/12                         Loss D: -21.4188, loss G: -0.1429\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [73/200] Batch 11/12                         Loss D: -23.0687, loss G: -0.1509\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [74/200] Batch 11/12                         Loss D: -24.1427, loss G: -0.2483\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [75/200] Batch 11/12                         Loss D: -25.3041, loss G: -0.2751\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [76/200] Batch 11/12                         Loss D: -26.6456, loss G: -0.3210\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [77/200] Batch 11/12                         Loss D: -27.3951, loss G: -0.4163\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [78/200] Batch 11/12                         Loss D: -27.9475, loss G: -0.4540\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [79/200] Batch 11/12                         Loss D: -28.8968, loss G: -0.5312\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [80/200] Batch 11/12                         Loss D: -29.3295, loss G: -0.6225\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [81/200] Batch 11/12                         Loss D: -29.7289, loss G: -0.7006\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [82/200] Batch 11/12                         Loss D: -29.9556, loss G: -0.7911\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [83/200] Batch 11/12                         Loss D: -30.1507, loss G: -0.8880\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [84/200] Batch 11/12                         Loss D: -30.4735, loss G: -0.9494\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [85/200] Batch 11/12                         Loss D: -30.5320, loss G: -1.0303\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [86/200] Batch 11/12                         Loss D: -30.3467, loss G: -1.1333\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [87/200] Batch 11/12                         Loss D: -29.9927, loss G: -1.2309\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [88/200] Batch 11/12                         Loss D: -29.6561, loss G: -1.3162\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [89/200] Batch 11/12                         Loss D: -29.9335, loss G: -1.3735\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [90/200] Batch 11/12                         Loss D: -30.4171, loss G: -1.3899\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [91/200] Batch 11/12                         Loss D: -31.5329, loss G: -1.3657\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [92/200] Batch 11/12                         Loss D: -32.4899, loss G: -1.3837\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [93/200] Batch 11/12                         Loss D: -33.0131, loss G: -1.4120\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [94/200] Batch 11/12                         Loss D: -34.1818, loss G: -1.3819\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [95/200] Batch 11/12                         Loss D: -34.5902, loss G: -1.3851\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [96/200] Batch 11/12                         Loss D: -35.6495, loss G: -1.3684\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [97/200] Batch 11/12                         Loss D: -36.0197, loss G: -1.3117\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [98/200] Batch 11/12                         Loss D: -37.3715, loss G: -1.3347\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [99/200] Batch 11/12                         Loss D: -38.2581, loss G: -1.3231\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [100/200] Batch 11/12                         Loss D: -39.1159, loss G: -1.3224\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [101/200] Batch 11/12                         Loss D: -39.8275, loss G: -1.2741\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [102/200] Batch 11/12                         Loss D: -41.0373, loss G: -1.2574\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [103/200] Batch 11/12                         Loss D: -42.2916, loss G: -1.2222\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [104/200] Batch 11/12                         Loss D: -42.8139, loss G: -1.2371\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [105/200] Batch 11/12                         Loss D: -42.8631, loss G: -1.1392\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [106/200] Batch 11/12                         Loss D: -44.5255, loss G: -1.1765\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [107/200] Batch 11/12                         Loss D: -45.3344, loss G: -1.1676\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [108/200] Batch 11/12                         Loss D: -46.8905, loss G: -1.1069\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [109/200] Batch 11/12                         Loss D: -47.1298, loss G: -1.1042\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [110/200] Batch 11/12                         Loss D: -48.4984, loss G: -1.0690\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [111/200] Batch 11/12                         Loss D: -49.6641, loss G: -1.0339\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [112/200] Batch 11/12                         Loss D: -49.6365, loss G: -0.9926\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [113/200] Batch 11/12                         Loss D: -51.2756, loss G: -0.9833\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [114/200] Batch 11/12                         Loss D: -51.5546, loss G: -0.9341\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [115/200] Batch 11/12                         Loss D: -53.8399, loss G: -0.8657\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [116/200] Batch 11/12                         Loss D: -54.2390, loss G: -0.8806\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [117/200] Batch 11/12                         Loss D: -55.2927, loss G: -0.9001\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [118/200] Batch 11/12                         Loss D: -56.5941, loss G: -0.8995\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [119/200] Batch 11/12                         Loss D: -57.1489, loss G: -0.8952\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [120/200] Batch 11/12                         Loss D: -58.2410, loss G: -0.9068\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [121/200] Batch 11/12                         Loss D: -59.2001, loss G: -0.9209\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [122/200] Batch 11/12                         Loss D: -60.6700, loss G: -0.9131\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [123/200] Batch 11/12                         Loss D: -60.4240, loss G: -0.8893\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [124/200] Batch 11/12                         Loss D: -62.4280, loss G: -0.9217\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [125/200] Batch 11/12                         Loss D: -63.1606, loss G: -0.9326\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [126/200] Batch 11/12                         Loss D: -64.6979, loss G: -0.9206\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [127/200] Batch 11/12                         Loss D: -65.4282, loss G: -0.9317\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [128/200] Batch 11/12                         Loss D: -66.6368, loss G: -0.9051\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [129/200] Batch 11/12                         Loss D: -67.3393, loss G: -0.9157\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [130/200] Batch 11/12                         Loss D: -68.6530, loss G: -0.8898\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [131/200] Batch 11/12                         Loss D: -69.3693, loss G: -0.9057\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [132/200] Batch 11/12                         Loss D: -70.6655, loss G: -0.9146\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [133/200] Batch 11/12                         Loss D: -71.1681, loss G: -0.8820\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [134/200] Batch 11/12                         Loss D: -73.3003, loss G: -0.9156\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [135/200] Batch 11/12                         Loss D: -73.4278, loss G: -0.8860\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [136/200] Batch 11/12                         Loss D: -76.5066, loss G: -0.9014\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [137/200] Batch 11/12                         Loss D: -75.9887, loss G: -0.8736\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [138/200] Batch 11/12                         Loss D: -78.2062, loss G: -0.8516\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [139/200] Batch 11/12                         Loss D: -79.7081, loss G: -0.8370\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [140/200] Batch 11/12                         Loss D: -79.8843, loss G: -0.8122\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [141/200] Batch 11/12                         Loss D: -81.8059, loss G: -0.8009\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [142/200] Batch 11/12                         Loss D: -83.0157, loss G: -0.7548\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [143/200] Batch 11/12                         Loss D: -83.4593, loss G: -0.7131\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [144/200] Batch 11/12                         Loss D: -84.3498, loss G: -0.6800\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [145/200] Batch 11/12                         Loss D: -86.6942, loss G: -0.6436\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [146/200] Batch 11/12                         Loss D: -87.1138, loss G: -0.6079\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [147/200] Batch 11/12                         Loss D: -88.8910, loss G: -0.5926\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [148/200] Batch 11/12                         Loss D: -90.3193, loss G: -0.5419\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [149/200] Batch 11/12                         Loss D: -91.7569, loss G: -0.5124\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [150/200] Batch 11/12                         Loss D: -92.6436, loss G: -0.4191\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [151/200] Batch 11/12                         Loss D: -93.0782, loss G: -0.3432\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [152/200] Batch 11/12                         Loss D: -94.9615, loss G: -0.3363\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [153/200] Batch 11/12                         Loss D: -95.5866, loss G: -0.2533\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [154/200] Batch 11/12                         Loss D: -96.9063, loss G: -0.2048\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [155/200] Batch 11/12                         Loss D: -98.7619, loss G: -0.1320\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [156/200] Batch 11/12                         Loss D: -99.3207, loss G: -0.0546\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [157/200] Batch 11/12                         Loss D: -100.5189, loss G: 0.0202\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [158/200] Batch 11/12                         Loss D: -100.3908, loss G: 0.1094\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [159/200] Batch 11/12                         Loss D: -101.6445, loss G: 0.2044\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [160/200] Batch 11/12                         Loss D: -103.1380, loss G: 0.2682\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [161/200] Batch 11/12                         Loss D: -104.6206, loss G: 0.3454\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [162/200] Batch 11/12                         Loss D: -104.4241, loss G: 0.4320\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [163/200] Batch 11/12                         Loss D: -105.2347, loss G: 0.5173\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [164/200] Batch 11/12                         Loss D: -105.8446, loss G: 0.6025\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [165/200] Batch 11/12                         Loss D: -107.8642, loss G: 0.7052\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [166/200] Batch 11/12                         Loss D: -107.6844, loss G: 0.7808\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [167/200] Batch 11/12                         Loss D: -108.8277, loss G: 0.8727\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [168/200] Batch 11/12                         Loss D: -109.9943, loss G: 0.9441\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [169/200] Batch 11/12                         Loss D: -109.8458, loss G: 1.0240\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [170/200] Batch 11/12                         Loss D: -111.7405, loss G: 1.1293\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [171/200] Batch 11/12                         Loss D: -111.3930, loss G: 1.2115\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [172/200] Batch 11/12                         Loss D: -112.2152, loss G: 1.2923\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [173/200] Batch 11/12                         Loss D: -113.3268, loss G: 1.3855\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [174/200] Batch 11/12                         Loss D: -113.1967, loss G: 1.4988\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [175/200] Batch 11/12                         Loss D: -114.2026, loss G: 1.5581\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [176/200] Batch 11/12                         Loss D: -115.1326, loss G: 1.6649\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [177/200] Batch 11/12                         Loss D: -116.0035, loss G: 1.7607\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [178/200] Batch 11/12                         Loss D: -117.9281, loss G: 1.9026\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [179/200] Batch 11/12                         Loss D: -117.5994, loss G: 1.9421\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [180/200] Batch 11/12                         Loss D: -118.5853, loss G: 2.0533\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [181/200] Batch 11/12                         Loss D: -119.2327, loss G: 2.1598\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [182/200] Batch 11/12                         Loss D: -119.9205, loss G: 2.2327\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [183/200] Batch 11/12                         Loss D: -118.7403, loss G: 2.3605\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [184/200] Batch 11/12                         Loss D: -119.5179, loss G: 2.4413\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [185/200] Batch 11/12                         Loss D: -119.2180, loss G: 2.5483\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [186/200] Batch 11/12                         Loss D: -121.2369, loss G: 2.6303\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [187/200] Batch 11/12                         Loss D: -122.7864, loss G: 2.7591\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [188/200] Batch 11/12                         Loss D: -122.1969, loss G: 2.8559\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [189/200] Batch 11/12                         Loss D: -124.8452, loss G: 2.9342\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [190/200] Batch 11/12                         Loss D: -123.6076, loss G: 3.0365\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [191/200] Batch 11/12                         Loss D: -124.8709, loss G: 3.1214\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [192/200] Batch 11/12                         Loss D: -125.6245, loss G: 3.2130\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [193/200] Batch 11/12                         Loss D: -124.6886, loss G: 3.3176\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [194/200] Batch 11/12                         Loss D: -124.4078, loss G: 3.4106\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [195/200] Batch 11/12                         Loss D: -124.2741, loss G: 3.5033\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [196/200] Batch 11/12                         Loss D: -122.3463, loss G: 3.5718\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [197/200] Batch 11/12                         Loss D: -120.1142, loss G: 3.6386\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [198/200] Batch 11/12                         Loss D: -119.3451, loss G: 3.7362\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [199/200] Batch 11/12                         Loss D: -116.8247, loss G: 3.7902\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [0/200] Batch 11/12                         Loss D: -0.4564, loss G: 33.9770\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [1/200] Batch 11/12                         Loss D: -0.7715, loss G: 33.2423\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [2/200] Batch 11/12                         Loss D: -1.3554, loss G: 31.9812\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [3/200] Batch 11/12                         Loss D: -2.3792, loss G: 29.9094\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [4/200] Batch 11/12                         Loss D: -3.4791, loss G: 28.6296\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [5/200] Batch 11/12                         Loss D: -4.8865, loss G: 27.2235\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [6/200] Batch 11/12                         Loss D: -6.7338, loss G: 25.3716\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [7/200] Batch 11/12                         Loss D: -9.0943, loss G: 22.7399\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [8/200] Batch 11/12                         Loss D: -11.7589, loss G: 19.4043\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [9/200] Batch 11/12                         Loss D: -15.0511, loss G: 15.0754\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [10/200] Batch 11/12                         Loss D: -19.2365, loss G: 11.0200\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [11/200] Batch 11/12                         Loss D: -21.8979, loss G: 9.0462\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [12/200] Batch 11/12                         Loss D: -24.6634, loss G: 6.6654\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [13/200] Batch 11/12                         Loss D: -26.6515, loss G: 4.4772\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [14/200] Batch 11/12                         Loss D: -28.3112, loss G: 1.5912\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [15/200] Batch 11/12                         Loss D: -29.4337, loss G: 1.6436\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [16/200] Batch 11/12                         Loss D: -29.9003, loss G: 1.4733\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [17/200] Batch 11/12                         Loss D: -30.5921, loss G: 1.5552\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [18/200] Batch 11/12                         Loss D: -31.6031, loss G: 1.4659\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [19/200] Batch 11/12                         Loss D: -32.4685, loss G: 1.5947\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [20/200] Batch 11/12                         Loss D: -33.2322, loss G: 1.8095\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [21/200] Batch 11/12                         Loss D: -33.5639, loss G: 1.6740\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [22/200] Batch 11/12                         Loss D: -34.0592, loss G: 1.9531\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [23/200] Batch 11/12                         Loss D: -34.7305, loss G: 2.0949\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [24/200] Batch 11/12                         Loss D: -35.9690, loss G: 1.8043\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [25/200] Batch 11/12                         Loss D: -36.0079, loss G: 2.1842\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [26/200] Batch 11/12                         Loss D: -37.3006, loss G: 1.7637\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [27/200] Batch 11/12                         Loss D: -38.0065, loss G: 1.8624\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [28/200] Batch 11/12                         Loss D: -38.9010, loss G: 1.8423\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [29/200] Batch 11/12                         Loss D: -39.4434, loss G: 2.0000\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [30/200] Batch 11/12                         Loss D: -40.0673, loss G: 2.0292\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [31/200] Batch 11/12                         Loss D: -40.9264, loss G: 1.9060\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [32/200] Batch 11/12                         Loss D: -41.5494, loss G: 2.0292\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [33/200] Batch 11/12                         Loss D: -42.7400, loss G: 2.1888\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [34/200] Batch 11/12                         Loss D: -42.6819, loss G: 2.2761\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [35/200] Batch 11/12                         Loss D: -43.1214, loss G: 2.4960\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [36/200] Batch 11/12                         Loss D: -44.8496, loss G: 2.2273\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [37/200] Batch 11/12                         Loss D: -45.5841, loss G: 2.3858\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [38/200] Batch 11/12                         Loss D: -45.9724, loss G: 2.2661\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [39/200] Batch 11/12                         Loss D: -46.0936, loss G: 2.5699\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [40/200] Batch 11/12                         Loss D: -47.0020, loss G: 2.5860\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [41/200] Batch 11/12                         Loss D: -47.2831, loss G: 2.8118\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [42/200] Batch 11/12                         Loss D: -49.1943, loss G: 2.5389\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [43/200] Batch 11/12                         Loss D: -49.7563, loss G: 2.4501\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [44/200] Batch 11/12                         Loss D: -50.9099, loss G: 2.8050\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [45/200] Batch 11/12                         Loss D: -50.8630, loss G: 2.6684\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [46/200] Batch 11/12                         Loss D: -51.5871, loss G: 2.7694\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [47/200] Batch 11/12                         Loss D: -52.5067, loss G: 2.6354\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [48/200] Batch 11/12                         Loss D: -53.3894, loss G: 2.6499\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [49/200] Batch 11/12                         Loss D: -54.1930, loss G: 2.6894\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [50/200] Batch 11/12                         Loss D: -54.7789, loss G: 2.7798\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [51/200] Batch 11/12                         Loss D: -56.2201, loss G: 3.0224\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [52/200] Batch 11/12                         Loss D: -55.8687, loss G: 3.1459\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [53/200] Batch 11/12                         Loss D: -57.2100, loss G: 2.8717\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [54/200] Batch 11/12                         Loss D: -57.7510, loss G: 2.9648\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [55/200] Batch 11/12                         Loss D: -58.0844, loss G: 3.3935\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [56/200] Batch 11/12                         Loss D: -60.0592, loss G: 3.1550\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [57/200] Batch 11/12                         Loss D: -60.3964, loss G: 3.0477\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [58/200] Batch 11/12                         Loss D: -61.7543, loss G: 3.2451\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [59/200] Batch 11/12                         Loss D: -62.1276, loss G: 3.1058\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [60/200] Batch 11/12                         Loss D: -61.7564, loss G: 3.6879\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [61/200] Batch 11/12                         Loss D: -63.2470, loss G: 3.3145\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [62/200] Batch 11/12                         Loss D: -65.4837, loss G: 3.6801\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [63/200] Batch 11/12                         Loss D: -65.0310, loss G: 3.4557\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [64/200] Batch 11/12                         Loss D: -65.3856, loss G: 3.7443\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [65/200] Batch 11/12                         Loss D: -67.1666, loss G: 3.3988\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [66/200] Batch 11/12                         Loss D: -66.9754, loss G: 3.7989\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [67/200] Batch 11/12                         Loss D: -69.1150, loss G: 3.6306\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [68/200] Batch 11/12                         Loss D: -69.0173, loss G: 3.7640\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [69/200] Batch 11/12                         Loss D: -70.5946, loss G: 3.6800\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [70/200] Batch 11/12                         Loss D: -71.7447, loss G: 3.8046\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [71/200] Batch 11/12                         Loss D: -72.1000, loss G: 3.7637\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [72/200] Batch 11/12                         Loss D: -72.7087, loss G: 3.7618\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [73/200] Batch 11/12                         Loss D: -74.8815, loss G: 4.0974\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [74/200] Batch 11/12                         Loss D: -75.1652, loss G: 3.8800\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [75/200] Batch 11/12                         Loss D: -74.0523, loss G: 4.5109\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [76/200] Batch 11/12                         Loss D: -76.6528, loss G: 3.9783\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [77/200] Batch 11/12                         Loss D: -77.5764, loss G: 4.1313\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [78/200] Batch 11/12                         Loss D: -77.9944, loss G: 4.1130\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [79/200] Batch 11/12                         Loss D: -79.5942, loss G: 4.2295\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [80/200] Batch 11/12                         Loss D: -80.0865, loss G: 4.1292\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [81/200] Batch 11/12                         Loss D: -81.0936, loss G: 4.2385\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [82/200] Batch 11/12                         Loss D: -81.4435, loss G: 4.3748\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [83/200] Batch 11/12                         Loss D: -83.4136, loss G: 4.3497\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [84/200] Batch 11/12                         Loss D: -83.3782, loss G: 4.4245\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [85/200] Batch 11/12                         Loss D: -85.0510, loss G: 4.3975\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [86/200] Batch 11/12                         Loss D: -87.3796, loss G: 5.0415\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [87/200] Batch 11/12                         Loss D: -86.7797, loss G: 4.6325\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [88/200] Batch 11/12                         Loss D: -87.7480, loss G: 4.6588\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [89/200] Batch 11/12                         Loss D: -89.5352, loss G: 4.8678\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [90/200] Batch 11/12                         Loss D: -90.3662, loss G: 4.9563\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [91/200] Batch 11/12                         Loss D: -91.1102, loss G: 4.8331\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [92/200] Batch 11/12                         Loss D: -91.7860, loss G: 4.7910\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [93/200] Batch 11/12                         Loss D: -92.4624, loss G: 4.8834\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [94/200] Batch 11/12                         Loss D: -94.0182, loss G: 4.9580\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [95/200] Batch 11/12                         Loss D: -94.5657, loss G: 5.0008\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [96/200] Batch 11/12                         Loss D: -94.7383, loss G: 5.2633\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [97/200] Batch 11/12                         Loss D: -95.7308, loss G: 5.2119\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [98/200] Batch 11/12                         Loss D: -97.0975, loss G: 5.1928\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [99/200] Batch 11/12                         Loss D: -99.2302, loss G: 5.3706\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [100/200] Batch 11/12                         Loss D: -99.1740, loss G: 5.2889\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [101/200] Batch 11/12                         Loss D: -101.7735, loss G: 5.5906\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [102/200] Batch 11/12                         Loss D: -100.7879, loss G: 5.4807\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [103/200] Batch 11/12                         Loss D: -102.1890, loss G: 5.5302\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [104/200] Batch 11/12                         Loss D: -103.0048, loss G: 5.5941\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [105/200] Batch 11/12                         Loss D: -104.1469, loss G: 5.7086\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [106/200] Batch 11/12                         Loss D: -104.2373, loss G: 6.0200\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [107/200] Batch 11/12                         Loss D: -106.8258, loss G: 5.6866\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [108/200] Batch 11/12                         Loss D: -107.1490, loss G: 5.8757\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [109/200] Batch 11/12                         Loss D: -108.9165, loss G: 5.8024\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [110/200] Batch 11/12                         Loss D: -109.8302, loss G: 5.9001\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [111/200] Batch 11/12                         Loss D: -112.2386, loss G: 6.1484\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [112/200] Batch 11/12                         Loss D: -112.1885, loss G: 6.0313\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [113/200] Batch 11/12                         Loss D: -112.7156, loss G: 6.1768\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [114/200] Batch 11/12                         Loss D: -115.2831, loss G: 6.1995\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [115/200] Batch 11/12                         Loss D: -115.3703, loss G: 6.1781\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [116/200] Batch 11/12                         Loss D: -116.4323, loss G: 6.3128\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [117/200] Batch 11/12                         Loss D: -118.1447, loss G: 6.2553\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [118/200] Batch 11/12                         Loss D: -118.4781, loss G: 6.4232\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [119/200] Batch 11/12                         Loss D: -118.2695, loss G: 6.7620\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [120/200] Batch 11/12                         Loss D: -121.9942, loss G: 6.5745\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [121/200] Batch 11/12                         Loss D: -121.7235, loss G: 6.6753\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [122/200] Batch 11/12                         Loss D: -123.7264, loss G: 6.6069\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [123/200] Batch 11/12                         Loss D: -125.2708, loss G: 6.7777\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [124/200] Batch 11/12                         Loss D: -125.0257, loss G: 6.9388\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [125/200] Batch 11/12                         Loss D: -126.2059, loss G: 6.9520\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [126/200] Batch 11/12                         Loss D: -127.2742, loss G: 7.0415\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [127/200] Batch 11/12                         Loss D: -129.4960, loss G: 6.8996\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [128/200] Batch 11/12                         Loss D: -129.1633, loss G: 7.2866\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [129/200] Batch 11/12                         Loss D: -132.7663, loss G: 7.2783\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [130/200] Batch 11/12                         Loss D: -133.9567, loss G: 7.3980\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [131/200] Batch 11/12                         Loss D: -134.5077, loss G: 7.2592\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [132/200] Batch 11/12                         Loss D: -136.0283, loss G: 7.3548\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [133/200] Batch 11/12                         Loss D: -135.9351, loss G: 7.4007\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [134/200] Batch 11/12                         Loss D: -138.2499, loss G: 7.5894\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [135/200] Batch 11/12                         Loss D: -140.7614, loss G: 7.8515\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [136/200] Batch 11/12                         Loss D: -138.6280, loss G: 7.9367\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [137/200] Batch 11/12                         Loss D: -140.8455, loss G: 7.6685\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [138/200] Batch 11/12                         Loss D: -141.4894, loss G: 7.9266\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [139/200] Batch 11/12                         Loss D: -144.6422, loss G: 8.0298\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [140/200] Batch 11/12                         Loss D: -145.0151, loss G: 7.9434\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [141/200] Batch 11/12                         Loss D: -146.3002, loss G: 7.9956\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [142/200] Batch 11/12                         Loss D: -147.9299, loss G: 8.0605\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [143/200] Batch 11/12                         Loss D: -147.5152, loss G: 8.2400\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [144/200] Batch 11/12                         Loss D: -151.6257, loss G: 8.3297\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [145/200] Batch 11/12                         Loss D: -150.4166, loss G: 8.3681\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [146/200] Batch 11/12                         Loss D: -152.6912, loss G: 8.3106\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [147/200] Batch 11/12                         Loss D: -154.2362, loss G: 8.3174\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [148/200] Batch 11/12                         Loss D: -154.4662, loss G: 8.5053\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [149/200] Batch 11/12                         Loss D: -156.5013, loss G: 8.5443\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [150/200] Batch 11/12                         Loss D: -157.8828, loss G: 8.6219\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [151/200] Batch 11/12                         Loss D: -160.9782, loss G: 8.8890\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [152/200] Batch 11/12                         Loss D: -160.9259, loss G: 8.6923\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [153/200] Batch 11/12                         Loss D: -163.7595, loss G: 9.0774\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [154/200] Batch 11/12                         Loss D: -161.9276, loss G: 9.0124\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [155/200] Batch 11/12                         Loss D: -162.0410, loss G: 9.2597\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [156/200] Batch 11/12                         Loss D: -164.7685, loss G: 9.1412\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [157/200] Batch 11/12                         Loss D: -168.0286, loss G: 9.1718\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [158/200] Batch 11/12                         Loss D: -169.0036, loss G: 9.2908\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [159/200] Batch 11/12                         Loss D: -168.2192, loss G: 9.4967\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [160/200] Batch 11/12                         Loss D: -172.1624, loss G: 9.5311\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [161/200] Batch 11/12                         Loss D: -170.2902, loss G: 9.7206\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [162/200] Batch 11/12                         Loss D: -173.0883, loss G: 9.5977\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [163/200] Batch 11/12                         Loss D: -174.6629, loss G: 9.6875\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [164/200] Batch 11/12                         Loss D: -175.7254, loss G: 9.7528\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [165/200] Batch 11/12                         Loss D: -178.5222, loss G: 9.8552\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [166/200] Batch 11/12                         Loss D: -179.7169, loss G: 9.8431\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [167/200] Batch 11/12                         Loss D: -181.0088, loss G: 9.9386\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [168/200] Batch 11/12                         Loss D: -182.3611, loss G: 10.0024\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [169/200] Batch 11/12                         Loss D: -184.1681, loss G: 10.0499\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [170/200] Batch 11/12                         Loss D: -188.5624, loss G: 10.6813\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [171/200] Batch 11/12                         Loss D: -184.7516, loss G: 10.4879\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [172/200] Batch 11/12                         Loss D: -189.3577, loss G: 10.4108\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [173/200] Batch 11/12                         Loss D: -189.9333, loss G: 10.3786\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [174/200] Batch 11/12                         Loss D: -189.2138, loss G: 10.7284\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [175/200] Batch 11/12                         Loss D: -194.5746, loss G: 10.7388\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [176/200] Batch 11/12                         Loss D: -192.6724, loss G: 10.8321\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [177/200] Batch 11/12                         Loss D: -195.0921, loss G: 10.7644\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [178/200] Batch 11/12                         Loss D: -195.9608, loss G: 10.8923\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [179/200] Batch 11/12                         Loss D: -197.7301, loss G: 11.0207\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [180/200] Batch 11/12                         Loss D: -201.1210, loss G: 11.0258\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [181/200] Batch 11/12                         Loss D: -200.8486, loss G: 11.1913\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [182/200] Batch 11/12                         Loss D: -203.7801, loss G: 11.1570\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [183/200] Batch 11/12                         Loss D: -206.7063, loss G: 11.3787\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [184/200] Batch 11/12                         Loss D: -208.4971, loss G: 11.5910\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [185/200] Batch 11/12                         Loss D: -209.6477, loss G: 11.6867\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [186/200] Batch 11/12                         Loss D: -207.1232, loss G: 11.6617\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [187/200] Batch 11/12                         Loss D: -211.5444, loss G: 11.5396\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [188/200] Batch 11/12                         Loss D: -212.2271, loss G: 11.6838\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [189/200] Batch 11/12                         Loss D: -213.6378, loss G: 11.7364\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [190/200] Batch 11/12                         Loss D: -215.6224, loss G: 11.8151\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [191/200] Batch 11/12                         Loss D: -217.7662, loss G: 12.0090\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [192/200] Batch 11/12                         Loss D: -219.9932, loss G: 12.0915\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [193/200] Batch 11/12                         Loss D: -218.0336, loss G: 12.3290\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [194/200] Batch 11/12                         Loss D: -223.1161, loss G: 12.2701\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [195/200] Batch 11/12                         Loss D: -221.6057, loss G: 12.3307\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [196/200] Batch 11/12                         Loss D: -223.5442, loss G: 12.4327\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [197/200] Batch 11/12                         Loss D: -226.1107, loss G: 12.4629\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [198/200] Batch 11/12                         Loss D: -226.9028, loss G: 12.5698\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [199/200] Batch 11/12                         Loss D: -229.1685, loss G: 12.6747\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [0/200] Batch 11/12                         Loss D: 0.3076, loss G: 17.2488\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [1/200] Batch 11/12                         Loss D: 1.1988, loss G: 16.8882\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [2/200] Batch 11/12                         Loss D: 2.5252, loss G: 16.2702\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [3/200] Batch 11/12                         Loss D: 4.7150, loss G: 15.2061\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [4/200] Batch 11/12                         Loss D: 7.1551, loss G: 14.1869\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [5/200] Batch 11/12                         Loss D: 10.0433, loss G: 13.0721\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [6/200] Batch 11/12                         Loss D: 13.7774, loss G: 11.5724\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [7/200] Batch 11/12                         Loss D: 17.7617, loss G: 9.8139\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [8/200] Batch 11/12                         Loss D: 22.5947, loss G: 7.5800\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [9/200] Batch 11/12                         Loss D: 27.4795, loss G: 5.1039\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [10/200] Batch 11/12                         Loss D: 28.5908, loss G: 3.6215\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [11/200] Batch 11/12                         Loss D: 28.1044, loss G: 2.6974\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [12/200] Batch 11/12                         Loss D: 27.6255, loss G: 1.6730\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [13/200] Batch 11/12                         Loss D: 28.0471, loss G: 0.2965\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [14/200] Batch 11/12                         Loss D: 27.7759, loss G: -1.1408\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [15/200] Batch 11/12                         Loss D: 26.9815, loss G: -1.1647\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [16/200] Batch 11/12                         Loss D: 25.2171, loss G: -0.8794\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [17/200] Batch 11/12                         Loss D: 24.5934, loss G: -1.0762\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [18/200] Batch 11/12                         Loss D: 23.7058, loss G: -1.0827\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [19/200] Batch 11/12                         Loss D: 22.6595, loss G: -1.0274\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [20/200] Batch 11/12                         Loss D: 21.9450, loss G: -0.8809\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [21/200] Batch 11/12                         Loss D: 20.6032, loss G: -0.7930\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [22/200] Batch 11/12                         Loss D: 20.0541, loss G: -0.8893\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [23/200] Batch 11/12                         Loss D: 19.1113, loss G: -0.8406\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [24/200] Batch 11/12                         Loss D: 18.5018, loss G: -0.6543\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [25/200] Batch 11/12                         Loss D: 17.4361, loss G: -0.7485\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [26/200] Batch 11/12                         Loss D: 16.5914, loss G: -0.7135\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [27/200] Batch 11/12                         Loss D: 15.7988, loss G: -0.6673\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [28/200] Batch 11/12                         Loss D: 15.1481, loss G: -0.4273\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [29/200] Batch 11/12                         Loss D: 13.9272, loss G: -0.5032\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [30/200] Batch 11/12                         Loss D: 13.3370, loss G: -0.5208\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [31/200] Batch 11/12                         Loss D: 12.2835, loss G: -0.3612\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [32/200] Batch 11/12                         Loss D: 11.6526, loss G: -0.4836\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [33/200] Batch 11/12                         Loss D: 10.7562, loss G: -0.3591\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [34/200] Batch 11/12                         Loss D: 10.0317, loss G: -0.4249\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [35/200] Batch 11/12                         Loss D: 9.2143, loss G: -0.3327\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [36/200] Batch 11/12                         Loss D: 8.4995, loss G: -0.3143\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [37/200] Batch 11/12                         Loss D: 7.7294, loss G: -0.2123\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [38/200] Batch 11/12                         Loss D: 6.9475, loss G: -0.0935\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [39/200] Batch 11/12                         Loss D: 6.0668, loss G: -0.2085\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [40/200] Batch 11/12                         Loss D: 5.2626, loss G: -0.1626\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [41/200] Batch 11/12                         Loss D: 4.5363, loss G: 0.1585\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [42/200] Batch 11/12                         Loss D: 3.6190, loss G: -0.0958\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [43/200] Batch 11/12                         Loss D: 2.8637, loss G: 0.1084\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [44/200] Batch 11/12                         Loss D: 1.9985, loss G: 0.0240\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [45/200] Batch 11/12                         Loss D: 1.1820, loss G: 0.1312\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [46/200] Batch 11/12                         Loss D: 0.3456, loss G: 0.1605\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [47/200] Batch 11/12                         Loss D: -0.5077, loss G: 0.3995\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [48/200] Batch 11/12                         Loss D: -1.3344, loss G: 0.2943\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [49/200] Batch 11/12                         Loss D: -2.1540, loss G: 0.2960\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [50/200] Batch 11/12                         Loss D: -3.0326, loss G: 0.2886\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [51/200] Batch 11/12                         Loss D: -3.8908, loss G: 0.3166\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [52/200] Batch 11/12                         Loss D: -4.7787, loss G: 0.4425\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [53/200] Batch 11/12                         Loss D: -5.4570, loss G: 0.6975\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [54/200] Batch 11/12                         Loss D: -6.4926, loss G: 0.5636\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [55/200] Batch 11/12                         Loss D: -7.4324, loss G: 0.7182\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [56/200] Batch 11/12                         Loss D: -8.1625, loss G: 0.5897\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [57/200] Batch 11/12                         Loss D: -8.9344, loss G: 0.8022\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [58/200] Batch 11/12                         Loss D: -9.9420, loss G: 0.6935\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [59/200] Batch 11/12                         Loss D: -10.8397, loss G: 0.6899\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [60/200] Batch 11/12                         Loss D: -11.9493, loss G: 0.9420\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [61/200] Batch 11/12                         Loss D: -12.5574, loss G: 0.9476\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [62/200] Batch 11/12                         Loss D: -13.5960, loss G: 0.7946\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [63/200] Batch 11/12                         Loss D: -14.3006, loss G: 0.9964\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [64/200] Batch 11/12                         Loss D: -15.3233, loss G: 0.9797\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [65/200] Batch 11/12                         Loss D: -16.2931, loss G: 0.9783\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [66/200] Batch 11/12                         Loss D: -17.1479, loss G: 1.0194\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [67/200] Batch 11/12                         Loss D: -18.2037, loss G: 1.0727\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [68/200] Batch 11/12                         Loss D: -19.0864, loss G: 1.0545\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [69/200] Batch 11/12                         Loss D: -19.7620, loss G: 1.1737\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [70/200] Batch 11/12                         Loss D: -20.9811, loss G: 1.1546\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [71/200] Batch 11/12                         Loss D: -21.7077, loss G: 1.2224\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [72/200] Batch 11/12                         Loss D: -22.8815, loss G: 1.2746\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [73/200] Batch 11/12                         Loss D: -24.1231, loss G: 1.3918\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [74/200] Batch 11/12                         Loss D: -24.6014, loss G: 1.3741\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [75/200] Batch 11/12                         Loss D: -25.5818, loss G: 1.3987\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [76/200] Batch 11/12                         Loss D: -26.7074, loss G: 1.4136\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [77/200] Batch 11/12                         Loss D: -27.7665, loss G: 1.4247\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [78/200] Batch 11/12                         Loss D: -29.0769, loss G: 1.6583\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [79/200] Batch 11/12                         Loss D: -29.9147, loss G: 1.5598\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [80/200] Batch 11/12                         Loss D: -30.6928, loss G: 1.5784\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [81/200] Batch 11/12                         Loss D: -31.3819, loss G: 1.6630\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [82/200] Batch 11/12                         Loss D: -32.7529, loss G: 1.6798\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [83/200] Batch 11/12                         Loss D: -33.3125, loss G: 1.8176\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [84/200] Batch 11/12                         Loss D: -34.7610, loss G: 1.8146\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [85/200] Batch 11/12                         Loss D: -36.1187, loss G: 1.8964\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [86/200] Batch 11/12                         Loss D: -36.9837, loss G: 1.9068\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [87/200] Batch 11/12                         Loss D: -37.5844, loss G: 1.8899\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [88/200] Batch 11/12                         Loss D: -38.7524, loss G: 1.9404\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [89/200] Batch 11/12                         Loss D: -40.0130, loss G: 1.9436\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [90/200] Batch 11/12                         Loss D: -40.5512, loss G: 2.0292\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [91/200] Batch 11/12                         Loss D: -42.2275, loss G: 2.1116\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [92/200] Batch 11/12                         Loss D: -43.2676, loss G: 2.0754\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [93/200] Batch 11/12                         Loss D: -44.3523, loss G: 2.1713\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [94/200] Batch 11/12                         Loss D: -45.4400, loss G: 2.2186\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [95/200] Batch 11/12                         Loss D: -46.0817, loss G: 2.1802\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [96/200] Batch 11/12                         Loss D: -47.2349, loss G: 2.2410\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [97/200] Batch 11/12                         Loss D: -48.8494, loss G: 2.4250\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [98/200] Batch 11/12                         Loss D: -49.4868, loss G: 2.3391\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [99/200] Batch 11/12                         Loss D: -50.9780, loss G: 2.4464\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [100/200] Batch 11/12                         Loss D: -51.7372, loss G: 2.5073\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [101/200] Batch 11/12                         Loss D: -52.8243, loss G: 2.4805\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [102/200] Batch 11/12                         Loss D: -53.6590, loss G: 2.5115\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [103/200] Batch 11/12                         Loss D: -55.0420, loss G: 2.5778\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [104/200] Batch 11/12                         Loss D: -56.4138, loss G: 2.7226\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [105/200] Batch 11/12                         Loss D: -56.2697, loss G: 2.8596\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [106/200] Batch 11/12                         Loss D: -57.9734, loss G: 2.7745\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [107/200] Batch 11/12                         Loss D: -59.5661, loss G: 2.8014\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [108/200] Batch 11/12                         Loss D: -59.9108, loss G: 2.8670\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [109/200] Batch 11/12                         Loss D: -61.3800, loss G: 2.9150\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [110/200] Batch 11/12                         Loss D: -62.6764, loss G: 2.9348\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [111/200] Batch 11/12                         Loss D: -63.1754, loss G: 3.0597\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [112/200] Batch 11/12                         Loss D: -65.0952, loss G: 3.0886\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [113/200] Batch 11/12                         Loss D: -66.5572, loss G: 3.1052\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [114/200] Batch 11/12                         Loss D: -67.4749, loss G: 3.1928\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [115/200] Batch 11/12                         Loss D: -68.3163, loss G: 3.2256\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [116/200] Batch 11/12                         Loss D: -69.1212, loss G: 3.3830\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [117/200] Batch 11/12                         Loss D: -70.8710, loss G: 3.3628\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [118/200] Batch 11/12                         Loss D: -70.7942, loss G: 3.3925\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [119/200] Batch 11/12                         Loss D: -68.6635, loss G: 3.4546\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [120/200] Batch 11/12                         Loss D: -65.9443, loss G: 3.3366\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [121/200] Batch 11/12                         Loss D: -62.3984, loss G: 3.2493\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [122/200] Batch 11/12                         Loss D: -59.2542, loss G: 3.1265\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [123/200] Batch 11/12                         Loss D: -54.3533, loss G: 3.1757\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [124/200] Batch 11/12                         Loss D: -46.1045, loss G: 3.2106\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [125/200] Batch 11/12                         Loss D: -34.1123, loss G: 3.3214\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [126/200] Batch 11/12                         Loss D: -17.0450, loss G: 2.9371\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [127/200] Batch 11/12                         Loss D: 7.2837, loss G: 2.6407\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [128/200] Batch 11/12                         Loss D: 7.1444, loss G: 2.7949\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [129/200] Batch 11/12                         Loss D: 6.5516, loss G: 2.8865\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [130/200] Batch 11/12                         Loss D: 7.1634, loss G: 2.9482\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [131/200] Batch 11/12                         Loss D: 6.8803, loss G: 3.0424\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [132/200] Batch 11/12                         Loss D: 7.5746, loss G: 3.1247\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [133/200] Batch 11/12                         Loss D: 7.2595, loss G: 3.1492\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [134/200] Batch 11/12                         Loss D: 7.6273, loss G: 3.2108\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [135/200] Batch 11/12                         Loss D: 8.0209, loss G: 3.3243\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [136/200] Batch 11/12                         Loss D: 8.2577, loss G: 3.3787\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [137/200] Batch 11/12                         Loss D: 7.7130, loss G: 3.3914\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [138/200] Batch 11/12                         Loss D: 8.0561, loss G: 3.4242\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [139/200] Batch 11/12                         Loss D: 8.3489, loss G: 3.5431\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [140/200] Batch 11/12                         Loss D: 7.4812, loss G: 3.6807\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [141/200] Batch 11/12                         Loss D: 7.9545, loss G: 3.5768\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [142/200] Batch 11/12                         Loss D: 8.8059, loss G: 3.7248\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [143/200] Batch 11/12                         Loss D: 8.7089, loss G: 3.6688\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [144/200] Batch 11/12                         Loss D: 8.9497, loss G: 3.7295\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [145/200] Batch 11/12                         Loss D: 8.8395, loss G: 3.7956\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [146/200] Batch 11/12                         Loss D: 8.9851, loss G: 3.9313\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [147/200] Batch 11/12                         Loss D: 8.4377, loss G: 3.9318\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [148/200] Batch 11/12                         Loss D: 8.7494, loss G: 4.0261\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [149/200] Batch 11/12                         Loss D: 9.3069, loss G: 4.0426\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [150/200] Batch 11/12                         Loss D: 8.8487, loss G: 4.0533\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [151/200] Batch 11/12                         Loss D: 9.3676, loss G: 4.0907\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [152/200] Batch 11/12                         Loss D: 9.4877, loss G: 4.1305\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [153/200] Batch 11/12                         Loss D: 9.5798, loss G: 4.1842\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [154/200] Batch 11/12                         Loss D: 9.5421, loss G: 4.2551\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [155/200] Batch 11/12                         Loss D: 9.2982, loss G: 4.3327\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [156/200] Batch 11/12                         Loss D: 8.9582, loss G: 4.3502\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [157/200] Batch 11/12                         Loss D: 9.6393, loss G: 4.3141\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [158/200] Batch 11/12                         Loss D: 8.9144, loss G: 4.4067\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [159/200] Batch 11/12                         Loss D: 10.4656, loss G: 4.3960\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [160/200] Batch 11/12                         Loss D: 9.9137, loss G: 4.4580\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [161/200] Batch 11/12                         Loss D: 10.2537, loss G: 4.4768\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [162/200] Batch 11/12                         Loss D: 10.3804, loss G: 4.5099\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [163/200] Batch 11/12                         Loss D: 9.7641, loss G: 4.5546\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [164/200] Batch 11/12                         Loss D: 10.3393, loss G: 4.6303\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [165/200] Batch 11/12                         Loss D: 10.6810, loss G: 4.7162\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [166/200] Batch 11/12                         Loss D: 10.0083, loss G: 4.6836\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [167/200] Batch 11/12                         Loss D: 10.0860, loss G: 4.7699\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [168/200] Batch 11/12                         Loss D: 9.9352, loss G: 4.8176\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [169/200] Batch 11/12                         Loss D: 10.2186, loss G: 4.8678\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [170/200] Batch 11/12                         Loss D: 10.7079, loss G: 4.9937\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [171/200] Batch 11/12                         Loss D: 10.8508, loss G: 4.8957\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [172/200] Batch 11/12                         Loss D: 10.2837, loss G: 4.9544\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [173/200] Batch 11/12                         Loss D: 10.5301, loss G: 4.9594\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [174/200] Batch 11/12                         Loss D: 10.3781, loss G: 4.9946\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [175/200] Batch 11/12                         Loss D: 10.7943, loss G: 5.0069\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [176/200] Batch 11/12                         Loss D: 10.6930, loss G: 5.0434\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [177/200] Batch 11/12                         Loss D: 11.0882, loss G: 5.1336\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [178/200] Batch 11/12                         Loss D: 10.5545, loss G: 5.2004\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [179/200] Batch 11/12                         Loss D: 10.9154, loss G: 5.2507\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [180/200] Batch 11/12                         Loss D: 11.2269, loss G: 5.1987\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [181/200] Batch 11/12                         Loss D: 11.0395, loss G: 5.3104\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [182/200] Batch 11/12                         Loss D: 11.1986, loss G: 5.4009\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [183/200] Batch 11/12                         Loss D: 11.7949, loss G: 5.3552\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [184/200] Batch 11/12                         Loss D: 10.5774, loss G: 5.3964\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [185/200] Batch 11/12                         Loss D: 11.2878, loss G: 5.6049\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [186/200] Batch 11/12                         Loss D: 11.7279, loss G: 5.5217\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [187/200] Batch 11/12                         Loss D: 11.5462, loss G: 5.4708\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [188/200] Batch 11/12                         Loss D: 10.9057, loss G: 5.5663\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [189/200] Batch 11/12                         Loss D: 11.7557, loss G: 5.5176\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [190/200] Batch 11/12                         Loss D: 12.1836, loss G: 5.5683\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [191/200] Batch 11/12                         Loss D: 11.5263, loss G: 5.6067\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [192/200] Batch 11/12                         Loss D: 11.4593, loss G: 5.6457\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [193/200] Batch 11/12                         Loss D: 11.9115, loss G: 5.7994\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [194/200] Batch 11/12                         Loss D: 11.7923, loss G: 5.7045\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [195/200] Batch 11/12                         Loss D: 12.1506, loss G: 5.8355\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [196/200] Batch 11/12                         Loss D: 11.8133, loss G: 5.8064\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [197/200] Batch 11/12                         Loss D: 12.1647, loss G: 5.8372\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [198/200] Batch 11/12                         Loss D: 11.8299, loss G: 5.8474\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [199/200] Batch 11/12                         Loss D: 12.4161, loss G: 5.9768\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [0/200] Batch 11/12                         Loss D: 0.2323, loss G: 3.4274\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [1/200] Batch 11/12                         Loss D: 0.6783, loss G: 3.3775\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [2/200] Batch 11/12                         Loss D: 2.1590, loss G: 3.2564\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [3/200] Batch 11/12                         Loss D: 4.4910, loss G: 3.0146\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [4/200] Batch 11/12                         Loss D: 7.0940, loss G: 2.7411\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [5/200] Batch 11/12                         Loss D: 10.5758, loss G: 2.4941\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [6/200] Batch 11/12                         Loss D: 16.7252, loss G: 1.8659\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [7/200] Batch 11/12                         Loss D: 24.7276, loss G: 1.0093\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [8/200] Batch 11/12                         Loss D: 33.2804, loss G: 0.0651\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [9/200] Batch 11/12                         Loss D: 43.6028, loss G: -1.0906\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [10/200] Batch 11/12                         Loss D: 51.0434, loss G: -1.8222\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [11/200] Batch 11/12                         Loss D: 57.2768, loss G: -2.4195\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [12/200] Batch 11/12                         Loss D: 62.7610, loss G: -3.0031\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [13/200] Batch 11/12                         Loss D: 66.1050, loss G: -3.2746\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [14/200] Batch 11/12                         Loss D: 63.4127, loss G: -3.1561\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [15/200] Batch 11/12                         Loss D: 60.9590, loss G: -3.0184\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [16/200] Batch 11/12                         Loss D: 57.1292, loss G: -2.9022\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [17/200] Batch 11/12                         Loss D: 53.6131, loss G: -2.8088\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [18/200] Batch 11/12                         Loss D: 51.8677, loss G: -2.6949\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [19/200] Batch 11/12                         Loss D: 50.5919, loss G: -2.5820\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [20/200] Batch 11/12                         Loss D: 48.5232, loss G: -2.4707\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [21/200] Batch 11/12                         Loss D: 46.7304, loss G: -2.3606\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [22/200] Batch 11/12                         Loss D: 45.3130, loss G: -2.2465\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [23/200] Batch 11/12                         Loss D: 42.9921, loss G: -2.1379\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [24/200] Batch 11/12                         Loss D: 40.5186, loss G: -2.0371\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [25/200] Batch 11/12                         Loss D: 39.0339, loss G: -1.9350\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [26/200] Batch 11/12                         Loss D: 36.6147, loss G: -1.8569\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [27/200] Batch 11/12                         Loss D: 34.7616, loss G: -1.7666\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [28/200] Batch 11/12                         Loss D: 32.6406, loss G: -1.6807\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [29/200] Batch 11/12                         Loss D: 31.8076, loss G: -1.5657\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [30/200] Batch 11/12                         Loss D: 29.3949, loss G: -1.4927\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [31/200] Batch 11/12                         Loss D: 27.9790, loss G: -1.4063\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [32/200] Batch 11/12                         Loss D: 26.3132, loss G: -1.3174\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [33/200] Batch 11/12                         Loss D: 25.1295, loss G: -1.2115\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [34/200] Batch 11/12                         Loss D: 23.3618, loss G: -1.1449\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [35/200] Batch 11/12                         Loss D: 21.8009, loss G: -1.0451\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [36/200] Batch 11/12                         Loss D: 20.4646, loss G: -0.9650\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [37/200] Batch 11/12                         Loss D: 18.7820, loss G: -0.8759\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [38/200] Batch 11/12                         Loss D: 17.2291, loss G: -0.7961\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [39/200] Batch 11/12                         Loss D: 15.3228, loss G: -0.7154\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [40/200] Batch 11/12                         Loss D: 13.6896, loss G: -0.6300\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [41/200] Batch 11/12                         Loss D: 12.0709, loss G: -0.5535\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [42/200] Batch 11/12                         Loss D: 10.4613, loss G: -0.4715\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [43/200] Batch 11/12                         Loss D: 8.6828, loss G: -0.3776\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [44/200] Batch 11/12                         Loss D: 7.0260, loss G: -0.3154\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [45/200] Batch 11/12                         Loss D: 5.3038, loss G: -0.2382\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [46/200] Batch 11/12                         Loss D: 3.7839, loss G: -0.1467\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [47/200] Batch 11/12                         Loss D: 1.7305, loss G: -0.0894\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [48/200] Batch 11/12                         Loss D: 0.2197, loss G: -0.0122\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [49/200] Batch 11/12                         Loss D: -1.7483, loss G: 0.0483\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [50/200] Batch 11/12                         Loss D: -3.0382, loss G: 0.1736\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [51/200] Batch 11/12                         Loss D: -4.6846, loss G: 0.2310\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [52/200] Batch 11/12                         Loss D: -6.0718, loss G: 0.2867\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [53/200] Batch 11/12                         Loss D: -7.3692, loss G: 0.3787\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [54/200] Batch 11/12                         Loss D: -8.8675, loss G: 0.4318\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [55/200] Batch 11/12                         Loss D: -10.2432, loss G: 0.5027\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [56/200] Batch 11/12                         Loss D: -11.3845, loss G: 0.5944\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [57/200] Batch 11/12                         Loss D: -12.8265, loss G: 0.6783\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [58/200] Batch 11/12                         Loss D: -14.2972, loss G: 0.7609\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [59/200] Batch 11/12                         Loss D: -15.6438, loss G: 0.8244\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [60/200] Batch 11/12                         Loss D: -16.8649, loss G: 0.8906\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [61/200] Batch 11/12                         Loss D: -17.7627, loss G: 0.9665\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [62/200] Batch 11/12                         Loss D: -19.1305, loss G: 1.0430\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [63/200] Batch 11/12                         Loss D: -19.8655, loss G: 1.1043\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [64/200] Batch 11/12                         Loss D: -20.4839, loss G: 1.1651\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [65/200] Batch 11/12                         Loss D: -21.0141, loss G: 1.2477\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [66/200] Batch 11/12                         Loss D: -21.0977, loss G: 1.2938\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [67/200] Batch 11/12                         Loss D: -21.4424, loss G: 1.3662\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [68/200] Batch 11/12                         Loss D: -21.1087, loss G: 1.3929\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [69/200] Batch 11/12                         Loss D: -20.5677, loss G: 1.4446\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [70/200] Batch 11/12                         Loss D: -19.2890, loss G: 1.4593\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [71/200] Batch 11/12                         Loss D: -17.4849, loss G: 1.4753\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [72/200] Batch 11/12                         Loss D: -15.1562, loss G: 1.4784\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [73/200] Batch 11/12                         Loss D: -11.8438, loss G: 1.4712\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [74/200] Batch 11/12                         Loss D: -7.9994, loss G: 1.4325\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [75/200] Batch 11/12                         Loss D: -3.6176, loss G: 1.3649\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [76/200] Batch 11/12                         Loss D: -3.9375, loss G: 1.3952\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [77/200] Batch 11/12                         Loss D: -4.3660, loss G: 1.4208\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [78/200] Batch 11/12                         Loss D: -4.7323, loss G: 1.4420\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [79/200] Batch 11/12                         Loss D: -5.1594, loss G: 1.4830\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [80/200] Batch 11/12                         Loss D: -5.5896, loss G: 1.4980\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [81/200] Batch 11/12                         Loss D: -5.9243, loss G: 1.5264\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [82/200] Batch 11/12                         Loss D: -6.3031, loss G: 1.5439\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [83/200] Batch 11/12                         Loss D: -6.6659, loss G: 1.5724\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [84/200] Batch 11/12                         Loss D: -7.0992, loss G: 1.5902\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [85/200] Batch 11/12                         Loss D: -7.3553, loss G: 1.6365\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [86/200] Batch 11/12                         Loss D: -7.8154, loss G: 1.6368\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [87/200] Batch 11/12                         Loss D: -8.3428, loss G: 1.6619\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [88/200] Batch 11/12                         Loss D: -8.5522, loss G: 1.7241\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [89/200] Batch 11/12                         Loss D: -9.1900, loss G: 1.7197\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [90/200] Batch 11/12                         Loss D: -9.5870, loss G: 1.7417\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [91/200] Batch 11/12                         Loss D: -9.9582, loss G: 1.7669\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [92/200] Batch 11/12                         Loss D: -10.4615, loss G: 1.8083\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [93/200] Batch 11/12                         Loss D: -10.7502, loss G: 1.8223\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [94/200] Batch 11/12                         Loss D: -11.2505, loss G: 1.8498\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [95/200] Batch 11/12                         Loss D: -11.6509, loss G: 1.8742\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [96/200] Batch 11/12                         Loss D: -12.3514, loss G: 1.9307\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [97/200] Batch 11/12                         Loss D: -12.4864, loss G: 1.9421\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [98/200] Batch 11/12                         Loss D: -13.0332, loss G: 1.9565\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [99/200] Batch 11/12                         Loss D: -13.5841, loss G: 1.9808\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [100/200] Batch 11/12                         Loss D: -13.9691, loss G: 2.0117\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [101/200] Batch 11/12                         Loss D: -14.5411, loss G: 2.0327\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [102/200] Batch 11/12                         Loss D: -14.8890, loss G: 2.0699\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [103/200] Batch 11/12                         Loss D: -15.4722, loss G: 2.0920\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [104/200] Batch 11/12                         Loss D: -15.7211, loss G: 2.1427\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [105/200] Batch 11/12                         Loss D: -16.2609, loss G: 2.1585\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [106/200] Batch 11/12                         Loss D: -17.0319, loss G: 2.1901\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [107/200] Batch 11/12                         Loss D: -17.2597, loss G: 2.2224\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [108/200] Batch 11/12                         Loss D: -17.7555, loss G: 2.2538\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [109/200] Batch 11/12                         Loss D: -18.1488, loss G: 2.2939\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [110/200] Batch 11/12                         Loss D: -18.7129, loss G: 2.3144\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [111/200] Batch 11/12                         Loss D: -19.3673, loss G: 2.3456\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [112/200] Batch 11/12                         Loss D: -20.0327, loss G: 2.3772\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [113/200] Batch 11/12                         Loss D: -20.4197, loss G: 2.4028\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [114/200] Batch 11/12                         Loss D: -21.1251, loss G: 2.4356\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [115/200] Batch 11/12                         Loss D: -21.7722, loss G: 2.4808\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [116/200] Batch 11/12                         Loss D: -21.8405, loss G: 2.5124\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [117/200] Batch 11/12                         Loss D: -22.7856, loss G: 2.5356\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [118/200] Batch 11/12                         Loss D: -23.1829, loss G: 2.5673\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [119/200] Batch 11/12                         Loss D: -23.6422, loss G: 2.6041\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [120/200] Batch 11/12                         Loss D: -24.0589, loss G: 2.6417\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [121/200] Batch 11/12                         Loss D: -25.0815, loss G: 2.6747\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [122/200] Batch 11/12                         Loss D: -25.4304, loss G: 2.7057\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [123/200] Batch 11/12                         Loss D: -25.8693, loss G: 2.7442\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [124/200] Batch 11/12                         Loss D: -26.8178, loss G: 2.7760\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [125/200] Batch 11/12                         Loss D: -26.8195, loss G: 2.8172\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [126/200] Batch 11/12                         Loss D: -27.5091, loss G: 2.8513\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [127/200] Batch 11/12                         Loss D: -28.0156, loss G: 2.8884\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [128/200] Batch 11/12                         Loss D: -29.2811, loss G: 2.9220\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [129/200] Batch 11/12                         Loss D: -29.5038, loss G: 2.9627\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [130/200] Batch 11/12                         Loss D: -29.9504, loss G: 3.0009\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [131/200] Batch 11/12                         Loss D: -30.7458, loss G: 3.0377\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [132/200] Batch 11/12                         Loss D: -31.6628, loss G: 3.0747\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [133/200] Batch 11/12                         Loss D: -31.7912, loss G: 3.1145\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [134/200] Batch 11/12                         Loss D: -32.2027, loss G: 3.1528\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [135/200] Batch 11/12                         Loss D: -32.4828, loss G: 3.1903\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [136/200] Batch 11/12                         Loss D: -32.4978, loss G: 3.2250\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [137/200] Batch 11/12                         Loss D: -32.3432, loss G: 3.2583\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [138/200] Batch 11/12                         Loss D: -32.4106, loss G: 3.3071\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [139/200] Batch 11/12                         Loss D: -32.8562, loss G: 3.3527\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [140/200] Batch 11/12                         Loss D: -32.9520, loss G: 3.3942\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [141/200] Batch 11/12                         Loss D: -33.1622, loss G: 3.4328\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [142/200] Batch 11/12                         Loss D: -33.3486, loss G: 3.4700\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [143/200] Batch 11/12                         Loss D: -32.8430, loss G: 3.4985\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [144/200] Batch 11/12                         Loss D: -31.8624, loss G: 3.5176\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [145/200] Batch 11/12                         Loss D: -30.5457, loss G: 3.5319\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [146/200] Batch 11/12                         Loss D: -28.5846, loss G: 3.5361\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [147/200] Batch 11/12                         Loss D: -26.8467, loss G: 3.5419\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [148/200] Batch 11/12                         Loss D: -23.8565, loss G: 3.5253\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [149/200] Batch 11/12                         Loss D: -20.7398, loss G: 3.5046\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [150/200] Batch 11/12                         Loss D: -17.1620, loss G: 3.4694\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [151/200] Batch 11/12                         Loss D: -13.4062, loss G: 3.4207\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [152/200] Batch 11/12                         Loss D: -8.7227, loss G: 3.3571\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [153/200] Batch 11/12                         Loss D: -5.7368, loss G: 3.3197\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [154/200] Batch 11/12                         Loss D: -5.1638, loss G: 3.2960\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [155/200] Batch 11/12                         Loss D: -4.7834, loss G: 3.2676\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [156/200] Batch 11/12                         Loss D: -4.2194, loss G: 3.2347\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [157/200] Batch 11/12                         Loss D: -3.3468, loss G: 3.2304\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [158/200] Batch 11/12                         Loss D: -3.4524, loss G: 3.2339\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [159/200] Batch 11/12                         Loss D: -3.3338, loss G: 3.2369\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [160/200] Batch 11/12                         Loss D: -3.1944, loss G: 3.2343\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [161/200] Batch 11/12                         Loss D: -3.1161, loss G: 3.2352\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [162/200] Batch 11/12                         Loss D: -2.4665, loss G: 3.2314\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [163/200] Batch 11/12                         Loss D: -2.3389, loss G: 3.2331\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [164/200] Batch 11/12                         Loss D: -2.2972, loss G: 3.2338\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [165/200] Batch 11/12                         Loss D: -2.4744, loss G: 3.2328\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [166/200] Batch 11/12                         Loss D: -2.4699, loss G: 3.2328\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [167/200] Batch 11/12                         Loss D: -2.4302, loss G: 3.2337\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [168/200] Batch 11/12                         Loss D: -2.4092, loss G: 3.2350\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [169/200] Batch 11/12                         Loss D: -2.4716, loss G: 3.2374\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [170/200] Batch 11/12                         Loss D: -2.5560, loss G: 3.2390\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [171/200] Batch 11/12                         Loss D: -2.5511, loss G: 3.2350\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [172/200] Batch 11/12                         Loss D: -2.5168, loss G: 3.2378\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [173/200] Batch 11/12                         Loss D: -2.7477, loss G: 3.2385\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [174/200] Batch 11/12                         Loss D: -2.8614, loss G: 3.2409\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [175/200] Batch 11/12                         Loss D: -2.7062, loss G: 3.2412\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [176/200] Batch 11/12                         Loss D: -2.6053, loss G: 3.2427\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [177/200] Batch 11/12                         Loss D: -2.7704, loss G: 3.2411\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [178/200] Batch 11/12                         Loss D: -2.7974, loss G: 3.2426\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [179/200] Batch 11/12                         Loss D: -2.8296, loss G: 3.2429\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [180/200] Batch 11/12                         Loss D: -2.7405, loss G: 3.2450\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [181/200] Batch 11/12                         Loss D: -2.8712, loss G: 3.2495\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [182/200] Batch 11/12                         Loss D: -2.9814, loss G: 3.2440\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [183/200] Batch 11/12                         Loss D: -2.9230, loss G: 3.2457\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [184/200] Batch 11/12                         Loss D: -2.9481, loss G: 3.2487\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [185/200] Batch 11/12                         Loss D: -2.8871, loss G: 3.2491\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [186/200] Batch 11/12                         Loss D: -3.1417, loss G: 3.2481\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [187/200] Batch 11/12                         Loss D: -3.2017, loss G: 3.2495\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [188/200] Batch 11/12                         Loss D: -3.0703, loss G: 3.2494\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [189/200] Batch 11/12                         Loss D: -3.3622, loss G: 3.2527\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [190/200] Batch 11/12                         Loss D: -3.0345, loss G: 3.2578\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [191/200] Batch 11/12                         Loss D: -3.1236, loss G: 3.2535\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [192/200] Batch 11/12                         Loss D: -3.3744, loss G: 3.2535\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [193/200] Batch 11/12                         Loss D: -3.3216, loss G: 3.2515\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [194/200] Batch 11/12                         Loss D: -3.4168, loss G: 3.2562\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [195/200] Batch 11/12                         Loss D: -3.5242, loss G: 3.2580\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [196/200] Batch 11/12                         Loss D: -3.5165, loss G: 3.2566\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [197/200] Batch 11/12                         Loss D: -3.3061, loss G: 3.2603\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [198/200] Batch 11/12                         Loss D: -3.3357, loss G: 3.2588\n",
      "[lr_G=0.0002, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [199/200] Batch 11/12                         Loss D: -3.5119, loss G: 3.2566\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [0/200] Batch 11/12                         Loss D: 7.9097, loss G: 34.0929\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [1/200] Batch 11/12                         Loss D: 7.4187, loss G: 33.8482\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [2/200] Batch 11/12                         Loss D: 6.8239, loss G: 33.5084\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [3/200] Batch 11/12                         Loss D: 6.0449, loss G: 33.0571\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [4/200] Batch 11/12                         Loss D: 5.2416, loss G: 32.5127\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [5/200] Batch 11/12                         Loss D: 4.1015, loss G: 31.7182\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [6/200] Batch 11/12                         Loss D: 2.7869, loss G: 30.7094\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [7/200] Batch 11/12                         Loss D: 1.4502, loss G: 29.8873\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [8/200] Batch 11/12                         Loss D: 0.1132, loss G: 29.4201\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [9/200] Batch 11/12                         Loss D: -1.7975, loss G: 28.9613\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [10/200] Batch 11/12                         Loss D: -4.5331, loss G: 28.4620\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [11/200] Batch 11/12                         Loss D: -8.0119, loss G: 27.8712\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [12/200] Batch 11/12                         Loss D: -12.1259, loss G: 27.1247\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [13/200] Batch 11/12                         Loss D: -17.0885, loss G: 26.2508\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [14/200] Batch 11/12                         Loss D: -23.7108, loss G: 25.3096\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [15/200] Batch 11/12                         Loss D: -31.4078, loss G: 24.3641\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [16/200] Batch 11/12                         Loss D: -41.9256, loss G: 23.1890\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [17/200] Batch 11/12                         Loss D: -53.7493, loss G: 22.0590\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [18/200] Batch 11/12                         Loss D: -67.4069, loss G: 20.8093\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [19/200] Batch 11/12                         Loss D: -82.8195, loss G: 19.5934\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [20/200] Batch 11/12                         Loss D: -100.5806, loss G: 18.3915\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [21/200] Batch 11/12                         Loss D: -115.7363, loss G: 18.0541\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [22/200] Batch 11/12                         Loss D: -132.1633, loss G: 17.6922\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [23/200] Batch 11/12                         Loss D: -149.3974, loss G: 17.5440\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [24/200] Batch 11/12                         Loss D: -167.3093, loss G: 17.7217\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [25/200] Batch 11/12                         Loss D: -180.1287, loss G: 17.8533\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [26/200] Batch 11/12                         Loss D: -198.0752, loss G: 17.9066\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [27/200] Batch 11/12                         Loss D: -215.3725, loss G: 18.0542\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [28/200] Batch 11/12                         Loss D: -231.0499, loss G: 18.5012\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [29/200] Batch 11/12                         Loss D: -251.4445, loss G: 18.8989\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [30/200] Batch 11/12                         Loss D: -269.5637, loss G: 19.3864\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [31/200] Batch 11/12                         Loss D: -290.4698, loss G: 20.0157\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [32/200] Batch 11/12                         Loss D: -308.9827, loss G: 20.4742\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [33/200] Batch 11/12                         Loss D: -328.1400, loss G: 21.2100\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [34/200] Batch 11/12                         Loss D: -352.7068, loss G: 21.7348\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [35/200] Batch 11/12                         Loss D: -376.2591, loss G: 22.3805\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [36/200] Batch 11/12                         Loss D: -394.0197, loss G: 23.1315\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [37/200] Batch 11/12                         Loss D: -404.7198, loss G: 24.0531\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [38/200] Batch 11/12                         Loss D: -416.9379, loss G: 24.8286\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [39/200] Batch 11/12                         Loss D: -431.8211, loss G: 25.6442\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [40/200] Batch 11/12                         Loss D: -453.7119, loss G: 26.4371\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [41/200] Batch 11/12                         Loss D: -458.9668, loss G: 27.1355\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [42/200] Batch 11/12                         Loss D: -469.8351, loss G: 27.9283\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [43/200] Batch 11/12                         Loss D: -491.6692, loss G: 28.6973\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [44/200] Batch 11/12                         Loss D: -496.2197, loss G: 29.5047\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [45/200] Batch 11/12                         Loss D: -515.3771, loss G: 30.2171\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [46/200] Batch 11/12                         Loss D: -525.8885, loss G: 31.0401\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [47/200] Batch 11/12                         Loss D: -537.1803, loss G: 31.8196\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [48/200] Batch 11/12                         Loss D: -557.4691, loss G: 32.6358\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [49/200] Batch 11/12                         Loss D: -564.8393, loss G: 33.4376\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [50/200] Batch 11/12                         Loss D: -577.7356, loss G: 34.2919\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [51/200] Batch 11/12                         Loss D: -590.6566, loss G: 35.1063\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [52/200] Batch 11/12                         Loss D: -599.4886, loss G: 35.9298\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [53/200] Batch 11/12                         Loss D: -595.2203, loss G: 36.6400\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [54/200] Batch 11/12                         Loss D: -604.8772, loss G: 37.3832\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [55/200] Batch 11/12                         Loss D: -600.8034, loss G: 38.0857\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [56/200] Batch 11/12                         Loss D: -602.1224, loss G: 38.7799\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [57/200] Batch 11/12                         Loss D: -597.4213, loss G: 39.3436\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [58/200] Batch 11/12                         Loss D: -584.4982, loss G: 39.8536\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [59/200] Batch 11/12                         Loss D: -566.1115, loss G: 40.1683\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [60/200] Batch 11/12                         Loss D: -556.1916, loss G: 40.6042\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [61/200] Batch 11/12                         Loss D: -543.9409, loss G: 40.9850\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [62/200] Batch 11/12                         Loss D: -521.6365, loss G: 41.1709\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [63/200] Batch 11/12                         Loss D: -498.2748, loss G: 41.2959\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [64/200] Batch 11/12                         Loss D: -468.1399, loss G: 41.3014\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [65/200] Batch 11/12                         Loss D: -445.5076, loss G: 41.3853\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [66/200] Batch 11/12                         Loss D: -411.7114, loss G: 41.2009\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [67/200] Batch 11/12                         Loss D: -366.7355, loss G: 40.7291\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [68/200] Batch 11/12                         Loss D: -321.9424, loss G: 40.2024\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [69/200] Batch 11/12                         Loss D: -266.7070, loss G: 39.3073\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [70/200] Batch 11/12                         Loss D: -203.2612, loss G: 38.1501\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [71/200] Batch 11/12                         Loss D: -134.8634, loss G: 36.8104\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [72/200] Batch 11/12                         Loss D: -52.2281, loss G: 35.0759\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [73/200] Batch 11/12                         Loss D: 6.6853, loss G: 34.1482\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [74/200] Batch 11/12                         Loss D: 3.4842, loss G: 34.3441\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [75/200] Batch 11/12                         Loss D: -2.4591, loss G: 34.2561\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [76/200] Batch 11/12                         Loss D: -2.3884, loss G: 34.1591\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [77/200] Batch 11/12                         Loss D: -1.5355, loss G: 34.0665\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [78/200] Batch 11/12                         Loss D: -1.9494, loss G: 33.9694\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [79/200] Batch 11/12                         Loss D: -2.9138, loss G: 33.8919\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [80/200] Batch 11/12                         Loss D: -4.4265, loss G: 33.8040\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [81/200] Batch 11/12                         Loss D: -3.6918, loss G: 33.5792\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [82/200] Batch 11/12                         Loss D: -3.2990, loss G: 32.3465\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [83/200] Batch 11/12                         Loss D: 36.5833, loss G: 30.0723\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [84/200] Batch 11/12                         Loss D: 51.3351, loss G: 28.9507\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [85/200] Batch 11/12                         Loss D: 58.9013, loss G: 28.1111\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [86/200] Batch 11/12                         Loss D: 62.2061, loss G: 27.2027\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [87/200] Batch 11/12                         Loss D: 62.0819, loss G: 26.5315\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [88/200] Batch 11/12                         Loss D: 59.1796, loss G: 26.0863\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [89/200] Batch 11/12                         Loss D: 51.9465, loss G: 25.8802\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [90/200] Batch 11/12                         Loss D: 40.7527, loss G: 26.0008\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [91/200] Batch 11/12                         Loss D: 26.5224, loss G: 26.6830\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [92/200] Batch 11/12                         Loss D: 1.5204, loss G: 27.7134\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [93/200] Batch 11/12                         Loss D: -27.1009, loss G: 28.9865\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [94/200] Batch 11/12                         Loss D: -57.4018, loss G: 30.4074\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [95/200] Batch 11/12                         Loss D: -92.1948, loss G: 31.7990\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [96/200] Batch 11/12                         Loss D: -121.7511, loss G: 33.1988\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [97/200] Batch 11/12                         Loss D: -147.5167, loss G: 34.3356\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [98/200] Batch 11/12                         Loss D: -174.7862, loss G: 35.2328\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [99/200] Batch 11/12                         Loss D: -199.9061, loss G: 35.8995\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [100/200] Batch 11/12                         Loss D: -221.9196, loss G: 36.4158\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [101/200] Batch 11/12                         Loss D: -238.8955, loss G: 36.8168\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [102/200] Batch 11/12                         Loss D: -256.9800, loss G: 37.0843\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [103/200] Batch 11/12                         Loss D: -279.1525, loss G: 37.3232\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [104/200] Batch 11/12                         Loss D: -272.1006, loss G: 37.4600\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [105/200] Batch 11/12                         Loss D: -263.9294, loss G: 37.5111\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [106/200] Batch 11/12                         Loss D: -249.8888, loss G: 37.3919\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [107/200] Batch 11/12                         Loss D: -235.2937, loss G: 37.1957\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [108/200] Batch 11/12                         Loss D: -218.7385, loss G: 36.9098\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [109/200] Batch 11/12                         Loss D: -195.1515, loss G: 36.4784\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [110/200] Batch 11/12                         Loss D: -173.6312, loss G: 36.0286\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [111/200] Batch 11/12                         Loss D: -158.7954, loss G: 35.7624\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [112/200] Batch 11/12                         Loss D: -153.1177, loss G: 35.8214\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [113/200] Batch 11/12                         Loss D: -146.1627, loss G: 35.8321\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [114/200] Batch 11/12                         Loss D: -139.7795, loss G: 35.7899\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [115/200] Batch 11/12                         Loss D: -131.3257, loss G: 35.6778\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [116/200] Batch 11/12                         Loss D: -124.0450, loss G: 35.6134\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [117/200] Batch 11/12                         Loss D: -117.3984, loss G: 35.5872\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [118/200] Batch 11/12                         Loss D: -106.9491, loss G: 35.5134\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [119/200] Batch 11/12                         Loss D: -99.1420, loss G: 35.4369\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [120/200] Batch 11/12                         Loss D: -86.0052, loss G: 35.1231\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [121/200] Batch 11/12                         Loss D: -68.4875, loss G: 34.6930\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [122/200] Batch 11/12                         Loss D: -61.1167, loss G: 34.6141\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [123/200] Batch 11/12                         Loss D: -59.1585, loss G: 34.6655\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [124/200] Batch 11/12                         Loss D: -56.2890, loss G: 34.6976\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [125/200] Batch 11/12                         Loss D: -53.7441, loss G: 34.7274\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [126/200] Batch 11/12                         Loss D: -50.7389, loss G: 34.7429\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [127/200] Batch 11/12                         Loss D: -48.0667, loss G: 34.7509\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [128/200] Batch 11/12                         Loss D: -45.7131, loss G: 34.7549\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [129/200] Batch 11/12                         Loss D: -43.4703, loss G: 34.7607\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [130/200] Batch 11/12                         Loss D: -40.8247, loss G: 34.7556\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [131/200] Batch 11/12                         Loss D: -39.0748, loss G: 34.7495\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [132/200] Batch 11/12                         Loss D: -36.8091, loss G: 34.7273\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [133/200] Batch 11/12                         Loss D: -34.9968, loss G: 34.7179\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [134/200] Batch 11/12                         Loss D: -32.3406, loss G: 34.6797\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [135/200] Batch 11/12                         Loss D: -30.4304, loss G: 34.6615\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [136/200] Batch 11/12                         Loss D: -28.9417, loss G: 34.6352\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [137/200] Batch 11/12                         Loss D: -27.6097, loss G: 34.6080\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [138/200] Batch 11/12                         Loss D: -25.9169, loss G: 34.5775\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [139/200] Batch 11/12                         Loss D: -24.3668, loss G: 34.5443\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [140/200] Batch 11/12                         Loss D: -22.3163, loss G: 34.4925\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [141/200] Batch 11/12                         Loss D: -20.7469, loss G: 34.4500\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [142/200] Batch 11/12                         Loss D: -19.0786, loss G: 34.3996\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [143/200] Batch 11/12                         Loss D: -17.4949, loss G: 34.3482\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [144/200] Batch 11/12                         Loss D: -15.0915, loss G: 34.2985\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [145/200] Batch 11/12                         Loss D: -11.9141, loss G: 34.2468\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [146/200] Batch 11/12                         Loss D: -9.0849, loss G: 34.1963\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [147/200] Batch 11/12                         Loss D: -6.0552, loss G: 34.1399\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [148/200] Batch 11/12                         Loss D: -3.7368, loss G: 34.0544\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [149/200] Batch 11/12                         Loss D: -4.2155, loss G: 33.8214\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [150/200] Batch 11/12                         Loss D: -4.6869, loss G: 33.6314\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [151/200] Batch 11/12                         Loss D: -0.7458, loss G: 33.4768\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [152/200] Batch 11/12                         Loss D: 0.9247, loss G: 33.2988\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [153/200] Batch 11/12                         Loss D: 0.4878, loss G: 33.1129\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [154/200] Batch 11/12                         Loss D: 0.6159, loss G: 33.1336\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [155/200] Batch 11/12                         Loss D: 0.3760, loss G: 33.1835\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [156/200] Batch 11/12                         Loss D: 0.0825, loss G: 33.2004\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [157/200] Batch 11/12                         Loss D: 0.2909, loss G: 33.2004\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [158/200] Batch 11/12                         Loss D: 0.2892, loss G: 33.2390\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [159/200] Batch 11/12                         Loss D: -0.1199, loss G: 33.2277\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [160/200] Batch 11/12                         Loss D: 0.2184, loss G: 33.2500\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [161/200] Batch 11/12                         Loss D: 0.2187, loss G: 33.2679\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [162/200] Batch 11/12                         Loss D: 0.2548, loss G: 33.2750\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [163/200] Batch 11/12                         Loss D: 0.2602, loss G: 33.3076\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [164/200] Batch 11/12                         Loss D: 0.4547, loss G: 33.3256\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [165/200] Batch 11/12                         Loss D: 0.7339, loss G: 33.3326\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [166/200] Batch 11/12                         Loss D: 0.3920, loss G: 33.3450\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [167/200] Batch 11/12                         Loss D: 0.7523, loss G: 33.3505\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [168/200] Batch 11/12                         Loss D: 0.5679, loss G: 33.3878\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [169/200] Batch 11/12                         Loss D: 1.0125, loss G: 33.4015\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [170/200] Batch 11/12                         Loss D: 1.9449, loss G: 33.4053\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [171/200] Batch 11/12                         Loss D: 1.5073, loss G: 33.4267\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [172/200] Batch 11/12                         Loss D: 0.9049, loss G: 33.4227\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [173/200] Batch 11/12                         Loss D: 1.6239, loss G: 33.4377\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [174/200] Batch 11/12                         Loss D: 2.0484, loss G: 33.4619\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [175/200] Batch 11/12                         Loss D: 2.7019, loss G: 33.4736\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [176/200] Batch 11/12                         Loss D: 3.9897, loss G: 33.4804\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [177/200] Batch 11/12                         Loss D: 6.8525, loss G: 33.5160\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [178/200] Batch 11/12                         Loss D: 5.3141, loss G: 33.5151\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [179/200] Batch 11/12                         Loss D: 5.8508, loss G: 33.5315\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [180/200] Batch 11/12                         Loss D: 2.6985, loss G: 33.5319\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [181/200] Batch 11/12                         Loss D: 2.4830, loss G: 33.5670\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [182/200] Batch 11/12                         Loss D: 3.0877, loss G: 33.5542\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [183/200] Batch 11/12                         Loss D: 3.1931, loss G: 33.5658\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [184/200] Batch 11/12                         Loss D: 4.4082, loss G: 33.5818\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [185/200] Batch 11/12                         Loss D: 3.3101, loss G: 33.5897\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [186/200] Batch 11/12                         Loss D: 4.8905, loss G: 33.6087\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [187/200] Batch 11/12                         Loss D: 4.7678, loss G: 33.6124\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [188/200] Batch 11/12                         Loss D: 4.0763, loss G: 33.6248\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [189/200] Batch 11/12                         Loss D: 6.7683, loss G: 33.6489\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [190/200] Batch 11/12                         Loss D: 3.9935, loss G: 33.6473\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [191/200] Batch 11/12                         Loss D: 5.5782, loss G: 33.6691\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [192/200] Batch 11/12                         Loss D: 4.1438, loss G: 33.6745\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [193/200] Batch 11/12                         Loss D: 5.0381, loss G: 33.6825\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [194/200] Batch 11/12                         Loss D: 6.7493, loss G: 33.6959\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [195/200] Batch 11/12                         Loss D: 6.2389, loss G: 33.7082\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [196/200] Batch 11/12                         Loss D: 5.2435, loss G: 33.7155\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [197/200] Batch 11/12                         Loss D: 6.2892, loss G: 33.7171\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [198/200] Batch 11/12                         Loss D: 8.0608, loss G: 33.7420\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [199/200] Batch 11/12                         Loss D: 5.7644, loss G: 33.7478\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [0/200] Batch 11/12                         Loss D: 8.7870, loss G: 16.9871\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [1/200] Batch 11/12                         Loss D: 9.0286, loss G: 16.8795\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [2/200] Batch 11/12                         Loss D: 9.4351, loss G: 16.7398\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [3/200] Batch 11/12                         Loss D: 10.1588, loss G: 16.5043\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [4/200] Batch 11/12                         Loss D: 11.0260, loss G: 16.1343\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [5/200] Batch 11/12                         Loss D: 11.6056, loss G: 15.7404\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [6/200] Batch 11/12                         Loss D: 11.7920, loss G: 15.3205\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [7/200] Batch 11/12                         Loss D: 11.5809, loss G: 14.8415\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [8/200] Batch 11/12                         Loss D: 10.8126, loss G: 14.3258\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [9/200] Batch 11/12                         Loss D: 9.2569, loss G: 14.0403\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [10/200] Batch 11/12                         Loss D: 6.9538, loss G: 13.7785\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [11/200] Batch 11/12                         Loss D: 3.0323, loss G: 13.5688\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [12/200] Batch 11/12                         Loss D: -1.3546, loss G: 13.3523\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [13/200] Batch 11/12                         Loss D: -6.4436, loss G: 13.1420\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [14/200] Batch 11/12                         Loss D: -12.6205, loss G: 12.9028\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [15/200] Batch 11/12                         Loss D: -19.8791, loss G: 12.7354\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [16/200] Batch 11/12                         Loss D: -28.5937, loss G: 12.5961\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [17/200] Batch 11/12                         Loss D: -39.1735, loss G: 12.4796\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [18/200] Batch 11/12                         Loss D: -50.8161, loss G: 12.4849\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [19/200] Batch 11/12                         Loss D: -64.7594, loss G: 12.5489\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [20/200] Batch 11/12                         Loss D: -80.7015, loss G: 12.7093\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [21/200] Batch 11/12                         Loss D: -97.4059, loss G: 13.0358\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [22/200] Batch 11/12                         Loss D: -115.2687, loss G: 13.4952\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [23/200] Batch 11/12                         Loss D: -135.0826, loss G: 14.0250\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [24/200] Batch 11/12                         Loss D: -152.0900, loss G: 14.7246\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [25/200] Batch 11/12                         Loss D: -167.6488, loss G: 15.4547\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [26/200] Batch 11/12                         Loss D: -180.8762, loss G: 16.1718\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [27/200] Batch 11/12                         Loss D: -194.5887, loss G: 16.8683\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [28/200] Batch 11/12                         Loss D: -201.0695, loss G: 17.4459\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [29/200] Batch 11/12                         Loss D: -208.9934, loss G: 17.9556\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [30/200] Batch 11/12                         Loss D: -212.2215, loss G: 18.2512\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [31/200] Batch 11/12                         Loss D: -214.1708, loss G: 18.4544\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [32/200] Batch 11/12                         Loss D: -212.5123, loss G: 18.5480\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [33/200] Batch 11/12                         Loss D: -204.0049, loss G: 18.5149\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [34/200] Batch 11/12                         Loss D: -192.1742, loss G: 18.3812\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [35/200] Batch 11/12                         Loss D: -176.6280, loss G: 17.5612\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [36/200] Batch 11/12                         Loss D: -175.1664, loss G: 17.3758\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [37/200] Batch 11/12                         Loss D: -180.3780, loss G: 17.6956\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [38/200] Batch 11/12                         Loss D: -181.1179, loss G: 18.1339\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [39/200] Batch 11/12                         Loss D: -178.2500, loss G: 18.5550\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [40/200] Batch 11/12                         Loss D: -173.1851, loss G: 18.9510\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [41/200] Batch 11/12                         Loss D: -159.8869, loss G: 19.2217\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [42/200] Batch 11/12                         Loss D: -144.1219, loss G: 19.4180\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [43/200] Batch 11/12                         Loss D: -122.1772, loss G: 19.4795\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [44/200] Batch 11/12                         Loss D: -98.2212, loss G: 19.4749\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [45/200] Batch 11/12                         Loss D: -80.8411, loss G: 19.4885\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [46/200] Batch 11/12                         Loss D: -71.8759, loss G: 19.4473\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [47/200] Batch 11/12                         Loss D: -67.1840, loss G: 19.4977\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [48/200] Batch 11/12                         Loss D: -59.4295, loss G: 19.4011\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [49/200] Batch 11/12                         Loss D: -51.5301, loss G: 19.2463\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [50/200] Batch 11/12                         Loss D: -44.7166, loss G: 19.0960\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [51/200] Batch 11/12                         Loss D: -37.6268, loss G: 18.9202\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [52/200] Batch 11/12                         Loss D: -30.9406, loss G: 18.7283\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [53/200] Batch 11/12                         Loss D: -24.4881, loss G: 18.5243\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [54/200] Batch 11/12                         Loss D: -18.7041, loss G: 18.2865\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [55/200] Batch 11/12                         Loss D: -13.1998, loss G: 18.0692\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [56/200] Batch 11/12                         Loss D: -6.6288, loss G: 17.8031\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [57/200] Batch 11/12                         Loss D: -0.0327, loss G: 17.5385\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [58/200] Batch 11/12                         Loss D: 1.3914, loss G: 17.3371\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [59/200] Batch 11/12                         Loss D: 2.4205, loss G: 17.2674\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [60/200] Batch 11/12                         Loss D: 2.1287, loss G: 17.2655\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [61/200] Batch 11/12                         Loss D: 2.1425, loss G: 17.2645\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [62/200] Batch 11/12                         Loss D: 2.0339, loss G: 17.2659\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [63/200] Batch 11/12                         Loss D: 1.9182, loss G: 17.2644\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [64/200] Batch 11/12                         Loss D: 2.0852, loss G: 17.2663\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [65/200] Batch 11/12                         Loss D: 2.0007, loss G: 17.2660\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [66/200] Batch 11/12                         Loss D: 1.6354, loss G: 17.2653\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [67/200] Batch 11/12                         Loss D: 1.5826, loss G: 17.2660\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [68/200] Batch 11/12                         Loss D: 1.6084, loss G: 17.2666\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [69/200] Batch 11/12                         Loss D: 1.5261, loss G: 17.2676\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [70/200] Batch 11/12                         Loss D: 1.3760, loss G: 17.2682\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [71/200] Batch 11/12                         Loss D: 1.3514, loss G: 17.2692\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [72/200] Batch 11/12                         Loss D: 1.3741, loss G: 17.2705\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [73/200] Batch 11/12                         Loss D: 1.2786, loss G: 17.2717\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [74/200] Batch 11/12                         Loss D: 1.3496, loss G: 17.2724\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [75/200] Batch 11/12                         Loss D: 0.9634, loss G: 17.2777\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [76/200] Batch 11/12                         Loss D: 1.0911, loss G: 17.2835\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [77/200] Batch 11/12                         Loss D: 1.0548, loss G: 17.2879\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [78/200] Batch 11/12                         Loss D: 0.8994, loss G: 17.2923\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [79/200] Batch 11/12                         Loss D: 0.8649, loss G: 17.2954\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [80/200] Batch 11/12                         Loss D: 0.8031, loss G: 17.2993\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [81/200] Batch 11/12                         Loss D: 0.7162, loss G: 17.3034\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [82/200] Batch 11/12                         Loss D: 0.4863, loss G: 17.3077\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [83/200] Batch 11/12                         Loss D: 0.4248, loss G: 17.3130\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [84/200] Batch 11/12                         Loss D: 0.2198, loss G: 17.3181\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [85/200] Batch 11/12                         Loss D: 0.3168, loss G: 17.3208\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [86/200] Batch 11/12                         Loss D: 0.4516, loss G: 17.3245\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [87/200] Batch 11/12                         Loss D: 0.2594, loss G: 17.3277\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [88/200] Batch 11/12                         Loss D: 0.2427, loss G: 17.3312\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [89/200] Batch 11/12                         Loss D: 0.0938, loss G: 17.3352\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [90/200] Batch 11/12                         Loss D: -0.1406, loss G: 17.3405\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [91/200] Batch 11/12                         Loss D: 0.9201, loss G: 17.3539\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [92/200] Batch 11/12                         Loss D: 0.9355, loss G: 17.3592\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [93/200] Batch 11/12                         Loss D: 0.8371, loss G: 17.3637\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [94/200] Batch 11/12                         Loss D: 0.8093, loss G: 17.3684\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [95/200] Batch 11/12                         Loss D: 0.6861, loss G: 17.3731\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [96/200] Batch 11/12                         Loss D: 0.6945, loss G: 17.3791\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [97/200] Batch 11/12                         Loss D: 0.4664, loss G: 17.3816\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [98/200] Batch 11/12                         Loss D: 0.5403, loss G: 17.3887\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [99/200] Batch 11/12                         Loss D: 0.4338, loss G: 17.3938\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [100/200] Batch 11/12                         Loss D: 0.2798, loss G: 17.3982\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [101/200] Batch 11/12                         Loss D: 0.0905, loss G: 17.4033\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [102/200] Batch 11/12                         Loss D: -0.1427, loss G: 17.4079\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [103/200] Batch 11/12                         Loss D: -0.5469, loss G: 17.4128\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [104/200] Batch 11/12                         Loss D: -0.7154, loss G: 17.4194\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [105/200] Batch 11/12                         Loss D: -0.8938, loss G: 17.4267\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [106/200] Batch 11/12                         Loss D: -0.9208, loss G: 17.4340\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [107/200] Batch 11/12                         Loss D: -1.0121, loss G: 17.4419\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [108/200] Batch 11/12                         Loss D: -1.1258, loss G: 17.4494\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [109/200] Batch 11/12                         Loss D: -1.3346, loss G: 17.4575\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [110/200] Batch 11/12                         Loss D: -1.4972, loss G: 17.4654\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [111/200] Batch 11/12                         Loss D: -1.6101, loss G: 17.4744\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [112/200] Batch 11/12                         Loss D: -1.8938, loss G: 17.4820\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [113/200] Batch 11/12                         Loss D: -2.1352, loss G: 17.4905\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [114/200] Batch 11/12                         Loss D: -2.3671, loss G: 17.4999\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [115/200] Batch 11/12                         Loss D: -2.6809, loss G: 17.5092\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [116/200] Batch 11/12                         Loss D: -3.1101, loss G: 17.5184\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [117/200] Batch 11/12                         Loss D: -3.5101, loss G: 17.5281\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [118/200] Batch 11/12                         Loss D: -3.9464, loss G: 17.5382\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [119/200] Batch 11/12                         Loss D: -4.4808, loss G: 17.5490\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [120/200] Batch 11/12                         Loss D: -4.9077, loss G: 17.5616\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [121/200] Batch 11/12                         Loss D: -5.6836, loss G: 17.5726\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [122/200] Batch 11/12                         Loss D: -6.4419, loss G: 17.5852\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [123/200] Batch 11/12                         Loss D: -7.2280, loss G: 17.5986\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [124/200] Batch 11/12                         Loss D: -8.1672, loss G: 17.6111\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [125/200] Batch 11/12                         Loss D: -9.1574, loss G: 17.6209\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [126/200] Batch 11/12                         Loss D: -9.9619, loss G: 17.6229\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [127/200] Batch 11/12                         Loss D: -10.6375, loss G: 17.6235\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [128/200] Batch 11/12                         Loss D: -10.5162, loss G: 17.6329\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [129/200] Batch 11/12                         Loss D: -10.6274, loss G: 17.6430\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [130/200] Batch 11/12                         Loss D: -11.0711, loss G: 17.6513\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [131/200] Batch 11/12                         Loss D: -11.0881, loss G: 17.6596\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [132/200] Batch 11/12                         Loss D: -11.0482, loss G: 17.6669\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [133/200] Batch 11/12                         Loss D: -10.3789, loss G: 17.6725\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [134/200] Batch 11/12                         Loss D: -9.0243, loss G: 17.6759\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [135/200] Batch 11/12                         Loss D: -8.4630, loss G: 17.6803\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [136/200] Batch 11/12                         Loss D: -7.9318, loss G: 17.6841\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [137/200] Batch 11/12                         Loss D: -6.3358, loss G: 17.6862\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [138/200] Batch 11/12                         Loss D: -4.1116, loss G: 17.6867\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [139/200] Batch 11/12                         Loss D: -1.9048, loss G: 17.6873\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [140/200] Batch 11/12                         Loss D: 22.6909, loss G: 15.6034\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [141/200] Batch 11/12                         Loss D: 37.8602, loss G: 13.4512\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [142/200] Batch 11/12                         Loss D: 39.7194, loss G: 12.6664\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [143/200] Batch 11/12                         Loss D: 36.6671, loss G: 12.1611\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [144/200] Batch 11/12                         Loss D: 29.8745, loss G: 11.8345\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [145/200] Batch 11/12                         Loss D: 16.2883, loss G: 11.8148\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [146/200] Batch 11/12                         Loss D: -5.3107, loss G: 12.6399\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [147/200] Batch 11/12                         Loss D: -23.0677, loss G: 13.7153\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [148/200] Batch 11/12                         Loss D: -42.4656, loss G: 14.6926\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [149/200] Batch 11/12                         Loss D: -57.0597, loss G: 15.6185\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [150/200] Batch 11/12                         Loss D: -73.7010, loss G: 16.5128\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [151/200] Batch 11/12                         Loss D: -85.1578, loss G: 17.3896\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [152/200] Batch 11/12                         Loss D: -94.5080, loss G: 18.1932\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [153/200] Batch 11/12                         Loss D: -97.3411, loss G: 18.8880\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [154/200] Batch 11/12                         Loss D: -92.3927, loss G: 19.3750\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [155/200] Batch 11/12                         Loss D: -82.7159, loss G: 19.6205\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [156/200] Batch 11/12                         Loss D: -67.9224, loss G: 19.6060\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [157/200] Batch 11/12                         Loss D: -47.4075, loss G: 19.2529\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [158/200] Batch 11/12                         Loss D: -25.8527, loss G: 18.7296\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [159/200] Batch 11/12                         Loss D: -7.7627, loss G: 18.2330\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [160/200] Batch 11/12                         Loss D: -10.7086, loss G: 18.1960\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [161/200] Batch 11/12                         Loss D: -11.6894, loss G: 18.1924\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [162/200] Batch 11/12                         Loss D: -11.4729, loss G: 18.2019\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [163/200] Batch 11/12                         Loss D: -11.0176, loss G: 18.2133\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [164/200] Batch 11/12                         Loss D: -10.3318, loss G: 18.2073\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [165/200] Batch 11/12                         Loss D: -8.2820, loss G: 18.2020\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [166/200] Batch 11/12                         Loss D: -6.2465, loss G: 18.1941\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [167/200] Batch 11/12                         Loss D: -4.2340, loss G: 18.1674\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [168/200] Batch 11/12                         Loss D: -1.5976, loss G: 18.1180\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [169/200] Batch 11/12                         Loss D: 0.8079, loss G: 18.0595\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [170/200] Batch 11/12                         Loss D: 3.0909, loss G: 17.9934\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [171/200] Batch 11/12                         Loss D: 5.0382, loss G: 17.9435\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [172/200] Batch 11/12                         Loss D: 7.0415, loss G: 17.8850\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [173/200] Batch 11/12                         Loss D: 7.7659, loss G: 17.8391\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [174/200] Batch 11/12                         Loss D: 7.4198, loss G: 17.8026\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [175/200] Batch 11/12                         Loss D: 7.6374, loss G: 17.7747\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [176/200] Batch 11/12                         Loss D: 6.6767, loss G: 17.7355\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [177/200] Batch 11/12                         Loss D: 5.8636, loss G: 17.6951\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [178/200] Batch 11/12                         Loss D: 4.6128, loss G: 17.6431\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [179/200] Batch 11/12                         Loss D: 3.6825, loss G: 17.5876\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [180/200] Batch 11/12                         Loss D: -0.6131, loss G: 17.4461\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [181/200] Batch 11/12                         Loss D: 0.7649, loss G: 17.3911\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [182/200] Batch 11/12                         Loss D: 1.6784, loss G: 17.3967\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [183/200] Batch 11/12                         Loss D: 2.8378, loss G: 17.4020\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [184/200] Batch 11/12                         Loss D: 4.8832, loss G: 17.4219\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [185/200] Batch 11/12                         Loss D: 4.0017, loss G: 17.4407\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [186/200] Batch 11/12                         Loss D: 4.6117, loss G: 17.4640\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [187/200] Batch 11/12                         Loss D: 4.4428, loss G: 17.4916\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [188/200] Batch 11/12                         Loss D: 4.8267, loss G: 17.5163\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [189/200] Batch 11/12                         Loss D: 3.9767, loss G: 17.5330\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [190/200] Batch 11/12                         Loss D: 1.8552, loss G: 17.5429\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [191/200] Batch 11/12                         Loss D: 0.7266, loss G: 17.5522\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [192/200] Batch 11/12                         Loss D: -0.4528, loss G: 17.5638\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [193/200] Batch 11/12                         Loss D: -1.4086, loss G: 17.5688\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [194/200] Batch 11/12                         Loss D: -1.8741, loss G: 17.5848\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [195/200] Batch 11/12                         Loss D: -1.3976, loss G: 17.5794\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [196/200] Batch 11/12                         Loss D: -1.5456, loss G: 17.5907\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [197/200] Batch 11/12                         Loss D: -1.6988, loss G: 17.6020\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [198/200] Batch 11/12                         Loss D: -1.6741, loss G: 17.6097\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [199/200] Batch 11/12                         Loss D: -1.6984, loss G: 17.6199\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [0/200] Batch 11/12                         Loss D: 8.7463, loss G: 3.2394\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [1/200] Batch 11/12                         Loss D: 9.0097, loss G: 3.2133\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [2/200] Batch 11/12                         Loss D: 9.3176, loss G: 3.1817\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [3/200] Batch 11/12                         Loss D: 9.7437, loss G: 3.1401\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [4/200] Batch 11/12                         Loss D: 10.0465, loss G: 3.0938\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [5/200] Batch 11/12                         Loss D: 10.2831, loss G: 3.0369\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [6/200] Batch 11/12                         Loss D: 10.2627, loss G: 2.9837\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [7/200] Batch 11/12                         Loss D: 9.9607, loss G: 2.9402\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [8/200] Batch 11/12                         Loss D: 9.4929, loss G: 2.9063\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [9/200] Batch 11/12                         Loss D: 8.8112, loss G: 2.8859\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [10/200] Batch 11/12                         Loss D: 7.9936, loss G: 2.8691\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [11/200] Batch 11/12                         Loss D: 6.8974, loss G: 2.8614\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [12/200] Batch 11/12                         Loss D: 5.4996, loss G: 2.8567\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [13/200] Batch 11/12                         Loss D: 3.8968, loss G: 2.8674\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [14/200] Batch 11/12                         Loss D: 2.1156, loss G: 2.8825\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [15/200] Batch 11/12                         Loss D: 0.1004, loss G: 2.9191\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [16/200] Batch 11/12                         Loss D: -1.6458, loss G: 2.9540\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [17/200] Batch 11/12                         Loss D: -3.5361, loss G: 2.9918\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [18/200] Batch 11/12                         Loss D: -5.2090, loss G: 3.0377\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [19/200] Batch 11/12                         Loss D: -6.9812, loss G: 3.0895\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [20/200] Batch 11/12                         Loss D: -8.6188, loss G: 3.1432\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [21/200] Batch 11/12                         Loss D: -10.4011, loss G: 3.1987\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [22/200] Batch 11/12                         Loss D: -11.7793, loss G: 3.2553\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [23/200] Batch 11/12                         Loss D: -13.1281, loss G: 3.3127\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [24/200] Batch 11/12                         Loss D: -14.3856, loss G: 3.3655\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [25/200] Batch 11/12                         Loss D: -14.9070, loss G: 3.4130\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [26/200] Batch 11/12                         Loss D: -15.9868, loss G: 3.4621\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [27/200] Batch 11/12                         Loss D: -16.3121, loss G: 3.4977\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [28/200] Batch 11/12                         Loss D: -16.5891, loss G: 3.5325\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [29/200] Batch 11/12                         Loss D: -16.6673, loss G: 3.5589\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [30/200] Batch 11/12                         Loss D: -16.6119, loss G: 3.5766\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [31/200] Batch 11/12                         Loss D: -16.3118, loss G: 3.5901\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [32/200] Batch 11/12                         Loss D: -15.9255, loss G: 3.5951\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [33/200] Batch 11/12                         Loss D: -15.7700, loss G: 3.5989\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [34/200] Batch 11/12                         Loss D: -15.2851, loss G: 3.5919\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [35/200] Batch 11/12                         Loss D: -15.1356, loss G: 3.5944\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [36/200] Batch 11/12                         Loss D: -15.0321, loss G: 3.5970\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [37/200] Batch 11/12                         Loss D: -14.9560, loss G: 3.5964\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [38/200] Batch 11/12                         Loss D: -14.8012, loss G: 3.5903\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [39/200] Batch 11/12                         Loss D: -14.3364, loss G: 3.5791\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [40/200] Batch 11/12                         Loss D: -13.1053, loss G: 3.5601\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [41/200] Batch 11/12                         Loss D: -10.4105, loss G: 3.5329\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [42/200] Batch 11/12                         Loss D: -4.5480, loss G: 3.4826\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [43/200] Batch 11/12                         Loss D: 17.2720, loss G: 2.3760\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [44/200] Batch 11/12                         Loss D: 27.6462, loss G: 1.5519\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [45/200] Batch 11/12                         Loss D: 36.8895, loss G: 0.9450\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [46/200] Batch 11/12                         Loss D: 42.5177, loss G: 0.6005\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [47/200] Batch 11/12                         Loss D: 44.1362, loss G: 0.4855\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [48/200] Batch 11/12                         Loss D: 41.9807, loss G: 0.5422\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [49/200] Batch 11/12                         Loss D: 36.6836, loss G: 0.7092\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [50/200] Batch 11/12                         Loss D: 29.8060, loss G: 0.9395\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [51/200] Batch 11/12                         Loss D: 27.9189, loss G: 0.9255\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [52/200] Batch 11/12                         Loss D: 30.8727, loss G: 0.3323\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [53/200] Batch 11/12                         Loss D: 29.5223, loss G: 0.2111\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [54/200] Batch 11/12                         Loss D: 9.7729, loss G: 0.8987\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [55/200] Batch 11/12                         Loss D: -9.6778, loss G: 1.8818\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [56/200] Batch 11/12                         Loss D: -27.8021, loss G: 2.9050\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [57/200] Batch 11/12                         Loss D: -44.7923, loss G: 3.8974\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [58/200] Batch 11/12                         Loss D: -58.6276, loss G: 4.7849\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [59/200] Batch 11/12                         Loss D: -67.1513, loss G: 5.4653\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [60/200] Batch 11/12                         Loss D: -71.9029, loss G: 5.9756\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [61/200] Batch 11/12                         Loss D: -72.6285, loss G: 6.2741\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [62/200] Batch 11/12                         Loss D: -70.7091, loss G: 6.4044\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [63/200] Batch 11/12                         Loss D: -66.5728, loss G: 6.3934\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [64/200] Batch 11/12                         Loss D: -59.7094, loss G: 6.2154\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [65/200] Batch 11/12                         Loss D: -50.8562, loss G: 5.9060\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [66/200] Batch 11/12                         Loss D: -43.1768, loss G: 5.6256\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [67/200] Batch 11/12                         Loss D: -32.9420, loss G: 5.2215\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [68/200] Batch 11/12                         Loss D: -25.9086, loss G: 5.0534\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [69/200] Batch 11/12                         Loss D: -19.3624, loss G: 4.8907\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [70/200] Batch 11/12                         Loss D: -12.1605, loss G: 4.6124\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [71/200] Batch 11/12                         Loss D: -9.7864, loss G: 4.5355\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [72/200] Batch 11/12                         Loss D: -7.4661, loss G: 4.4440\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [73/200] Batch 11/12                         Loss D: -5.2115, loss G: 4.3495\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [74/200] Batch 11/12                         Loss D: -2.5406, loss G: 4.2186\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [75/200] Batch 11/12                         Loss D: -0.1158, loss G: 4.0559\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [76/200] Batch 11/12                         Loss D: 1.9756, loss G: 3.8973\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [77/200] Batch 11/12                         Loss D: 3.2548, loss G: 3.8076\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [78/200] Batch 11/12                         Loss D: 3.7156, loss G: 3.7692\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [79/200] Batch 11/12                         Loss D: 4.1723, loss G: 3.7335\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [80/200] Batch 11/12                         Loss D: 4.8696, loss G: 3.6886\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [81/200] Batch 11/12                         Loss D: 5.5223, loss G: 3.6508\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [82/200] Batch 11/12                         Loss D: 6.0631, loss G: 3.6242\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [83/200] Batch 11/12                         Loss D: 6.6139, loss G: 3.5922\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [84/200] Batch 11/12                         Loss D: 7.1690, loss G: 3.5616\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [85/200] Batch 11/12                         Loss D: 7.5691, loss G: 3.5286\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [86/200] Batch 11/12                         Loss D: 7.4583, loss G: 3.4737\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [87/200] Batch 11/12                         Loss D: 7.3214, loss G: 3.4047\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [88/200] Batch 11/12                         Loss D: 7.7593, loss G: 3.3938\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [89/200] Batch 11/12                         Loss D: 8.1431, loss G: 3.3812\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [90/200] Batch 11/12                         Loss D: 8.5113, loss G: 3.3631\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [91/200] Batch 11/12                         Loss D: 8.8429, loss G: 3.3463\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [92/200] Batch 11/12                         Loss D: 9.0134, loss G: 3.3324\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [93/200] Batch 11/12                         Loss D: 9.3128, loss G: 3.3154\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [94/200] Batch 11/12                         Loss D: 9.4026, loss G: 3.3164\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [95/200] Batch 11/12                         Loss D: 9.2748, loss G: 3.3164\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [96/200] Batch 11/12                         Loss D: 9.4609, loss G: 3.3206\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [97/200] Batch 11/12                         Loss D: 9.6926, loss G: 3.3289\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [98/200] Batch 11/12                         Loss D: 9.7417, loss G: 3.3283\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [99/200] Batch 11/12                         Loss D: 9.6385, loss G: 3.3276\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [100/200] Batch 11/12                         Loss D: 9.2700, loss G: 3.3253\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [101/200] Batch 11/12                         Loss D: 9.3496, loss G: 3.3255\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [102/200] Batch 11/12                         Loss D: 9.3726, loss G: 3.3308\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [103/200] Batch 11/12                         Loss D: 9.2007, loss G: 3.3323\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [104/200] Batch 11/12                         Loss D: 9.6683, loss G: 3.3408\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [105/200] Batch 11/12                         Loss D: 9.6944, loss G: 3.3416\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [106/200] Batch 11/12                         Loss D: 9.6189, loss G: 3.3424\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [107/200] Batch 11/12                         Loss D: 9.4631, loss G: 3.3384\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [108/200] Batch 11/12                         Loss D: 9.4384, loss G: 3.3403\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [109/200] Batch 11/12                         Loss D: 9.4037, loss G: 3.3431\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [110/200] Batch 11/12                         Loss D: 9.5212, loss G: 3.3435\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [111/200] Batch 11/12                         Loss D: 9.4097, loss G: 3.3489\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [112/200] Batch 11/12                         Loss D: 9.4680, loss G: 3.3477\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [113/200] Batch 11/12                         Loss D: 9.3313, loss G: 3.3603\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [114/200] Batch 11/12                         Loss D: 9.3189, loss G: 3.3581\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [115/200] Batch 11/12                         Loss D: 9.5893, loss G: 3.3560\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [116/200] Batch 11/12                         Loss D: 9.6413, loss G: 3.3572\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [117/200] Batch 11/12                         Loss D: 9.6811, loss G: 3.3609\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [118/200] Batch 11/12                         Loss D: 9.6065, loss G: 3.3617\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [119/200] Batch 11/12                         Loss D: 9.6980, loss G: 3.3622\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [120/200] Batch 11/12                         Loss D: 9.7440, loss G: 3.3687\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [121/200] Batch 11/12                         Loss D: 9.5014, loss G: 3.3683\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [122/200] Batch 11/12                         Loss D: 9.6645, loss G: 3.3697\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [123/200] Batch 11/12                         Loss D: 9.7210, loss G: 3.3716\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [124/200] Batch 11/12                         Loss D: 9.7690, loss G: 3.3745\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [125/200] Batch 11/12                         Loss D: 9.6828, loss G: 3.3765\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [126/200] Batch 11/12                         Loss D: 9.8029, loss G: 3.3777\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [127/200] Batch 11/12                         Loss D: 9.8632, loss G: 3.3816\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [128/200] Batch 11/12                         Loss D: 9.8063, loss G: 3.3827\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [129/200] Batch 11/12                         Loss D: 9.7786, loss G: 3.3874\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [130/200] Batch 11/12                         Loss D: 9.7331, loss G: 3.3912\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [131/200] Batch 11/12                         Loss D: 9.5153, loss G: 3.3964\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [132/200] Batch 11/12                         Loss D: 9.5194, loss G: 3.3961\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [133/200] Batch 11/12                         Loss D: 9.6377, loss G: 3.3943\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [134/200] Batch 11/12                         Loss D: 9.8550, loss G: 3.3964\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [135/200] Batch 11/12                         Loss D: 10.0093, loss G: 3.4016\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [136/200] Batch 11/12                         Loss D: 10.0540, loss G: 3.4079\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [137/200] Batch 11/12                         Loss D: 9.7602, loss G: 3.4055\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [138/200] Batch 11/12                         Loss D: 9.6946, loss G: 3.4061\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [139/200] Batch 11/12                         Loss D: 9.9315, loss G: 3.4094\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [140/200] Batch 11/12                         Loss D: 9.8827, loss G: 3.4103\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [141/200] Batch 11/12                         Loss D: 9.9433, loss G: 3.4131\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [142/200] Batch 11/12                         Loss D: 9.9616, loss G: 3.4148\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [143/200] Batch 11/12                         Loss D: 9.9475, loss G: 3.4175\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [144/200] Batch 11/12                         Loss D: 9.9825, loss G: 3.4213\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [145/200] Batch 11/12                         Loss D: 9.9991, loss G: 3.4222\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [146/200] Batch 11/12                         Loss D: 10.0969, loss G: 3.4289\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [147/200] Batch 11/12                         Loss D: 9.8747, loss G: 3.4311\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [148/200] Batch 11/12                         Loss D: 9.7734, loss G: 3.4294\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [149/200] Batch 11/12                         Loss D: 9.8886, loss G: 3.4315\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [150/200] Batch 11/12                         Loss D: 9.8281, loss G: 3.4332\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [151/200] Batch 11/12                         Loss D: 9.8044, loss G: 3.4355\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [152/200] Batch 11/12                         Loss D: 9.8185, loss G: 3.4378\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [153/200] Batch 11/12                         Loss D: 9.7373, loss G: 3.4396\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [154/200] Batch 11/12                         Loss D: 9.5251, loss G: 3.4427\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [155/200] Batch 11/12                         Loss D: 9.2418, loss G: 3.4425\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [156/200] Batch 11/12                         Loss D: 9.1719, loss G: 3.4429\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [157/200] Batch 11/12                         Loss D: 9.0765, loss G: 3.4439\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [158/200] Batch 11/12                         Loss D: 8.9532, loss G: 3.4449\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [159/200] Batch 11/12                         Loss D: 9.0026, loss G: 3.4437\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [160/200] Batch 11/12                         Loss D: 8.9104, loss G: 3.4457\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [161/200] Batch 11/12                         Loss D: 8.6146, loss G: 3.4435\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [162/200] Batch 11/12                         Loss D: 8.4969, loss G: 3.4442\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [163/200] Batch 11/12                         Loss D: 8.0814, loss G: 3.4427\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [164/200] Batch 11/12                         Loss D: 7.9924, loss G: 3.4395\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [165/200] Batch 11/12                         Loss D: 7.7709, loss G: 3.4350\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [166/200] Batch 11/12                         Loss D: 7.3728, loss G: 3.4275\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [167/200] Batch 11/12                         Loss D: 6.8096, loss G: 3.4203\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [168/200] Batch 11/12                         Loss D: 6.6490, loss G: 3.4163\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [169/200] Batch 11/12                         Loss D: 6.5913, loss G: 3.4163\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [170/200] Batch 11/12                         Loss D: 6.5814, loss G: 3.4165\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [171/200] Batch 11/12                         Loss D: 6.4686, loss G: 3.4167\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [172/200] Batch 11/12                         Loss D: 6.5167, loss G: 3.4166\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [173/200] Batch 11/12                         Loss D: 6.5413, loss G: 3.4182\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [174/200] Batch 11/12                         Loss D: 6.5315, loss G: 3.4174\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [175/200] Batch 11/12                         Loss D: 6.3417, loss G: 3.4176\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [176/200] Batch 11/12                         Loss D: 6.3136, loss G: 3.4188\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [177/200] Batch 11/12                         Loss D: 6.4028, loss G: 3.4187\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [178/200] Batch 11/12                         Loss D: 6.4422, loss G: 3.4224\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [179/200] Batch 11/12                         Loss D: 6.3322, loss G: 3.4181\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [180/200] Batch 11/12                         Loss D: 6.2526, loss G: 3.4198\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [181/200] Batch 11/12                         Loss D: 6.5576, loss G: 3.4345\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [182/200] Batch 11/12                         Loss D: 6.0494, loss G: 3.4207\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [183/200] Batch 11/12                         Loss D: 6.2791, loss G: 3.4198\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [184/200] Batch 11/12                         Loss D: 6.1252, loss G: 3.4214\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [185/200] Batch 11/12                         Loss D: 6.2051, loss G: 3.4205\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [186/200] Batch 11/12                         Loss D: 6.1854, loss G: 3.4200\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [187/200] Batch 11/12                         Loss D: 5.8099, loss G: 3.4250\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [188/200] Batch 11/12                         Loss D: 6.1831, loss G: 3.4303\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [189/200] Batch 11/12                         Loss D: 6.0913, loss G: 3.4210\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [190/200] Batch 11/12                         Loss D: 5.9854, loss G: 3.4216\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [191/200] Batch 11/12                         Loss D: 6.0001, loss G: 3.4213\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [192/200] Batch 11/12                         Loss D: 5.7593, loss G: 3.4246\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [193/200] Batch 11/12                         Loss D: 6.0394, loss G: 3.4277\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [194/200] Batch 11/12                         Loss D: 5.7757, loss G: 3.4268\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [195/200] Batch 11/12                         Loss D: 5.9438, loss G: 3.4233\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [196/200] Batch 11/12                         Loss D: 5.8911, loss G: 3.4325\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [197/200] Batch 11/12                         Loss D: 5.8515, loss G: 3.4241\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [198/200] Batch 11/12                         Loss D: 5.8109, loss G: 3.4328\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [199/200] Batch 11/12                         Loss D: 5.6995, loss G: 3.4235\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [0/200] Batch 11/12                         Loss D: 0.8653, loss G: 34.2590\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [1/200] Batch 11/12                         Loss D: 0.7093, loss G: 34.0163\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [2/200] Batch 11/12                         Loss D: 0.4797, loss G: 33.7416\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [3/200] Batch 11/12                         Loss D: 0.0872, loss G: 33.3144\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [4/200] Batch 11/12                         Loss D: -0.5248, loss G: 32.7387\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [5/200] Batch 11/12                         Loss D: -1.4269, loss G: 32.0290\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [6/200] Batch 11/12                         Loss D: -2.7019, loss G: 31.1949\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [7/200] Batch 11/12                         Loss D: -4.4783, loss G: 30.1935\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [8/200] Batch 11/12                         Loss D: -6.3893, loss G: 29.3873\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [9/200] Batch 11/12                         Loss D: -8.4574, loss G: 28.7363\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [10/200] Batch 11/12                         Loss D: -10.8278, loss G: 28.1022\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [11/200] Batch 11/12                         Loss D: -13.7795, loss G: 27.3596\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [12/200] Batch 11/12                         Loss D: -17.6909, loss G: 26.4469\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [13/200] Batch 11/12                         Loss D: -21.7512, loss G: 25.6494\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [14/200] Batch 11/12                         Loss D: -27.3376, loss G: 24.5573\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [15/200] Batch 11/12                         Loss D: -34.0934, loss G: 23.3649\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [16/200] Batch 11/12                         Loss D: -42.6129, loss G: 22.0013\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [17/200] Batch 11/12                         Loss D: -51.9830, loss G: 20.7836\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [18/200] Batch 11/12                         Loss D: -63.9726, loss G: 19.2591\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [19/200] Batch 11/12                         Loss D: -76.8445, loss G: 17.9355\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [20/200] Batch 11/12                         Loss D: -93.8037, loss G: 16.2732\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [21/200] Batch 11/12                         Loss D: -106.6211, loss G: 15.8605\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [22/200] Batch 11/12                         Loss D: -118.6983, loss G: 15.8381\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [23/200] Batch 11/12                         Loss D: -130.0446, loss G: 15.5665\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [24/200] Batch 11/12                         Loss D: -141.9804, loss G: 15.4197\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [25/200] Batch 11/12                         Loss D: -156.1528, loss G: 15.0623\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [26/200] Batch 11/12                         Loss D: -172.0121, loss G: 14.5529\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [27/200] Batch 11/12                         Loss D: -187.8639, loss G: 14.0774\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [28/200] Batch 11/12                         Loss D: -207.8889, loss G: 13.5843\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [29/200] Batch 11/12                         Loss D: -227.6738, loss G: 13.5025\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [30/200] Batch 11/12                         Loss D: -244.9971, loss G: 13.7546\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [31/200] Batch 11/12                         Loss D: -256.8626, loss G: 14.5893\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [32/200] Batch 11/12                         Loss D: -272.2893, loss G: 15.1689\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [33/200] Batch 11/12                         Loss D: -288.3842, loss G: 15.8940\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [34/200] Batch 11/12                         Loss D: -303.4721, loss G: 16.6293\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [35/200] Batch 11/12                         Loss D: -312.5420, loss G: 17.4796\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [36/200] Batch 11/12                         Loss D: -330.4393, loss G: 18.1875\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [37/200] Batch 11/12                         Loss D: -343.8534, loss G: 19.0696\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [38/200] Batch 11/12                         Loss D: -354.8853, loss G: 19.7842\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [39/200] Batch 11/12                         Loss D: -371.5599, loss G: 20.5206\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [40/200] Batch 11/12                         Loss D: -379.6136, loss G: 21.5511\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [41/200] Batch 11/12                         Loss D: -397.1405, loss G: 22.3313\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [42/200] Batch 11/12                         Loss D: -414.2528, loss G: 23.2788\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [43/200] Batch 11/12                         Loss D: -422.8692, loss G: 24.1584\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [44/200] Batch 11/12                         Loss D: -439.3928, loss G: 24.9976\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [45/200] Batch 11/12                         Loss D: -451.1118, loss G: 25.9832\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [46/200] Batch 11/12                         Loss D: -461.2650, loss G: 26.9421\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [47/200] Batch 11/12                         Loss D: -477.3038, loss G: 27.9119\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [48/200] Batch 11/12                         Loss D: -482.7116, loss G: 28.8956\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [49/200] Batch 11/12                         Loss D: -491.8091, loss G: 29.8705\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [50/200] Batch 11/12                         Loss D: -502.4361, loss G: 30.8823\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [51/200] Batch 11/12                         Loss D: -513.3172, loss G: 31.8194\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [52/200] Batch 11/12                         Loss D: -510.7051, loss G: 32.8298\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [53/200] Batch 11/12                         Loss D: -526.7097, loss G: 33.7809\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [54/200] Batch 11/12                         Loss D: -526.1835, loss G: 34.7429\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [55/200] Batch 11/12                         Loss D: -525.9954, loss G: 35.6603\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [56/200] Batch 11/12                         Loss D: -522.8717, loss G: 36.5464\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [57/200] Batch 11/12                         Loss D: -521.6186, loss G: 37.3828\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [58/200] Batch 11/12                         Loss D: -519.7200, loss G: 38.2230\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [59/200] Batch 11/12                         Loss D: -503.0058, loss G: 38.7788\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [60/200] Batch 11/12                         Loss D: -485.6574, loss G: 39.3012\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [61/200] Batch 11/12                         Loss D: -461.5759, loss G: 39.6890\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [62/200] Batch 11/12                         Loss D: -430.8298, loss G: 39.9125\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [63/200] Batch 11/12                         Loss D: -397.8445, loss G: 40.0397\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [64/200] Batch 11/12                         Loss D: -355.4095, loss G: 39.9411\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [65/200] Batch 11/12                         Loss D: -314.9576, loss G: 39.7966\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [66/200] Batch 11/12                         Loss D: -265.8930, loss G: 39.4386\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [67/200] Batch 11/12                         Loss D: -220.9494, loss G: 39.3159\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [68/200] Batch 11/12                         Loss D: -176.0713, loss G: 38.9949\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [69/200] Batch 11/12                         Loss D: -141.5460, loss G: 38.6746\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [70/200] Batch 11/12                         Loss D: -128.5817, loss G: 38.8270\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [71/200] Batch 11/12                         Loss D: -111.6613, loss G: 38.7575\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [72/200] Batch 11/12                         Loss D: -92.7655, loss G: 38.5546\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [73/200] Batch 11/12                         Loss D: -97.6983, loss G: 38.6028\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [74/200] Batch 11/12                         Loss D: -101.1721, loss G: 38.5280\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [75/200] Batch 11/12                         Loss D: -104.3226, loss G: 38.3221\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [76/200] Batch 11/12                         Loss D: -104.8123, loss G: 37.7912\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [77/200] Batch 11/12                         Loss D: -104.3927, loss G: 37.2635\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [78/200] Batch 11/12                         Loss D: -104.8543, loss G: 36.7456\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [79/200] Batch 11/12                         Loss D: -106.0905, loss G: 36.2636\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [80/200] Batch 11/12                         Loss D: -105.7143, loss G: 35.9482\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [81/200] Batch 11/12                         Loss D: -105.0463, loss G: 35.5783\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [82/200] Batch 11/12                         Loss D: -102.6923, loss G: 34.2892\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [83/200] Batch 11/12                         Loss D: -89.4140, loss G: 32.4890\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [84/200] Batch 11/12                         Loss D: -2.8641, loss G: 26.1842\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [85/200] Batch 11/12                         Loss D: 48.7333, loss G: 21.7791\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [86/200] Batch 11/12                         Loss D: 78.3207, loss G: 18.3987\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [87/200] Batch 11/12                         Loss D: 95.5950, loss G: 15.7714\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [88/200] Batch 11/12                         Loss D: 100.6589, loss G: 13.6399\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [89/200] Batch 11/12                         Loss D: 78.7085, loss G: 14.8411\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [90/200] Batch 11/12                         Loss D: 45.8372, loss G: 16.9141\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [91/200] Batch 11/12                         Loss D: 26.9201, loss G: 18.4300\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [92/200] Batch 11/12                         Loss D: 11.8147, loss G: 19.7387\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [93/200] Batch 11/12                         Loss D: 4.0486, loss G: 20.6842\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [94/200] Batch 11/12                         Loss D: 3.5424, loss G: 21.7745\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [95/200] Batch 11/12                         Loss D: 7.3412, loss G: 22.2849\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [96/200] Batch 11/12                         Loss D: 16.0131, loss G: 22.9808\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [97/200] Batch 11/12                         Loss D: 30.1122, loss G: 23.3866\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [98/200] Batch 11/12                         Loss D: 44.0455, loss G: 23.8783\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [99/200] Batch 11/12                         Loss D: 56.0351, loss G: 24.2480\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [100/200] Batch 11/12                         Loss D: 64.1666, loss G: 24.4917\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [101/200] Batch 11/12                         Loss D: 59.9984, loss G: 24.8325\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [102/200] Batch 11/12                         Loss D: 53.6713, loss G: 25.1988\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [103/200] Batch 11/12                         Loss D: 49.5004, loss G: 25.5539\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [104/200] Batch 11/12                         Loss D: 45.7704, loss G: 25.8414\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [105/200] Batch 11/12                         Loss D: 42.6950, loss G: 26.4439\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [106/200] Batch 11/12                         Loss D: 32.7333, loss G: 27.0952\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [107/200] Batch 11/12                         Loss D: 21.4372, loss G: 27.8366\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [108/200] Batch 11/12                         Loss D: 12.0039, loss G: 28.7358\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [109/200] Batch 11/12                         Loss D: -0.4859, loss G: 29.5936\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [110/200] Batch 11/12                         Loss D: -12.8094, loss G: 30.5155\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [111/200] Batch 11/12                         Loss D: -23.9305, loss G: 31.3498\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [112/200] Batch 11/12                         Loss D: -37.3399, loss G: 32.2323\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [113/200] Batch 11/12                         Loss D: -49.6864, loss G: 33.1073\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [114/200] Batch 11/12                         Loss D: -62.3348, loss G: 33.9801\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [115/200] Batch 11/12                         Loss D: -74.9724, loss G: 34.8495\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [116/200] Batch 11/12                         Loss D: -86.9686, loss G: 35.7333\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [117/200] Batch 11/12                         Loss D: -96.5349, loss G: 36.5751\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [118/200] Batch 11/12                         Loss D: -103.8282, loss G: 37.3377\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [119/200] Batch 11/12                         Loss D: -112.0443, loss G: 38.0510\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [120/200] Batch 11/12                         Loss D: -118.3470, loss G: 38.6806\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [121/200] Batch 11/12                         Loss D: -120.5236, loss G: 39.2437\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [122/200] Batch 11/12                         Loss D: -124.0056, loss G: 39.6982\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [123/200] Batch 11/12                         Loss D: -121.4340, loss G: 40.0265\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [124/200] Batch 11/12                         Loss D: -122.2189, loss G: 40.3167\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [125/200] Batch 11/12                         Loss D: -116.6326, loss G: 40.4208\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [126/200] Batch 11/12                         Loss D: -111.2793, loss G: 40.4834\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [127/200] Batch 11/12                         Loss D: -102.6535, loss G: 40.3573\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [128/200] Batch 11/12                         Loss D: -93.8878, loss G: 40.2004\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [129/200] Batch 11/12                         Loss D: -83.5776, loss G: 39.9901\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [130/200] Batch 11/12                         Loss D: -68.4415, loss G: 39.5742\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [131/200] Batch 11/12                         Loss D: -53.9672, loss G: 39.2122\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [132/200] Batch 11/12                         Loss D: -39.3105, loss G: 38.8062\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [133/200] Batch 11/12                         Loss D: -24.0525, loss G: 38.3291\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [134/200] Batch 11/12                         Loss D: -4.9091, loss G: 37.5881\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [135/200] Batch 11/12                         Loss D: 13.4393, loss G: 36.6421\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [136/200] Batch 11/12                         Loss D: 21.3485, loss G: 35.5712\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [137/200] Batch 11/12                         Loss D: 20.0175, loss G: 34.8438\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [138/200] Batch 11/12                         Loss D: 22.5211, loss G: 34.7862\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [139/200] Batch 11/12                         Loss D: 23.5797, loss G: 34.7787\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [140/200] Batch 11/12                         Loss D: 23.5964, loss G: 34.7756\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [141/200] Batch 11/12                         Loss D: 21.9658, loss G: 34.7748\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [142/200] Batch 11/12                         Loss D: 19.6157, loss G: 34.7680\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [143/200] Batch 11/12                         Loss D: 17.8382, loss G: 34.7643\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [144/200] Batch 11/12                         Loss D: 15.0646, loss G: 34.7482\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [145/200] Batch 11/12                         Loss D: 12.3909, loss G: 34.7320\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [146/200] Batch 11/12                         Loss D: 9.8103, loss G: 34.7116\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [147/200] Batch 11/12                         Loss D: 7.6018, loss G: 34.6930\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [148/200] Batch 11/12                         Loss D: 5.3018, loss G: 34.6786\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [149/200] Batch 11/12                         Loss D: 3.8924, loss G: 34.6545\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [150/200] Batch 11/12                         Loss D: 1.7153, loss G: 34.6364\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [151/200] Batch 11/12                         Loss D: -0.8912, loss G: 34.6230\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [152/200] Batch 11/12                         Loss D: -2.3900, loss G: 34.6118\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [153/200] Batch 11/12                         Loss D: -0.4520, loss G: 34.6350\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [154/200] Batch 11/12                         Loss D: -1.4495, loss G: 34.6232\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [155/200] Batch 11/12                         Loss D: -1.7255, loss G: 34.6289\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [156/200] Batch 11/12                         Loss D: -1.7941, loss G: 34.6316\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [157/200] Batch 11/12                         Loss D: -2.1577, loss G: 34.6298\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [158/200] Batch 11/12                         Loss D: -2.3603, loss G: 34.6272\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [159/200] Batch 11/12                         Loss D: -2.4973, loss G: 34.6276\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [160/200] Batch 11/12                         Loss D: -2.4433, loss G: 34.6282\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [161/200] Batch 11/12                         Loss D: -2.5364, loss G: 34.6325\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [162/200] Batch 11/12                         Loss D: -2.5259, loss G: 34.6349\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [163/200] Batch 11/12                         Loss D: -2.3220, loss G: 34.6385\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [164/200] Batch 11/12                         Loss D: -2.4596, loss G: 34.6386\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [165/200] Batch 11/12                         Loss D: -2.4058, loss G: 34.6394\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [166/200] Batch 11/12                         Loss D: -2.5231, loss G: 34.6361\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [167/200] Batch 11/12                         Loss D: -2.5349, loss G: 34.6417\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [168/200] Batch 11/12                         Loss D: -2.4122, loss G: 34.6441\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [169/200] Batch 11/12                         Loss D: -2.5647, loss G: 34.6434\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [170/200] Batch 11/12                         Loss D: -2.3833, loss G: 34.6461\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [171/200] Batch 11/12                         Loss D: -2.5299, loss G: 34.6490\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [172/200] Batch 11/12                         Loss D: -2.5746, loss G: 34.6516\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [173/200] Batch 11/12                         Loss D: -2.5044, loss G: 34.6524\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [174/200] Batch 11/12                         Loss D: -2.5151, loss G: 34.6567\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [175/200] Batch 11/12                         Loss D: -2.4060, loss G: 34.6596\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [176/200] Batch 11/12                         Loss D: -2.6861, loss G: 34.6585\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [177/200] Batch 11/12                         Loss D: -2.5633, loss G: 34.6627\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [178/200] Batch 11/12                         Loss D: -2.5601, loss G: 34.6647\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [179/200] Batch 11/12                         Loss D: -2.7021, loss G: 34.6663\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [180/200] Batch 11/12                         Loss D: -2.5621, loss G: 34.6695\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [181/200] Batch 11/12                         Loss D: -2.6313, loss G: 34.6736\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [182/200] Batch 11/12                         Loss D: -2.6859, loss G: 34.6756\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [183/200] Batch 11/12                         Loss D: -2.7911, loss G: 34.6762\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [184/200] Batch 11/12                         Loss D: -2.7673, loss G: 34.6799\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [185/200] Batch 11/12                         Loss D: -2.8176, loss G: 34.6826\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [186/200] Batch 11/12                         Loss D: -2.8196, loss G: 34.6872\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [187/200] Batch 11/12                         Loss D: -3.0500, loss G: 34.6852\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [188/200] Batch 11/12                         Loss D: -3.1681, loss G: 34.6856\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [189/200] Batch 11/12                         Loss D: -3.0929, loss G: 34.6898\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [190/200] Batch 11/12                         Loss D: -3.1733, loss G: 34.6919\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [191/200] Batch 11/12                         Loss D: -3.2626, loss G: 34.6946\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [192/200] Batch 11/12                         Loss D: -3.4445, loss G: 34.6931\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [193/200] Batch 11/12                         Loss D: -3.6195, loss G: 34.6930\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [194/200] Batch 11/12                         Loss D: -3.6317, loss G: 34.6982\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [195/200] Batch 11/12                         Loss D: -3.6644, loss G: 34.6997\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [196/200] Batch 11/12                         Loss D: -3.9584, loss G: 34.6994\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [197/200] Batch 11/12                         Loss D: -4.3245, loss G: 34.6987\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [198/200] Batch 11/12                         Loss D: -6.3353, loss G: 34.6844\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [199/200] Batch 11/12                         Loss D: -5.2096, loss G: 34.6981\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [0/200] Batch 11/12                         Loss D: 0.7478, loss G: 17.1752\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [1/200] Batch 11/12                         Loss D: 0.4254, loss G: 17.0633\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [2/200] Batch 11/12                         Loss D: -0.1208, loss G: 16.8837\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [3/200] Batch 11/12                         Loss D: -0.8311, loss G: 16.7268\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [4/200] Batch 11/12                         Loss D: -1.8662, loss G: 16.5376\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [5/200] Batch 11/12                         Loss D: -3.3640, loss G: 16.2970\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [6/200] Batch 11/12                         Loss D: -5.3470, loss G: 15.9961\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [7/200] Batch 11/12                         Loss D: -7.9566, loss G: 15.6460\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [8/200] Batch 11/12                         Loss D: -10.9426, loss G: 15.4043\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [9/200] Batch 11/12                         Loss D: -13.9389, loss G: 15.2971\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [10/200] Batch 11/12                         Loss D: -18.0592, loss G: 15.1456\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [11/200] Batch 11/12                         Loss D: -22.1446, loss G: 15.0398\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [12/200] Batch 11/12                         Loss D: -26.7767, loss G: 14.9746\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [13/200] Batch 11/12                         Loss D: -32.7708, loss G: 14.9125\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [14/200] Batch 11/12                         Loss D: -38.8090, loss G: 14.8886\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [15/200] Batch 11/12                         Loss D: -46.6858, loss G: 14.8626\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [16/200] Batch 11/12                         Loss D: -54.2488, loss G: 14.9124\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [17/200] Batch 11/12                         Loss D: -62.7652, loss G: 14.9997\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [18/200] Batch 11/12                         Loss D: -72.0334, loss G: 15.1214\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [19/200] Batch 11/12                         Loss D: -81.3616, loss G: 15.2858\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [20/200] Batch 11/12                         Loss D: -90.3340, loss G: 15.5013\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [21/200] Batch 11/12                         Loss D: -99.2546, loss G: 15.7691\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [22/200] Batch 11/12                         Loss D: -106.2770, loss G: 16.0418\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [23/200] Batch 11/12                         Loss D: -114.1245, loss G: 16.3346\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [24/200] Batch 11/12                         Loss D: -116.1796, loss G: 16.6080\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [25/200] Batch 11/12                         Loss D: -119.2123, loss G: 16.8844\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [26/200] Batch 11/12                         Loss D: -117.8139, loss G: 17.1201\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [27/200] Batch 11/12                         Loss D: -116.8703, loss G: 17.3135\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [28/200] Batch 11/12                         Loss D: -115.5214, loss G: 17.5032\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [29/200] Batch 11/12                         Loss D: -107.9556, loss G: 17.5716\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [30/200] Batch 11/12                         Loss D: -101.4068, loss G: 17.6391\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [31/200] Batch 11/12                         Loss D: -96.0214, loss G: 17.6818\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [32/200] Batch 11/12                         Loss D: -87.4253, loss G: 17.6582\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [33/200] Batch 11/12                         Loss D: -80.2045, loss G: 17.6212\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [34/200] Batch 11/12                         Loss D: -71.9968, loss G: 17.5617\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [35/200] Batch 11/12                         Loss D: -62.8906, loss G: 17.4626\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [36/200] Batch 11/12                         Loss D: -55.9834, loss G: 17.3866\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [37/200] Batch 11/12                         Loss D: -46.6779, loss G: 17.2373\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [38/200] Batch 11/12                         Loss D: -36.9034, loss G: 17.0874\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [39/200] Batch 11/12                         Loss D: -27.2624, loss G: 16.9160\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [40/200] Batch 11/12                         Loss D: -16.3885, loss G: 16.7325\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [41/200] Batch 11/12                         Loss D: -8.2594, loss G: 16.6472\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [42/200] Batch 11/12                         Loss D: -2.9283, loss G: 16.6103\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [43/200] Batch 11/12                         Loss D: 0.6266, loss G: 16.5996\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [44/200] Batch 11/12                         Loss D: 2.3231, loss G: 16.5999\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [45/200] Batch 11/12                         Loss D: 3.3939, loss G: 16.5913\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [46/200] Batch 11/12                         Loss D: 3.9637, loss G: 16.5918\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [47/200] Batch 11/12                         Loss D: 3.8815, loss G: 16.6065\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [48/200] Batch 11/12                         Loss D: 3.4600, loss G: 16.5941\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [49/200] Batch 11/12                         Loss D: 2.8470, loss G: 16.5992\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [50/200] Batch 11/12                         Loss D: 2.0621, loss G: 16.5884\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [51/200] Batch 11/12                         Loss D: 1.5764, loss G: 16.6016\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [52/200] Batch 11/12                         Loss D: 0.5530, loss G: 16.6023\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [53/200] Batch 11/12                         Loss D: 0.1720, loss G: 16.6037\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [54/200] Batch 11/12                         Loss D: -1.2289, loss G: 16.6020\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [55/200] Batch 11/12                         Loss D: -1.7887, loss G: 16.6048\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [56/200] Batch 11/12                         Loss D: -2.6036, loss G: 16.6118\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [57/200] Batch 11/12                         Loss D: -3.4267, loss G: 16.6202\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [58/200] Batch 11/12                         Loss D: -4.3651, loss G: 16.6104\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [59/200] Batch 11/12                         Loss D: -5.3189, loss G: 16.6145\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [60/200] Batch 11/12                         Loss D: -6.3267, loss G: 16.6151\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [61/200] Batch 11/12                         Loss D: -7.3097, loss G: 16.6284\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [62/200] Batch 11/12                         Loss D: -8.4862, loss G: 16.6325\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [63/200] Batch 11/12                         Loss D: -9.7858, loss G: 16.6278\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [64/200] Batch 11/12                         Loss D: -10.7544, loss G: 16.6301\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [65/200] Batch 11/12                         Loss D: -12.0896, loss G: 16.6333\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [66/200] Batch 11/12                         Loss D: -13.3020, loss G: 16.6272\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [67/200] Batch 11/12                         Loss D: -14.5871, loss G: 16.6336\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [68/200] Batch 11/12                         Loss D: -16.0128, loss G: 16.6306\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [69/200] Batch 11/12                         Loss D: -17.3901, loss G: 16.6265\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [70/200] Batch 11/12                         Loss D: -18.9012, loss G: 16.6299\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [71/200] Batch 11/12                         Loss D: -20.4545, loss G: 16.6398\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [72/200] Batch 11/12                         Loss D: -21.8890, loss G: 16.6410\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [73/200] Batch 11/12                         Loss D: -23.4786, loss G: 16.6324\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [74/200] Batch 11/12                         Loss D: -25.1004, loss G: 16.6416\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [75/200] Batch 11/12                         Loss D: -26.9127, loss G: 16.6464\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [76/200] Batch 11/12                         Loss D: -28.6429, loss G: 16.6549\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [77/200] Batch 11/12                         Loss D: -30.6041, loss G: 16.6645\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [78/200] Batch 11/12                         Loss D: -32.2384, loss G: 16.6665\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [79/200] Batch 11/12                         Loss D: -34.1428, loss G: 16.6655\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [80/200] Batch 11/12                         Loss D: -36.0835, loss G: 16.6638\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [81/200] Batch 11/12                         Loss D: -37.8451, loss G: 16.6677\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [82/200] Batch 11/12                         Loss D: -39.4635, loss G: 16.6770\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [83/200] Batch 11/12                         Loss D: -41.4895, loss G: 16.6671\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [84/200] Batch 11/12                         Loss D: -42.6414, loss G: 16.6692\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [85/200] Batch 11/12                         Loss D: -43.0845, loss G: 16.6695\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [86/200] Batch 11/12                         Loss D: -43.0324, loss G: 16.6763\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [87/200] Batch 11/12                         Loss D: 15.2996, loss G: 14.4166\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [88/200] Batch 11/12                         Loss D: 226.7695, loss G: 2.3633\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [89/200] Batch 11/12                         Loss D: 405.8666, loss G: -8.2183\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [90/200] Batch 11/12                         Loss D: 546.4388, loss G: -16.8928\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [91/200] Batch 11/12                         Loss D: 615.9382, loss G: -18.8421\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [92/200] Batch 11/12                         Loss D: 647.0529, loss G: -18.4819\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [93/200] Batch 11/12                         Loss D: 657.8964, loss G: -17.1001\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [94/200] Batch 11/12                         Loss D: 650.9781, loss G: -14.8844\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [95/200] Batch 11/12                         Loss D: 618.7357, loss G: -11.6701\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [96/200] Batch 11/12                         Loss D: 580.7587, loss G: -8.1312\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [97/200] Batch 11/12                         Loss D: 531.7375, loss G: -4.1746\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [98/200] Batch 11/12                         Loss D: 462.6338, loss G: 0.1456\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [99/200] Batch 11/12                         Loss D: 398.2926, loss G: 4.2487\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [100/200] Batch 11/12                         Loss D: 327.6857, loss G: 8.0590\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [101/200] Batch 11/12                         Loss D: 265.1566, loss G: 11.4067\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [102/200] Batch 11/12                         Loss D: 206.1556, loss G: 14.1674\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [103/200] Batch 11/12                         Loss D: 156.0510, loss G: 16.2882\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [104/200] Batch 11/12                         Loss D: 116.5396, loss G: 17.7246\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [105/200] Batch 11/12                         Loss D: 87.5544, loss G: 18.6112\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [106/200] Batch 11/12                         Loss D: 69.8938, loss G: 18.8293\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [107/200] Batch 11/12                         Loss D: 50.0778, loss G: 18.9380\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [108/200] Batch 11/12                         Loss D: 31.5094, loss G: 18.8631\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [109/200] Batch 11/12                         Loss D: 16.5011, loss G: 18.6441\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [110/200] Batch 11/12                         Loss D: 5.4179, loss G: 18.2232\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [111/200] Batch 11/12                         Loss D: -1.4466, loss G: 17.6728\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [112/200] Batch 11/12                         Loss D: -5.1209, loss G: 16.9423\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [113/200] Batch 11/12                         Loss D: -10.0037, loss G: 16.4569\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [114/200] Batch 11/12                         Loss D: -14.2064, loss G: 16.9643\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [115/200] Batch 11/12                         Loss D: -22.6470, loss G: 17.5234\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [116/200] Batch 11/12                         Loss D: -32.6070, loss G: 18.4257\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [117/200] Batch 11/12                         Loss D: -47.3501, loss G: 19.4863\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [118/200] Batch 11/12                         Loss D: -63.3149, loss G: 20.5223\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [119/200] Batch 11/12                         Loss D: -77.0789, loss G: 21.3907\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [120/200] Batch 11/12                         Loss D: -89.3820, loss G: 22.1529\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [121/200] Batch 11/12                         Loss D: -98.4968, loss G: 22.7229\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [122/200] Batch 11/12                         Loss D: -102.9778, loss G: 23.0123\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [123/200] Batch 11/12                         Loss D: -105.7359, loss G: 23.1091\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [124/200] Batch 11/12                         Loss D: -103.3904, loss G: 22.9107\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [125/200] Batch 11/12                         Loss D: -100.6546, loss G: 22.7125\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [126/200] Batch 11/12                         Loss D: -93.5918, loss G: 22.3099\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [127/200] Batch 11/12                         Loss D: -85.0469, loss G: 21.8572\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [128/200] Batch 11/12                         Loss D: -76.2993, loss G: 21.4123\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [129/200] Batch 11/12                         Loss D: -62.7107, loss G: 20.7350\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [130/200] Batch 11/12                         Loss D: -47.4253, loss G: 19.9880\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [131/200] Batch 11/12                         Loss D: -29.4317, loss G: 19.0794\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [132/200] Batch 11/12                         Loss D: -10.4487, loss G: 18.1365\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [133/200] Batch 11/12                         Loss D: 5.3324, loss G: 17.3673\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [134/200] Batch 11/12                         Loss D: 10.8982, loss G: 17.0684\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [135/200] Batch 11/12                         Loss D: 12.9990, loss G: 17.0327\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [136/200] Batch 11/12                         Loss D: 15.2753, loss G: 16.9609\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [137/200] Batch 11/12                         Loss D: 16.3862, loss G: 16.8760\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [138/200] Batch 11/12                         Loss D: 16.9589, loss G: 16.7760\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [139/200] Batch 11/12                         Loss D: 17.4097, loss G: 16.6672\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [140/200] Batch 11/12                         Loss D: 18.8511, loss G: 16.5606\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [141/200] Batch 11/12                         Loss D: 19.7808, loss G: 16.4645\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [142/200] Batch 11/12                         Loss D: 21.8665, loss G: 16.3629\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [143/200] Batch 11/12                         Loss D: 21.9004, loss G: 16.2572\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [144/200] Batch 11/12                         Loss D: 24.1436, loss G: 16.1451\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [145/200] Batch 11/12                         Loss D: 26.0170, loss G: 16.0215\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [146/200] Batch 11/12                         Loss D: 26.8544, loss G: 15.9409\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [147/200] Batch 11/12                         Loss D: 29.8493, loss G: 15.8160\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [148/200] Batch 11/12                         Loss D: 30.7813, loss G: 15.7152\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [149/200] Batch 11/12                         Loss D: 31.8667, loss G: 15.5943\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [150/200] Batch 11/12                         Loss D: 32.2326, loss G: 15.5038\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [151/200] Batch 11/12                         Loss D: 33.3494, loss G: 15.3450\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [152/200] Batch 11/12                         Loss D: 33.5133, loss G: 15.2531\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [153/200] Batch 11/12                         Loss D: 33.7199, loss G: 15.1028\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [154/200] Batch 11/12                         Loss D: 33.5609, loss G: 14.9620\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [155/200] Batch 11/12                         Loss D: 33.4045, loss G: 14.8067\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [156/200] Batch 11/12                         Loss D: 33.1446, loss G: 14.6642\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [157/200] Batch 11/12                         Loss D: 32.9202, loss G: 14.5211\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [158/200] Batch 11/12                         Loss D: 32.6613, loss G: 14.3205\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [159/200] Batch 11/12                         Loss D: 32.4030, loss G: 14.1618\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [160/200] Batch 11/12                         Loss D: 32.0997, loss G: 13.9241\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [161/200] Batch 11/12                         Loss D: 31.8686, loss G: 13.7942\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [162/200] Batch 11/12                         Loss D: 31.6114, loss G: 13.6362\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [163/200] Batch 11/12                         Loss D: 31.3496, loss G: 13.3898\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [164/200] Batch 11/12                         Loss D: 31.0956, loss G: 13.1529\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [165/200] Batch 11/12                         Loss D: 30.8040, loss G: 12.9339\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [166/200] Batch 11/12                         Loss D: 30.5323, loss G: 12.7543\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [167/200] Batch 11/12                         Loss D: 30.2638, loss G: 12.5001\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [168/200] Batch 11/12                         Loss D: 29.9939, loss G: 12.2267\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [169/200] Batch 11/12                         Loss D: 29.7146, loss G: 12.2833\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [170/200] Batch 11/12                         Loss D: 29.4290, loss G: 12.2530\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [171/200] Batch 11/12                         Loss D: 29.1727, loss G: 12.3345\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [172/200] Batch 11/12                         Loss D: 28.8978, loss G: 12.2790\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [173/200] Batch 11/12                         Loss D: 28.5928, loss G: 12.2837\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [174/200] Batch 11/12                         Loss D: 28.2828, loss G: 12.3120\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [175/200] Batch 11/12                         Loss D: 28.0453, loss G: 12.2478\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [176/200] Batch 11/12                         Loss D: 27.7292, loss G: 12.2600\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [177/200] Batch 11/12                         Loss D: 27.4704, loss G: 12.2551\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [178/200] Batch 11/12                         Loss D: 27.1794, loss G: 12.3590\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [179/200] Batch 11/12                         Loss D: 26.9093, loss G: 12.2540\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [180/200] Batch 11/12                         Loss D: 26.5873, loss G: 12.2745\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [181/200] Batch 11/12                         Loss D: 26.3734, loss G: 12.4287\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [182/200] Batch 11/12                         Loss D: 26.0717, loss G: 12.2630\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [183/200] Batch 11/12                         Loss D: 25.7803, loss G: 12.2774\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [184/200] Batch 11/12                         Loss D: 25.5163, loss G: 12.2432\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [185/200] Batch 11/12                         Loss D: 25.1851, loss G: 12.2685\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [186/200] Batch 11/12                         Loss D: 24.9370, loss G: 12.3041\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [187/200] Batch 11/12                         Loss D: 24.6771, loss G: 12.2728\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [188/200] Batch 11/12                         Loss D: 24.4039, loss G: 12.2744\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [189/200] Batch 11/12                         Loss D: 24.0970, loss G: 12.5244\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [190/200] Batch 11/12                         Loss D: 23.7949, loss G: 12.2439\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [191/200] Batch 11/12                         Loss D: 23.5392, loss G: 12.2639\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [192/200] Batch 11/12                         Loss D: 23.2568, loss G: 12.3585\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [193/200] Batch 11/12                         Loss D: 23.0147, loss G: 12.2709\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [194/200] Batch 11/12                         Loss D: 22.7071, loss G: 12.3050\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [195/200] Batch 11/12                         Loss D: 22.4207, loss G: 12.2613\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [196/200] Batch 11/12                         Loss D: 22.1220, loss G: 12.3264\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [197/200] Batch 11/12                         Loss D: 21.8771, loss G: 12.2672\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [198/200] Batch 11/12                         Loss D: 21.6058, loss G: 12.2538\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [199/200] Batch 11/12                         Loss D: 21.3026, loss G: 12.2792\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [0/200] Batch 11/12                         Loss D: 1.6260, loss G: 3.3777\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [1/200] Batch 11/12                         Loss D: 2.5583, loss G: 3.3054\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [2/200] Batch 11/12                         Loss D: 3.6213, loss G: 3.2161\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [3/200] Batch 11/12                         Loss D: 4.8881, loss G: 3.1034\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [4/200] Batch 11/12                         Loss D: 6.3265, loss G: 2.9705\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [5/200] Batch 11/12                         Loss D: 7.8689, loss G: 2.8188\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [6/200] Batch 11/12                         Loss D: 9.4827, loss G: 2.6502\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [7/200] Batch 11/12                         Loss D: 10.8665, loss G: 2.4897\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [8/200] Batch 11/12                         Loss D: 12.1485, loss G: 2.3307\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [9/200] Batch 11/12                         Loss D: 12.5424, loss G: 2.2507\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [10/200] Batch 11/12                         Loss D: 12.6676, loss G: 2.1768\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [11/200] Batch 11/12                         Loss D: 12.0503, loss G: 2.1453\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [12/200] Batch 11/12                         Loss D: 11.5923, loss G: 2.0921\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [13/200] Batch 11/12                         Loss D: 10.5940, loss G: 2.0859\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [14/200] Batch 11/12                         Loss D: 9.3958, loss G: 2.0833\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [15/200] Batch 11/12                         Loss D: 7.7055, loss G: 2.1170\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [16/200] Batch 11/12                         Loss D: 5.6966, loss G: 2.1620\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [17/200] Batch 11/12                         Loss D: 3.2178, loss G: 2.2350\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [18/200] Batch 11/12                         Loss D: 0.2237, loss G: 2.3406\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [19/200] Batch 11/12                         Loss D: -3.3523, loss G: 2.4992\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [20/200] Batch 11/12                         Loss D: -7.3522, loss G: 2.6830\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [21/200] Batch 11/12                         Loss D: -10.5048, loss G: 2.8292\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [22/200] Batch 11/12                         Loss D: -13.7254, loss G: 2.9946\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [23/200] Batch 11/12                         Loss D: -17.2814, loss G: 3.1740\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [24/200] Batch 11/12                         Loss D: -20.4932, loss G: 3.3694\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [25/200] Batch 11/12                         Loss D: -23.8230, loss G: 3.5720\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [26/200] Batch 11/12                         Loss D: -26.1530, loss G: 3.7589\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [27/200] Batch 11/12                         Loss D: -28.1456, loss G: 3.9279\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [28/200] Batch 11/12                         Loss D: -29.4080, loss G: 4.0671\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [29/200] Batch 11/12                         Loss D: -30.7953, loss G: 4.1960\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [30/200] Batch 11/12                         Loss D: -30.4813, loss G: 4.2611\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [31/200] Batch 11/12                         Loss D: -30.0688, loss G: 4.3076\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [32/200] Batch 11/12                         Loss D: -29.1445, loss G: 4.3247\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [33/200] Batch 11/12                         Loss D: -27.1313, loss G: 4.3022\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [34/200] Batch 11/12                         Loss D: -25.6799, loss G: 4.2473\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [35/200] Batch 11/12                         Loss D: -23.3003, loss G: 4.1473\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [36/200] Batch 11/12                         Loss D: -20.9776, loss G: 4.0588\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [37/200] Batch 11/12                         Loss D: -18.3539, loss G: 3.9392\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [38/200] Batch 11/12                         Loss D: -15.2588, loss G: 3.7809\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [39/200] Batch 11/12                         Loss D: -12.9419, loss G: 3.6852\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [40/200] Batch 11/12                         Loss D: -10.4010, loss G: 3.6247\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [41/200] Batch 11/12                         Loss D: -7.3205, loss G: 3.5676\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [42/200] Batch 11/12                         Loss D: -1.4054, loss G: 3.4233\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [43/200] Batch 11/12                         Loss D: 1.8508, loss G: 3.3313\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [44/200] Batch 11/12                         Loss D: 1.2189, loss G: 3.3403\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [45/200] Batch 11/12                         Loss D: 0.4888, loss G: 3.3704\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [46/200] Batch 11/12                         Loss D: -0.2529, loss G: 3.4004\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [47/200] Batch 11/12                         Loss D: -1.0265, loss G: 3.4346\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [48/200] Batch 11/12                         Loss D: -1.9634, loss G: 3.4718\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [49/200] Batch 11/12                         Loss D: -2.7183, loss G: 3.5123\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [50/200] Batch 11/12                         Loss D: -3.3333, loss G: 3.5506\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [51/200] Batch 11/12                         Loss D: -3.8923, loss G: 3.5885\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [52/200] Batch 11/12                         Loss D: -4.3354, loss G: 3.6270\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [53/200] Batch 11/12                         Loss D: -4.6547, loss G: 3.6643\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [54/200] Batch 11/12                         Loss D: -4.8795, loss G: 3.6959\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [55/200] Batch 11/12                         Loss D: -4.9095, loss G: 3.7235\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [56/200] Batch 11/12                         Loss D: -4.9893, loss G: 3.7487\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [57/200] Batch 11/12                         Loss D: -4.9297, loss G: 3.7698\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [58/200] Batch 11/12                         Loss D: -4.8999, loss G: 3.7859\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [59/200] Batch 11/12                         Loss D: -4.6795, loss G: 3.7973\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [60/200] Batch 11/12                         Loss D: -4.5192, loss G: 3.8101\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [61/200] Batch 11/12                         Loss D: -4.0871, loss G: 3.8154\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [62/200] Batch 11/12                         Loss D: -3.6953, loss G: 3.8203\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [63/200] Batch 11/12                         Loss D: -3.1992, loss G: 3.8186\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [64/200] Batch 11/12                         Loss D: -2.5881, loss G: 3.8107\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [65/200] Batch 11/12                         Loss D: -2.0334, loss G: 3.7979\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [66/200] Batch 11/12                         Loss D: -1.4490, loss G: 3.7813\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [67/200] Batch 11/12                         Loss D: -0.7203, loss G: 3.7617\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [68/200] Batch 11/12                         Loss D: 0.2375, loss G: 3.7427\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [69/200] Batch 11/12                         Loss D: 0.9416, loss G: 3.7296\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [70/200] Batch 11/12                         Loss D: 1.6077, loss G: 3.7202\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [71/200] Batch 11/12                         Loss D: 1.8864, loss G: 3.6699\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [72/200] Batch 11/12                         Loss D: 1.0379, loss G: 3.6129\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [73/200] Batch 11/12                         Loss D: 0.3700, loss G: 3.6121\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [74/200] Batch 11/12                         Loss D: 0.0018, loss G: 3.6164\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [75/200] Batch 11/12                         Loss D: -0.1503, loss G: 3.6202\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [76/200] Batch 11/12                         Loss D: -0.2833, loss G: 3.6224\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [77/200] Batch 11/12                         Loss D: -0.4009, loss G: 3.6241\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [78/200] Batch 11/12                         Loss D: -0.5264, loss G: 3.6259\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [79/200] Batch 11/12                         Loss D: -0.5773, loss G: 3.6278\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [80/200] Batch 11/12                         Loss D: -0.6899, loss G: 3.6289\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [81/200] Batch 11/12                         Loss D: -0.8019, loss G: 3.6300\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [82/200] Batch 11/12                         Loss D: -0.8917, loss G: 3.6306\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [83/200] Batch 11/12                         Loss D: -1.0088, loss G: 3.6321\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [84/200] Batch 11/12                         Loss D: -1.0544, loss G: 3.6332\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [85/200] Batch 11/12                         Loss D: -1.1657, loss G: 3.6340\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [86/200] Batch 11/12                         Loss D: -1.2854, loss G: 3.6349\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [87/200] Batch 11/12                         Loss D: -1.4087, loss G: 3.6360\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [88/200] Batch 11/12                         Loss D: -1.4579, loss G: 3.6366\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [89/200] Batch 11/12                         Loss D: -1.5930, loss G: 3.6373\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [90/200] Batch 11/12                         Loss D: -1.6706, loss G: 3.6377\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [91/200] Batch 11/12                         Loss D: -1.7701, loss G: 3.6384\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [92/200] Batch 11/12                         Loss D: -1.8471, loss G: 3.6388\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [93/200] Batch 11/12                         Loss D: -1.9701, loss G: 3.6389\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [94/200] Batch 11/12                         Loss D: -2.0457, loss G: 3.6390\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [95/200] Batch 11/12                         Loss D: -2.1571, loss G: 3.6396\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [96/200] Batch 11/12                         Loss D: -2.2196, loss G: 3.6397\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [97/200] Batch 11/12                         Loss D: -2.2640, loss G: 3.6399\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [98/200] Batch 11/12                         Loss D: -2.4341, loss G: 3.6400\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [99/200] Batch 11/12                         Loss D: -2.4624, loss G: 3.6401\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [100/200] Batch 11/12                         Loss D: -2.5029, loss G: 3.6406\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [101/200] Batch 11/12                         Loss D: -2.5889, loss G: 3.6404\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [102/200] Batch 11/12                         Loss D: -2.6959, loss G: 3.6406\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [103/200] Batch 11/12                         Loss D: -2.8027, loss G: 3.6412\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [104/200] Batch 11/12                         Loss D: -2.7942, loss G: 3.6413\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [105/200] Batch 11/12                         Loss D: -2.7950, loss G: 3.6417\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [106/200] Batch 11/12                         Loss D: -3.0029, loss G: 3.6423\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [107/200] Batch 11/12                         Loss D: -3.0249, loss G: 3.6422\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [108/200] Batch 11/12                         Loss D: -2.9465, loss G: 3.6426\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [109/200] Batch 11/12                         Loss D: -3.0785, loss G: 3.6430\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [110/200] Batch 11/12                         Loss D: -3.0093, loss G: 3.6430\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [111/200] Batch 11/12                         Loss D: -3.1392, loss G: 3.6437\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [112/200] Batch 11/12                         Loss D: -3.2890, loss G: 3.6435\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [113/200] Batch 11/12                         Loss D: -3.3018, loss G: 3.6435\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [114/200] Batch 11/12                         Loss D: -3.2443, loss G: 3.6441\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [115/200] Batch 11/12                         Loss D: -3.2800, loss G: 3.6444\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [116/200] Batch 11/12                         Loss D: -3.3859, loss G: 3.6445\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [117/200] Batch 11/12                         Loss D: -3.2967, loss G: 3.6448\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [118/200] Batch 11/12                         Loss D: -3.4613, loss G: 3.6451\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [119/200] Batch 11/12                         Loss D: -3.3897, loss G: 3.6448\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [120/200] Batch 11/12                         Loss D: -3.3942, loss G: 3.6451\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [121/200] Batch 11/12                         Loss D: -3.3550, loss G: 3.6450\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [122/200] Batch 11/12                         Loss D: -3.3620, loss G: 3.6456\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [123/200] Batch 11/12                         Loss D: -3.2318, loss G: 3.6458\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [124/200] Batch 11/12                         Loss D: -3.4860, loss G: 3.6456\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [125/200] Batch 11/12                         Loss D: -3.4319, loss G: 3.6453\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [126/200] Batch 11/12                         Loss D: -3.3906, loss G: 3.6455\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [127/200] Batch 11/12                         Loss D: -3.2471, loss G: 3.6462\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [128/200] Batch 11/12                         Loss D: -3.0263, loss G: 3.6463\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [129/200] Batch 11/12                         Loss D: -3.3017, loss G: 3.6458\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [130/200] Batch 11/12                         Loss D: -3.2938, loss G: 3.6463\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [131/200] Batch 11/12                         Loss D: -3.6569, loss G: 3.6472\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [132/200] Batch 11/12                         Loss D: -3.1710, loss G: 3.6458\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [133/200] Batch 11/12                         Loss D: -2.8079, loss G: 3.6469\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [134/200] Batch 11/12                         Loss D: -3.2310, loss G: 3.6456\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [135/200] Batch 11/12                         Loss D: -3.3982, loss G: 3.6459\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [136/200] Batch 11/12                         Loss D: -2.7424, loss G: 3.6462\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [137/200] Batch 11/12                         Loss D: -3.1754, loss G: 3.6454\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [138/200] Batch 11/12                         Loss D: -3.0538, loss G: 3.6456\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [139/200] Batch 11/12                         Loss D: -3.0138, loss G: 3.6448\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [140/200] Batch 11/12                         Loss D: -3.1661, loss G: 3.6447\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [141/200] Batch 11/12                         Loss D: -3.0089, loss G: 3.6441\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [142/200] Batch 11/12                         Loss D: -3.0883, loss G: 3.6445\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [143/200] Batch 11/12                         Loss D: -2.8304, loss G: 3.6436\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [144/200] Batch 11/12                         Loss D: -2.5278, loss G: 3.6440\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [145/200] Batch 11/12                         Loss D: -2.8650, loss G: 3.6433\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [146/200] Batch 11/12                         Loss D: -2.6305, loss G: 3.6431\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [147/200] Batch 11/12                         Loss D: -2.5824, loss G: 3.6427\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [148/200] Batch 11/12                         Loss D: -2.6140, loss G: 3.6439\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [149/200] Batch 11/12                         Loss D: -1.9696, loss G: 3.6435\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [150/200] Batch 11/12                         Loss D: -2.2630, loss G: 3.6419\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [151/200] Batch 11/12                         Loss D: -1.9492, loss G: 3.6423\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [152/200] Batch 11/12                         Loss D: -2.1262, loss G: 3.6409\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [153/200] Batch 11/12                         Loss D: -2.0053, loss G: 3.6409\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [154/200] Batch 11/12                         Loss D: -1.9206, loss G: 3.6401\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [155/200] Batch 11/12                         Loss D: -1.8320, loss G: 3.6395\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [156/200] Batch 11/12                         Loss D: -1.8832, loss G: 3.6387\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [157/200] Batch 11/12                         Loss D: -1.7591, loss G: 3.6378\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [158/200] Batch 11/12                         Loss D: -1.6159, loss G: 3.6372\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [159/200] Batch 11/12                         Loss D: -1.4668, loss G: 3.6361\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [160/200] Batch 11/12                         Loss D: -1.4601, loss G: 3.6356\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [161/200] Batch 11/12                         Loss D: -1.3369, loss G: 3.6350\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [162/200] Batch 11/12                         Loss D: -1.1684, loss G: 3.6338\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [163/200] Batch 11/12                         Loss D: -1.1124, loss G: 3.6329\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [164/200] Batch 11/12                         Loss D: -0.9321, loss G: 3.6322\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [165/200] Batch 11/12                         Loss D: -0.9192, loss G: 3.6317\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [166/200] Batch 11/12                         Loss D: -0.7735, loss G: 3.6302\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [167/200] Batch 11/12                         Loss D: -0.6347, loss G: 3.6294\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [168/200] Batch 11/12                         Loss D: -0.5510, loss G: 3.6288\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [169/200] Batch 11/12                         Loss D: -0.4884, loss G: 3.6277\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [170/200] Batch 11/12                         Loss D: -0.3591, loss G: 3.6263\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [171/200] Batch 11/12                         Loss D: -0.2199, loss G: 3.6261\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [172/200] Batch 11/12                         Loss D: -0.0355, loss G: 3.6248\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [173/200] Batch 11/12                         Loss D: 0.1111, loss G: 3.6233\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [174/200] Batch 11/12                         Loss D: 0.1958, loss G: 3.6222\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [175/200] Batch 11/12                         Loss D: 0.5132, loss G: 3.6217\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [176/200] Batch 11/12                         Loss D: 0.7362, loss G: 3.6211\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [177/200] Batch 11/12                         Loss D: 2.0897, loss G: 3.6197\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [178/200] Batch 11/12                         Loss D: 3.5620, loss G: 3.6231\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [179/200] Batch 11/12                         Loss D: 4.3715, loss G: 3.6327\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [180/200] Batch 11/12                         Loss D: 4.4193, loss G: 3.6448\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [181/200] Batch 11/12                         Loss D: 3.9761, loss G: 3.6575\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [182/200] Batch 11/12                         Loss D: 3.4866, loss G: 3.6673\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [183/200] Batch 11/12                         Loss D: 3.0639, loss G: 3.6751\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [184/200] Batch 11/12                         Loss D: 2.6833, loss G: 3.6804\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [185/200] Batch 11/12                         Loss D: 2.5114, loss G: 3.6880\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [186/200] Batch 11/12                         Loss D: 2.4257, loss G: 3.6973\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [187/200] Batch 11/12                         Loss D: 2.2615, loss G: 3.7078\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [188/200] Batch 11/12                         Loss D: 2.0095, loss G: 3.7174\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [189/200] Batch 11/12                         Loss D: 1.7597, loss G: 3.7254\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [190/200] Batch 11/12                         Loss D: 1.4244, loss G: 3.7312\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [191/200] Batch 11/12                         Loss D: 1.1461, loss G: 3.7350\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [192/200] Batch 11/12                         Loss D: 0.9026, loss G: 3.7365\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [193/200] Batch 11/12                         Loss D: 0.6863, loss G: 3.7365\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [194/200] Batch 11/12                         Loss D: 0.6261, loss G: 3.7349\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [195/200] Batch 11/12                         Loss D: 0.1922, loss G: 3.7347\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [196/200] Batch 11/12                         Loss D: -0.4642, loss G: 3.7368\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [197/200] Batch 11/12                         Loss D: -1.3309, loss G: 3.7386\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [198/200] Batch 11/12                         Loss D: -2.2009, loss G: 3.7411\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [199/200] Batch 11/12                         Loss D: -3.1360, loss G: 3.7443\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [0/200] Batch 11/12                         Loss D: 0.2623, loss G: 34.2700\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [1/200] Batch 11/12                         Loss D: 0.2429, loss G: 34.0186\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [2/200] Batch 11/12                         Loss D: 0.1803, loss G: 33.7108\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [3/200] Batch 11/12                         Loss D: 0.0682, loss G: 33.2851\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [4/200] Batch 11/12                         Loss D: -0.1261, loss G: 32.7308\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [5/200] Batch 11/12                         Loss D: -0.4343, loss G: 32.0524\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [6/200] Batch 11/12                         Loss D: -0.8773, loss G: 31.2211\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [7/200] Batch 11/12                         Loss D: -1.4830, loss G: 30.2346\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [8/200] Batch 11/12                         Loss D: -2.2612, loss G: 29.2449\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [9/200] Batch 11/12                         Loss D: -3.1081, loss G: 28.4676\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [10/200] Batch 11/12                         Loss D: -4.0760, loss G: 27.6706\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [11/200] Batch 11/12                         Loss D: -5.2483, loss G: 26.8058\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [12/200] Batch 11/12                         Loss D: -6.8265, loss G: 25.7765\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [13/200] Batch 11/12                         Loss D: -8.6736, loss G: 24.7376\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [14/200] Batch 11/12                         Loss D: -11.1356, loss G: 23.4903\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [15/200] Batch 11/12                         Loss D: -14.2891, loss G: 22.0979\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [16/200] Batch 11/12                         Loss D: -18.2444, loss G: 20.4394\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [17/200] Batch 11/12                         Loss D: -23.1717, loss G: 18.8399\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [18/200] Batch 11/12                         Loss D: -28.5809, loss G: 17.2724\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [19/200] Batch 11/12                         Loss D: -35.9059, loss G: 15.2881\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [20/200] Batch 11/12                         Loss D: -44.4931, loss G: 13.5230\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [21/200] Batch 11/12                         Loss D: -51.2736, loss G: 13.2699\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [22/200] Batch 11/12                         Loss D: -59.7128, loss G: 12.8664\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [23/200] Batch 11/12                         Loss D: -68.0780, loss G: 12.4823\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [24/200] Batch 11/12                         Loss D: -76.8113, loss G: 12.1311\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [25/200] Batch 11/12                         Loss D: -86.4795, loss G: 11.7984\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [26/200] Batch 11/12                         Loss D: -98.2273, loss G: 11.4731\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [27/200] Batch 11/12                         Loss D: -110.7094, loss G: 11.0838\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [28/200] Batch 11/12                         Loss D: -124.9448, loss G: 10.7608\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [29/200] Batch 11/12                         Loss D: -142.0336, loss G: 10.3873\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [30/200] Batch 11/12                         Loss D: -158.6852, loss G: 10.1986\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [31/200] Batch 11/12                         Loss D: -174.3802, loss G: 10.6775\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [32/200] Batch 11/12                         Loss D: -186.0450, loss G: 11.4862\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [33/200] Batch 11/12                         Loss D: -199.8086, loss G: 12.5044\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [34/200] Batch 11/12                         Loss D: -208.0744, loss G: 12.9078\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [35/200] Batch 11/12                         Loss D: -222.4713, loss G: 13.6488\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [36/200] Batch 11/12                         Loss D: -231.8574, loss G: 14.4285\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [37/200] Batch 11/12                         Loss D: -246.3430, loss G: 15.0449\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [38/200] Batch 11/12                         Loss D: -258.7543, loss G: 15.8414\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [39/200] Batch 11/12                         Loss D: -270.3297, loss G: 16.7155\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [40/200] Batch 11/12                         Loss D: -285.7507, loss G: 17.4067\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [41/200] Batch 11/12                         Loss D: -298.6098, loss G: 18.2373\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [42/200] Batch 11/12                         Loss D: -309.2874, loss G: 19.2489\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [43/200] Batch 11/12                         Loss D: -322.3576, loss G: 20.1147\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [44/200] Batch 11/12                         Loss D: -338.3850, loss G: 20.8949\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [45/200] Batch 11/12                         Loss D: -354.2402, loss G: 21.7350\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [46/200] Batch 11/12                         Loss D: -370.7669, loss G: 22.7968\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [47/200] Batch 11/12                         Loss D: -382.6327, loss G: 23.4803\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [48/200] Batch 11/12                         Loss D: -391.1840, loss G: 24.5066\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [49/200] Batch 11/12                         Loss D: -410.0162, loss G: 25.2853\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [50/200] Batch 11/12                         Loss D: -425.3742, loss G: 26.2199\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [51/200] Batch 11/12                         Loss D: -437.4712, loss G: 27.1671\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [52/200] Batch 11/12                         Loss D: -458.8919, loss G: 28.3567\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [53/200] Batch 11/12                         Loss D: -466.8451, loss G: 29.0406\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [54/200] Batch 11/12                         Loss D: -486.2500, loss G: 29.9583\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [55/200] Batch 11/12                         Loss D: -496.8829, loss G: 30.9058\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [56/200] Batch 11/12                         Loss D: -514.5923, loss G: 31.8787\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [57/200] Batch 11/12                         Loss D: -526.5126, loss G: 32.8496\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [58/200] Batch 11/12                         Loss D: -534.9115, loss G: 33.4672\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [59/200] Batch 11/12                         Loss D: -553.8162, loss G: 34.6181\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [60/200] Batch 11/12                         Loss D: -556.6450, loss G: 35.5930\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [61/200] Batch 11/12                         Loss D: -558.7025, loss G: 36.8532\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [62/200] Batch 11/12                         Loss D: -563.4382, loss G: 38.2049\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [63/200] Batch 11/12                         Loss D: -560.4265, loss G: 39.6216\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [64/200] Batch 11/12                         Loss D: -555.7665, loss G: 41.0703\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [65/200] Batch 11/12                         Loss D: -543.5591, loss G: 42.4328\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [66/200] Batch 11/12                         Loss D: -521.3098, loss G: 43.6129\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [67/200] Batch 11/12                         Loss D: -494.0474, loss G: 44.6276\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [68/200] Batch 11/12                         Loss D: -463.9057, loss G: 45.5069\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [69/200] Batch 11/12                         Loss D: -422.5436, loss G: 45.9188\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [70/200] Batch 11/12                         Loss D: -371.2090, loss G: 45.8441\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [71/200] Batch 11/12                         Loss D: -311.3606, loss G: 45.2365\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [72/200] Batch 11/12                         Loss D: -254.4361, loss G: 44.5662\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [73/200] Batch 11/12                         Loss D: -196.7317, loss G: 43.5449\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [74/200] Batch 11/12                         Loss D: -143.9397, loss G: 42.5955\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [75/200] Batch 11/12                         Loss D: -90.6210, loss G: 41.4583\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [76/200] Batch 11/12                         Loss D: -60.5424, loss G: 40.7464\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [77/200] Batch 11/12                         Loss D: -63.9552, loss G: 40.3896\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [78/200] Batch 11/12                         Loss D: -63.7954, loss G: 39.7371\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [79/200] Batch 11/12                         Loss D: -65.2757, loss G: 38.4000\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [80/200] Batch 11/12                         Loss D: -59.4565, loss G: 36.6006\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [81/200] Batch 11/12                         Loss D: -59.3727, loss G: 36.1897\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [82/200] Batch 11/12                         Loss D: -55.5010, loss G: 35.5918\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [83/200] Batch 11/12                         Loss D: -48.6077, loss G: 34.8812\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [84/200] Batch 11/12                         Loss D: -39.0619, loss G: 33.9852\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [85/200] Batch 11/12                         Loss D: -30.8058, loss G: 33.5639\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [86/200] Batch 11/12                         Loss D: -28.4307, loss G: 33.5127\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [87/200] Batch 11/12                         Loss D: 7.6554, loss G: 31.5334\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [88/200] Batch 11/12                         Loss D: 78.5655, loss G: 26.8133\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [89/200] Batch 11/12                         Loss D: 117.6532, loss G: 22.8580\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [90/200] Batch 11/12                         Loss D: 142.6720, loss G: 19.8497\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [91/200] Batch 11/12                         Loss D: 161.0500, loss G: 17.0485\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [92/200] Batch 11/12                         Loss D: 173.5426, loss G: 14.8272\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [93/200] Batch 11/12                         Loss D: 179.3248, loss G: 13.4417\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [94/200] Batch 11/12                         Loss D: 162.0794, loss G: 14.5237\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [95/200] Batch 11/12                         Loss D: 151.9689, loss G: 15.4696\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [96/200] Batch 11/12                         Loss D: 143.2756, loss G: 16.4102\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [97/200] Batch 11/12                         Loss D: 128.9901, loss G: 17.3691\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [98/200] Batch 11/12                         Loss D: 114.9844, loss G: 18.0615\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [99/200] Batch 11/12                         Loss D: 102.2607, loss G: 18.8899\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [100/200] Batch 11/12                         Loss D: 91.5616, loss G: 19.4016\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [101/200] Batch 11/12                         Loss D: 83.1776, loss G: 20.1085\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [102/200] Batch 11/12                         Loss D: 74.1685, loss G: 20.6657\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [103/200] Batch 11/12                         Loss D: 65.7003, loss G: 21.1554\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [104/200] Batch 11/12                         Loss D: 58.2183, loss G: 21.8365\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [105/200] Batch 11/12                         Loss D: 50.4893, loss G: 22.2734\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [106/200] Batch 11/12                         Loss D: 42.7762, loss G: 22.8318\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [107/200] Batch 11/12                         Loss D: 35.9568, loss G: 23.1653\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [108/200] Batch 11/12                         Loss D: 28.7343, loss G: 23.7852\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [109/200] Batch 11/12                         Loss D: 23.2532, loss G: 24.0500\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [110/200] Batch 11/12                         Loss D: 16.2807, loss G: 24.5359\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [111/200] Batch 11/12                         Loss D: 9.5827, loss G: 24.9760\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [112/200] Batch 11/12                         Loss D: 3.6079, loss G: 25.2910\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [113/200] Batch 11/12                         Loss D: -1.9310, loss G: 25.8325\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [114/200] Batch 11/12                         Loss D: -7.7593, loss G: 26.2844\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [115/200] Batch 11/12                         Loss D: -12.4775, loss G: 26.4655\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [116/200] Batch 11/12                         Loss D: -15.4595, loss G: 26.8792\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [117/200] Batch 11/12                         Loss D: -23.3097, loss G: 27.2033\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [118/200] Batch 11/12                         Loss D: -24.9729, loss G: 27.4991\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [119/200] Batch 11/12                         Loss D: -29.3874, loss G: 27.8528\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [120/200] Batch 11/12                         Loss D: -35.6581, loss G: 28.1224\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [121/200] Batch 11/12                         Loss D: -42.5149, loss G: 28.4562\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [122/200] Batch 11/12                         Loss D: -49.1542, loss G: 28.8252\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [123/200] Batch 11/12                         Loss D: -53.8139, loss G: 29.1184\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [124/200] Batch 11/12                         Loss D: -60.1943, loss G: 29.4114\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [125/200] Batch 11/12                         Loss D: -66.2326, loss G: 29.7386\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [126/200] Batch 11/12                         Loss D: -71.0531, loss G: 30.1370\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [127/200] Batch 11/12                         Loss D: -79.6821, loss G: 30.3906\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [128/200] Batch 11/12                         Loss D: -84.1339, loss G: 30.7548\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [129/200] Batch 11/12                         Loss D: -87.8490, loss G: 31.0750\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [130/200] Batch 11/12                         Loss D: -94.7986, loss G: 31.4045\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [131/200] Batch 11/12                         Loss D: -98.2290, loss G: 31.7749\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [132/200] Batch 11/12                         Loss D: -104.9617, loss G: 32.1309\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [133/200] Batch 11/12                         Loss D: -113.8941, loss G: 32.4331\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [134/200] Batch 11/12                         Loss D: -117.9595, loss G: 32.8544\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [135/200] Batch 11/12                         Loss D: -125.8417, loss G: 33.1768\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [136/200] Batch 11/12                         Loss D: -130.9600, loss G: 33.5895\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [137/200] Batch 11/12                         Loss D: -131.7342, loss G: 33.9803\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [138/200] Batch 11/12                         Loss D: -134.2432, loss G: 34.3497\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [139/200] Batch 11/12                         Loss D: -139.7854, loss G: 34.7859\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [140/200] Batch 11/12                         Loss D: -139.7793, loss G: 35.1265\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [141/200] Batch 11/12                         Loss D: -140.4789, loss G: 35.4890\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [142/200] Batch 11/12                         Loss D: -141.9261, loss G: 35.8583\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [143/200] Batch 11/12                         Loss D: -140.0591, loss G: 36.1801\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [144/200] Batch 11/12                         Loss D: -136.8686, loss G: 36.5024\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [145/200] Batch 11/12                         Loss D: -135.2716, loss G: 36.7917\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [146/200] Batch 11/12                         Loss D: -133.4237, loss G: 37.0629\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [147/200] Batch 11/12                         Loss D: -133.6274, loss G: 37.3127\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [148/200] Batch 11/12                         Loss D: -135.1591, loss G: 37.6027\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [149/200] Batch 11/12                         Loss D: -149.3961, loss G: 38.1085\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [150/200] Batch 11/12                         Loss D: -163.7495, loss G: 38.2287\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [151/200] Batch 11/12                         Loss D: -160.3165, loss G: 38.5011\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [152/200] Batch 11/12                         Loss D: -152.4449, loss G: 38.5861\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [153/200] Batch 11/12                         Loss D: -144.4796, loss G: 38.6321\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [154/200] Batch 11/12                         Loss D: -135.0482, loss G: 38.5922\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [155/200] Batch 11/12                         Loss D: -120.6489, loss G: 38.3292\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [156/200] Batch 11/12                         Loss D: -106.6764, loss G: 38.0144\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [157/200] Batch 11/12                         Loss D: -87.8853, loss G: 37.5131\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [158/200] Batch 11/12                         Loss D: -69.6498, loss G: 36.9502\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [159/200] Batch 11/12                         Loss D: -51.6934, loss G: 36.3234\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [160/200] Batch 11/12                         Loss D: -33.7157, loss G: 35.6126\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [161/200] Batch 11/12                         Loss D: -16.8286, loss G: 34.9134\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [162/200] Batch 11/12                         Loss D: 1.3480, loss G: 34.2569\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [163/200] Batch 11/12                         Loss D: 3.3716, loss G: 34.0903\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [164/200] Batch 11/12                         Loss D: 4.6887, loss G: 33.9765\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [165/200] Batch 11/12                         Loss D: 5.8161, loss G: 33.9652\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [166/200] Batch 11/12                         Loss D: 5.8025, loss G: 33.9895\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [167/200] Batch 11/12                         Loss D: 6.1346, loss G: 33.9875\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [168/200] Batch 11/12                         Loss D: 6.1867, loss G: 33.9946\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [169/200] Batch 11/12                         Loss D: 5.9487, loss G: 33.9997\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [170/200] Batch 11/12                         Loss D: 6.2637, loss G: 34.0102\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [171/200] Batch 11/12                         Loss D: 6.2779, loss G: 34.0156\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [172/200] Batch 11/12                         Loss D: 6.5582, loss G: 34.0308\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [173/200] Batch 11/12                         Loss D: 6.7168, loss G: 34.0444\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [174/200] Batch 11/12                         Loss D: 6.6269, loss G: 34.0339\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [175/200] Batch 11/12                         Loss D: 6.9816, loss G: 34.0438\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [176/200] Batch 11/12                         Loss D: 6.9781, loss G: 34.0547\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [177/200] Batch 11/12                         Loss D: 7.1024, loss G: 34.0588\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [178/200] Batch 11/12                         Loss D: 7.3877, loss G: 34.0743\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [179/200] Batch 11/12                         Loss D: 7.3746, loss G: 34.0840\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [180/200] Batch 11/12                         Loss D: 7.9170, loss G: 34.1301\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [181/200] Batch 11/12                         Loss D: 7.9297, loss G: 34.0942\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [182/200] Batch 11/12                         Loss D: 7.6708, loss G: 34.0974\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [183/200] Batch 11/12                         Loss D: 8.1802, loss G: 34.1101\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [184/200] Batch 11/12                         Loss D: 8.1906, loss G: 34.1206\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [185/200] Batch 11/12                         Loss D: 8.2322, loss G: 34.1191\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [186/200] Batch 11/12                         Loss D: 8.3428, loss G: 34.1376\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [187/200] Batch 11/12                         Loss D: 8.5089, loss G: 34.1491\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [188/200] Batch 11/12                         Loss D: 8.3414, loss G: 34.1524\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [189/200] Batch 11/12                         Loss D: 8.8489, loss G: 34.1572\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [190/200] Batch 11/12                         Loss D: 8.8566, loss G: 34.1648\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [191/200] Batch 11/12                         Loss D: 8.9119, loss G: 34.1643\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [192/200] Batch 11/12                         Loss D: 8.6314, loss G: 34.1842\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [193/200] Batch 11/12                         Loss D: 9.3254, loss G: 34.1795\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [194/200] Batch 11/12                         Loss D: 9.3935, loss G: 34.1977\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [195/200] Batch 11/12                         Loss D: 9.0285, loss G: 34.2052\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [196/200] Batch 11/12                         Loss D: 9.3766, loss G: 34.2212\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [197/200] Batch 11/12                         Loss D: 9.4604, loss G: 34.2212\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [198/200] Batch 11/12                         Loss D: 9.8127, loss G: 34.2228\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [199/200] Batch 11/12                         Loss D: 9.8672, loss G: 34.2277\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [0/200] Batch 11/12                         Loss D: 0.2449, loss G: 17.2748\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [1/200] Batch 11/12                         Loss D: 0.1719, loss G: 17.1461\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [2/200] Batch 11/12                         Loss D: 0.0484, loss G: 16.9888\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [3/200] Batch 11/12                         Loss D: -0.1394, loss G: 16.7930\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [4/200] Batch 11/12                         Loss D: -0.4426, loss G: 16.5589\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [5/200] Batch 11/12                         Loss D: -0.9259, loss G: 16.2424\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [6/200] Batch 11/12                         Loss D: -1.6245, loss G: 15.8574\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [7/200] Batch 11/12                         Loss D: -2.5990, loss G: 15.4019\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [8/200] Batch 11/12                         Loss D: -3.9557, loss G: 14.8686\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [9/200] Batch 11/12                         Loss D: -5.8425, loss G: 14.4833\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [10/200] Batch 11/12                         Loss D: -8.2517, loss G: 14.1946\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [11/200] Batch 11/12                         Loss D: -11.0629, loss G: 13.8906\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [12/200] Batch 11/12                         Loss D: -14.5504, loss G: 13.5630\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [13/200] Batch 11/12                         Loss D: -18.9380, loss G: 13.2249\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [14/200] Batch 11/12                         Loss D: -24.4179, loss G: 12.8766\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [15/200] Batch 11/12                         Loss D: -31.2251, loss G: 12.5600\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [16/200] Batch 11/12                         Loss D: -39.1999, loss G: 12.2732\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [17/200] Batch 11/12                         Loss D: -49.3072, loss G: 11.9456\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [18/200] Batch 11/12                         Loss D: -59.1395, loss G: 11.7594\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [19/200] Batch 11/12                         Loss D: -70.9849, loss G: 11.6246\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [20/200] Batch 11/12                         Loss D: -83.2067, loss G: 11.6233\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [21/200] Batch 11/12                         Loss D: -95.8336, loss G: 11.7048\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [22/200] Batch 11/12                         Loss D: -109.5807, loss G: 11.8764\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [23/200] Batch 11/12                         Loss D: -122.2400, loss G: 12.1829\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [24/200] Batch 11/12                         Loss D: -136.6159, loss G: 12.3718\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [25/200] Batch 11/12                         Loss D: -145.6740, loss G: 12.8159\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [26/200] Batch 11/12                         Loss D: -156.2900, loss G: 13.4043\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [27/200] Batch 11/12                         Loss D: -165.7185, loss G: 14.0135\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [28/200] Batch 11/12                         Loss D: -173.3954, loss G: 14.6331\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [29/200] Batch 11/12                         Loss D: -178.8975, loss G: 15.6212\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [30/200] Batch 11/12                         Loss D: -188.0696, loss G: 16.6413\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [31/200] Batch 11/12                         Loss D: -193.0877, loss G: 17.6337\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [32/200] Batch 11/12                         Loss D: -199.1401, loss G: 18.5935\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [33/200] Batch 11/12                         Loss D: -202.0633, loss G: 19.4241\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [34/200] Batch 11/12                         Loss D: -205.1003, loss G: 20.1748\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [35/200] Batch 11/12                         Loss D: -203.8419, loss G: 20.7421\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [36/200] Batch 11/12                         Loss D: -203.2953, loss G: 21.2712\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [37/200] Batch 11/12                         Loss D: -198.0724, loss G: 21.5325\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [38/200] Batch 11/12                         Loss D: -192.9599, loss G: 21.7186\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [39/200] Batch 11/12                         Loss D: -186.4566, loss G: 21.7888\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [40/200] Batch 11/12                         Loss D: -180.0396, loss G: 21.8092\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [41/200] Batch 11/12                         Loss D: -170.2912, loss G: 21.7034\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [42/200] Batch 11/12                         Loss D: -161.8071, loss G: 21.6011\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [43/200] Batch 11/12                         Loss D: -150.6618, loss G: 21.3979\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [44/200] Batch 11/12                         Loss D: -142.3604, loss G: 21.2492\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [45/200] Batch 11/12                         Loss D: -132.5873, loss G: 21.0267\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [46/200] Batch 11/12                         Loss D: -120.9329, loss G: 20.7272\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [47/200] Batch 11/12                         Loss D: -111.3604, loss G: 20.4601\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [48/200] Batch 11/12                         Loss D: -98.4744, loss G: 20.0451\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [49/200] Batch 11/12                         Loss D: -71.9043, loss G: 18.3551\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [50/200] Batch 11/12                         Loss D: -40.8846, loss G: 16.4464\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [51/200] Batch 11/12                         Loss D: -15.9809, loss G: 15.1616\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [52/200] Batch 11/12                         Loss D: -2.8059, loss G: 14.6250\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [53/200] Batch 11/12                         Loss D: -2.2344, loss G: 14.5875\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [54/200] Batch 11/12                         Loss D: -1.9666, loss G: 14.5760\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [55/200] Batch 11/12                         Loss D: -1.8433, loss G: 14.5872\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [56/200] Batch 11/12                         Loss D: -2.2296, loss G: 14.7007\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [57/200] Batch 11/12                         Loss D: -2.2485, loss G: 14.8023\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [58/200] Batch 11/12                         Loss D: -3.5086, loss G: 14.9796\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [59/200] Batch 11/12                         Loss D: -6.3291, loss G: 15.1741\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [60/200] Batch 11/12                         Loss D: -10.0084, loss G: 15.4153\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [61/200] Batch 11/12                         Loss D: -14.1986, loss G: 15.5952\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [62/200] Batch 11/12                         Loss D: -18.4539, loss G: 15.8598\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [63/200] Batch 11/12                         Loss D: -23.1659, loss G: 16.1579\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [64/200] Batch 11/12                         Loss D: -28.4489, loss G: 16.4573\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [65/200] Batch 11/12                         Loss D: -32.3541, loss G: 16.7788\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [66/200] Batch 11/12                         Loss D: -35.7981, loss G: 17.0974\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [67/200] Batch 11/12                         Loss D: -37.5714, loss G: 17.4060\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [68/200] Batch 11/12                         Loss D: -37.8962, loss G: 17.6857\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [69/200] Batch 11/12                         Loss D: -35.9284, loss G: 17.9103\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [70/200] Batch 11/12                         Loss D: -31.2856, loss G: 18.0832\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [71/200] Batch 11/12                         Loss D: -28.5298, loss G: 18.2480\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [72/200] Batch 11/12                         Loss D: -26.9259, loss G: 18.4123\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [73/200] Batch 11/12                         Loss D: -23.8952, loss G: 18.5425\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [74/200] Batch 11/12                         Loss D: -20.3195, loss G: 18.6297\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [75/200] Batch 11/12                         Loss D: -17.3356, loss G: 18.7087\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [76/200] Batch 11/12                         Loss D: -12.9863, loss G: 18.7470\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [77/200] Batch 11/12                         Loss D: -8.2419, loss G: 18.7670\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [78/200] Batch 11/12                         Loss D: -3.3426, loss G: 18.7645\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [79/200] Batch 11/12                         Loss D: 1.8325, loss G: 18.7329\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [80/200] Batch 11/12                         Loss D: 7.1612, loss G: 18.6849\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [81/200] Batch 11/12                         Loss D: 12.9135, loss G: 18.6054\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [82/200] Batch 11/12                         Loss D: 15.5067, loss G: 18.5513\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [83/200] Batch 11/12                         Loss D: 16.9141, loss G: 18.4981\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [84/200] Batch 11/12                         Loss D: 17.9346, loss G: 18.4376\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [85/200] Batch 11/12                         Loss D: 18.8597, loss G: 18.3610\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [86/200] Batch 11/12                         Loss D: 20.0188, loss G: 18.2773\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [87/200] Batch 11/12                         Loss D: 21.3635, loss G: 18.1956\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [88/200] Batch 11/12                         Loss D: 22.8641, loss G: 18.1177\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [89/200] Batch 11/12                         Loss D: 22.7482, loss G: 18.0167\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [90/200] Batch 11/12                         Loss D: 22.0950, loss G: 17.9239\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [91/200] Batch 11/12                         Loss D: 21.2529, loss G: 17.8265\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [92/200] Batch 11/12                         Loss D: 20.2726, loss G: 17.6992\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [93/200] Batch 11/12                         Loss D: 19.3239, loss G: 17.6590\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [94/200] Batch 11/12                         Loss D: 17.2494, loss G: 17.6368\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [95/200] Batch 11/12                         Loss D: 14.2617, loss G: 17.6024\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [96/200] Batch 11/12                         Loss D: 10.9620, loss G: 17.5581\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [97/200] Batch 11/12                         Loss D: 7.5528, loss G: 17.5042\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [98/200] Batch 11/12                         Loss D: 3.7457, loss G: 17.4361\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [99/200] Batch 11/12                         Loss D: -0.1479, loss G: 17.3840\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [100/200] Batch 11/12                         Loss D: -0.3529, loss G: 17.3636\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [101/200] Batch 11/12                         Loss D: -0.0591, loss G: 17.3569\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [102/200] Batch 11/12                         Loss D: -0.0925, loss G: 17.3550\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [103/200] Batch 11/12                         Loss D: -0.3502, loss G: 17.3530\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [104/200] Batch 11/12                         Loss D: -0.2295, loss G: 17.3505\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [105/200] Batch 11/12                         Loss D: -0.2321, loss G: 17.3488\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [106/200] Batch 11/12                         Loss D: -0.3338, loss G: 17.3470\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [107/200] Batch 11/12                         Loss D: -0.3359, loss G: 17.3453\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [108/200] Batch 11/12                         Loss D: -0.2252, loss G: 17.3440\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [109/200] Batch 11/12                         Loss D: -0.3382, loss G: 17.3432\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [110/200] Batch 11/12                         Loss D: -0.2816, loss G: 17.3417\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [111/200] Batch 11/12                         Loss D: -0.2506, loss G: 17.3413\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [112/200] Batch 11/12                         Loss D: -0.3326, loss G: 17.3407\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [113/200] Batch 11/12                         Loss D: -0.3993, loss G: 17.3393\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [114/200] Batch 11/12                         Loss D: -0.4011, loss G: 17.3384\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [115/200] Batch 11/12                         Loss D: -0.3129, loss G: 17.3379\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [116/200] Batch 11/12                         Loss D: -0.1446, loss G: 17.3382\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [117/200] Batch 11/12                         Loss D: -0.2795, loss G: 17.3368\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [118/200] Batch 11/12                         Loss D: -0.4811, loss G: 17.3356\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [119/200] Batch 11/12                         Loss D: -0.4313, loss G: 17.3360\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [120/200] Batch 11/12                         Loss D: -0.4629, loss G: 17.3355\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [121/200] Batch 11/12                         Loss D: -0.5872, loss G: 17.3368\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [122/200] Batch 11/12                         Loss D: -0.0881, loss G: 17.3368\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [123/200] Batch 11/12                         Loss D: -0.2948, loss G: 17.3339\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [124/200] Batch 11/12                         Loss D: -0.0237, loss G: 17.3384\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [125/200] Batch 11/12                         Loss D: -0.1861, loss G: 17.3349\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [126/200] Batch 11/12                         Loss D: -0.2325, loss G: 17.3348\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [127/200] Batch 11/12                         Loss D: -0.3634, loss G: 17.3337\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [128/200] Batch 11/12                         Loss D: -0.2749, loss G: 17.3336\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [129/200] Batch 11/12                         Loss D: -0.2611, loss G: 17.3341\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [130/200] Batch 11/12                         Loss D: -0.1877, loss G: 17.3343\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [131/200] Batch 11/12                         Loss D: -0.1534, loss G: 17.3341\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [132/200] Batch 11/12                         Loss D: -0.3922, loss G: 17.3322\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [133/200] Batch 11/12                         Loss D: -0.0797, loss G: 17.3353\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [134/200] Batch 11/12                         Loss D: -0.5381, loss G: 17.3324\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [135/200] Batch 11/12                         Loss D: -0.4867, loss G: 17.3318\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [136/200] Batch 11/12                         Loss D: 0.0070, loss G: 17.3351\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [137/200] Batch 11/12                         Loss D: -0.2064, loss G: 17.3320\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [138/200] Batch 11/12                         Loss D: -0.3949, loss G: 17.3299\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [139/200] Batch 11/12                         Loss D: -0.3976, loss G: 17.3292\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [140/200] Batch 11/12                         Loss D: -0.4239, loss G: 17.3279\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [141/200] Batch 11/12                         Loss D: -0.4765, loss G: 17.3273\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [142/200] Batch 11/12                         Loss D: -0.5334, loss G: 17.3256\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [143/200] Batch 11/12                         Loss D: -0.4725, loss G: 17.3239\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [144/200] Batch 11/12                         Loss D: -0.5817, loss G: 17.3232\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [145/200] Batch 11/12                         Loss D: -0.4728, loss G: 17.3231\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [146/200] Batch 11/12                         Loss D: -0.5093, loss G: 17.3230\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [147/200] Batch 11/12                         Loss D: -0.3644, loss G: 17.3228\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [148/200] Batch 11/12                         Loss D: -0.4872, loss G: 17.3221\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [149/200] Batch 11/12                         Loss D: -0.5341, loss G: 17.3231\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [150/200] Batch 11/12                         Loss D: -0.4392, loss G: 17.3220\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [151/200] Batch 11/12                         Loss D: -0.4385, loss G: 17.3216\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [152/200] Batch 11/12                         Loss D: -0.6567, loss G: 17.3230\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [153/200] Batch 11/12                         Loss D: -0.5956, loss G: 17.3225\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [154/200] Batch 11/12                         Loss D: -0.5869, loss G: 17.3215\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [155/200] Batch 11/12                         Loss D: -0.5772, loss G: 17.3211\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [156/200] Batch 11/12                         Loss D: -0.5886, loss G: 17.3210\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [157/200] Batch 11/12                         Loss D: -0.5442, loss G: 17.3206\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [158/200] Batch 11/12                         Loss D: -0.5788, loss G: 17.3206\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [159/200] Batch 11/12                         Loss D: -0.4606, loss G: 17.3206\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [160/200] Batch 11/12                         Loss D: -0.4779, loss G: 17.3202\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [161/200] Batch 11/12                         Loss D: -0.4532, loss G: 17.3202\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [162/200] Batch 11/12                         Loss D: -0.5888, loss G: 17.3200\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [163/200] Batch 11/12                         Loss D: -0.0474, loss G: 17.3234\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [164/200] Batch 11/12                         Loss D: -0.9137, loss G: 17.3255\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [165/200] Batch 11/12                         Loss D: -0.5559, loss G: 17.3216\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [166/200] Batch 11/12                         Loss D: -0.2258, loss G: 17.3217\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [167/200] Batch 11/12                         Loss D: -0.2574, loss G: 17.3211\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [168/200] Batch 11/12                         Loss D: -0.2631, loss G: 17.3209\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [169/200] Batch 11/12                         Loss D: -0.2873, loss G: 17.3205\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [170/200] Batch 11/12                         Loss D: -0.5509, loss G: 17.3188\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [171/200] Batch 11/12                         Loss D: -0.5830, loss G: 17.3193\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [172/200] Batch 11/12                         Loss D: -0.3435, loss G: 17.3199\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [173/200] Batch 11/12                         Loss D: -0.4261, loss G: 17.3193\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [174/200] Batch 11/12                         Loss D: -0.3931, loss G: 17.3199\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [175/200] Batch 11/12                         Loss D: -0.9295, loss G: 17.3230\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [176/200] Batch 11/12                         Loss D: -0.0737, loss G: 17.3231\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [177/200] Batch 11/12                         Loss D: -0.6126, loss G: 17.3222\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [178/200] Batch 11/12                         Loss D: -0.4463, loss G: 17.3202\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [179/200] Batch 11/12                         Loss D: -0.6809, loss G: 17.3211\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [180/200] Batch 11/12                         Loss D: -0.8982, loss G: 17.3216\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [181/200] Batch 11/12                         Loss D: -0.6090, loss G: 17.3194\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [182/200] Batch 11/12                         Loss D: -0.7900, loss G: 17.3208\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [183/200] Batch 11/12                         Loss D: -0.5958, loss G: 17.3196\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [184/200] Batch 11/12                         Loss D: -0.4880, loss G: 17.3204\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [185/200] Batch 11/12                         Loss D: -0.1694, loss G: 17.3237\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [186/200] Batch 11/12                         Loss D: -0.6784, loss G: 17.3200\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [187/200] Batch 11/12                         Loss D: -0.9217, loss G: 17.3218\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [188/200] Batch 11/12                         Loss D: -0.6608, loss G: 17.3204\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [189/200] Batch 11/12                         Loss D: -0.2806, loss G: 17.3222\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [190/200] Batch 11/12                         Loss D: 0.0708, loss G: 17.3256\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [191/200] Batch 11/12                         Loss D: -0.3197, loss G: 17.3254\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [192/200] Batch 11/12                         Loss D: -0.0828, loss G: 17.3251\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [193/200] Batch 11/12                         Loss D: -0.9464, loss G: 17.3212\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [194/200] Batch 11/12                         Loss D: -0.8444, loss G: 17.3197\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [195/200] Batch 11/12                         Loss D: -0.7197, loss G: 17.3199\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [196/200] Batch 11/12                         Loss D: -0.7618, loss G: 17.3203\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [197/200] Batch 11/12                         Loss D: -0.4328, loss G: 17.3221\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [198/200] Batch 11/12                         Loss D: -0.2354, loss G: 17.3234\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [199/200] Batch 11/12                         Loss D: -0.9535, loss G: 17.3211\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [0/200] Batch 11/12                         Loss D: 0.9438, loss G: 3.0889\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [1/200] Batch 11/12                         Loss D: 1.2604, loss G: 3.0425\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [2/200] Batch 11/12                         Loss D: 1.6261, loss G: 2.9787\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [3/200] Batch 11/12                         Loss D: 1.9427, loss G: 2.8970\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [4/200] Batch 11/12                         Loss D: 2.2583, loss G: 2.7932\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [5/200] Batch 11/12                         Loss D: 2.5017, loss G: 2.6829\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [6/200] Batch 11/12                         Loss D: 2.6739, loss G: 2.5497\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [7/200] Batch 11/12                         Loss D: 2.6389, loss G: 2.4158\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [8/200] Batch 11/12                         Loss D: 2.1646, loss G: 2.3974\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [9/200] Batch 11/12                         Loss D: 1.8955, loss G: 2.3972\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [10/200] Batch 11/12                         Loss D: 1.3171, loss G: 2.4059\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [11/200] Batch 11/12                         Loss D: 0.5726, loss G: 2.4240\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [12/200] Batch 11/12                         Loss D: -0.2646, loss G: 2.4482\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [13/200] Batch 11/12                         Loss D: -1.2044, loss G: 2.4822\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [14/200] Batch 11/12                         Loss D: -2.2033, loss G: 2.5355\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [15/200] Batch 11/12                         Loss D: -3.3289, loss G: 2.5906\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [16/200] Batch 11/12                         Loss D: -4.6728, loss G: 2.6287\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [17/200] Batch 11/12                         Loss D: -6.0949, loss G: 2.6750\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [18/200] Batch 11/12                         Loss D: -8.0168, loss G: 2.7479\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [19/200] Batch 11/12                         Loss D: -9.7303, loss G: 2.8430\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [20/200] Batch 11/12                         Loss D: -11.5465, loss G: 2.9479\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [21/200] Batch 11/12                         Loss D: -13.3331, loss G: 3.0559\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [22/200] Batch 11/12                         Loss D: -14.5042, loss G: 3.1694\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [23/200] Batch 11/12                         Loss D: -15.8942, loss G: 3.2723\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [24/200] Batch 11/12                         Loss D: -16.5706, loss G: 3.3684\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [25/200] Batch 11/12                         Loss D: -16.7752, loss G: 3.4467\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [26/200] Batch 11/12                         Loss D: -17.0001, loss G: 3.5144\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [27/200] Batch 11/12                         Loss D: -16.6126, loss G: 3.5599\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [28/200] Batch 11/12                         Loss D: -15.9256, loss G: 3.5922\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [29/200] Batch 11/12                         Loss D: -14.9931, loss G: 3.6072\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [30/200] Batch 11/12                         Loss D: -13.8801, loss G: 3.6124\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [31/200] Batch 11/12                         Loss D: -12.7944, loss G: 3.6075\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [32/200] Batch 11/12                         Loss D: -11.3384, loss G: 3.5761\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [33/200] Batch 11/12                         Loss D: -9.8001, loss G: 3.5380\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [34/200] Batch 11/12                         Loss D: -7.8491, loss G: 3.4753\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [35/200] Batch 11/12                         Loss D: -6.1354, loss G: 3.4247\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [36/200] Batch 11/12                         Loss D: -4.1718, loss G: 3.3673\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [37/200] Batch 11/12                         Loss D: -3.5012, loss G: 3.3594\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [38/200] Batch 11/12                         Loss D: -3.3675, loss G: 3.3602\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [39/200] Batch 11/12                         Loss D: -3.2352, loss G: 3.3616\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [40/200] Batch 11/12                         Loss D: -3.0658, loss G: 3.3597\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [41/200] Batch 11/12                         Loss D: -2.9749, loss G: 3.3581\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [42/200] Batch 11/12                         Loss D: -2.7756, loss G: 3.3526\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [43/200] Batch 11/12                         Loss D: -2.6177, loss G: 3.3453\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [44/200] Batch 11/12                         Loss D: -2.3511, loss G: 3.3319\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [45/200] Batch 11/12                         Loss D: -2.0240, loss G: 3.3201\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [46/200] Batch 11/12                         Loss D: -1.8403, loss G: 3.3121\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [47/200] Batch 11/12                         Loss D: -1.7001, loss G: 3.3032\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [48/200] Batch 11/12                         Loss D: -1.5756, loss G: 3.2946\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [49/200] Batch 11/12                         Loss D: 0.1593, loss G: 3.1958\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [50/200] Batch 11/12                         Loss D: 0.1483, loss G: 3.2005\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [51/200] Batch 11/12                         Loss D: -0.1048, loss G: 3.2140\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [52/200] Batch 11/12                         Loss D: -0.1502, loss G: 3.2231\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [53/200] Batch 11/12                         Loss D: -0.1936, loss G: 3.2286\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [54/200] Batch 11/12                         Loss D: -0.2333, loss G: 3.2328\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [55/200] Batch 11/12                         Loss D: -0.2567, loss G: 3.2356\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [56/200] Batch 11/12                         Loss D: -0.3102, loss G: 3.2392\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [57/200] Batch 11/12                         Loss D: -0.3536, loss G: 3.2426\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [58/200] Batch 11/12                         Loss D: -0.3784, loss G: 3.2462\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [59/200] Batch 11/12                         Loss D: -0.4247, loss G: 3.2485\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [60/200] Batch 11/12                         Loss D: -0.4428, loss G: 3.2509\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [61/200] Batch 11/12                         Loss D: -0.4705, loss G: 3.2527\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [62/200] Batch 11/12                         Loss D: -0.4750, loss G: 3.2544\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [63/200] Batch 11/12                         Loss D: -0.4823, loss G: 3.2558\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [64/200] Batch 11/12                         Loss D: -0.4896, loss G: 3.2569\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [65/200] Batch 11/12                         Loss D: -0.4428, loss G: 3.2580\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [66/200] Batch 11/12                         Loss D: -0.4425, loss G: 3.2583\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [67/200] Batch 11/12                         Loss D: -0.4362, loss G: 3.2588\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [68/200] Batch 11/12                         Loss D: -0.3896, loss G: 3.2587\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [69/200] Batch 11/12                         Loss D: -0.3976, loss G: 3.2585\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [70/200] Batch 11/12                         Loss D: -0.3753, loss G: 3.2581\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [71/200] Batch 11/12                         Loss D: -0.3401, loss G: 3.2576\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [72/200] Batch 11/12                         Loss D: -0.3670, loss G: 3.2571\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [73/200] Batch 11/12                         Loss D: -0.3710, loss G: 3.2565\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [74/200] Batch 11/12                         Loss D: -0.3677, loss G: 3.2557\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [75/200] Batch 11/12                         Loss D: -0.3650, loss G: 3.2550\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [76/200] Batch 11/12                         Loss D: -0.3210, loss G: 3.2540\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [77/200] Batch 11/12                         Loss D: -0.1962, loss G: 3.2530\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [78/200] Batch 11/12                         Loss D: 0.3182, loss G: 3.2497\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [79/200] Batch 11/12                         Loss D: 0.9363, loss G: 3.2469\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [80/200] Batch 11/12                         Loss D: 1.2496, loss G: 3.2459\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [81/200] Batch 11/12                         Loss D: 1.2792, loss G: 3.2453\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [82/200] Batch 11/12                         Loss D: 1.1112, loss G: 3.2446\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [83/200] Batch 11/12                         Loss D: 0.9301, loss G: 3.2440\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [84/200] Batch 11/12                         Loss D: 0.6449, loss G: 3.2427\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [85/200] Batch 11/12                         Loss D: 0.3000, loss G: 3.2402\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [86/200] Batch 11/12                         Loss D: 0.0069, loss G: 3.2381\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [87/200] Batch 11/12                         Loss D: -0.0450, loss G: 3.2373\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [88/200] Batch 11/12                         Loss D: -0.1108, loss G: 3.2364\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [89/200] Batch 11/12                         Loss D: -0.1832, loss G: 3.2350\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [90/200] Batch 11/12                         Loss D: -0.2562, loss G: 3.2340\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [91/200] Batch 11/12                         Loss D: -0.3027, loss G: 3.2322\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [92/200] Batch 11/12                         Loss D: -0.3804, loss G: 3.2309\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [93/200] Batch 11/12                         Loss D: -0.4497, loss G: 3.2295\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [94/200] Batch 11/12                         Loss D: -0.4966, loss G: 3.2282\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [95/200] Batch 11/12                         Loss D: -0.5651, loss G: 3.2268\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [96/200] Batch 11/12                         Loss D: -0.6330, loss G: 3.2257\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [97/200] Batch 11/12                         Loss D: -0.6730, loss G: 3.2250\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [98/200] Batch 11/12                         Loss D: -0.7316, loss G: 3.2235\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [99/200] Batch 11/12                         Loss D: -0.7887, loss G: 3.2224\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [100/200] Batch 11/12                         Loss D: -0.8754, loss G: 3.2213\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [101/200] Batch 11/12                         Loss D: -0.9314, loss G: 3.2201\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [102/200] Batch 11/12                         Loss D: -0.9710, loss G: 3.2189\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [103/200] Batch 11/12                         Loss D: -1.0340, loss G: 3.2184\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [104/200] Batch 11/12                         Loss D: -1.1088, loss G: 3.2166\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [105/200] Batch 11/12                         Loss D: -1.1786, loss G: 3.2154\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [106/200] Batch 11/12                         Loss D: -1.2896, loss G: 3.2140\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [107/200] Batch 11/12                         Loss D: -1.3953, loss G: 3.2128\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [108/200] Batch 11/12                         Loss D: -1.5410, loss G: 3.2119\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [109/200] Batch 11/12                         Loss D: -1.6678, loss G: 3.2112\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [110/200] Batch 11/12                         Loss D: -1.8769, loss G: 3.2096\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [111/200] Batch 11/12                         Loss D: -2.6604, loss G: 3.1896\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [112/200] Batch 11/12                         Loss D: -3.7495, loss G: 3.1627\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [113/200] Batch 11/12                         Loss D: -4.5405, loss G: 3.1640\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [114/200] Batch 11/12                         Loss D: -4.2858, loss G: 3.1956\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [115/200] Batch 11/12                         Loss D: -4.5796, loss G: 3.2335\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [116/200] Batch 11/12                         Loss D: -4.8614, loss G: 3.2536\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [117/200] Batch 11/12                         Loss D: -4.8141, loss G: 3.2619\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [118/200] Batch 11/12                         Loss D: -4.6722, loss G: 3.2679\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [119/200] Batch 11/12                         Loss D: -4.3760, loss G: 3.2708\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [120/200] Batch 11/12                         Loss D: -4.1598, loss G: 3.2696\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [121/200] Batch 11/12                         Loss D: -3.5626, loss G: 3.2645\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [122/200] Batch 11/12                         Loss D: -3.1080, loss G: 3.2574\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [123/200] Batch 11/12                         Loss D: -2.4670, loss G: 3.2495\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [124/200] Batch 11/12                         Loss D: -1.1163, loss G: 3.2358\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [125/200] Batch 11/12                         Loss D: 1.7367, loss G: 3.2098\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [126/200] Batch 11/12                         Loss D: 3.6365, loss G: 3.2010\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [127/200] Batch 11/12                         Loss D: 5.5012, loss G: 3.1957\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [128/200] Batch 11/12                         Loss D: 5.9934, loss G: 3.1981\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [129/200] Batch 11/12                         Loss D: 6.3306, loss G: 3.2040\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [130/200] Batch 11/12                         Loss D: 6.3484, loss G: 3.2203\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [131/200] Batch 11/12                         Loss D: 5.8138, loss G: 3.2305\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [132/200] Batch 11/12                         Loss D: 5.1491, loss G: 3.2342\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [133/200] Batch 11/12                         Loss D: 4.6881, loss G: 3.2365\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [134/200] Batch 11/12                         Loss D: 4.3115, loss G: 3.2374\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [135/200] Batch 11/12                         Loss D: 3.7745, loss G: 3.2377\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [136/200] Batch 11/12                         Loss D: 3.2742, loss G: 3.2373\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [137/200] Batch 11/12                         Loss D: 2.7903, loss G: 3.2367\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [138/200] Batch 11/12                         Loss D: 2.2038, loss G: 3.2350\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [139/200] Batch 11/12                         Loss D: 1.6618, loss G: 3.2326\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [140/200] Batch 11/12                         Loss D: 0.7425, loss G: 3.2298\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [141/200] Batch 11/12                         Loss D: -0.1329, loss G: 3.2265\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [142/200] Batch 11/12                         Loss D: -1.3359, loss G: 3.2215\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [143/200] Batch 11/12                         Loss D: -2.4564, loss G: 3.2150\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [144/200] Batch 11/12                         Loss D: -3.0148, loss G: 3.2105\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [145/200] Batch 11/12                         Loss D: -3.8619, loss G: 3.2115\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [146/200] Batch 11/12                         Loss D: -7.9188, loss G: 3.1811\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [147/200] Batch 11/12                         Loss D: -10.1810, loss G: 3.1614\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [148/200] Batch 11/12                         Loss D: -11.2105, loss G: 3.2137\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [149/200] Batch 11/12                         Loss D: -12.0872, loss G: 3.2910\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [150/200] Batch 11/12                         Loss D: -9.0161, loss G: 3.3419\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [151/200] Batch 11/12                         Loss D: -4.6330, loss G: 3.3732\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [152/200] Batch 11/12                         Loss D: -1.2278, loss G: 3.3873\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [153/200] Batch 11/12                         Loss D: 0.8679, loss G: 3.3929\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [154/200] Batch 11/12                         Loss D: 1.5104, loss G: 3.3803\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [155/200] Batch 11/12                         Loss D: 1.6972, loss G: 3.3706\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [156/200] Batch 11/12                         Loss D: 1.4793, loss G: 3.3655\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [157/200] Batch 11/12                         Loss D: 1.1679, loss G: 3.3605\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [158/200] Batch 11/12                         Loss D: 0.8466, loss G: 3.3576\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [159/200] Batch 11/12                         Loss D: 0.5286, loss G: 3.3528\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [160/200] Batch 11/12                         Loss D: 0.2066, loss G: 3.3504\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [161/200] Batch 11/12                         Loss D: -0.1260, loss G: 3.3449\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [162/200] Batch 11/12                         Loss D: -0.4543, loss G: 3.3413\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [163/200] Batch 11/12                         Loss D: -0.4006, loss G: 3.3254\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [164/200] Batch 11/12                         Loss D: -0.6115, loss G: 3.3129\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [165/200] Batch 11/12                         Loss D: -0.8813, loss G: 3.3059\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [166/200] Batch 11/12                         Loss D: -1.2136, loss G: 3.2984\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [167/200] Batch 11/12                         Loss D: -1.4971, loss G: 3.2930\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [168/200] Batch 11/12                         Loss D: -1.8418, loss G: 3.2870\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [169/200] Batch 11/12                         Loss D: -2.1696, loss G: 3.2812\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [170/200] Batch 11/12                         Loss D: -2.4870, loss G: 3.2702\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [171/200] Batch 11/12                         Loss D: -2.8975, loss G: 3.2571\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [172/200] Batch 11/12                         Loss D: -3.2266, loss G: 3.2471\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [173/200] Batch 11/12                         Loss D: -3.6859, loss G: 3.2361\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [174/200] Batch 11/12                         Loss D: -4.1490, loss G: 3.2264\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [175/200] Batch 11/12                         Loss D: -4.6561, loss G: 3.2161\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [176/200] Batch 11/12                         Loss D: -5.3138, loss G: 3.2057\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [177/200] Batch 11/12                         Loss D: -5.9050, loss G: 3.1949\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [178/200] Batch 11/12                         Loss D: -6.7569, loss G: 3.1841\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [179/200] Batch 11/12                         Loss D: -8.0037, loss G: 3.1705\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [180/200] Batch 11/12                         Loss D: -11.6898, loss G: 3.1213\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [181/200] Batch 11/12                         Loss D: -14.2652, loss G: 3.2407\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [182/200] Batch 11/12                         Loss D: -15.1078, loss G: 3.2657\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [183/200] Batch 11/12                         Loss D: -16.4085, loss G: 3.2793\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [184/200] Batch 11/12                         Loss D: -17.7292, loss G: 3.2961\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [185/200] Batch 11/12                         Loss D: -18.8886, loss G: 3.3137\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [186/200] Batch 11/12                         Loss D: -20.2060, loss G: 3.3287\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [187/200] Batch 11/12                         Loss D: -21.4241, loss G: 3.3417\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [188/200] Batch 11/12                         Loss D: -22.4514, loss G: 3.3474\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [189/200] Batch 11/12                         Loss D: -24.8120, loss G: 3.3798\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [190/200] Batch 11/12                         Loss D: -24.2793, loss G: 3.4259\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [191/200] Batch 11/12                         Loss D: -18.9332, loss G: 3.2191\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [192/200] Batch 11/12                         Loss D: -29.3140, loss G: 3.0879\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [193/200] Batch 11/12                         Loss D: -32.2536, loss G: 3.3358\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [194/200] Batch 11/12                         Loss D: -30.6620, loss G: 3.4462\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [195/200] Batch 11/12                         Loss D: -30.9123, loss G: 3.5371\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [196/200] Batch 11/12                         Loss D: 15.5347, loss G: 1.4476\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [197/200] Batch 11/12                         Loss D: 116.3121, loss G: -5.4996\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [198/200] Batch 11/12                         Loss D: 198.9388, loss G: -11.3825\n",
      "[lr_G=0.0001, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [199/200] Batch 11/12                         Loss D: 248.5470, loss G: -15.5555\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [0/200] Batch 11/12                         Loss D: 9.4128, loss G: 34.0446\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [1/200] Batch 11/12                         Loss D: 9.5284, loss G: 33.7914\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [2/200] Batch 11/12                         Loss D: 9.6938, loss G: 33.5067\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [3/200] Batch 11/12                         Loss D: 9.9165, loss G: 33.0945\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [4/200] Batch 11/12                         Loss D: 10.2002, loss G: 32.4735\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [5/200] Batch 11/12                         Loss D: 10.4523, loss G: 31.7414\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [6/200] Batch 11/12                         Loss D: 10.6849, loss G: 30.8498\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [7/200] Batch 11/12                         Loss D: 10.8590, loss G: 29.7983\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [8/200] Batch 11/12                         Loss D: 11.0175, loss G: 29.0220\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [9/200] Batch 11/12                         Loss D: 11.1023, loss G: 28.3805\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [10/200] Batch 11/12                         Loss D: 11.1064, loss G: 27.6011\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [11/200] Batch 11/12                         Loss D: 10.9218, loss G: 26.8438\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [12/200] Batch 11/12                         Loss D: 10.6002, loss G: 25.8673\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [13/200] Batch 11/12                         Loss D: 10.0863, loss G: 24.5008\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [14/200] Batch 11/12                         Loss D: 9.2559, loss G: 23.1062\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [15/200] Batch 11/12                         Loss D: 8.3196, loss G: 21.6225\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [16/200] Batch 11/12                         Loss D: 7.1021, loss G: 19.9786\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [17/200] Batch 11/12                         Loss D: 5.4689, loss G: 17.8935\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [18/200] Batch 11/12                         Loss D: 3.4644, loss G: 15.9416\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [19/200] Batch 11/12                         Loss D: 0.8031, loss G: 13.5246\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [20/200] Batch 11/12                         Loss D: -2.2297, loss G: 11.7919\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [21/200] Batch 11/12                         Loss D: -5.1537, loss G: 11.2099\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [22/200] Batch 11/12                         Loss D: -8.1066, loss G: 10.5021\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [23/200] Batch 11/12                         Loss D: -10.8393, loss G: 9.8297\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [24/200] Batch 11/12                         Loss D: -14.1273, loss G: 8.8811\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [25/200] Batch 11/12                         Loss D: -17.2902, loss G: 8.1320\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [26/200] Batch 11/12                         Loss D: -21.1507, loss G: 6.9809\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [27/200] Batch 11/12                         Loss D: -24.8060, loss G: 5.7753\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [28/200] Batch 11/12                         Loss D: -29.4665, loss G: 4.6608\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [29/200] Batch 11/12                         Loss D: -33.5828, loss G: 3.3900\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [30/200] Batch 11/12                         Loss D: -37.8732, loss G: 2.2217\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [31/200] Batch 11/12                         Loss D: -39.6061, loss G: 2.1885\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [32/200] Batch 11/12                         Loss D: -42.4103, loss G: 1.9018\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [33/200] Batch 11/12                         Loss D: -44.5029, loss G: 2.1947\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [34/200] Batch 11/12                         Loss D: -47.3354, loss G: 2.0961\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [35/200] Batch 11/12                         Loss D: -49.5794, loss G: 2.2467\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [36/200] Batch 11/12                         Loss D: -51.6749, loss G: 2.3021\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [37/200] Batch 11/12                         Loss D: -54.0723, loss G: 2.4340\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [38/200] Batch 11/12                         Loss D: -56.4956, loss G: 2.5312\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [39/200] Batch 11/12                         Loss D: -58.7234, loss G: 2.6876\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [40/200] Batch 11/12                         Loss D: -62.0940, loss G: 3.1004\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [41/200] Batch 11/12                         Loss D: -63.5991, loss G: 3.0635\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [42/200] Batch 11/12                         Loss D: -65.6563, loss G: 3.4070\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [43/200] Batch 11/12                         Loss D: -70.2204, loss G: 3.6908\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [44/200] Batch 11/12                         Loss D: -72.3993, loss G: 3.5805\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [45/200] Batch 11/12                         Loss D: -74.2410, loss G: 3.5098\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [46/200] Batch 11/12                         Loss D: -77.3773, loss G: 3.6767\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [47/200] Batch 11/12                         Loss D: -80.3248, loss G: 3.8522\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [48/200] Batch 11/12                         Loss D: -83.1464, loss G: 4.0079\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [49/200] Batch 11/12                         Loss D: -85.9084, loss G: 4.1593\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [50/200] Batch 11/12                         Loss D: -89.3483, loss G: 4.4212\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [51/200] Batch 11/12                         Loss D: -91.3145, loss G: 4.4537\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [52/200] Batch 11/12                         Loss D: -93.1640, loss G: 4.9783\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [53/200] Batch 11/12                         Loss D: -97.3636, loss G: 4.8470\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [54/200] Batch 11/12                         Loss D: -102.2331, loss G: 5.2576\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [55/200] Batch 11/12                         Loss D: -102.7384, loss G: 5.3769\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [56/200] Batch 11/12                         Loss D: -108.7021, loss G: 5.5681\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [57/200] Batch 11/12                         Loss D: -111.2134, loss G: 5.4529\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [58/200] Batch 11/12                         Loss D: -114.8987, loss G: 5.7511\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [59/200] Batch 11/12                         Loss D: -117.5833, loss G: 5.7752\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [60/200] Batch 11/12                         Loss D: -120.6782, loss G: 6.0592\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [61/200] Batch 11/12                         Loss D: -125.4952, loss G: 6.2658\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [62/200] Batch 11/12                         Loss D: -127.5492, loss G: 6.5181\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [63/200] Batch 11/12                         Loss D: -131.6633, loss G: 6.6095\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [64/200] Batch 11/12                         Loss D: -135.5771, loss G: 6.7830\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [65/200] Batch 11/12                         Loss D: -140.0137, loss G: 6.9371\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [66/200] Batch 11/12                         Loss D: -141.6532, loss G: 7.4979\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [67/200] Batch 11/12                         Loss D: -148.0531, loss G: 7.4075\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [68/200] Batch 11/12                         Loss D: -153.2136, loss G: 7.9330\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [69/200] Batch 11/12                         Loss D: -156.7629, loss G: 8.0278\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [70/200] Batch 11/12                         Loss D: -157.6198, loss G: 8.3796\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [71/200] Batch 11/12                         Loss D: -164.4085, loss G: 8.2926\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [72/200] Batch 11/12                         Loss D: -169.5417, loss G: 8.7449\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [73/200] Batch 11/12                         Loss D: -172.2645, loss G: 8.7391\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [74/200] Batch 11/12                         Loss D: -177.5065, loss G: 9.0485\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [75/200] Batch 11/12                         Loss D: -180.3928, loss G: 9.3391\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [76/200] Batch 11/12                         Loss D: -186.0938, loss G: 9.4689\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [77/200] Batch 11/12                         Loss D: -189.1192, loss G: 9.8540\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [78/200] Batch 11/12                         Loss D: -195.6464, loss G: 9.9901\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [79/200] Batch 11/12                         Loss D: -200.5312, loss G: 10.3052\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [80/200] Batch 11/12                         Loss D: -205.3470, loss G: 10.6229\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [81/200] Batch 11/12                         Loss D: -208.6958, loss G: 10.8134\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [82/200] Batch 11/12                         Loss D: -214.7833, loss G: 11.0918\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [83/200] Batch 11/12                         Loss D: -220.1752, loss G: 11.4372\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [84/200] Batch 11/12                         Loss D: -224.0090, loss G: 11.6119\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [85/200] Batch 11/12                         Loss D: -227.1252, loss G: 12.0893\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [86/200] Batch 11/12                         Loss D: -235.9429, loss G: 12.2877\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [87/200] Batch 11/12                         Loss D: -238.0349, loss G: 12.6111\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [88/200] Batch 11/12                         Loss D: -246.1166, loss G: 12.8211\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [89/200] Batch 11/12                         Loss D: -249.4019, loss G: 13.1321\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [90/200] Batch 11/12                         Loss D: -255.6858, loss G: 13.3870\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [91/200] Batch 11/12                         Loss D: -262.5543, loss G: 13.6913\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [92/200] Batch 11/12                         Loss D: -265.7771, loss G: 14.0422\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [93/200] Batch 11/12                         Loss D: -269.4417, loss G: 14.4878\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [94/200] Batch 11/12                         Loss D: -275.8951, loss G: 14.7553\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [95/200] Batch 11/12                         Loss D: -282.7902, loss G: 15.0162\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [96/200] Batch 11/12                         Loss D: -285.9269, loss G: 15.5004\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [97/200] Batch 11/12                         Loss D: -296.0104, loss G: 15.6080\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [98/200] Batch 11/12                         Loss D: -302.0729, loss G: 15.9575\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [99/200] Batch 11/12                         Loss D: -311.7232, loss G: 16.7076\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [100/200] Batch 11/12                         Loss D: -314.8181, loss G: 16.6209\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [101/200] Batch 11/12                         Loss D: -321.2075, loss G: 16.9400\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [102/200] Batch 11/12                         Loss D: -327.4195, loss G: 17.3580\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [103/200] Batch 11/12                         Loss D: -331.4356, loss G: 17.7763\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [104/200] Batch 11/12                         Loss D: -340.3915, loss G: 18.0264\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [105/200] Batch 11/12                         Loss D: -346.7404, loss G: 18.4328\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [106/200] Batch 11/12                         Loss D: -351.5272, loss G: 18.8438\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [107/200] Batch 11/12                         Loss D: -356.7258, loss G: 19.2736\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [108/200] Batch 11/12                         Loss D: -362.5852, loss G: 19.6834\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [109/200] Batch 11/12                         Loss D: -372.4800, loss G: 19.9543\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [110/200] Batch 11/12                         Loss D: -375.5906, loss G: 20.4636\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [111/200] Batch 11/12                         Loss D: -387.0193, loss G: 20.7296\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [112/200] Batch 11/12                         Loss D: -392.8420, loss G: 21.1760\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [113/200] Batch 11/12                         Loss D: -397.9526, loss G: 21.6230\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [114/200] Batch 11/12                         Loss D: -405.2376, loss G: 22.0453\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [115/200] Batch 11/12                         Loss D: -411.9436, loss G: 22.4318\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [116/200] Batch 11/12                         Loss D: -417.1773, loss G: 22.9021\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [117/200] Batch 11/12                         Loss D: -424.6045, loss G: 23.2198\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [118/200] Batch 11/12                         Loss D: -434.1170, loss G: 23.4782\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [119/200] Batch 11/12                         Loss D: -440.9515, loss G: 23.8730\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [120/200] Batch 11/12                         Loss D: -454.5826, loss G: 24.7997\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [121/200] Batch 11/12                         Loss D: -449.1949, loss G: 24.8157\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [122/200] Batch 11/12                         Loss D: -455.1792, loss G: 25.2584\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [123/200] Batch 11/12                         Loss D: -460.7568, loss G: 25.6986\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [124/200] Batch 11/12                         Loss D: -472.4905, loss G: 26.1291\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [125/200] Batch 11/12                         Loss D: -478.2538, loss G: 26.5686\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [126/200] Batch 11/12                         Loss D: -486.1442, loss G: 27.3097\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [127/200] Batch 11/12                         Loss D: -485.1259, loss G: 27.4615\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [128/200] Batch 11/12                         Loss D: -485.8326, loss G: 27.9612\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [129/200] Batch 11/12                         Loss D: -493.6982, loss G: 28.3859\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [130/200] Batch 11/12                         Loss D: -496.3840, loss G: 28.8783\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [131/200] Batch 11/12                         Loss D: -496.2881, loss G: 29.3465\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [132/200] Batch 11/12                         Loss D: -500.5834, loss G: 29.7996\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [133/200] Batch 11/12                         Loss D: -492.8454, loss G: 30.2847\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [134/200] Batch 11/12                         Loss D: -499.9213, loss G: 30.7402\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [135/200] Batch 11/12                         Loss D: -492.6595, loss G: 31.1951\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [136/200] Batch 11/12                         Loss D: -488.2992, loss G: 31.6612\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [137/200] Batch 11/12                         Loss D: -478.1968, loss G: 32.0922\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [138/200] Batch 11/12                         Loss D: -467.5984, loss G: 32.5789\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [139/200] Batch 11/12                         Loss D: -455.4251, loss G: 32.9765\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [140/200] Batch 11/12                         Loss D: -441.7467, loss G: 33.3659\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [141/200] Batch 11/12                         Loss D: -410.1239, loss G: 33.6906\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [142/200] Batch 11/12                         Loss D: -382.5033, loss G: 34.0314\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [143/200] Batch 11/12                         Loss D: -341.1580, loss G: 34.1744\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [144/200] Batch 11/12                         Loss D: -288.1631, loss G: 33.9085\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [145/200] Batch 11/12                         Loss D: -216.5180, loss G: 33.1939\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [146/200] Batch 11/12                         Loss D: -141.0506, loss G: 32.1342\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [147/200] Batch 11/12                         Loss D: -74.3547, loss G: 31.3980\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [148/200] Batch 11/12                         Loss D: -80.1249, loss G: 31.7523\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [149/200] Batch 11/12                         Loss D: -84.1072, loss G: 32.0842\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [150/200] Batch 11/12                         Loss D: -86.5208, loss G: 32.3847\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [151/200] Batch 11/12                         Loss D: -88.3829, loss G: 32.6816\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [152/200] Batch 11/12                         Loss D: -91.1123, loss G: 32.9375\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [153/200] Batch 11/12                         Loss D: -90.9991, loss G: 33.1944\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [154/200] Batch 11/12                         Loss D: -94.4852, loss G: 33.4503\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [155/200] Batch 11/12                         Loss D: -95.3154, loss G: 33.6907\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [156/200] Batch 11/12                         Loss D: -97.9529, loss G: 33.8993\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [157/200] Batch 11/12                         Loss D: -95.9591, loss G: 34.0965\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [158/200] Batch 11/12                         Loss D: -99.0332, loss G: 34.2896\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [159/200] Batch 11/12                         Loss D: -98.8541, loss G: 34.4303\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [160/200] Batch 11/12                         Loss D: -98.1546, loss G: 34.5798\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [161/200] Batch 11/12                         Loss D: -98.4152, loss G: 34.7094\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [162/200] Batch 11/12                         Loss D: -97.9842, loss G: 34.8352\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [163/200] Batch 11/12                         Loss D: -97.3353, loss G: 34.9638\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [164/200] Batch 11/12                         Loss D: -97.0835, loss G: 35.0731\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [165/200] Batch 11/12                         Loss D: -97.1326, loss G: 35.1883\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [166/200] Batch 11/12                         Loss D: -96.7902, loss G: 35.2599\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [167/200] Batch 11/12                         Loss D: -96.0485, loss G: 35.3512\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [168/200] Batch 11/12                         Loss D: -94.9770, loss G: 35.4002\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [169/200] Batch 11/12                         Loss D: -94.0997, loss G: 35.4821\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [170/200] Batch 11/12                         Loss D: -94.0274, loss G: 35.5467\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [171/200] Batch 11/12                         Loss D: -92.9354, loss G: 35.5722\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [172/200] Batch 11/12                         Loss D: -91.9902, loss G: 35.5973\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [173/200] Batch 11/12                         Loss D: -91.4414, loss G: 35.6381\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [174/200] Batch 11/12                         Loss D: -90.5908, loss G: 35.6659\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [175/200] Batch 11/12                         Loss D: -88.3721, loss G: 35.6358\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [176/200] Batch 11/12                         Loss D: -86.8516, loss G: 35.6352\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [177/200] Batch 11/12                         Loss D: -85.2446, loss G: 35.6243\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [178/200] Batch 11/12                         Loss D: -83.1818, loss G: 35.5917\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [179/200] Batch 11/12                         Loss D: -81.2575, loss G: 35.5391\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [180/200] Batch 11/12                         Loss D: -78.7029, loss G: 35.5065\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [181/200] Batch 11/12                         Loss D: -74.5772, loss G: 35.4456\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [182/200] Batch 11/12                         Loss D: -69.8528, loss G: 35.3527\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [183/200] Batch 11/12                         Loss D: -64.1071, loss G: 35.2783\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [184/200] Batch 11/12                         Loss D: -57.9807, loss G: 35.1672\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [185/200] Batch 11/12                         Loss D: -50.4020, loss G: 35.0685\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [186/200] Batch 11/12                         Loss D: -43.4464, loss G: 34.9530\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [187/200] Batch 11/12                         Loss D: -35.6007, loss G: 34.8316\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [188/200] Batch 11/12                         Loss D: -25.0978, loss G: 34.6842\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [189/200] Batch 11/12                         Loss D: -11.4130, loss G: 34.5273\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [190/200] Batch 11/12                         Loss D: -14.3933, loss G: 34.4257\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [191/200] Batch 11/12                         Loss D: -15.7051, loss G: 34.3097\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [192/200] Batch 11/12                         Loss D: -16.2862, loss G: 34.1974\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [193/200] Batch 11/12                         Loss D: -16.7879, loss G: 34.0607\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [194/200] Batch 11/12                         Loss D: -18.1219, loss G: 33.9125\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [195/200] Batch 11/12                         Loss D: -18.4421, loss G: 33.7996\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [196/200] Batch 11/12                         Loss D: -21.5598, loss G: 33.7343\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [197/200] Batch 11/12                         Loss D: -25.1823, loss G: 33.6701\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [198/200] Batch 11/12                         Loss D: -25.0892, loss G: 33.5943\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [199/200] Batch 11/12                         Loss D: -15.0294, loss G: 33.2397\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [0/200] Batch 11/12                         Loss D: 8.2741, loss G: 17.4081\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [1/200] Batch 11/12                         Loss D: 8.0066, loss G: 17.2578\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [2/200] Batch 11/12                         Loss D: 7.6904, loss G: 17.0850\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [3/200] Batch 11/12                         Loss D: 7.3963, loss G: 16.8820\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [4/200] Batch 11/12                         Loss D: 7.0458, loss G: 16.6206\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [5/200] Batch 11/12                         Loss D: 6.5363, loss G: 16.3015\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [6/200] Batch 11/12                         Loss D: 6.0814, loss G: 15.9304\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [7/200] Batch 11/12                         Loss D: 6.1563, loss G: 15.5646\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [8/200] Batch 11/12                         Loss D: 6.6961, loss G: 15.1587\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [9/200] Batch 11/12                         Loss D: 6.2547, loss G: 14.8749\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [10/200] Batch 11/12                         Loss D: 5.9488, loss G: 14.5916\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [11/200] Batch 11/12                         Loss D: 5.4777, loss G: 14.2831\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [12/200] Batch 11/12                         Loss D: 3.6849, loss G: 13.9689\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [13/200] Batch 11/12                         Loss D: 2.4621, loss G: 13.7270\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [14/200] Batch 11/12                         Loss D: 0.9708, loss G: 13.4893\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [15/200] Batch 11/12                         Loss D: -0.8550, loss G: 13.2664\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [16/200] Batch 11/12                         Loss D: -2.9652, loss G: 12.9884\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [17/200] Batch 11/12                         Loss D: -5.0659, loss G: 12.7307\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [18/200] Batch 11/12                         Loss D: -6.9822, loss G: 12.5127\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [19/200] Batch 11/12                         Loss D: -10.2229, loss G: 12.1603\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [20/200] Batch 11/12                         Loss D: -13.1326, loss G: 11.9041\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [21/200] Batch 11/12                         Loss D: -17.0604, loss G: 11.6148\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [22/200] Batch 11/12                         Loss D: -21.1102, loss G: 11.3575\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [23/200] Batch 11/12                         Loss D: -23.0982, loss G: 11.5446\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [24/200] Batch 11/12                         Loss D: -24.7469, loss G: 11.6095\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [25/200] Batch 11/12                         Loss D: -26.5812, loss G: 11.8206\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [26/200] Batch 11/12                         Loss D: -28.0033, loss G: 11.8613\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [27/200] Batch 11/12                         Loss D: -29.5587, loss G: 12.0022\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [28/200] Batch 11/12                         Loss D: -31.0885, loss G: 12.1050\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [29/200] Batch 11/12                         Loss D: -32.2848, loss G: 12.2657\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [30/200] Batch 11/12                         Loss D: -34.5722, loss G: 12.3096\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [31/200] Batch 11/12                         Loss D: -34.8938, loss G: 12.4971\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [32/200] Batch 11/12                         Loss D: -38.0575, loss G: 12.5758\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [33/200] Batch 11/12                         Loss D: -39.7200, loss G: 12.6624\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [34/200] Batch 11/12                         Loss D: -41.0556, loss G: 12.7567\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [35/200] Batch 11/12                         Loss D: -43.1220, loss G: 12.8517\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [36/200] Batch 11/12                         Loss D: -44.8773, loss G: 12.9763\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [37/200] Batch 11/12                         Loss D: -46.6364, loss G: 13.0840\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [38/200] Batch 11/12                         Loss D: -48.1655, loss G: 13.1930\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [39/200] Batch 11/12                         Loss D: -50.9329, loss G: 13.4144\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [40/200] Batch 11/12                         Loss D: -51.3363, loss G: 13.4394\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [41/200] Batch 11/12                         Loss D: -53.7366, loss G: 13.5046\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [42/200] Batch 11/12                         Loss D: -55.5855, loss G: 13.6115\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [43/200] Batch 11/12                         Loss D: -57.4572, loss G: 13.7226\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [44/200] Batch 11/12                         Loss D: -59.8224, loss G: 13.8381\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [45/200] Batch 11/12                         Loss D: -61.0048, loss G: 13.9575\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [46/200] Batch 11/12                         Loss D: -62.3169, loss G: 14.0898\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [47/200] Batch 11/12                         Loss D: -65.2973, loss G: 14.1807\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [48/200] Batch 11/12                         Loss D: -68.0595, loss G: 14.2899\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [49/200] Batch 11/12                         Loss D: -70.4179, loss G: 14.4091\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [50/200] Batch 11/12                         Loss D: -73.2161, loss G: 14.5201\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [51/200] Batch 11/12                         Loss D: -75.6360, loss G: 14.6436\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [52/200] Batch 11/12                         Loss D: -78.7680, loss G: 14.7492\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [53/200] Batch 11/12                         Loss D: -81.3882, loss G: 14.8670\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [54/200] Batch 11/12                         Loss D: -83.3971, loss G: 14.9934\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [55/200] Batch 11/12                         Loss D: -87.2586, loss G: 15.0981\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [56/200] Batch 11/12                         Loss D: -89.4828, loss G: 15.2272\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [57/200] Batch 11/12                         Loss D: -91.8223, loss G: 15.3559\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [58/200] Batch 11/12                         Loss D: -93.3993, loss G: 15.4904\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [59/200] Batch 11/12                         Loss D: -96.8694, loss G: 15.6164\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [60/200] Batch 11/12                         Loss D: -99.2795, loss G: 15.7532\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [61/200] Batch 11/12                         Loss D: -102.6309, loss G: 15.8902\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [62/200] Batch 11/12                         Loss D: -104.3221, loss G: 16.0299\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [63/200] Batch 11/12                         Loss D: -106.7381, loss G: 16.1735\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [64/200] Batch 11/12                         Loss D: -105.4939, loss G: 16.3144\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [65/200] Batch 11/12                         Loss D: -108.5375, loss G: 16.4922\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [66/200] Batch 11/12                         Loss D: -109.7140, loss G: 16.6691\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [67/200] Batch 11/12                         Loss D: -112.4611, loss G: 16.8471\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [68/200] Batch 11/12                         Loss D: -114.1072, loss G: 16.9922\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [69/200] Batch 11/12                         Loss D: -116.7732, loss G: 17.1197\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [70/200] Batch 11/12                         Loss D: -118.2692, loss G: 17.2384\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [71/200] Batch 11/12                         Loss D: -119.5869, loss G: 17.3541\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [72/200] Batch 11/12                         Loss D: -119.8893, loss G: 17.4890\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [73/200] Batch 11/12                         Loss D: -120.6126, loss G: 17.6015\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [74/200] Batch 11/12                         Loss D: -120.3185, loss G: 17.7154\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [75/200] Batch 11/12                         Loss D: -120.0590, loss G: 17.8148\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [76/200] Batch 11/12                         Loss D: -118.0785, loss G: 17.8921\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [77/200] Batch 11/12                         Loss D: -116.9062, loss G: 17.9830\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [78/200] Batch 11/12                         Loss D: -114.6919, loss G: 18.0492\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [79/200] Batch 11/12                         Loss D: -110.4065, loss G: 18.0800\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [80/200] Batch 11/12                         Loss D: -106.7572, loss G: 18.1214\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [81/200] Batch 11/12                         Loss D: -102.1948, loss G: 18.1480\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [82/200] Batch 11/12                         Loss D: -97.6069, loss G: 18.1953\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [83/200] Batch 11/12                         Loss D: -93.1518, loss G: 18.2599\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [84/200] Batch 11/12                         Loss D: -89.5567, loss G: 18.3151\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [85/200] Batch 11/12                         Loss D: -86.2337, loss G: 18.3007\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [86/200] Batch 11/12                         Loss D: -81.3820, loss G: 18.2156\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [87/200] Batch 11/12                         Loss D: -73.7970, loss G: 18.0632\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [88/200] Batch 11/12                         Loss D: -64.5204, loss G: 17.8411\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [89/200] Batch 11/12                         Loss D: -52.0472, loss G: 17.6141\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [90/200] Batch 11/12                         Loss D: -34.6479, loss G: 17.3310\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [91/200] Batch 11/12                         Loss D: -17.6495, loss G: 17.0721\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [92/200] Batch 11/12                         Loss D: -18.2044, loss G: 17.0962\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [93/200] Batch 11/12                         Loss D: -18.4978, loss G: 17.1260\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [94/200] Batch 11/12                         Loss D: -19.3038, loss G: 17.1521\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [95/200] Batch 11/12                         Loss D: -18.2731, loss G: 17.1848\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [96/200] Batch 11/12                         Loss D: -19.2132, loss G: 17.2132\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [97/200] Batch 11/12                         Loss D: -18.6748, loss G: 17.2373\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [98/200] Batch 11/12                         Loss D: -19.1391, loss G: 17.2634\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [99/200] Batch 11/12                         Loss D: -19.2544, loss G: 17.2897\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [100/200] Batch 11/12                         Loss D: -18.9162, loss G: 17.3182\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [101/200] Batch 11/12                         Loss D: -19.7041, loss G: 17.3435\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [102/200] Batch 11/12                         Loss D: -19.0549, loss G: 17.3701\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [103/200] Batch 11/12                         Loss D: -18.7571, loss G: 17.3945\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [104/200] Batch 11/12                         Loss D: -18.9175, loss G: 17.4186\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [105/200] Batch 11/12                         Loss D: -18.1363, loss G: 17.4388\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [106/200] Batch 11/12                         Loss D: -17.0407, loss G: 17.4557\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [107/200] Batch 11/12                         Loss D: -15.8646, loss G: 17.4677\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [108/200] Batch 11/12                         Loss D: -14.3223, loss G: 17.4748\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [109/200] Batch 11/12                         Loss D: -12.2646, loss G: 17.4721\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [110/200] Batch 11/12                         Loss D: -9.3005, loss G: 17.4198\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [111/200] Batch 11/12                         Loss D: -6.4725, loss G: 17.4047\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [112/200] Batch 11/12                         Loss D: -4.8847, loss G: 17.3986\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [113/200] Batch 11/12                         Loss D: -4.0111, loss G: 17.3961\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [114/200] Batch 11/12                         Loss D: -3.3480, loss G: 17.3972\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [115/200] Batch 11/12                         Loss D: -3.2090, loss G: 17.4004\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [116/200] Batch 11/12                         Loss D: -3.5590, loss G: 17.3999\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [117/200] Batch 11/12                         Loss D: -3.5461, loss G: 17.4024\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [118/200] Batch 11/12                         Loss D: -3.4654, loss G: 17.4054\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [119/200] Batch 11/12                         Loss D: -3.6353, loss G: 17.4083\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [120/200] Batch 11/12                         Loss D: -3.4662, loss G: 17.4099\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [121/200] Batch 11/12                         Loss D: -3.6851, loss G: 17.4137\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [122/200] Batch 11/12                         Loss D: -3.4941, loss G: 17.4138\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [123/200] Batch 11/12                         Loss D: -3.4934, loss G: 17.4170\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [124/200] Batch 11/12                         Loss D: -3.2668, loss G: 17.4181\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [125/200] Batch 11/12                         Loss D: -3.4172, loss G: 17.4217\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [126/200] Batch 11/12                         Loss D: -3.2924, loss G: 17.4226\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [127/200] Batch 11/12                         Loss D: -3.4499, loss G: 17.4263\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [128/200] Batch 11/12                         Loss D: -3.3441, loss G: 17.4289\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [129/200] Batch 11/12                         Loss D: -3.3127, loss G: 17.4299\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [130/200] Batch 11/12                         Loss D: -3.2642, loss G: 17.4324\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [131/200] Batch 11/12                         Loss D: -3.2407, loss G: 17.4342\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [132/200] Batch 11/12                         Loss D: -3.3592, loss G: 17.4378\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [133/200] Batch 11/12                         Loss D: -3.0619, loss G: 17.4387\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [134/200] Batch 11/12                         Loss D: -2.8493, loss G: 17.4418\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [135/200] Batch 11/12                         Loss D: -2.9662, loss G: 17.4437\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [136/200] Batch 11/12                         Loss D: -3.2294, loss G: 17.4454\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [137/200] Batch 11/12                         Loss D: -3.1701, loss G: 17.4482\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [138/200] Batch 11/12                         Loss D: -3.1589, loss G: 17.4505\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [139/200] Batch 11/12                         Loss D: -3.1287, loss G: 17.4519\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [140/200] Batch 11/12                         Loss D: -3.1990, loss G: 17.4538\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [141/200] Batch 11/12                         Loss D: -3.1749, loss G: 17.4574\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [142/200] Batch 11/12                         Loss D: -2.8240, loss G: 17.4583\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [143/200] Batch 11/12                         Loss D: -2.8845, loss G: 17.4596\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [144/200] Batch 11/12                         Loss D: -2.7265, loss G: 17.4626\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [145/200] Batch 11/12                         Loss D: -3.0287, loss G: 17.4652\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [146/200] Batch 11/12                         Loss D: -2.7996, loss G: 17.4669\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [147/200] Batch 11/12                         Loss D: -2.9837, loss G: 17.4688\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [148/200] Batch 11/12                         Loss D: -2.8374, loss G: 17.4710\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [149/200] Batch 11/12                         Loss D: -2.8973, loss G: 17.4729\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [150/200] Batch 11/12                         Loss D: -2.8814, loss G: 17.4746\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [151/200] Batch 11/12                         Loss D: -2.7857, loss G: 17.4773\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [152/200] Batch 11/12                         Loss D: -2.8736, loss G: 17.4794\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [153/200] Batch 11/12                         Loss D: -2.9891, loss G: 17.4813\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [154/200] Batch 11/12                         Loss D: -2.8137, loss G: 17.4833\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [155/200] Batch 11/12                         Loss D: -2.6812, loss G: 17.4863\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [156/200] Batch 11/12                         Loss D: -2.7811, loss G: 17.4877\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [157/200] Batch 11/12                         Loss D: -2.9167, loss G: 17.4902\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [158/200] Batch 11/12                         Loss D: -2.7863, loss G: 17.4915\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [159/200] Batch 11/12                         Loss D: -2.7118, loss G: 17.4935\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [160/200] Batch 11/12                         Loss D: -2.6711, loss G: 17.4955\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [161/200] Batch 11/12                         Loss D: -2.7216, loss G: 17.4976\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [162/200] Batch 11/12                         Loss D: -2.8309, loss G: 17.5001\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [163/200] Batch 11/12                         Loss D: -2.5213, loss G: 17.5015\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [164/200] Batch 11/12                         Loss D: -2.4698, loss G: 17.5034\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [165/200] Batch 11/12                         Loss D: -2.3185, loss G: 17.5051\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [166/200] Batch 11/12                         Loss D: -2.2417, loss G: 17.5069\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [167/200] Batch 11/12                         Loss D: -2.0502, loss G: 17.5085\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [168/200] Batch 11/12                         Loss D: -1.9700, loss G: 17.5100\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [169/200] Batch 11/12                         Loss D: -1.6225, loss G: 17.5113\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [170/200] Batch 11/12                         Loss D: -1.6166, loss G: 17.5126\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [171/200] Batch 11/12                         Loss D: -1.6300, loss G: 17.5144\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [172/200] Batch 11/12                         Loss D: -1.4089, loss G: 17.5156\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [173/200] Batch 11/12                         Loss D: -1.5362, loss G: 17.5170\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [174/200] Batch 11/12                         Loss D: -1.3010, loss G: 17.5182\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [175/200] Batch 11/12                         Loss D: -1.3323, loss G: 17.5198\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [176/200] Batch 11/12                         Loss D: -1.3705, loss G: 17.5210\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [177/200] Batch 11/12                         Loss D: -1.4348, loss G: 17.5221\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [178/200] Batch 11/12                         Loss D: -1.3161, loss G: 17.5232\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [179/200] Batch 11/12                         Loss D: -1.5970, loss G: 17.5255\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [180/200] Batch 11/12                         Loss D: -1.0404, loss G: 17.5261\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [181/200] Batch 11/12                         Loss D: -1.3427, loss G: 17.5269\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [182/200] Batch 11/12                         Loss D: -1.5650, loss G: 17.5297\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [183/200] Batch 11/12                         Loss D: -1.4998, loss G: 17.5299\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [184/200] Batch 11/12                         Loss D: -1.5910, loss G: 17.5324\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [185/200] Batch 11/12                         Loss D: -1.1967, loss G: 17.5314\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [186/200] Batch 11/12                         Loss D: -1.4551, loss G: 17.5329\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [187/200] Batch 11/12                         Loss D: -1.2769, loss G: 17.5338\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [188/200] Batch 11/12                         Loss D: -1.2892, loss G: 17.5345\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [189/200] Batch 11/12                         Loss D: -1.2647, loss G: 17.5356\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [190/200] Batch 11/12                         Loss D: -1.2520, loss G: 17.5368\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [191/200] Batch 11/12                         Loss D: -1.1481, loss G: 17.5381\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [192/200] Batch 11/12                         Loss D: -1.2917, loss G: 17.5389\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [193/200] Batch 11/12                         Loss D: -1.4709, loss G: 17.5413\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [194/200] Batch 11/12                         Loss D: -0.9913, loss G: 17.5412\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [195/200] Batch 11/12                         Loss D: -1.2922, loss G: 17.5430\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [196/200] Batch 11/12                         Loss D: -0.9439, loss G: 17.5439\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [197/200] Batch 11/12                         Loss D: -1.5194, loss G: 17.5464\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [198/200] Batch 11/12                         Loss D: -0.9515, loss G: 17.5457\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [199/200] Batch 11/12                         Loss D: -1.4936, loss G: 17.5489\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [0/200] Batch 11/12                         Loss D: 6.0403, loss G: 3.4187\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [1/200] Batch 11/12                         Loss D: 6.1695, loss G: 3.4115\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [2/200] Batch 11/12                         Loss D: 6.2119, loss G: 3.4094\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [3/200] Batch 11/12                         Loss D: 6.3761, loss G: 3.4069\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [4/200] Batch 11/12                         Loss D: 6.5924, loss G: 3.4041\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [5/200] Batch 11/12                         Loss D: 7.0192, loss G: 3.3998\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [6/200] Batch 11/12                         Loss D: 7.5519, loss G: 3.3950\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [7/200] Batch 11/12                         Loss D: 8.5308, loss G: 3.3874\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [8/200] Batch 11/12                         Loss D: 9.3814, loss G: 3.3790\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [9/200] Batch 11/12                         Loss D: 10.4948, loss G: 3.3686\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [10/200] Batch 11/12                         Loss D: 11.4343, loss G: 3.3614\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [11/200] Batch 11/12                         Loss D: 11.1134, loss G: 3.3618\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [12/200] Batch 11/12                         Loss D: 11.2457, loss G: 3.3587\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [13/200] Batch 11/12                         Loss D: 10.7549, loss G: 3.3581\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [14/200] Batch 11/12                         Loss D: 10.0535, loss G: 3.3608\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [15/200] Batch 11/12                         Loss D: 9.9736, loss G: 3.3576\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [16/200] Batch 11/12                         Loss D: 9.8563, loss G: 3.3575\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [17/200] Batch 11/12                         Loss D: 9.9008, loss G: 3.3599\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [18/200] Batch 11/12                         Loss D: 9.8576, loss G: 3.3599\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [19/200] Batch 11/12                         Loss D: 9.7953, loss G: 3.3559\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [20/200] Batch 11/12                         Loss D: 9.5472, loss G: 3.3570\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [21/200] Batch 11/12                         Loss D: 9.3562, loss G: 3.3573\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [22/200] Batch 11/12                         Loss D: 9.5618, loss G: 3.3552\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [23/200] Batch 11/12                         Loss D: 9.4988, loss G: 3.3551\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [24/200] Batch 11/12                         Loss D: 9.3727, loss G: 3.3559\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [25/200] Batch 11/12                         Loss D: 9.1366, loss G: 3.3553\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [26/200] Batch 11/12                         Loss D: 9.0747, loss G: 3.3552\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [27/200] Batch 11/12                         Loss D: 9.0020, loss G: 3.3551\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [28/200] Batch 11/12                         Loss D: 8.9417, loss G: 3.3551\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [29/200] Batch 11/12                         Loss D: 8.9055, loss G: 3.3547\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [30/200] Batch 11/12                         Loss D: 8.6421, loss G: 3.3563\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [31/200] Batch 11/12                         Loss D: 8.7599, loss G: 3.3551\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [32/200] Batch 11/12                         Loss D: 8.8707, loss G: 3.3563\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [33/200] Batch 11/12                         Loss D: 8.4008, loss G: 3.3567\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [34/200] Batch 11/12                         Loss D: 8.4833, loss G: 3.3562\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [35/200] Batch 11/12                         Loss D: 8.2219, loss G: 3.3563\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [36/200] Batch 11/12                         Loss D: 8.0691, loss G: 3.3574\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [37/200] Batch 11/12                         Loss D: 8.0454, loss G: 3.3592\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [38/200] Batch 11/12                         Loss D: 7.7521, loss G: 3.3588\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [39/200] Batch 11/12                         Loss D: 7.7143, loss G: 3.3601\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [40/200] Batch 11/12                         Loss D: 7.4091, loss G: 3.3613\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [41/200] Batch 11/12                         Loss D: 7.3872, loss G: 3.3626\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [42/200] Batch 11/12                         Loss D: 7.1075, loss G: 3.3650\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [43/200] Batch 11/12                         Loss D: 7.1406, loss G: 3.3657\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [44/200] Batch 11/12                         Loss D: 6.8845, loss G: 3.3677\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [45/200] Batch 11/12                         Loss D: 6.6658, loss G: 3.3704\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [46/200] Batch 11/12                         Loss D: 6.3267, loss G: 3.3706\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [47/200] Batch 11/12                         Loss D: 6.2385, loss G: 3.3740\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [48/200] Batch 11/12                         Loss D: 6.0377, loss G: 3.3760\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [49/200] Batch 11/12                         Loss D: 5.8424, loss G: 3.3775\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [50/200] Batch 11/12                         Loss D: 5.3739, loss G: 3.3796\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [51/200] Batch 11/12                         Loss D: 5.2661, loss G: 3.3812\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [52/200] Batch 11/12                         Loss D: 5.0952, loss G: 3.3836\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [53/200] Batch 11/12                         Loss D: 4.6966, loss G: 3.3861\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [54/200] Batch 11/12                         Loss D: 4.3510, loss G: 3.3901\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [55/200] Batch 11/12                         Loss D: 4.1321, loss G: 3.3919\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [56/200] Batch 11/12                         Loss D: 4.0235, loss G: 3.3948\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [57/200] Batch 11/12                         Loss D: 3.6397, loss G: 3.3972\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [58/200] Batch 11/12                         Loss D: 3.2902, loss G: 3.4000\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [59/200] Batch 11/12                         Loss D: 3.0875, loss G: 3.4031\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [60/200] Batch 11/12                         Loss D: 2.8652, loss G: 3.4056\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [61/200] Batch 11/12                         Loss D: 2.6295, loss G: 3.4084\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [62/200] Batch 11/12                         Loss D: 2.2015, loss G: 3.4117\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [63/200] Batch 11/12                         Loss D: 1.9162, loss G: 3.4146\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [64/200] Batch 11/12                         Loss D: 1.5512, loss G: 3.4180\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [65/200] Batch 11/12                         Loss D: 1.2149, loss G: 3.4212\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [66/200] Batch 11/12                         Loss D: 1.0987, loss G: 3.4244\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [67/200] Batch 11/12                         Loss D: 0.6895, loss G: 3.4274\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [68/200] Batch 11/12                         Loss D: 0.4413, loss G: 3.4311\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [69/200] Batch 11/12                         Loss D: -0.0901, loss G: 3.4342\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [70/200] Batch 11/12                         Loss D: -0.5390, loss G: 3.4375\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [71/200] Batch 11/12                         Loss D: -0.7583, loss G: 3.4410\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [72/200] Batch 11/12                         Loss D: -1.2876, loss G: 3.4463\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [73/200] Batch 11/12                         Loss D: -1.4704, loss G: 3.4509\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [74/200] Batch 11/12                         Loss D: -1.8945, loss G: 3.4554\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [75/200] Batch 11/12                         Loss D: -2.4393, loss G: 3.4602\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [76/200] Batch 11/12                         Loss D: -2.6289, loss G: 3.4645\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [77/200] Batch 11/12                         Loss D: -3.0625, loss G: 3.4715\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [78/200] Batch 11/12                         Loss D: -3.3015, loss G: 3.4793\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [79/200] Batch 11/12                         Loss D: -3.6859, loss G: 3.4874\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [80/200] Batch 11/12                         Loss D: -4.0598, loss G: 3.4944\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [81/200] Batch 11/12                         Loss D: -4.5068, loss G: 3.5014\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [82/200] Batch 11/12                         Loss D: -5.1961, loss G: 3.5093\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [83/200] Batch 11/12                         Loss D: -5.4894, loss G: 3.5180\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [84/200] Batch 11/12                         Loss D: -5.9198, loss G: 3.5267\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [85/200] Batch 11/12                         Loss D: -6.2917, loss G: 3.5353\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [86/200] Batch 11/12                         Loss D: -6.9411, loss G: 3.5438\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [87/200] Batch 11/12                         Loss D: -7.4551, loss G: 3.5518\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [88/200] Batch 11/12                         Loss D: -8.1877, loss G: 3.5598\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [89/200] Batch 11/12                         Loss D: -8.4351, loss G: 3.5673\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [90/200] Batch 11/12                         Loss D: -9.3199, loss G: 3.5748\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [91/200] Batch 11/12                         Loss D: -9.6505, loss G: 3.5824\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [92/200] Batch 11/12                         Loss D: -10.3953, loss G: 3.5899\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [93/200] Batch 11/12                         Loss D: -11.1324, loss G: 3.5971\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [94/200] Batch 11/12                         Loss D: -11.6382, loss G: 3.6074\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [95/200] Batch 11/12                         Loss D: -12.5953, loss G: 3.6174\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [96/200] Batch 11/12                         Loss D: -13.5096, loss G: 3.6255\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [97/200] Batch 11/12                         Loss D: -14.6181, loss G: 3.6331\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [98/200] Batch 11/12                         Loss D: -15.3542, loss G: 3.6407\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [99/200] Batch 11/12                         Loss D: -16.4267, loss G: 3.6326\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [100/200] Batch 11/12                         Loss D: -14.7483, loss G: 3.6058\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [101/200] Batch 11/12                         Loss D: -13.8071, loss G: 3.6135\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [102/200] Batch 11/12                         Loss D: -11.8741, loss G: 3.6183\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [103/200] Batch 11/12                         Loss D: -8.9972, loss G: 3.6211\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [104/200] Batch 11/12                         Loss D: -5.5884, loss G: 3.6220\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [105/200] Batch 11/12                         Loss D: -1.8234, loss G: 3.6216\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [106/200] Batch 11/12                         Loss D: 4.5206, loss G: 3.5749\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [107/200] Batch 11/12                         Loss D: 27.1891, loss G: 1.8966\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [108/200] Batch 11/12                         Loss D: 49.2553, loss G: 0.1972\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [109/200] Batch 11/12                         Loss D: 74.2441, loss G: -1.7599\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [110/200] Batch 11/12                         Loss D: 96.1831, loss G: -3.5593\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [111/200] Batch 11/12                         Loss D: 111.5435, loss G: -4.8542\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [112/200] Batch 11/12                         Loss D: 117.7462, loss G: -5.3103\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [113/200] Batch 11/12                         Loss D: 119.8478, loss G: -5.5677\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [114/200] Batch 11/12                         Loss D: 114.8271, loss G: -5.2573\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [115/200] Batch 11/12                         Loss D: 104.1641, loss G: -4.8345\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [116/200] Batch 11/12                         Loss D: 94.2195, loss G: -4.7612\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [117/200] Batch 11/12                         Loss D: 83.9526, loss G: -4.6679\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [118/200] Batch 11/12                         Loss D: 74.6871, loss G: -4.4924\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [119/200] Batch 11/12                         Loss D: 65.5622, loss G: -4.0439\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [120/200] Batch 11/12                         Loss D: 57.2407, loss G: -3.6113\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [121/200] Batch 11/12                         Loss D: 48.5237, loss G: -3.1702\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [122/200] Batch 11/12                         Loss D: 40.4133, loss G: -2.6695\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [123/200] Batch 11/12                         Loss D: 33.0557, loss G: -2.2143\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [124/200] Batch 11/12                         Loss D: 25.9872, loss G: -1.6709\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [125/200] Batch 11/12                         Loss D: 18.5597, loss G: -1.1823\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [126/200] Batch 11/12                         Loss D: 11.5743, loss G: -0.6349\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [127/200] Batch 11/12                         Loss D: 4.3973, loss G: -0.0215\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [128/200] Batch 11/12                         Loss D: -1.9855, loss G: 0.5752\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [129/200] Batch 11/12                         Loss D: -9.2103, loss G: 1.0752\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [130/200] Batch 11/12                         Loss D: -15.2685, loss G: 1.5812\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [131/200] Batch 11/12                         Loss D: -21.0360, loss G: 2.0723\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [132/200] Batch 11/12                         Loss D: -25.2024, loss G: 2.6604\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [133/200] Batch 11/12                         Loss D: -28.2688, loss G: 3.0802\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [134/200] Batch 11/12                         Loss D: -31.0047, loss G: 3.4777\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [135/200] Batch 11/12                         Loss D: -32.8995, loss G: 3.8451\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [136/200] Batch 11/12                         Loss D: -33.2740, loss G: 4.1637\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [137/200] Batch 11/12                         Loss D: -33.6522, loss G: 4.4604\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [138/200] Batch 11/12                         Loss D: -32.9344, loss G: 4.7138\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [139/200] Batch 11/12                         Loss D: -31.6991, loss G: 4.9369\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [140/200] Batch 11/12                         Loss D: -29.4665, loss G: 5.1087\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [141/200] Batch 11/12                         Loss D: -27.6078, loss G: 5.2820\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [142/200] Batch 11/12                         Loss D: -24.6167, loss G: 5.3830\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [143/200] Batch 11/12                         Loss D: -21.2020, loss G: 5.4356\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [144/200] Batch 11/12                         Loss D: -17.8454, loss G: 5.4791\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [145/200] Batch 11/12                         Loss D: -13.9276, loss G: 5.4585\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [146/200] Batch 11/12                         Loss D: -10.3811, loss G: 5.4631\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [147/200] Batch 11/12                         Loss D: -6.4229, loss G: 5.4218\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [148/200] Batch 11/12                         Loss D: -3.1474, loss G: 5.3435\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [149/200] Batch 11/12                         Loss D: -2.6297, loss G: 5.2185\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [150/200] Batch 11/12                         Loss D: -2.0622, loss G: 5.0676\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [151/200] Batch 11/12                         Loss D: -1.5065, loss G: 4.9258\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [152/200] Batch 11/12                         Loss D: -0.8112, loss G: 4.7579\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [153/200] Batch 11/12                         Loss D: 0.0539, loss G: 4.5641\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [154/200] Batch 11/12                         Loss D: 0.4421, loss G: 4.4511\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [155/200] Batch 11/12                         Loss D: 0.0303, loss G: 4.4831\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [156/200] Batch 11/12                         Loss D: -0.4742, loss G: 4.5306\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [157/200] Batch 11/12                         Loss D: -0.5926, loss G: 4.5319\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [158/200] Batch 11/12                         Loss D: -0.8269, loss G: 4.5471\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [159/200] Batch 11/12                         Loss D: -0.9861, loss G: 4.5536\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [160/200] Batch 11/12                         Loss D: -1.0066, loss G: 4.5491\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [161/200] Batch 11/12                         Loss D: -0.9729, loss G: 4.5397\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [162/200] Batch 11/12                         Loss D: -0.9170, loss G: 4.5254\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [163/200] Batch 11/12                         Loss D: -0.9076, loss G: 4.5187\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [164/200] Batch 11/12                         Loss D: -0.6853, loss G: 4.4865\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [165/200] Batch 11/12                         Loss D: -0.4394, loss G: 4.4540\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [166/200] Batch 11/12                         Loss D: -0.2299, loss G: 4.4245\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [167/200] Batch 11/12                         Loss D: 0.0858, loss G: 4.3877\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [168/200] Batch 11/12                         Loss D: 0.3970, loss G: 4.3476\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [169/200] Batch 11/12                         Loss D: 0.7779, loss G: 4.3043\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [170/200] Batch 11/12                         Loss D: 1.1661, loss G: 4.2536\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [171/200] Batch 11/12                         Loss D: 1.7316, loss G: 4.1894\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [172/200] Batch 11/12                         Loss D: 2.2590, loss G: 4.1309\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [173/200] Batch 11/12                         Loss D: 2.7724, loss G: 4.0661\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [174/200] Batch 11/12                         Loss D: 3.4317, loss G: 3.9980\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [175/200] Batch 11/12                         Loss D: 4.0953, loss G: 3.9209\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [176/200] Batch 11/12                         Loss D: 4.8063, loss G: 3.8404\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [177/200] Batch 11/12                         Loss D: 5.6332, loss G: 3.7505\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [178/200] Batch 11/12                         Loss D: 6.5499, loss G: 3.6579\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [179/200] Batch 11/12                         Loss D: 7.6092, loss G: 3.5573\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [180/200] Batch 11/12                         Loss D: 8.9722, loss G: 3.4242\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [181/200] Batch 11/12                         Loss D: 8.9999, loss G: 3.4164\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [182/200] Batch 11/12                         Loss D: 9.0197, loss G: 3.4146\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [183/200] Batch 11/12                         Loss D: 8.9381, loss G: 3.4139\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [184/200] Batch 11/12                         Loss D: 8.9562, loss G: 3.4138\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [185/200] Batch 11/12                         Loss D: 8.9771, loss G: 3.4136\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [186/200] Batch 11/12                         Loss D: 8.9560, loss G: 3.4131\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [187/200] Batch 11/12                         Loss D: 8.9752, loss G: 3.4135\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [188/200] Batch 11/12                         Loss D: 8.9418, loss G: 3.4132\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [189/200] Batch 11/12                         Loss D: 9.0166, loss G: 3.4133\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [190/200] Batch 11/12                         Loss D: 8.9332, loss G: 3.4129\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [191/200] Batch 11/12                         Loss D: 8.9500, loss G: 3.4130\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [192/200] Batch 11/12                         Loss D: 8.9181, loss G: 3.4127\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [193/200] Batch 11/12                         Loss D: 8.9440, loss G: 3.4130\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [194/200] Batch 11/12                         Loss D: 8.9777, loss G: 3.4129\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [195/200] Batch 11/12                         Loss D: 8.9096, loss G: 3.4127\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [196/200] Batch 11/12                         Loss D: 8.9183, loss G: 3.4129\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [197/200] Batch 11/12                         Loss D: 8.8417, loss G: 3.4129\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [198/200] Batch 11/12                         Loss D: 8.9719, loss G: 3.4129\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [199/200] Batch 11/12                         Loss D: 8.8475, loss G: 3.4132\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [0/200] Batch 11/12                         Loss D: 2.3021, loss G: 34.1717\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [1/200] Batch 11/12                         Loss D: 2.6539, loss G: 33.9146\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [2/200] Batch 11/12                         Loss D: 3.0678, loss G: 33.6106\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [3/200] Batch 11/12                         Loss D: 3.4398, loss G: 33.2330\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [4/200] Batch 11/12                         Loss D: 3.4125, loss G: 32.6931\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [5/200] Batch 11/12                         Loss D: 3.3392, loss G: 32.0840\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [6/200] Batch 11/12                         Loss D: 3.3213, loss G: 31.1948\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [7/200] Batch 11/12                         Loss D: 3.2386, loss G: 30.2265\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [8/200] Batch 11/12                         Loss D: 3.1818, loss G: 29.1016\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [9/200] Batch 11/12                         Loss D: 3.0992, loss G: 28.3825\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [10/200] Batch 11/12                         Loss D: 3.0264, loss G: 27.5118\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [11/200] Batch 11/12                         Loss D: 2.9543, loss G: 26.4118\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [12/200] Batch 11/12                         Loss D: 2.8689, loss G: 25.2454\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [13/200] Batch 11/12                         Loss D: 2.8175, loss G: 23.9269\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [14/200] Batch 11/12                         Loss D: 2.7778, loss G: 22.4113\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [15/200] Batch 11/12                         Loss D: 2.7192, loss G: 20.8063\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [16/200] Batch 11/12                         Loss D: 2.6592, loss G: 19.0664\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [17/200] Batch 11/12                         Loss D: 2.6091, loss G: 17.0531\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [18/200] Batch 11/12                         Loss D: 2.5705, loss G: 14.5031\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [19/200] Batch 11/12                         Loss D: 2.5215, loss G: 12.0507\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [20/200] Batch 11/12                         Loss D: 2.4653, loss G: 10.7720\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [21/200] Batch 11/12                         Loss D: 2.4226, loss G: 9.7438\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [22/200] Batch 11/12                         Loss D: 2.3768, loss G: 8.8484\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [23/200] Batch 11/12                         Loss D: 2.3326, loss G: 7.8766\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [24/200] Batch 11/12                         Loss D: 2.2700, loss G: 7.0191\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [25/200] Batch 11/12                         Loss D: 2.2280, loss G: 5.7572\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [26/200] Batch 11/12                         Loss D: 2.1891, loss G: 4.7362\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [27/200] Batch 11/12                         Loss D: 2.1416, loss G: 3.3818\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [28/200] Batch 11/12                         Loss D: 2.0961, loss G: 2.1409\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [29/200] Batch 11/12                         Loss D: 2.0234, loss G: 1.2412\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [30/200] Batch 11/12                         Loss D: 1.9073, loss G: 0.0915\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [31/200] Batch 11/12                         Loss D: 1.9134, loss G: 0.3619\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [32/200] Batch 11/12                         Loss D: 1.9058, loss G: 0.4065\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [33/200] Batch 11/12                         Loss D: 1.8791, loss G: 0.1576\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [34/200] Batch 11/12                         Loss D: 1.8568, loss G: -0.0133\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [35/200] Batch 11/12                         Loss D: 1.8402, loss G: -0.0505\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [36/200] Batch 11/12                         Loss D: 1.8254, loss G: -0.0319\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [37/200] Batch 11/12                         Loss D: 1.7843, loss G: 0.2066\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [38/200] Batch 11/12                         Loss D: 1.7627, loss G: -0.0653\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [39/200] Batch 11/12                         Loss D: 1.7365, loss G: 0.4098\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [40/200] Batch 11/12                         Loss D: 1.7006, loss G: 0.2867\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [41/200] Batch 11/12                         Loss D: 1.6735, loss G: -0.1394\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [42/200] Batch 11/12                         Loss D: 1.6523, loss G: -0.0879\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [43/200] Batch 11/12                         Loss D: 1.6302, loss G: 0.0941\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [44/200] Batch 11/12                         Loss D: 1.6049, loss G: -0.0364\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [45/200] Batch 11/12                         Loss D: 1.5776, loss G: -0.0864\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [46/200] Batch 11/12                         Loss D: 1.5512, loss G: -0.0312\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [47/200] Batch 11/12                         Loss D: 1.5343, loss G: -0.0350\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [48/200] Batch 11/12                         Loss D: 1.5070, loss G: 0.0483\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [49/200] Batch 11/12                         Loss D: 1.4894, loss G: 0.2202\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [50/200] Batch 11/12                         Loss D: 1.4668, loss G: 0.2477\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [51/200] Batch 11/12                         Loss D: 1.4426, loss G: -0.0758\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [52/200] Batch 11/12                         Loss D: 1.4236, loss G: 0.0640\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [53/200] Batch 11/12                         Loss D: 1.3969, loss G: -0.0774\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [54/200] Batch 11/12                         Loss D: 1.3734, loss G: 0.1063\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [55/200] Batch 11/12                         Loss D: 1.3551, loss G: 0.1511\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [56/200] Batch 11/12                         Loss D: 1.3295, loss G: 0.1132\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [57/200] Batch 11/12                         Loss D: 1.3109, loss G: -0.0977\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [58/200] Batch 11/12                         Loss D: 1.2811, loss G: -0.0250\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [59/200] Batch 11/12                         Loss D: 1.2662, loss G: -0.0765\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [60/200] Batch 11/12                         Loss D: 1.2492, loss G: -0.1336\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [61/200] Batch 11/12                         Loss D: 1.2218, loss G: -0.0958\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [62/200] Batch 11/12                         Loss D: 1.1993, loss G: -0.0151\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [63/200] Batch 11/12                         Loss D: 1.1786, loss G: 0.1371\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [64/200] Batch 11/12                         Loss D: 1.1518, loss G: -0.1252\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [65/200] Batch 11/12                         Loss D: 1.1314, loss G: 0.0088\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [66/200] Batch 11/12                         Loss D: 1.1047, loss G: -0.0836\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [67/200] Batch 11/12                         Loss D: 1.0726, loss G: -0.1016\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [68/200] Batch 11/12                         Loss D: 1.0410, loss G: -0.1276\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [69/200] Batch 11/12                         Loss D: 1.0134, loss G: -0.1528\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [70/200] Batch 11/12                         Loss D: 0.9934, loss G: 0.0049\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [71/200] Batch 11/12                         Loss D: 0.9683, loss G: -0.1460\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [72/200] Batch 11/12                         Loss D: 0.9526, loss G: -0.0904\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [73/200] Batch 11/12                         Loss D: 0.9256, loss G: 0.0209\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [74/200] Batch 11/12                         Loss D: 0.8967, loss G: 0.2860\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [75/200] Batch 11/12                         Loss D: 0.8642, loss G: -0.1224\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [76/200] Batch 11/12                         Loss D: 0.8339, loss G: -0.1287\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [77/200] Batch 11/12                         Loss D: 0.7763, loss G: -0.0469\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [78/200] Batch 11/12                         Loss D: 0.6665, loss G: -0.2674\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [79/200] Batch 11/12                         Loss D: 0.5056, loss G: -0.2721\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [80/200] Batch 11/12                         Loss D: 0.4286, loss G: -0.5133\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [81/200] Batch 11/12                         Loss D: 0.3937, loss G: -0.5164\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [82/200] Batch 11/12                         Loss D: 0.3317, loss G: -0.5126\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [83/200] Batch 11/12                         Loss D: 0.2924, loss G: -0.5288\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [84/200] Batch 11/12                         Loss D: 0.2991, loss G: -0.2127\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [85/200] Batch 11/12                         Loss D: 0.2610, loss G: -0.5765\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [86/200] Batch 11/12                         Loss D: 0.2080, loss G: -0.6312\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [87/200] Batch 11/12                         Loss D: 0.1924, loss G: -0.7107\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [88/200] Batch 11/12                         Loss D: 0.1464, loss G: -0.6640\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [89/200] Batch 11/12                         Loss D: 0.0916, loss G: -0.5634\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [90/200] Batch 11/12                         Loss D: 0.0898, loss G: -0.6237\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [91/200] Batch 11/12                         Loss D: 0.0527, loss G: -0.2715\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [92/200] Batch 11/12                         Loss D: -0.0029, loss G: -0.7077\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [93/200] Batch 11/12                         Loss D: -0.0022, loss G: -0.4295\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [94/200] Batch 11/12                         Loss D: -0.0680, loss G: -0.7655\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [95/200] Batch 11/12                         Loss D: -0.1321, loss G: -0.7815\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [96/200] Batch 11/12                         Loss D: -0.1429, loss G: -0.6896\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [97/200] Batch 11/12                         Loss D: -0.1632, loss G: -0.8326\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [98/200] Batch 11/12                         Loss D: -0.2254, loss G: -0.7612\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [99/200] Batch 11/12                         Loss D: -0.2499, loss G: -0.5736\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [100/200] Batch 11/12                         Loss D: -0.3026, loss G: -0.7563\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [101/200] Batch 11/12                         Loss D: -0.3582, loss G: -0.7832\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [102/200] Batch 11/12                         Loss D: -0.3592, loss G: -0.6387\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [103/200] Batch 11/12                         Loss D: -0.4259, loss G: -0.7573\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [104/200] Batch 11/12                         Loss D: -0.4916, loss G: -0.9347\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [105/200] Batch 11/12                         Loss D: -0.5195, loss G: -0.8726\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [106/200] Batch 11/12                         Loss D: -0.5394, loss G: -0.8295\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [107/200] Batch 11/12                         Loss D: -0.6041, loss G: -0.6959\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [108/200] Batch 11/12                         Loss D: -0.6590, loss G: -0.9594\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [109/200] Batch 11/12                         Loss D: -0.6919, loss G: -0.7557\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [110/200] Batch 11/12                         Loss D: -0.7705, loss G: -0.8885\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [111/200] Batch 11/12                         Loss D: -0.8053, loss G: -0.8655\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [112/200] Batch 11/12                         Loss D: -0.8522, loss G: -0.6758\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [113/200] Batch 11/12                         Loss D: -0.8850, loss G: -0.9322\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [114/200] Batch 11/12                         Loss D: -0.9149, loss G: -0.8472\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [115/200] Batch 11/12                         Loss D: -1.0206, loss G: -0.8958\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [116/200] Batch 11/12                         Loss D: -1.0382, loss G: -0.8733\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [117/200] Batch 11/12                         Loss D: -1.0875, loss G: -0.6033\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [118/200] Batch 11/12                         Loss D: -1.1714, loss G: -0.7432\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [119/200] Batch 11/12                         Loss D: -1.1958, loss G: -0.5387\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [120/200] Batch 11/12                         Loss D: -1.2459, loss G: -0.8857\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [121/200] Batch 11/12                         Loss D: -1.3130, loss G: -0.8294\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [122/200] Batch 11/12                         Loss D: -1.3729, loss G: -0.8066\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [123/200] Batch 11/12                         Loss D: -1.4426, loss G: -0.8981\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [124/200] Batch 11/12                         Loss D: -1.5261, loss G: -0.7451\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [125/200] Batch 11/12                         Loss D: -1.5923, loss G: -0.8191\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [126/200] Batch 11/12                         Loss D: -1.7167, loss G: -0.6930\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [127/200] Batch 11/12                         Loss D: -1.7973, loss G: -0.7986\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [128/200] Batch 11/12                         Loss D: -1.8856, loss G: -0.8668\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [129/200] Batch 11/12                         Loss D: -2.0055, loss G: -0.3308\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [130/200] Batch 11/12                         Loss D: -2.1364, loss G: -0.7657\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [131/200] Batch 11/12                         Loss D: -2.2840, loss G: -0.6614\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [132/200] Batch 11/12                         Loss D: -2.4631, loss G: -0.7297\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [133/200] Batch 11/12                         Loss D: -2.6004, loss G: -0.3493\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [134/200] Batch 11/12                         Loss D: -2.7545, loss G: -0.6117\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [135/200] Batch 11/12                         Loss D: -2.9128, loss G: -0.6257\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [136/200] Batch 11/12                         Loss D: -3.1062, loss G: -0.5459\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [137/200] Batch 11/12                         Loss D: -3.2935, loss G: -0.4756\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [138/200] Batch 11/12                         Loss D: -3.5213, loss G: -0.6039\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [139/200] Batch 11/12                         Loss D: -3.7702, loss G: -0.5352\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [140/200] Batch 11/12                         Loss D: -4.0549, loss G: -0.4516\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [141/200] Batch 11/12                         Loss D: -4.3668, loss G: -0.3120\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [142/200] Batch 11/12                         Loss D: -4.6333, loss G: -0.4087\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [143/200] Batch 11/12                         Loss D: -4.9213, loss G: -0.3506\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [144/200] Batch 11/12                         Loss D: -5.3310, loss G: -0.3304\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [145/200] Batch 11/12                         Loss D: -5.6821, loss G: -0.1583\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [146/200] Batch 11/12                         Loss D: -5.9038, loss G: -0.1938\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [147/200] Batch 11/12                         Loss D: -6.2970, loss G: 0.0532\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [148/200] Batch 11/12                         Loss D: -6.6157, loss G: -0.1593\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [149/200] Batch 11/12                         Loss D: -6.9109, loss G: 0.1119\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [150/200] Batch 11/12                         Loss D: -7.3649, loss G: -0.0306\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [151/200] Batch 11/12                         Loss D: -7.7682, loss G: 0.0823\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [152/200] Batch 11/12                         Loss D: -8.1526, loss G: 0.0016\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [153/200] Batch 11/12                         Loss D: -8.6151, loss G: 0.2266\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [154/200] Batch 11/12                         Loss D: -9.0670, loss G: 0.3449\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [155/200] Batch 11/12                         Loss D: -9.6437, loss G: 0.3764\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [156/200] Batch 11/12                         Loss D: -10.1723, loss G: 0.3179\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [157/200] Batch 11/12                         Loss D: -10.8097, loss G: 0.4653\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [158/200] Batch 11/12                         Loss D: -11.4023, loss G: 0.5764\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [159/200] Batch 11/12                         Loss D: -11.9466, loss G: 0.5887\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [160/200] Batch 11/12                         Loss D: -12.7009, loss G: 0.7566\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [161/200] Batch 11/12                         Loss D: -12.8299, loss G: 1.2459\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [162/200] Batch 11/12                         Loss D: -13.9770, loss G: 0.9681\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [163/200] Batch 11/12                         Loss D: -14.7995, loss G: 1.2011\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [164/200] Batch 11/12                         Loss D: -14.5484, loss G: 1.3268\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [165/200] Batch 11/12                         Loss D: -16.3955, loss G: 1.4370\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [166/200] Batch 11/12                         Loss D: -16.6632, loss G: 1.5632\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [167/200] Batch 11/12                         Loss D: -17.2794, loss G: 1.6582\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [168/200] Batch 11/12                         Loss D: -16.9391, loss G: 2.0953\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [169/200] Batch 11/12                         Loss D: -16.8804, loss G: 2.5949\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [170/200] Batch 11/12                         Loss D: -18.6401, loss G: 2.5835\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [171/200] Batch 11/12                         Loss D: -20.3800, loss G: 2.9358\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [172/200] Batch 11/12                         Loss D: -20.9771, loss G: 3.2504\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [173/200] Batch 11/12                         Loss D: -20.0032, loss G: 3.9861\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [174/200] Batch 11/12                         Loss D: -22.5042, loss G: 4.0135\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [175/200] Batch 11/12                         Loss D: -23.1637, loss G: 4.7088\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [176/200] Batch 11/12                         Loss D: -22.1536, loss G: 5.0637\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [177/200] Batch 11/12                         Loss D: -22.2017, loss G: 5.5619\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [178/200] Batch 11/12                         Loss D: -24.1137, loss G: 5.9531\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [179/200] Batch 11/12                         Loss D: -24.0432, loss G: 6.4901\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [180/200] Batch 11/12                         Loss D: -25.3417, loss G: 6.9298\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [181/200] Batch 11/12                         Loss D: -25.0666, loss G: 7.4694\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [182/200] Batch 11/12                         Loss D: -27.9685, loss G: 7.9443\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [183/200] Batch 11/12                         Loss D: -30.3843, loss G: 8.1629\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [184/200] Batch 11/12                         Loss D: -31.0583, loss G: 8.5143\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [185/200] Batch 11/12                         Loss D: -33.5472, loss G: 8.8983\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [186/200] Batch 11/12                         Loss D: -32.5699, loss G: 9.0139\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [187/200] Batch 11/12                         Loss D: -35.7525, loss G: 9.2814\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [188/200] Batch 11/12                         Loss D: -35.6585, loss G: 9.6164\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [189/200] Batch 11/12                         Loss D: -36.9098, loss G: 9.8613\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [190/200] Batch 11/12                         Loss D: -38.5458, loss G: 9.8931\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [191/200] Batch 11/12                         Loss D: -38.4002, loss G: 10.0765\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [192/200] Batch 11/12                         Loss D: -40.4225, loss G: 10.6387\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [193/200] Batch 11/12                         Loss D: -42.0695, loss G: 10.5986\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [194/200] Batch 11/12                         Loss D: -43.7860, loss G: 10.8108\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [195/200] Batch 11/12                         Loss D: -45.0844, loss G: 10.9141\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [196/200] Batch 11/12                         Loss D: -45.8629, loss G: 11.0232\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [197/200] Batch 11/12                         Loss D: -47.1413, loss G: 10.7689\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [198/200] Batch 11/12                         Loss D: -47.9806, loss G: 10.7231\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [199/200] Batch 11/12                         Loss D: -48.9207, loss G: 10.5253\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [0/200] Batch 11/12                         Loss D: 0.6384, loss G: 17.2029\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [1/200] Batch 11/12                         Loss D: 0.0581, loss G: 17.0891\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [2/200] Batch 11/12                         Loss D: -0.7189, loss G: 16.9697\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [3/200] Batch 11/12                         Loss D: -1.7274, loss G: 16.8331\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [4/200] Batch 11/12                         Loss D: -3.1983, loss G: 16.6477\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [5/200] Batch 11/12                         Loss D: -5.1311, loss G: 16.4561\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [6/200] Batch 11/12                         Loss D: -7.2391, loss G: 16.2879\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [7/200] Batch 11/12                         Loss D: -10.0013, loss G: 16.1011\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [8/200] Batch 11/12                         Loss D: -13.0214, loss G: 15.9286\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [9/200] Batch 11/12                         Loss D: -16.6242, loss G: 15.7609\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [10/200] Batch 11/12                         Loss D: -20.0551, loss G: 15.6613\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [11/200] Batch 11/12                         Loss D: -23.8631, loss G: 15.5740\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [12/200] Batch 11/12                         Loss D: -27.7202, loss G: 15.5144\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [13/200] Batch 11/12                         Loss D: -32.3553, loss G: 15.4420\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [14/200] Batch 11/12                         Loss D: -37.6561, loss G: 15.3782\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [15/200] Batch 11/12                         Loss D: -43.3427, loss G: 15.3400\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [16/200] Batch 11/12                         Loss D: -49.4250, loss G: 15.3197\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [17/200] Batch 11/12                         Loss D: -56.7537, loss G: 15.2976\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [18/200] Batch 11/12                         Loss D: -64.1240, loss G: 15.3112\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [19/200] Batch 11/12                         Loss D: -71.5329, loss G: 15.3594\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [20/200] Batch 11/12                         Loss D: -78.2411, loss G: 15.4456\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [21/200] Batch 11/12                         Loss D: -87.3657, loss G: 15.5078\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [22/200] Batch 11/12                         Loss D: -92.9823, loss G: 15.6432\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [23/200] Batch 11/12                         Loss D: -100.0492, loss G: 15.7560\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [24/200] Batch 11/12                         Loss D: -107.4568, loss G: 15.8744\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [25/200] Batch 11/12                         Loss D: -111.7596, loss G: 16.0116\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [26/200] Batch 11/12                         Loss D: -116.7149, loss G: 16.1341\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [27/200] Batch 11/12                         Loss D: -120.8884, loss G: 16.2811\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [28/200] Batch 11/12                         Loss D: -126.5437, loss G: 16.4807\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [29/200] Batch 11/12                         Loss D: -130.5237, loss G: 16.6899\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [30/200] Batch 11/12                         Loss D: -136.8439, loss G: 16.8959\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [31/200] Batch 11/12                         Loss D: -138.3237, loss G: 17.1070\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [32/200] Batch 11/12                         Loss D: -141.2260, loss G: 17.3089\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [33/200] Batch 11/12                         Loss D: -140.7393, loss G: 17.4936\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [34/200] Batch 11/12                         Loss D: -141.2508, loss G: 17.6685\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [35/200] Batch 11/12                         Loss D: -140.0074, loss G: 17.8215\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [36/200] Batch 11/12                         Loss D: -134.5551, loss G: 17.9290\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [37/200] Batch 11/12                         Loss D: -130.8733, loss G: 18.0294\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [38/200] Batch 11/12                         Loss D: -124.5875, loss G: 18.0897\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [39/200] Batch 11/12                         Loss D: -117.5991, loss G: 18.1235\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [40/200] Batch 11/12                         Loss D: -109.9157, loss G: 18.1322\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [41/200] Batch 11/12                         Loss D: -101.5285, loss G: 18.1143\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [42/200] Batch 11/12                         Loss D: -92.6261, loss G: 18.0732\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [43/200] Batch 11/12                         Loss D: -84.3467, loss G: 18.0222\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [44/200] Batch 11/12                         Loss D: -75.4393, loss G: 17.9481\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [45/200] Batch 11/12                         Loss D: -67.8061, loss G: 17.8761\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [46/200] Batch 11/12                         Loss D: -58.7972, loss G: 17.7745\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [47/200] Batch 11/12                         Loss D: -50.5190, loss G: 17.6751\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [48/200] Batch 11/12                         Loss D: -45.3832, loss G: 17.6153\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [49/200] Batch 11/12                         Loss D: -41.5992, loss G: 17.5654\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [50/200] Batch 11/12                         Loss D: -36.7737, loss G: 17.4938\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [51/200] Batch 11/12                         Loss D: -32.2737, loss G: 17.4179\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [52/200] Batch 11/12                         Loss D: -27.3273, loss G: 17.3222\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [53/200] Batch 11/12                         Loss D: -21.2688, loss G: 17.1948\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [54/200] Batch 11/12                         Loss D: -19.8315, loss G: 17.1825\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [55/200] Batch 11/12                         Loss D: -18.8465, loss G: 17.1795\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [56/200] Batch 11/12                         Loss D: -18.0444, loss G: 17.1786\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [57/200] Batch 11/12                         Loss D: -17.5184, loss G: 17.1774\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [58/200] Batch 11/12                         Loss D: -16.9829, loss G: 17.1790\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [59/200] Batch 11/12                         Loss D: -16.3884, loss G: 17.1794\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [60/200] Batch 11/12                         Loss D: -15.9972, loss G: 17.1808\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [61/200] Batch 11/12                         Loss D: -15.6552, loss G: 17.1818\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [62/200] Batch 11/12                         Loss D: -14.9520, loss G: 17.1831\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [63/200] Batch 11/12                         Loss D: -14.5677, loss G: 17.1842\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [64/200] Batch 11/12                         Loss D: -14.0426, loss G: 17.1852\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [65/200] Batch 11/12                         Loss D: -13.1920, loss G: 17.1847\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [66/200] Batch 11/12                         Loss D: -13.0989, loss G: 17.1792\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [67/200] Batch 11/12                         Loss D: -13.0003, loss G: 17.1626\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [68/200] Batch 11/12                         Loss D: -10.3898, loss G: 17.1356\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [69/200] Batch 11/12                         Loss D: -8.4604, loss G: 17.1209\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [70/200] Batch 11/12                         Loss D: -7.0291, loss G: 17.1122\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [71/200] Batch 11/12                         Loss D: -4.0365, loss G: 17.0717\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [72/200] Batch 11/12                         Loss D: -3.5352, loss G: 17.0668\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [73/200] Batch 11/12                         Loss D: -3.4987, loss G: 17.0661\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [74/200] Batch 11/12                         Loss D: -3.4150, loss G: 17.0665\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [75/200] Batch 11/12                         Loss D: -3.4878, loss G: 17.0661\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [76/200] Batch 11/12                         Loss D: -3.5330, loss G: 17.0660\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [77/200] Batch 11/12                         Loss D: -3.4759, loss G: 17.0663\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [78/200] Batch 11/12                         Loss D: -3.4486, loss G: 17.0662\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [79/200] Batch 11/12                         Loss D: -3.4797, loss G: 17.0660\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [80/200] Batch 11/12                         Loss D: -3.5439, loss G: 17.0665\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [81/200] Batch 11/12                         Loss D: -3.6069, loss G: 17.0669\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [82/200] Batch 11/12                         Loss D: -3.5043, loss G: 17.0670\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [83/200] Batch 11/12                         Loss D: -3.4913, loss G: 17.0667\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [84/200] Batch 11/12                         Loss D: -3.4192, loss G: 17.0670\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [85/200] Batch 11/12                         Loss D: -3.4879, loss G: 17.0667\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [86/200] Batch 11/12                         Loss D: -3.4925, loss G: 17.0665\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [87/200] Batch 11/12                         Loss D: -3.6064, loss G: 17.0672\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [88/200] Batch 11/12                         Loss D: -3.6145, loss G: 17.0673\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [89/200] Batch 11/12                         Loss D: -3.5287, loss G: 17.0680\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [90/200] Batch 11/12                         Loss D: -3.5223, loss G: 17.0676\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [91/200] Batch 11/12                         Loss D: -3.4537, loss G: 17.0683\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [92/200] Batch 11/12                         Loss D: -3.6668, loss G: 17.0679\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [93/200] Batch 11/12                         Loss D: -3.5777, loss G: 17.0686\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [94/200] Batch 11/12                         Loss D: -3.5295, loss G: 17.0677\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [95/200] Batch 11/12                         Loss D: -3.6165, loss G: 17.0686\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [96/200] Batch 11/12                         Loss D: -3.5898, loss G: 17.0690\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [97/200] Batch 11/12                         Loss D: -3.5627, loss G: 17.0692\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [98/200] Batch 11/12                         Loss D: -3.4396, loss G: 17.0692\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [99/200] Batch 11/12                         Loss D: -3.5987, loss G: 17.0695\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [100/200] Batch 11/12                         Loss D: -3.5699, loss G: 17.0700\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [101/200] Batch 11/12                         Loss D: -3.6625, loss G: 17.0700\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [102/200] Batch 11/12                         Loss D: -3.6745, loss G: 17.0704\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [103/200] Batch 11/12                         Loss D: -3.4617, loss G: 17.0707\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [104/200] Batch 11/12                         Loss D: -3.5294, loss G: 17.0708\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [105/200] Batch 11/12                         Loss D: -3.6318, loss G: 17.0707\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [106/200] Batch 11/12                         Loss D: -3.6883, loss G: 17.0721\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [107/200] Batch 11/12                         Loss D: -3.7966, loss G: 17.0723\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [108/200] Batch 11/12                         Loss D: -3.5776, loss G: 17.0718\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [109/200] Batch 11/12                         Loss D: -3.6890, loss G: 17.0720\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [110/200] Batch 11/12                         Loss D: -3.6844, loss G: 17.0730\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [111/200] Batch 11/12                         Loss D: -3.6801, loss G: 17.0734\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [112/200] Batch 11/12                         Loss D: -3.6343, loss G: 17.0732\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [113/200] Batch 11/12                         Loss D: -3.7044, loss G: 17.0731\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [114/200] Batch 11/12                         Loss D: -3.5476, loss G: 17.0743\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [115/200] Batch 11/12                         Loss D: -3.6654, loss G: 17.0750\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [116/200] Batch 11/12                         Loss D: -3.7253, loss G: 17.0741\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [117/200] Batch 11/12                         Loss D: -3.7109, loss G: 17.0740\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [118/200] Batch 11/12                         Loss D: -3.6507, loss G: 17.0748\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [119/200] Batch 11/12                         Loss D: -3.7101, loss G: 17.0755\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [120/200] Batch 11/12                         Loss D: -3.7081, loss G: 17.0761\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [121/200] Batch 11/12                         Loss D: -3.7158, loss G: 17.0758\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [122/200] Batch 11/12                         Loss D: -3.6804, loss G: 17.0764\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [123/200] Batch 11/12                         Loss D: -3.7708, loss G: 17.0767\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [124/200] Batch 11/12                         Loss D: -3.6745, loss G: 17.0769\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [125/200] Batch 11/12                         Loss D: -3.5794, loss G: 17.0777\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [126/200] Batch 11/12                         Loss D: -3.9286, loss G: 17.0773\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [127/200] Batch 11/12                         Loss D: -3.8209, loss G: 17.0785\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [128/200] Batch 11/12                         Loss D: -3.8606, loss G: 17.0788\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [129/200] Batch 11/12                         Loss D: -3.8223, loss G: 17.0788\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [130/200] Batch 11/12                         Loss D: -3.9232, loss G: 17.0788\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [131/200] Batch 11/12                         Loss D: -3.6488, loss G: 17.0797\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [132/200] Batch 11/12                         Loss D: -3.8758, loss G: 17.0794\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [133/200] Batch 11/12                         Loss D: -3.8249, loss G: 17.0794\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [134/200] Batch 11/12                         Loss D: -3.7986, loss G: 17.0800\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [135/200] Batch 11/12                         Loss D: -3.9525, loss G: 17.0806\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [136/200] Batch 11/12                         Loss D: -3.7028, loss G: 17.0809\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [137/200] Batch 11/12                         Loss D: -3.6619, loss G: 17.0823\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [138/200] Batch 11/12                         Loss D: -3.5772, loss G: 17.0826\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [139/200] Batch 11/12                         Loss D: -3.6267, loss G: 17.0830\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [140/200] Batch 11/12                         Loss D: -3.9571, loss G: 17.0823\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [141/200] Batch 11/12                         Loss D: -3.7455, loss G: 17.0831\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [142/200] Batch 11/12                         Loss D: -3.9379, loss G: 17.0822\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [143/200] Batch 11/12                         Loss D: -3.9390, loss G: 17.0826\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [144/200] Batch 11/12                         Loss D: -4.0044, loss G: 17.0836\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [145/200] Batch 11/12                         Loss D: -4.0081, loss G: 17.0840\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [146/200] Batch 11/12                         Loss D: -3.9940, loss G: 17.0844\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [147/200] Batch 11/12                         Loss D: -4.0171, loss G: 17.0842\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [148/200] Batch 11/12                         Loss D: -4.1773, loss G: 17.0851\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [149/200] Batch 11/12                         Loss D: -4.0942, loss G: 17.0854\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [150/200] Batch 11/12                         Loss D: -4.0411, loss G: 17.0853\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [151/200] Batch 11/12                         Loss D: -4.0392, loss G: 17.0859\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [152/200] Batch 11/12                         Loss D: -4.0950, loss G: 17.0864\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [153/200] Batch 11/12                         Loss D: -4.1434, loss G: 17.0872\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [154/200] Batch 11/12                         Loss D: -4.0407, loss G: 17.0872\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [155/200] Batch 11/12                         Loss D: -4.2362, loss G: 17.0871\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [156/200] Batch 11/12                         Loss D: -4.2896, loss G: 17.0877\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [157/200] Batch 11/12                         Loss D: -4.3503, loss G: 17.0873\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [158/200] Batch 11/12                         Loss D: -4.3574, loss G: 17.0870\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [159/200] Batch 11/12                         Loss D: -4.2558, loss G: 17.0869\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [160/200] Batch 11/12                         Loss D: -4.4422, loss G: 17.0866\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [161/200] Batch 11/12                         Loss D: -4.4768, loss G: 17.0862\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [162/200] Batch 11/12                         Loss D: -4.4880, loss G: 17.0858\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [163/200] Batch 11/12                         Loss D: -4.3758, loss G: 17.0859\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [164/200] Batch 11/12                         Loss D: -4.5751, loss G: 17.0850\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [165/200] Batch 11/12                         Loss D: -4.5828, loss G: 17.0843\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [166/200] Batch 11/12                         Loss D: -4.6654, loss G: 17.0839\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [167/200] Batch 11/12                         Loss D: -4.5371, loss G: 17.0833\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [168/200] Batch 11/12                         Loss D: -4.7943, loss G: 17.0823\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [169/200] Batch 11/12                         Loss D: -4.7117, loss G: 17.0819\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [170/200] Batch 11/12                         Loss D: -4.7470, loss G: 17.0809\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [171/200] Batch 11/12                         Loss D: -4.7972, loss G: 17.0801\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [172/200] Batch 11/12                         Loss D: -4.7508, loss G: 17.0793\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [173/200] Batch 11/12                         Loss D: -4.7808, loss G: 17.0783\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [174/200] Batch 11/12                         Loss D: -4.8384, loss G: 17.0768\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [175/200] Batch 11/12                         Loss D: -4.4461, loss G: 17.0762\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [176/200] Batch 11/12                         Loss D: -4.2028, loss G: 17.0734\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [177/200] Batch 11/12                         Loss D: -3.5459, loss G: 17.0711\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [178/200] Batch 11/12                         Loss D: -2.7033, loss G: 17.0683\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [179/200] Batch 11/12                         Loss D: -1.6262, loss G: 17.0672\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [180/200] Batch 11/12                         Loss D: -0.5287, loss G: 17.0743\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [181/200] Batch 11/12                         Loss D: -0.3831, loss G: 17.0816\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [182/200] Batch 11/12                         Loss D: -0.4681, loss G: 17.0864\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [183/200] Batch 11/12                         Loss D: -0.5725, loss G: 17.0890\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [184/200] Batch 11/12                         Loss D: -0.9251, loss G: 17.0894\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [185/200] Batch 11/12                         Loss D: -1.3334, loss G: 17.0895\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [186/200] Batch 11/12                         Loss D: -1.7861, loss G: 17.0889\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [187/200] Batch 11/12                         Loss D: -1.9916, loss G: 17.0888\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [188/200] Batch 11/12                         Loss D: -2.1559, loss G: 17.0890\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [189/200] Batch 11/12                         Loss D: -2.2346, loss G: 17.0889\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [190/200] Batch 11/12                         Loss D: -2.5621, loss G: 17.0883\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [191/200] Batch 11/12                         Loss D: -2.4995, loss G: 17.0886\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [192/200] Batch 11/12                         Loss D: -2.5049, loss G: 17.0883\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [193/200] Batch 11/12                         Loss D: -2.5106, loss G: 17.0880\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [194/200] Batch 11/12                         Loss D: -2.3055, loss G: 17.0880\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [195/200] Batch 11/12                         Loss D: -2.3177, loss G: 17.0883\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [196/200] Batch 11/12                         Loss D: -1.9820, loss G: 17.0881\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [197/200] Batch 11/12                         Loss D: -1.5135, loss G: 17.0886\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [198/200] Batch 11/12                         Loss D: -1.3275, loss G: 17.0880\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [199/200] Batch 11/12                         Loss D: -1.0982, loss G: 17.0880\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [0/200] Batch 11/12                         Loss D: 0.8043, loss G: 3.6006\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [1/200] Batch 11/12                         Loss D: 0.4282, loss G: 3.5878\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [2/200] Batch 11/12                         Loss D: -0.1115, loss G: 3.5767\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [3/200] Batch 11/12                         Loss D: -0.7450, loss G: 3.5664\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [4/200] Batch 11/12                         Loss D: -1.5517, loss G: 3.5535\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [5/200] Batch 11/12                         Loss D: -2.4878, loss G: 3.5422\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [6/200] Batch 11/12                         Loss D: -3.5043, loss G: 3.5335\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [7/200] Batch 11/12                         Loss D: -4.3838, loss G: 3.5373\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [8/200] Batch 11/12                         Loss D: -4.8201, loss G: 3.5521\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [9/200] Batch 11/12                         Loss D: -4.9514, loss G: 3.5663\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [10/200] Batch 11/12                         Loss D: -4.9945, loss G: 3.5761\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [11/200] Batch 11/12                         Loss D: -5.0222, loss G: 3.5854\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [12/200] Batch 11/12                         Loss D: -4.9998, loss G: 3.5932\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [13/200] Batch 11/12                         Loss D: -5.0285, loss G: 3.6002\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [14/200] Batch 11/12                         Loss D: -4.9611, loss G: 3.6058\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [15/200] Batch 11/12                         Loss D: -4.8165, loss G: 3.6103\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [16/200] Batch 11/12                         Loss D: -4.5944, loss G: 3.6139\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [17/200] Batch 11/12                         Loss D: -4.3300, loss G: 3.6159\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [18/200] Batch 11/12                         Loss D: -3.8633, loss G: 3.6159\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [19/200] Batch 11/12                         Loss D: -3.4405, loss G: 3.6150\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [20/200] Batch 11/12                         Loss D: -3.1000, loss G: 3.6141\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [21/200] Batch 11/12                         Loss D: -2.8191, loss G: 3.6130\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [22/200] Batch 11/12                         Loss D: -2.7214, loss G: 3.6133\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [23/200] Batch 11/12                         Loss D: -2.6538, loss G: 3.6138\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [24/200] Batch 11/12                         Loss D: -2.5415, loss G: 3.6147\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [25/200] Batch 11/12                         Loss D: -2.3388, loss G: 3.6156\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [26/200] Batch 11/12                         Loss D: -2.0661, loss G: 3.6162\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [27/200] Batch 11/12                         Loss D: -1.7204, loss G: 3.6164\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [28/200] Batch 11/12                         Loss D: -1.2620, loss G: 3.6163\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [29/200] Batch 11/12                         Loss D: -0.7251, loss G: 3.6163\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [30/200] Batch 11/12                         Loss D: -0.5815, loss G: 3.6184\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [31/200] Batch 11/12                         Loss D: -0.5646, loss G: 3.6213\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [32/200] Batch 11/12                         Loss D: -0.5771, loss G: 3.6243\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [33/200] Batch 11/12                         Loss D: -0.6370, loss G: 3.6272\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [34/200] Batch 11/12                         Loss D: -0.7010, loss G: 3.6288\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [35/200] Batch 11/12                         Loss D: -0.7553, loss G: 3.6295\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [36/200] Batch 11/12                         Loss D: -0.8575, loss G: 3.6300\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [37/200] Batch 11/12                         Loss D: -0.9038, loss G: 3.6298\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [38/200] Batch 11/12                         Loss D: -0.9196, loss G: 3.6294\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [39/200] Batch 11/12                         Loss D: -1.0047, loss G: 3.6291\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [40/200] Batch 11/12                         Loss D: -1.0672, loss G: 3.6291\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [41/200] Batch 11/12                         Loss D: -1.0161, loss G: 3.6294\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [42/200] Batch 11/12                         Loss D: -0.9265, loss G: 3.6294\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [43/200] Batch 11/12                         Loss D: -0.8540, loss G: 3.6302\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [44/200] Batch 11/12                         Loss D: -0.7424, loss G: 3.6320\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [45/200] Batch 11/12                         Loss D: -0.6500, loss G: 3.6350\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [46/200] Batch 11/12                         Loss D: -0.6725, loss G: 3.6387\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [47/200] Batch 11/12                         Loss D: -0.7379, loss G: 3.6421\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [48/200] Batch 11/12                         Loss D: -0.8848, loss G: 3.6444\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [49/200] Batch 11/12                         Loss D: -1.0169, loss G: 3.6452\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [50/200] Batch 11/12                         Loss D: -1.1568, loss G: 3.6451\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [51/200] Batch 11/12                         Loss D: -1.1093, loss G: 3.6437\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [52/200] Batch 11/12                         Loss D: -1.1809, loss G: 3.6430\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [53/200] Batch 11/12                         Loss D: -1.3089, loss G: 3.6423\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [54/200] Batch 11/12                         Loss D: -1.4263, loss G: 3.6416\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [55/200] Batch 11/12                         Loss D: -1.4089, loss G: 3.6409\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [56/200] Batch 11/12                         Loss D: -1.2344, loss G: 3.6406\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [57/200] Batch 11/12                         Loss D: -1.0535, loss G: 3.6411\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [58/200] Batch 11/12                         Loss D: -0.9632, loss G: 3.6426\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [59/200] Batch 11/12                         Loss D: -0.8884, loss G: 3.6455\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [60/200] Batch 11/12                         Loss D: -0.9241, loss G: 3.6492\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [61/200] Batch 11/12                         Loss D: -1.0101, loss G: 3.6523\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [62/200] Batch 11/12                         Loss D: -1.1243, loss G: 3.6548\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [63/200] Batch 11/12                         Loss D: -1.2477, loss G: 3.6558\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [64/200] Batch 11/12                         Loss D: -1.3931, loss G: 3.6560\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [65/200] Batch 11/12                         Loss D: -1.3992, loss G: 3.6551\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [66/200] Batch 11/12                         Loss D: -1.4702, loss G: 3.6541\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [67/200] Batch 11/12                         Loss D: -1.5135, loss G: 3.6533\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [68/200] Batch 11/12                         Loss D: -1.5803, loss G: 3.6524\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [69/200] Batch 11/12                         Loss D: -1.5312, loss G: 3.6521\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [70/200] Batch 11/12                         Loss D: -1.4703, loss G: 3.6525\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [71/200] Batch 11/12                         Loss D: -1.3158, loss G: 3.6532\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [72/200] Batch 11/12                         Loss D: -1.1981, loss G: 3.6552\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [73/200] Batch 11/12                         Loss D: -1.1982, loss G: 3.6581\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [74/200] Batch 11/12                         Loss D: -1.2441, loss G: 3.6609\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [75/200] Batch 11/12                         Loss D: -1.3102, loss G: 3.6635\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [76/200] Batch 11/12                         Loss D: -1.4067, loss G: 3.6655\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [77/200] Batch 11/12                         Loss D: -1.5348, loss G: 3.6667\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [78/200] Batch 11/12                         Loss D: -1.5718, loss G: 3.6660\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [79/200] Batch 11/12                         Loss D: -1.5918, loss G: 3.6653\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [80/200] Batch 11/12                         Loss D: -1.6555, loss G: 3.6643\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [81/200] Batch 11/12                         Loss D: -1.7071, loss G: 3.6635\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [82/200] Batch 11/12                         Loss D: -1.6920, loss G: 3.6637\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [83/200] Batch 11/12                         Loss D: -1.6693, loss G: 3.6640\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [84/200] Batch 11/12                         Loss D: -1.5499, loss G: 3.6651\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [85/200] Batch 11/12                         Loss D: -1.5242, loss G: 3.6668\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [86/200] Batch 11/12                         Loss D: -1.4828, loss G: 3.6695\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [87/200] Batch 11/12                         Loss D: -1.5339, loss G: 3.6723\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [88/200] Batch 11/12                         Loss D: -1.6937, loss G: 3.6750\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [89/200] Batch 11/12                         Loss D: -1.6883, loss G: 3.6763\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [90/200] Batch 11/12                         Loss D: -1.7092, loss G: 3.6765\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [91/200] Batch 11/12                         Loss D: -1.7252, loss G: 3.6755\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [92/200] Batch 11/12                         Loss D: -1.7651, loss G: 3.6748\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [93/200] Batch 11/12                         Loss D: -1.8674, loss G: 3.6743\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [94/200] Batch 11/12                         Loss D: -1.9312, loss G: 3.6742\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [95/200] Batch 11/12                         Loss D: -1.9030, loss G: 3.6747\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [96/200] Batch 11/12                         Loss D: -1.7920, loss G: 3.6759\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [97/200] Batch 11/12                         Loss D: -1.7513, loss G: 3.6778\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [98/200] Batch 11/12                         Loss D: -1.8268, loss G: 3.6801\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [99/200] Batch 11/12                         Loss D: -1.8308, loss G: 3.6826\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [100/200] Batch 11/12                         Loss D: -1.8769, loss G: 3.6847\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [101/200] Batch 11/12                         Loss D: -1.8990, loss G: 3.6856\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [102/200] Batch 11/12                         Loss D: -1.9312, loss G: 3.6855\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [103/200] Batch 11/12                         Loss D: -2.0245, loss G: 3.6852\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [104/200] Batch 11/12                         Loss D: -2.0382, loss G: 3.6849\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [105/200] Batch 11/12                         Loss D: -2.0338, loss G: 3.6847\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [106/200] Batch 11/12                         Loss D: -2.0142, loss G: 3.6854\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [107/200] Batch 11/12                         Loss D: -2.0626, loss G: 3.6863\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [108/200] Batch 11/12                         Loss D: -2.0872, loss G: 3.6881\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [109/200] Batch 11/12                         Loss D: -2.0593, loss G: 3.6900\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [110/200] Batch 11/12                         Loss D: -2.0555, loss G: 3.6916\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [111/200] Batch 11/12                         Loss D: -2.0714, loss G: 3.6933\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [112/200] Batch 11/12                         Loss D: -2.1432, loss G: 3.6939\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [113/200] Batch 11/12                         Loss D: -2.1239, loss G: 3.6944\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [114/200] Batch 11/12                         Loss D: -2.1831, loss G: 3.6946\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [115/200] Batch 11/12                         Loss D: -2.1678, loss G: 3.6948\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [116/200] Batch 11/12                         Loss D: -2.1952, loss G: 3.6953\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [117/200] Batch 11/12                         Loss D: -2.2674, loss G: 3.6962\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [118/200] Batch 11/12                         Loss D: -2.3087, loss G: 3.6972\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [119/200] Batch 11/12                         Loss D: -2.2302, loss G: 3.6986\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [120/200] Batch 11/12                         Loss D: -2.2298, loss G: 3.6999\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [121/200] Batch 11/12                         Loss D: -2.3257, loss G: 3.7011\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [122/200] Batch 11/12                         Loss D: -2.3912, loss G: 3.7020\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [123/200] Batch 11/12                         Loss D: -2.4576, loss G: 3.7031\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [124/200] Batch 11/12                         Loss D: -2.3088, loss G: 3.7038\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [125/200] Batch 11/12                         Loss D: -2.4002, loss G: 3.7045\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [126/200] Batch 11/12                         Loss D: -2.4868, loss G: 3.7050\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [127/200] Batch 11/12                         Loss D: -2.5126, loss G: 3.7058\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [128/200] Batch 11/12                         Loss D: -2.5292, loss G: 3.7068\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [129/200] Batch 11/12                         Loss D: -2.5211, loss G: 3.7078\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [130/200] Batch 11/12                         Loss D: -2.4817, loss G: 3.7089\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [131/200] Batch 11/12                         Loss D: -2.6052, loss G: 3.7100\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [132/200] Batch 11/12                         Loss D: -2.5740, loss G: 3.7108\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [133/200] Batch 11/12                         Loss D: -2.6089, loss G: 3.7116\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [134/200] Batch 11/12                         Loss D: -2.6121, loss G: 3.7126\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [135/200] Batch 11/12                         Loss D: -2.6301, loss G: 3.7135\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [136/200] Batch 11/12                         Loss D: -2.6978, loss G: 3.7145\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [137/200] Batch 11/12                         Loss D: -2.6685, loss G: 3.7152\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [138/200] Batch 11/12                         Loss D: -2.7181, loss G: 3.7162\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [139/200] Batch 11/12                         Loss D: -2.6650, loss G: 3.7170\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [140/200] Batch 11/12                         Loss D: -2.8036, loss G: 3.7182\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [141/200] Batch 11/12                         Loss D: -2.8046, loss G: 3.7191\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [142/200] Batch 11/12                         Loss D: -2.8496, loss G: 3.7202\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [143/200] Batch 11/12                         Loss D: -2.7905, loss G: 3.7210\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [144/200] Batch 11/12                         Loss D: -2.8171, loss G: 3.7218\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [145/200] Batch 11/12                         Loss D: -2.8618, loss G: 3.7230\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [146/200] Batch 11/12                         Loss D: -2.7833, loss G: 3.7236\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [147/200] Batch 11/12                         Loss D: -2.8322, loss G: 3.7247\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [148/200] Batch 11/12                         Loss D: -2.8458, loss G: 3.7256\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [149/200] Batch 11/12                         Loss D: -2.8847, loss G: 3.7265\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [150/200] Batch 11/12                         Loss D: -2.8830, loss G: 3.7277\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [151/200] Batch 11/12                         Loss D: -2.9203, loss G: 3.7286\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [152/200] Batch 11/12                         Loss D: -2.9547, loss G: 3.7293\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [153/200] Batch 11/12                         Loss D: -2.9253, loss G: 3.7303\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [154/200] Batch 11/12                         Loss D: -2.9732, loss G: 3.7312\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [155/200] Batch 11/12                         Loss D: -2.9363, loss G: 3.7324\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [156/200] Batch 11/12                         Loss D: -2.9521, loss G: 3.7333\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [157/200] Batch 11/12                         Loss D: -3.0221, loss G: 3.7341\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [158/200] Batch 11/12                         Loss D: -3.0375, loss G: 3.7352\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [159/200] Batch 11/12                         Loss D: -3.0333, loss G: 3.7361\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [160/200] Batch 11/12                         Loss D: -3.0719, loss G: 3.7371\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [161/200] Batch 11/12                         Loss D: -3.0113, loss G: 3.7381\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [162/200] Batch 11/12                         Loss D: -3.0610, loss G: 3.7389\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [163/200] Batch 11/12                         Loss D: -3.0992, loss G: 3.7401\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [164/200] Batch 11/12                         Loss D: -3.1581, loss G: 3.7410\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [165/200] Batch 11/12                         Loss D: -3.1518, loss G: 3.7419\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [166/200] Batch 11/12                         Loss D: -3.1957, loss G: 3.7427\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [167/200] Batch 11/12                         Loss D: -3.1237, loss G: 3.7440\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [168/200] Batch 11/12                         Loss D: -3.2857, loss G: 3.7445\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [169/200] Batch 11/12                         Loss D: -3.1833, loss G: 3.7456\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [170/200] Batch 11/12                         Loss D: -3.2019, loss G: 3.7466\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [171/200] Batch 11/12                         Loss D: -3.2084, loss G: 3.7478\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [172/200] Batch 11/12                         Loss D: -3.2110, loss G: 3.7486\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [173/200] Batch 11/12                         Loss D: -3.1664, loss G: 3.7497\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [174/200] Batch 11/12                         Loss D: -3.2025, loss G: 3.7500\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [175/200] Batch 11/12                         Loss D: -3.1724, loss G: 3.7510\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [176/200] Batch 11/12                         Loss D: -3.0543, loss G: 3.7519\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [177/200] Batch 11/12                         Loss D: -2.7319, loss G: 3.7527\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [178/200] Batch 11/12                         Loss D: -2.4935, loss G: 3.7536\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [179/200] Batch 11/12                         Loss D: -2.3384, loss G: 3.7538\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [180/200] Batch 11/12                         Loss D: -2.1560, loss G: 3.7543\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [181/200] Batch 11/12                         Loss D: -2.1249, loss G: 3.7541\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [182/200] Batch 11/12                         Loss D: -2.1016, loss G: 3.7545\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [183/200] Batch 11/12                         Loss D: -2.1451, loss G: 3.7548\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [184/200] Batch 11/12                         Loss D: -2.1949, loss G: 3.7554\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [185/200] Batch 11/12                         Loss D: -2.3009, loss G: 3.7561\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [186/200] Batch 11/12                         Loss D: -2.3386, loss G: 3.7569\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [187/200] Batch 11/12                         Loss D: -2.3523, loss G: 3.7576\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [188/200] Batch 11/12                         Loss D: -2.3241, loss G: 3.7582\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [189/200] Batch 11/12                         Loss D: -2.2746, loss G: 3.7587\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [190/200] Batch 11/12                         Loss D: -2.2287, loss G: 3.7591\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [191/200] Batch 11/12                         Loss D: -2.2483, loss G: 3.7591\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [192/200] Batch 11/12                         Loss D: -2.3427, loss G: 3.7590\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [193/200] Batch 11/12                         Loss D: -2.3657, loss G: 3.7593\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [194/200] Batch 11/12                         Loss D: -2.3927, loss G: 3.7597\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [195/200] Batch 11/12                         Loss D: -2.3933, loss G: 3.7603\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [196/200] Batch 11/12                         Loss D: -2.4755, loss G: 3.7608\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [197/200] Batch 11/12                         Loss D: -2.4580, loss G: 3.7616\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [198/200] Batch 11/12                         Loss D: -2.5730, loss G: 3.7623\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [199/200] Batch 11/12                         Loss D: -2.6169, loss G: 3.7635\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [0/200] Batch 11/12                         Loss D: 0.1240, loss G: 34.6630\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [1/200] Batch 11/12                         Loss D: 0.1602, loss G: 34.4380\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [2/200] Batch 11/12                         Loss D: 0.2008, loss G: 34.1215\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [3/200] Batch 11/12                         Loss D: 0.2408, loss G: 33.7243\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [4/200] Batch 11/12                         Loss D: 0.2832, loss G: 33.1814\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [5/200] Batch 11/12                         Loss D: 0.3164, loss G: 32.4781\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [6/200] Batch 11/12                         Loss D: 0.3289, loss G: 31.6200\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [7/200] Batch 11/12                         Loss D: 0.3063, loss G: 30.6429\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [8/200] Batch 11/12                         Loss D: 0.2436, loss G: 29.5484\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [9/200] Batch 11/12                         Loss D: 0.1278, loss G: 28.7012\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [10/200] Batch 11/12                         Loss D: -0.0456, loss G: 27.9513\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [11/200] Batch 11/12                         Loss D: -0.2896, loss G: 26.9210\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [12/200] Batch 11/12                         Loss D: -0.6250, loss G: 25.8328\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [13/200] Batch 11/12                         Loss D: -1.0782, loss G: 24.6424\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [14/200] Batch 11/12                         Loss D: -1.6993, loss G: 23.1841\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [15/200] Batch 11/12                         Loss D: -2.4721, loss G: 21.7806\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [16/200] Batch 11/12                         Loss D: -3.4609, loss G: 20.1606\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [17/200] Batch 11/12                         Loss D: -4.7720, loss G: 18.1270\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [18/200] Batch 11/12                         Loss D: -6.5037, loss G: 15.7297\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [19/200] Batch 11/12                         Loss D: -8.4477, loss G: 13.5196\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [20/200] Batch 11/12                         Loss D: -10.6647, loss G: 11.3873\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [21/200] Batch 11/12                         Loss D: -12.5321, loss G: 10.3472\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [22/200] Batch 11/12                         Loss D: -14.5165, loss G: 9.4285\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [23/200] Batch 11/12                         Loss D: -16.4935, loss G: 8.5860\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [24/200] Batch 11/12                         Loss D: -18.4583, loss G: 7.6907\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [25/200] Batch 11/12                         Loss D: -20.6625, loss G: 6.7543\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [26/200] Batch 11/12                         Loss D: -22.6362, loss G: 5.7893\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [27/200] Batch 11/12                         Loss D: -25.2310, loss G: 4.3565\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [28/200] Batch 11/12                         Loss D: -27.4959, loss G: 3.1733\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [29/200] Batch 11/12                         Loss D: -30.0830, loss G: 2.2925\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [30/200] Batch 11/12                         Loss D: -32.0157, loss G: 2.2768\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [31/200] Batch 11/12                         Loss D: -34.2731, loss G: 2.3623\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [32/200] Batch 11/12                         Loss D: -36.4945, loss G: 2.6601\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [33/200] Batch 11/12                         Loss D: -38.0847, loss G: 2.7580\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [34/200] Batch 11/12                         Loss D: -40.2286, loss G: 2.7658\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [35/200] Batch 11/12                         Loss D: -42.2110, loss G: 2.8118\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [36/200] Batch 11/12                         Loss D: -44.5076, loss G: 3.2534\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [37/200] Batch 11/12                         Loss D: -45.4761, loss G: 3.3368\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [38/200] Batch 11/12                         Loss D: -47.8019, loss G: 3.1773\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [39/200] Batch 11/12                         Loss D: -49.7460, loss G: 3.2860\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [40/200] Batch 11/12                         Loss D: -51.5472, loss G: 3.5383\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [41/200] Batch 11/12                         Loss D: -53.2343, loss G: 3.6251\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [42/200] Batch 11/12                         Loss D: -55.4977, loss G: 3.6207\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [43/200] Batch 11/12                         Loss D: -57.6503, loss G: 3.8745\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [44/200] Batch 11/12                         Loss D: -59.2552, loss G: 3.8636\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [45/200] Batch 11/12                         Loss D: -60.7749, loss G: 4.1859\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [46/200] Batch 11/12                         Loss D: -63.8315, loss G: 4.3583\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [47/200] Batch 11/12                         Loss D: -64.9025, loss G: 4.3803\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [48/200] Batch 11/12                         Loss D: -67.6035, loss G: 4.4196\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [49/200] Batch 11/12                         Loss D: -69.6537, loss G: 4.4814\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [50/200] Batch 11/12                         Loss D: -71.1783, loss G: 4.7451\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [51/200] Batch 11/12                         Loss D: -73.6717, loss G: 4.7000\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [52/200] Batch 11/12                         Loss D: -75.6658, loss G: 4.9030\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [53/200] Batch 11/12                         Loss D: -78.2326, loss G: 4.9868\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [54/200] Batch 11/12                         Loss D: -78.9706, loss G: 5.5112\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [55/200] Batch 11/12                         Loss D: -82.8607, loss G: 5.3326\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [56/200] Batch 11/12                         Loss D: -85.3102, loss G: 5.5354\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [57/200] Batch 11/12                         Loss D: -86.7528, loss G: 5.5687\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [58/200] Batch 11/12                         Loss D: -89.3453, loss G: 5.6742\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [59/200] Batch 11/12                         Loss D: -92.2902, loss G: 5.7904\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [60/200] Batch 11/12                         Loss D: -93.8783, loss G: 6.0278\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [61/200] Batch 11/12                         Loss D: -97.2906, loss G: 5.8842\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [62/200] Batch 11/12                         Loss D: -99.9063, loss G: 5.7807\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [63/200] Batch 11/12                         Loss D: -102.2484, loss G: 5.7583\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [64/200] Batch 11/12                         Loss D: -104.7055, loss G: 5.7358\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [65/200] Batch 11/12                         Loss D: -108.6188, loss G: 5.8656\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [66/200] Batch 11/12                         Loss D: -110.2333, loss G: 5.5821\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [67/200] Batch 11/12                         Loss D: -112.7306, loss G: 5.4626\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [68/200] Batch 11/12                         Loss D: -117.0213, loss G: 5.4215\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [69/200] Batch 11/12                         Loss D: -119.5670, loss G: 5.2401\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [70/200] Batch 11/12                         Loss D: -122.4091, loss G: 5.0818\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [71/200] Batch 11/12                         Loss D: -124.4662, loss G: 5.0601\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [72/200] Batch 11/12                         Loss D: -126.7850, loss G: 5.2109\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [73/200] Batch 11/12                         Loss D: -130.7434, loss G: 5.2545\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [74/200] Batch 11/12                         Loss D: -134.0839, loss G: 5.4256\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [75/200] Batch 11/12                         Loss D: -135.0986, loss G: 5.5079\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [76/200] Batch 11/12                         Loss D: -141.6954, loss G: 5.8607\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [77/200] Batch 11/12                         Loss D: -141.2597, loss G: 5.6456\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [78/200] Batch 11/12                         Loss D: -143.1514, loss G: 5.9829\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [79/200] Batch 11/12                         Loss D: -148.6094, loss G: 6.0021\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [80/200] Batch 11/12                         Loss D: -150.2342, loss G: 6.1086\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [81/200] Batch 11/12                         Loss D: -154.7349, loss G: 6.3214\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [82/200] Batch 11/12                         Loss D: -156.8878, loss G: 6.4333\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [83/200] Batch 11/12                         Loss D: -158.8573, loss G: 6.6065\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [84/200] Batch 11/12                         Loss D: -161.5333, loss G: 6.7784\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [85/200] Batch 11/12                         Loss D: -166.0464, loss G: 7.2392\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [86/200] Batch 11/12                         Loss D: -167.4510, loss G: 7.3281\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [87/200] Batch 11/12                         Loss D: -170.8692, loss G: 7.7346\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [88/200] Batch 11/12                         Loss D: -172.2394, loss G: 7.8090\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [89/200] Batch 11/12                         Loss D: -172.8680, loss G: 8.1777\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [90/200] Batch 11/12                         Loss D: -175.5712, loss G: 8.3855\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [91/200] Batch 11/12                         Loss D: -177.9383, loss G: 8.7569\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [92/200] Batch 11/12                         Loss D: -179.5616, loss G: 9.0998\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [93/200] Batch 11/12                         Loss D: -179.3305, loss G: 9.4747\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [94/200] Batch 11/12                         Loss D: -180.8933, loss G: 9.9003\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [95/200] Batch 11/12                         Loss D: -180.5091, loss G: 10.3067\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [96/200] Batch 11/12                         Loss D: -179.3269, loss G: 10.9356\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [97/200] Batch 11/12                         Loss D: -179.3088, loss G: 11.3167\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [98/200] Batch 11/12                         Loss D: -177.5663, loss G: 11.8724\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [99/200] Batch 11/12                         Loss D: -173.6812, loss G: 12.4257\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [100/200] Batch 11/12                         Loss D: -167.5766, loss G: 12.7819\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [101/200] Batch 11/12                         Loss D: -161.5457, loss G: 13.2895\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [102/200] Batch 11/12                         Loss D: -153.7672, loss G: 13.6361\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [103/200] Batch 11/12                         Loss D: -145.6130, loss G: 14.0639\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [104/200] Batch 11/12                         Loss D: -134.9030, loss G: 14.4795\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [105/200] Batch 11/12                         Loss D: -125.1535, loss G: 14.8171\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [106/200] Batch 11/12                         Loss D: -114.7518, loss G: 15.1024\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [107/200] Batch 11/12                         Loss D: -104.2665, loss G: 15.4999\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [108/200] Batch 11/12                         Loss D: -92.3777, loss G: 15.6812\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [109/200] Batch 11/12                         Loss D: -80.8224, loss G: 16.1001\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [110/200] Batch 11/12                         Loss D: -68.4534, loss G: 16.2309\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [111/200] Batch 11/12                         Loss D: -56.1860, loss G: 16.5180\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [112/200] Batch 11/12                         Loss D: -46.6731, loss G: 16.7194\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [113/200] Batch 11/12                         Loss D: -45.8554, loss G: 17.2130\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [114/200] Batch 11/12                         Loss D: -53.7526, loss G: 17.5850\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [115/200] Batch 11/12                         Loss D: -59.0071, loss G: 17.9002\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [116/200] Batch 11/12                         Loss D: -62.2517, loss G: 18.1667\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [117/200] Batch 11/12                         Loss D: -65.5113, loss G: 18.4300\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [118/200] Batch 11/12                         Loss D: -69.9912, loss G: 18.7481\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [119/200] Batch 11/12                         Loss D: -72.8591, loss G: 18.8955\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [120/200] Batch 11/12                         Loss D: -76.3523, loss G: 19.2224\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [121/200] Batch 11/12                         Loss D: -78.6739, loss G: 19.4838\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [122/200] Batch 11/12                         Loss D: -81.9848, loss G: 19.6098\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [123/200] Batch 11/12                         Loss D: -84.8731, loss G: 19.9367\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [124/200] Batch 11/12                         Loss D: -86.7563, loss G: 20.2705\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [125/200] Batch 11/12                         Loss D: -90.7477, loss G: 20.4267\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [126/200] Batch 11/12                         Loss D: -95.6861, loss G: 20.8004\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [127/200] Batch 11/12                         Loss D: -97.1574, loss G: 20.8867\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [128/200] Batch 11/12                         Loss D: -100.4111, loss G: 21.1464\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [129/200] Batch 11/12                         Loss D: -104.5075, loss G: 21.3448\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [130/200] Batch 11/12                         Loss D: -108.1688, loss G: 21.6199\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [131/200] Batch 11/12                         Loss D: -109.7061, loss G: 21.9621\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [132/200] Batch 11/12                         Loss D: -114.9228, loss G: 22.1433\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [133/200] Batch 11/12                         Loss D: -115.4708, loss G: 22.5241\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [134/200] Batch 11/12                         Loss D: -121.0187, loss G: 22.6691\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [135/200] Batch 11/12                         Loss D: -123.9927, loss G: 22.9363\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [136/200] Batch 11/12                         Loss D: -127.0454, loss G: 23.1796\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [137/200] Batch 11/12                         Loss D: -130.5140, loss G: 23.3947\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [138/200] Batch 11/12                         Loss D: -136.6408, loss G: 23.5761\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [139/200] Batch 11/12                         Loss D: -146.4547, loss G: 23.7634\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [140/200] Batch 11/12                         Loss D: -157.0546, loss G: 23.9852\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [141/200] Batch 11/12                         Loss D: -171.8220, loss G: 24.0602\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [142/200] Batch 11/12                         Loss D: -186.5055, loss G: 24.0631\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [143/200] Batch 11/12                         Loss D: -199.2119, loss G: 24.1561\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [144/200] Batch 11/12                         Loss D: -217.2887, loss G: 24.2319\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [145/200] Batch 11/12                         Loss D: -229.8421, loss G: 23.9392\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [146/200] Batch 11/12                         Loss D: -243.0131, loss G: 23.9608\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [147/200] Batch 11/12                         Loss D: -254.6807, loss G: 24.0052\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [148/200] Batch 11/12                         Loss D: -263.3570, loss G: 24.1297\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [149/200] Batch 11/12                         Loss D: -275.7824, loss G: 24.0573\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [150/200] Batch 11/12                         Loss D: -290.4404, loss G: 23.8932\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [151/200] Batch 11/12                         Loss D: -304.1068, loss G: 23.7957\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [152/200] Batch 11/12                         Loss D: -314.7121, loss G: 23.8898\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [153/200] Batch 11/12                         Loss D: -332.3468, loss G: 23.8933\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [154/200] Batch 11/12                         Loss D: -343.5447, loss G: 23.9799\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [155/200] Batch 11/12                         Loss D: -359.5388, loss G: 24.1673\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [156/200] Batch 11/12                         Loss D: -370.3657, loss G: 24.4361\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [157/200] Batch 11/12                         Loss D: -380.8592, loss G: 24.7788\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [158/200] Batch 11/12                         Loss D: -397.2464, loss G: 25.0042\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [159/200] Batch 11/12                         Loss D: -410.4877, loss G: 25.3498\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [160/200] Batch 11/12                         Loss D: -417.2787, loss G: 25.9053\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [161/200] Batch 11/12                         Loss D: -431.6918, loss G: 26.5997\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [162/200] Batch 11/12                         Loss D: -433.5681, loss G: 26.8844\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [163/200] Batch 11/12                         Loss D: -444.2855, loss G: 27.3339\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [164/200] Batch 11/12                         Loss D: -447.2440, loss G: 27.9033\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [165/200] Batch 11/12                         Loss D: -458.3807, loss G: 28.3448\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [166/200] Batch 11/12                         Loss D: -468.6526, loss G: 28.8113\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [167/200] Batch 11/12                         Loss D: -472.2955, loss G: 29.3743\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [168/200] Batch 11/12                         Loss D: -481.3112, loss G: 29.8387\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [169/200] Batch 11/12                         Loss D: -483.0970, loss G: 30.3731\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [170/200] Batch 11/12                         Loss D: -493.8513, loss G: 30.8156\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [171/200] Batch 11/12                         Loss D: -512.4307, loss G: 31.3382\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [172/200] Batch 11/12                         Loss D: -508.6371, loss G: 31.7710\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [173/200] Batch 11/12                         Loss D: -520.4254, loss G: 32.2310\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [174/200] Batch 11/12                         Loss D: -529.8911, loss G: 32.7221\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [175/200] Batch 11/12                         Loss D: -536.6265, loss G: 33.1802\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [176/200] Batch 11/12                         Loss D: -539.6250, loss G: 33.6878\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [177/200] Batch 11/12                         Loss D: -549.7289, loss G: 34.1914\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [178/200] Batch 11/12                         Loss D: -556.6579, loss G: 34.6758\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [179/200] Batch 11/12                         Loss D: -565.5551, loss G: 35.1489\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [180/200] Batch 11/12                         Loss D: -571.0449, loss G: 35.6580\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [181/200] Batch 11/12                         Loss D: -581.4547, loss G: 36.1292\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [182/200] Batch 11/12                         Loss D: -584.5110, loss G: 36.6004\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [183/200] Batch 11/12                         Loss D: -590.8957, loss G: 37.0913\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [184/200] Batch 11/12                         Loss D: -595.8751, loss G: 37.5615\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [185/200] Batch 11/12                         Loss D: -598.2934, loss G: 38.0079\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [186/200] Batch 11/12                         Loss D: -600.6506, loss G: 38.4854\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [187/200] Batch 11/12                         Loss D: -601.8736, loss G: 38.8894\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [188/200] Batch 11/12                         Loss D: -603.7136, loss G: 39.3246\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [189/200] Batch 11/12                         Loss D: -605.2429, loss G: 39.7272\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [190/200] Batch 11/12                         Loss D: -606.7623, loss G: 40.1578\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [191/200] Batch 11/12                         Loss D: -596.7101, loss G: 40.4145\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [192/200] Batch 11/12                         Loss D: -594.6768, loss G: 40.7268\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [193/200] Batch 11/12                         Loss D: -592.6903, loss G: 41.0401\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [194/200] Batch 11/12                         Loss D: -586.6543, loss G: 41.3461\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [195/200] Batch 11/12                         Loss D: -573.9910, loss G: 41.4368\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [196/200] Batch 11/12                         Loss D: -569.4975, loss G: 41.6436\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [197/200] Batch 11/12                         Loss D: -553.9588, loss G: 41.6969\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [198/200] Batch 11/12                         Loss D: -544.7709, loss G: 41.7479\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [199/200] Batch 11/12                         Loss D: -535.9326, loss G: 41.8563\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [0/200] Batch 11/12                         Loss D: 0.0590, loss G: 17.3545\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [1/200] Batch 11/12                         Loss D: 0.7033, loss G: 17.1536\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [2/200] Batch 11/12                         Loss D: 1.2988, loss G: 16.9433\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [3/200] Batch 11/12                         Loss D: 1.9875, loss G: 16.6834\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [4/200] Batch 11/12                         Loss D: 2.8060, loss G: 16.3645\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [5/200] Batch 11/12                         Loss D: 3.9301, loss G: 15.9394\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [6/200] Batch 11/12                         Loss D: 5.2047, loss G: 15.4265\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [7/200] Batch 11/12                         Loss D: 6.5511, loss G: 14.8387\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [8/200] Batch 11/12                         Loss D: 8.0929, loss G: 14.2496\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [9/200] Batch 11/12                         Loss D: 9.6908, loss G: 13.7694\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [10/200] Batch 11/12                         Loss D: 11.4288, loss G: 13.2335\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [11/200] Batch 11/12                         Loss D: 13.1021, loss G: 12.6788\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [12/200] Batch 11/12                         Loss D: 15.2983, loss G: 11.9590\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [13/200] Batch 11/12                         Loss D: 17.2661, loss G: 11.2630\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [14/200] Batch 11/12                         Loss D: 19.6071, loss G: 10.4031\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [15/200] Batch 11/12                         Loss D: 21.9511, loss G: 9.4818\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [16/200] Batch 11/12                         Loss D: 24.7327, loss G: 8.3833\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [17/200] Batch 11/12                         Loss D: 27.2760, loss G: 7.2699\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [18/200] Batch 11/12                         Loss D: 30.0468, loss G: 6.0098\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [19/200] Batch 11/12                         Loss D: 33.1928, loss G: 4.5217\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [20/200] Batch 11/12                         Loss D: 35.6364, loss G: 3.1874\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [21/200] Batch 11/12                         Loss D: 38.3754, loss G: 1.7557\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [22/200] Batch 11/12                         Loss D: 40.2619, loss G: 0.9192\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [23/200] Batch 11/12                         Loss D: 43.0318, loss G: -0.1898\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [24/200] Batch 11/12                         Loss D: 45.7229, loss G: -1.2979\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [25/200] Batch 11/12                         Loss D: 49.7479, loss G: -2.5221\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [26/200] Batch 11/12                         Loss D: 53.8331, loss G: -3.6382\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [27/200] Batch 11/12                         Loss D: 53.8681, loss G: -3.9391\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [28/200] Batch 11/12                         Loss D: 51.4064, loss G: -3.4527\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [29/200] Batch 11/12                         Loss D: 47.8529, loss G: -3.5182\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [30/200] Batch 11/12                         Loss D: 45.4894, loss G: -3.2656\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [31/200] Batch 11/12                         Loss D: 44.9763, loss G: -3.3234\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [32/200] Batch 11/12                         Loss D: 42.7533, loss G: -3.2678\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [33/200] Batch 11/12                         Loss D: 40.8421, loss G: -2.9653\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [34/200] Batch 11/12                         Loss D: 40.0863, loss G: -3.0633\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [35/200] Batch 11/12                         Loss D: 38.6468, loss G: -2.9269\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [36/200] Batch 11/12                         Loss D: 37.5291, loss G: -2.9231\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [37/200] Batch 11/12                         Loss D: 36.4037, loss G: -2.7714\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [38/200] Batch 11/12                         Loss D: 34.5840, loss G: -2.6912\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [39/200] Batch 11/12                         Loss D: 33.5249, loss G: -2.7232\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [40/200] Batch 11/12                         Loss D: 32.4784, loss G: -2.6546\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [41/200] Batch 11/12                         Loss D: 31.6623, loss G: -2.6317\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [42/200] Batch 11/12                         Loss D: 30.7287, loss G: -2.5340\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [43/200] Batch 11/12                         Loss D: 29.5854, loss G: -2.5343\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [44/200] Batch 11/12                         Loss D: 28.7217, loss G: -2.4786\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [45/200] Batch 11/12                         Loss D: 28.6294, loss G: -2.3235\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [46/200] Batch 11/12                         Loss D: 26.9887, loss G: -2.3448\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [47/200] Batch 11/12                         Loss D: 25.6908, loss G: -2.0785\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [48/200] Batch 11/12                         Loss D: 25.1783, loss G: -2.2830\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [49/200] Batch 11/12                         Loss D: 24.5820, loss G: -2.2119\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [50/200] Batch 11/12                         Loss D: 23.7472, loss G: -2.1976\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [51/200] Batch 11/12                         Loss D: 22.9384, loss G: -2.1631\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [52/200] Batch 11/12                         Loss D: 22.1868, loss G: -2.1360\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [53/200] Batch 11/12                         Loss D: 21.6225, loss G: -2.0568\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [54/200] Batch 11/12                         Loss D: 20.7719, loss G: -2.0577\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [55/200] Batch 11/12                         Loss D: 19.7562, loss G: -1.9128\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [56/200] Batch 11/12                         Loss D: 19.2974, loss G: -1.9686\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [57/200] Batch 11/12                         Loss D: 18.7863, loss G: -1.9598\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [58/200] Batch 11/12                         Loss D: 18.3372, loss G: -1.8970\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [59/200] Batch 11/12                         Loss D: 17.4251, loss G: -1.9131\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [60/200] Batch 11/12                         Loss D: 16.8331, loss G: -1.9023\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [61/200] Batch 11/12                         Loss D: 16.4154, loss G: -1.8471\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [62/200] Batch 11/12                         Loss D: 15.8413, loss G: -1.8115\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [63/200] Batch 11/12                         Loss D: 15.0262, loss G: -1.8398\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [64/200] Batch 11/12                         Loss D: 14.6364, loss G: -1.7892\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [65/200] Batch 11/12                         Loss D: 14.0560, loss G: -1.7926\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [66/200] Batch 11/12                         Loss D: 13.6117, loss G: -1.7373\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [67/200] Batch 11/12                         Loss D: 12.8653, loss G: -1.7767\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [68/200] Batch 11/12                         Loss D: 12.3131, loss G: -1.7487\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [69/200] Batch 11/12                         Loss D: 11.8798, loss G: -1.7203\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [70/200] Batch 11/12                         Loss D: 11.4288, loss G: -1.7031\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [71/200] Batch 11/12                         Loss D: 10.9237, loss G: -1.6929\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [72/200] Batch 11/12                         Loss D: 10.2518, loss G: -1.6624\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [73/200] Batch 11/12                         Loss D: 9.9104, loss G: -1.6668\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [74/200] Batch 11/12                         Loss D: 9.4322, loss G: -1.6698\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [75/200] Batch 11/12                         Loss D: 8.9664, loss G: -1.6407\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [76/200] Batch 11/12                         Loss D: 8.5294, loss G: -1.6282\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [77/200] Batch 11/12                         Loss D: 8.2556, loss G: -1.5810\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [78/200] Batch 11/12                         Loss D: 7.6092, loss G: -1.6066\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [79/200] Batch 11/12                         Loss D: 7.1971, loss G: -1.6070\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [80/200] Batch 11/12                         Loss D: 6.8076, loss G: -1.5696\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [81/200] Batch 11/12                         Loss D: 6.3887, loss G: -1.5679\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [82/200] Batch 11/12                         Loss D: 5.9851, loss G: -1.5518\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [83/200] Batch 11/12                         Loss D: 5.5429, loss G: -1.5563\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [84/200] Batch 11/12                         Loss D: 5.1278, loss G: -1.5369\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [85/200] Batch 11/12                         Loss D: 4.7703, loss G: -1.5121\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [86/200] Batch 11/12                         Loss D: 4.3970, loss G: -1.4762\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [87/200] Batch 11/12                         Loss D: 3.9501, loss G: -1.4600\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [88/200] Batch 11/12                         Loss D: 3.6189, loss G: -1.3969\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [89/200] Batch 11/12                         Loss D: 3.3095, loss G: -1.3146\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [90/200] Batch 11/12                         Loss D: 3.0652, loss G: -1.1880\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [91/200] Batch 11/12                         Loss D: 2.8349, loss G: -1.1083\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [92/200] Batch 11/12                         Loss D: 2.3846, loss G: -1.0293\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [93/200] Batch 11/12                         Loss D: 2.1100, loss G: -0.8885\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [94/200] Batch 11/12                         Loss D: 1.8164, loss G: -0.8281\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [95/200] Batch 11/12                         Loss D: 1.5171, loss G: -0.7184\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [96/200] Batch 11/12                         Loss D: 1.2792, loss G: -0.5475\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [97/200] Batch 11/12                         Loss D: 0.9053, loss G: -0.4132\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [98/200] Batch 11/12                         Loss D: 0.7843, loss G: -0.2313\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [99/200] Batch 11/12                         Loss D: 0.7008, loss G: -0.1121\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [100/200] Batch 11/12                         Loss D: 0.5649, loss G: 0.0323\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [101/200] Batch 11/12                         Loss D: 0.4540, loss G: 0.1980\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [102/200] Batch 11/12                         Loss D: 0.2918, loss G: 0.3716\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [103/200] Batch 11/12                         Loss D: 0.2613, loss G: 0.5820\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [104/200] Batch 11/12                         Loss D: 0.1502, loss G: 0.8034\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [105/200] Batch 11/12                         Loss D: -0.0366, loss G: 0.9493\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [106/200] Batch 11/12                         Loss D: -0.1575, loss G: 1.2174\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [107/200] Batch 11/12                         Loss D: -0.1581, loss G: 1.4321\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [108/200] Batch 11/12                         Loss D: -0.3421, loss G: 1.6561\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [109/200] Batch 11/12                         Loss D: -0.2358, loss G: 1.8435\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [110/200] Batch 11/12                         Loss D: -0.0986, loss G: 2.1144\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [111/200] Batch 11/12                         Loss D: -0.1577, loss G: 2.2970\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [112/200] Batch 11/12                         Loss D: 0.0793, loss G: 2.6524\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [113/200] Batch 11/12                         Loss D: -0.1362, loss G: 2.7416\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [114/200] Batch 11/12                         Loss D: -0.0656, loss G: 2.9198\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [115/200] Batch 11/12                         Loss D: 1.4991, loss G: 3.1126\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [116/200] Batch 11/12                         Loss D: 1.9703, loss G: 3.0177\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [117/200] Batch 11/12                         Loss D: 0.1158, loss G: 3.0242\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [118/200] Batch 11/12                         Loss D: -1.4236, loss G: 2.9434\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [119/200] Batch 11/12                         Loss D: -3.0887, loss G: 3.0058\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [120/200] Batch 11/12                         Loss D: -4.8052, loss G: 3.0527\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [121/200] Batch 11/12                         Loss D: -5.8887, loss G: 3.0630\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [122/200] Batch 11/12                         Loss D: -6.1188, loss G: 3.0665\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [123/200] Batch 11/12                         Loss D: -5.5624, loss G: 2.8046\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [124/200] Batch 11/12                         Loss D: -2.9541, loss G: 2.1754\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [125/200] Batch 11/12                         Loss D: -0.1407, loss G: 1.8173\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [126/200] Batch 11/12                         Loss D: 7.9782, loss G: 1.1672\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [127/200] Batch 11/12                         Loss D: 33.5122, loss G: -0.7935\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [128/200] Batch 11/12                         Loss D: 47.3807, loss G: -2.6577\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [129/200] Batch 11/12                         Loss D: 42.1821, loss G: -2.8620\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [130/200] Batch 11/12                         Loss D: 37.0086, loss G: -2.6412\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [131/200] Batch 11/12                         Loss D: 32.4294, loss G: -2.2819\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [132/200] Batch 11/12                         Loss D: 27.2658, loss G: -1.9279\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [133/200] Batch 11/12                         Loss D: 23.7053, loss G: -1.6478\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [134/200] Batch 11/12                         Loss D: 21.4478, loss G: -1.3903\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [135/200] Batch 11/12                         Loss D: 19.2902, loss G: -1.1698\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [136/200] Batch 11/12                         Loss D: 16.8481, loss G: -0.9468\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [137/200] Batch 11/12                         Loss D: 14.5712, loss G: -0.5206\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [138/200] Batch 11/12                         Loss D: 12.4675, loss G: -0.2627\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [139/200] Batch 11/12                         Loss D: 11.9859, loss G: -0.0878\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [140/200] Batch 11/12                         Loss D: 11.8884, loss G: 0.1712\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [141/200] Batch 11/12                         Loss D: 11.9189, loss G: 0.5660\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [142/200] Batch 11/12                         Loss D: 11.7834, loss G: 1.0765\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [143/200] Batch 11/12                         Loss D: 11.4842, loss G: 1.4161\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [144/200] Batch 11/12                         Loss D: 11.6191, loss G: 1.7695\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [145/200] Batch 11/12                         Loss D: 11.1056, loss G: 2.2604\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [146/200] Batch 11/12                         Loss D: 10.7489, loss G: 2.5465\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [147/200] Batch 11/12                         Loss D: 10.2033, loss G: 3.0466\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [148/200] Batch 11/12                         Loss D: 10.0735, loss G: 3.5301\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [149/200] Batch 11/12                         Loss D: 8.8754, loss G: 3.8315\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [150/200] Batch 11/12                         Loss D: 8.4800, loss G: 4.1796\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [151/200] Batch 11/12                         Loss D: 7.9409, loss G: 4.6862\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [152/200] Batch 11/12                         Loss D: 7.3470, loss G: 5.0711\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [153/200] Batch 11/12                         Loss D: 6.3916, loss G: 5.4167\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [154/200] Batch 11/12                         Loss D: 5.6968, loss G: 5.8121\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [155/200] Batch 11/12                         Loss D: 5.1642, loss G: 6.1384\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [156/200] Batch 11/12                         Loss D: 3.7203, loss G: 6.5360\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [157/200] Batch 11/12                         Loss D: 2.9768, loss G: 6.8607\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [158/200] Batch 11/12                         Loss D: 2.0887, loss G: 7.2023\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [159/200] Batch 11/12                         Loss D: 0.9294, loss G: 7.5915\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [160/200] Batch 11/12                         Loss D: -0.0256, loss G: 7.9292\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [161/200] Batch 11/12                         Loss D: -1.1674, loss G: 8.3117\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [162/200] Batch 11/12                         Loss D: -2.1379, loss G: 8.5672\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [163/200] Batch 11/12                         Loss D: -3.1359, loss G: 8.9234\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [164/200] Batch 11/12                         Loss D: -4.4953, loss G: 9.2302\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [165/200] Batch 11/12                         Loss D: -5.4847, loss G: 9.5671\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [166/200] Batch 11/12                         Loss D: -6.8890, loss G: 10.1091\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [167/200] Batch 11/12                         Loss D: -7.5389, loss G: 10.2220\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [168/200] Batch 11/12                         Loss D: -8.7763, loss G: 10.5010\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [169/200] Batch 11/12                         Loss D: -9.8274, loss G: 10.8281\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [170/200] Batch 11/12                         Loss D: -11.3780, loss G: 11.0817\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [171/200] Batch 11/12                         Loss D: -12.0491, loss G: 11.4118\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [172/200] Batch 11/12                         Loss D: -13.6619, loss G: 11.6224\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [173/200] Batch 11/12                         Loss D: -15.0137, loss G: 11.9147\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [174/200] Batch 11/12                         Loss D: -16.0302, loss G: 12.0856\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [175/200] Batch 11/12                         Loss D: -17.3071, loss G: 12.3316\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [176/200] Batch 11/12                         Loss D: -18.2616, loss G: 12.5662\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [177/200] Batch 11/12                         Loss D: -19.0726, loss G: 12.7076\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [178/200] Batch 11/12                         Loss D: -19.7722, loss G: 12.7923\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [179/200] Batch 11/12                         Loss D: -20.4948, loss G: 12.8082\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [180/200] Batch 11/12                         Loss D: -21.2404, loss G: 12.8693\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [181/200] Batch 11/12                         Loss D: -21.8126, loss G: 12.8752\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [182/200] Batch 11/12                         Loss D: -22.6090, loss G: 12.9214\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [183/200] Batch 11/12                         Loss D: -23.1759, loss G: 13.0323\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [184/200] Batch 11/12                         Loss D: -23.8904, loss G: 13.0344\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [185/200] Batch 11/12                         Loss D: -24.7580, loss G: 13.0381\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [186/200] Batch 11/12                         Loss D: -25.0042, loss G: 13.0930\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [187/200] Batch 11/12                         Loss D: -25.9989, loss G: 13.0771\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [188/200] Batch 11/12                         Loss D: -26.3209, loss G: 13.1460\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [189/200] Batch 11/12                         Loss D: -27.3588, loss G: 13.1369\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [190/200] Batch 11/12                         Loss D: -28.2024, loss G: 13.1930\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [191/200] Batch 11/12                         Loss D: -28.6906, loss G: 13.1988\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [192/200] Batch 11/12                         Loss D: -29.6242, loss G: 13.1925\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [193/200] Batch 11/12                         Loss D: -30.7891, loss G: 13.4345\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [194/200] Batch 11/12                         Loss D: -31.0045, loss G: 13.2743\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [195/200] Batch 11/12                         Loss D: -32.0917, loss G: 13.2803\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [196/200] Batch 11/12                         Loss D: -32.6971, loss G: 13.3414\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [197/200] Batch 11/12                         Loss D: -33.9816, loss G: 13.3029\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [198/200] Batch 11/12                         Loss D: -34.7369, loss G: 13.3324\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [199/200] Batch 11/12                         Loss D: -35.6249, loss G: 13.3756\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [0/200] Batch 11/12                         Loss D: 0.3911, loss G: 3.7186\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [1/200] Batch 11/12                         Loss D: 0.6089, loss G: 3.6998\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [2/200] Batch 11/12                         Loss D: 0.8673, loss G: 3.6819\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [3/200] Batch 11/12                         Loss D: 1.1201, loss G: 3.6684\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [4/200] Batch 11/12                         Loss D: 1.2869, loss G: 3.6561\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [5/200] Batch 11/12                         Loss D: 1.4107, loss G: 3.6241\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [6/200] Batch 11/12                         Loss D: 1.4389, loss G: 3.5979\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [7/200] Batch 11/12                         Loss D: 1.2857, loss G: 3.5775\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [8/200] Batch 11/12                         Loss D: 0.8422, loss G: 3.5686\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [9/200] Batch 11/12                         Loss D: 0.2230, loss G: 3.5804\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [10/200] Batch 11/12                         Loss D: -0.4254, loss G: 3.6022\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [11/200] Batch 11/12                         Loss D: -0.9784, loss G: 3.6252\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [12/200] Batch 11/12                         Loss D: -1.3550, loss G: 3.6451\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [13/200] Batch 11/12                         Loss D: -1.6273, loss G: 3.6612\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [14/200] Batch 11/12                         Loss D: -1.8469, loss G: 3.6737\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [15/200] Batch 11/12                         Loss D: -2.1238, loss G: 3.6844\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [16/200] Batch 11/12                         Loss D: -2.3038, loss G: 3.6942\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [17/200] Batch 11/12                         Loss D: -2.4617, loss G: 3.7032\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [18/200] Batch 11/12                         Loss D: -2.5041, loss G: 3.7104\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [19/200] Batch 11/12                         Loss D: -2.5350, loss G: 3.7159\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [20/200] Batch 11/12                         Loss D: -2.3518, loss G: 3.7183\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [21/200] Batch 11/12                         Loss D: -2.1590, loss G: 3.7190\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [22/200] Batch 11/12                         Loss D: -1.8711, loss G: 3.7171\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [23/200] Batch 11/12                         Loss D: -1.5641, loss G: 3.7138\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [24/200] Batch 11/12                         Loss D: -1.2037, loss G: 3.7086\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [25/200] Batch 11/12                         Loss D: -0.8689, loss G: 3.7031\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [26/200] Batch 11/12                         Loss D: -0.2824, loss G: 3.6843\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [27/200] Batch 11/12                         Loss D: -0.0383, loss G: 3.6785\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [28/200] Batch 11/12                         Loss D: -0.0339, loss G: 3.6779\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [29/200] Batch 11/12                         Loss D: -0.0659, loss G: 3.6778\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [30/200] Batch 11/12                         Loss D: -0.0894, loss G: 3.6777\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [31/200] Batch 11/12                         Loss D: -0.1247, loss G: 3.6774\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [32/200] Batch 11/12                         Loss D: -0.1531, loss G: 3.6772\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [33/200] Batch 11/12                         Loss D: -0.1724, loss G: 3.6774\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [34/200] Batch 11/12                         Loss D: -0.2145, loss G: 3.6772\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [35/200] Batch 11/12                         Loss D: -0.2420, loss G: 3.6771\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [36/200] Batch 11/12                         Loss D: -0.2742, loss G: 3.6771\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [37/200] Batch 11/12                         Loss D: -0.3053, loss G: 3.6769\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [38/200] Batch 11/12                         Loss D: -0.3316, loss G: 3.6770\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [39/200] Batch 11/12                         Loss D: -0.3704, loss G: 3.6768\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [40/200] Batch 11/12                         Loss D: -0.3957, loss G: 3.6769\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [41/200] Batch 11/12                         Loss D: -0.4281, loss G: 3.6766\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [42/200] Batch 11/12                         Loss D: -0.4669, loss G: 3.6767\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [43/200] Batch 11/12                         Loss D: -0.4974, loss G: 3.6764\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [44/200] Batch 11/12                         Loss D: -0.5303, loss G: 3.6764\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [45/200] Batch 11/12                         Loss D: -0.5619, loss G: 3.6763\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [46/200] Batch 11/12                         Loss D: -0.6024, loss G: 3.6763\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [47/200] Batch 11/12                         Loss D: -0.6378, loss G: 3.6761\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [48/200] Batch 11/12                         Loss D: -0.6675, loss G: 3.6762\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [49/200] Batch 11/12                         Loss D: -0.7113, loss G: 3.6761\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [50/200] Batch 11/12                         Loss D: -0.7391, loss G: 3.6758\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [51/200] Batch 11/12                         Loss D: -0.7665, loss G: 3.6756\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [52/200] Batch 11/12                         Loss D: -0.8052, loss G: 3.6756\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [53/200] Batch 11/12                         Loss D: -0.8469, loss G: 3.6757\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [54/200] Batch 11/12                         Loss D: -0.8875, loss G: 3.6754\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [55/200] Batch 11/12                         Loss D: -0.9295, loss G: 3.6755\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [56/200] Batch 11/12                         Loss D: -0.9567, loss G: 3.6753\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [57/200] Batch 11/12                         Loss D: -0.9950, loss G: 3.6752\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [58/200] Batch 11/12                         Loss D: -1.0373, loss G: 3.6750\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [59/200] Batch 11/12                         Loss D: -1.0702, loss G: 3.6749\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [60/200] Batch 11/12                         Loss D: -1.1222, loss G: 3.6748\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [61/200] Batch 11/12                         Loss D: -1.1602, loss G: 3.6749\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [62/200] Batch 11/12                         Loss D: -1.1765, loss G: 3.6747\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [63/200] Batch 11/12                         Loss D: -1.2215, loss G: 3.6744\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [64/200] Batch 11/12                         Loss D: -1.3062, loss G: 3.6742\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [65/200] Batch 11/12                         Loss D: -1.4917, loss G: 3.6734\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [66/200] Batch 11/12                         Loss D: -1.6050, loss G: 3.6731\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [67/200] Batch 11/12                         Loss D: -1.6793, loss G: 3.6733\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [68/200] Batch 11/12                         Loss D: -1.7481, loss G: 3.6730\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [69/200] Batch 11/12                         Loss D: -1.8057, loss G: 3.6729\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [70/200] Batch 11/12                         Loss D: -1.8616, loss G: 3.6731\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [71/200] Batch 11/12                         Loss D: -1.9509, loss G: 3.6731\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [72/200] Batch 11/12                         Loss D: -1.9968, loss G: 3.6733\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [73/200] Batch 11/12                         Loss D: -2.0887, loss G: 3.6731\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [74/200] Batch 11/12                         Loss D: -2.1596, loss G: 3.6730\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [75/200] Batch 11/12                         Loss D: -2.2291, loss G: 3.6731\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [76/200] Batch 11/12                         Loss D: -2.2841, loss G: 3.6731\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [77/200] Batch 11/12                         Loss D: -2.3867, loss G: 3.6730\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [78/200] Batch 11/12                         Loss D: -2.4110, loss G: 3.6732\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [79/200] Batch 11/12                         Loss D: -2.5230, loss G: 3.6732\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [80/200] Batch 11/12                         Loss D: -2.5899, loss G: 3.6732\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [81/200] Batch 11/12                         Loss D: -2.6580, loss G: 3.6734\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [82/200] Batch 11/12                         Loss D: -2.7395, loss G: 3.6735\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [83/200] Batch 11/12                         Loss D: -2.7680, loss G: 3.6736\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [84/200] Batch 11/12                         Loss D: -2.8916, loss G: 3.6735\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [85/200] Batch 11/12                         Loss D: -2.9248, loss G: 3.6735\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [86/200] Batch 11/12                         Loss D: -3.0188, loss G: 3.6737\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [87/200] Batch 11/12                         Loss D: -3.0901, loss G: 3.6737\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [88/200] Batch 11/12                         Loss D: -3.1914, loss G: 3.6737\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [89/200] Batch 11/12                         Loss D: -3.2786, loss G: 3.6737\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [90/200] Batch 11/12                         Loss D: -3.3604, loss G: 3.6739\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [91/200] Batch 11/12                         Loss D: -3.4234, loss G: 3.6740\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [92/200] Batch 11/12                         Loss D: -3.4774, loss G: 3.6739\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [93/200] Batch 11/12                         Loss D: -3.5777, loss G: 3.6740\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [94/200] Batch 11/12                         Loss D: -3.6478, loss G: 3.6741\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [95/200] Batch 11/12                         Loss D: -3.7475, loss G: 3.6742\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [96/200] Batch 11/12                         Loss D: -3.8723, loss G: 3.6743\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [97/200] Batch 11/12                         Loss D: -3.8895, loss G: 3.6744\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [98/200] Batch 11/12                         Loss D: -4.0052, loss G: 3.6745\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [99/200] Batch 11/12                         Loss D: -4.0890, loss G: 3.6747\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [100/200] Batch 11/12                         Loss D: -4.1836, loss G: 3.6746\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [101/200] Batch 11/12                         Loss D: -4.2704, loss G: 3.6746\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [102/200] Batch 11/12                         Loss D: -4.3767, loss G: 3.6764\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [103/200] Batch 11/12                         Loss D: -4.4101, loss G: 3.6808\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [104/200] Batch 11/12                         Loss D: -4.5111, loss G: 3.6837\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [105/200] Batch 11/12                         Loss D: -4.5634, loss G: 3.6865\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [106/200] Batch 11/12                         Loss D: -4.6062, loss G: 3.6893\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [107/200] Batch 11/12                         Loss D: -4.7462, loss G: 3.6910\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [108/200] Batch 11/12                         Loss D: -4.8376, loss G: 3.6932\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [109/200] Batch 11/12                         Loss D: -4.9737, loss G: 3.6953\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [110/200] Batch 11/12                         Loss D: -5.2580, loss G: 3.6976\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [111/200] Batch 11/12                         Loss D: -5.5062, loss G: 3.7003\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [112/200] Batch 11/12                         Loss D: -5.9003, loss G: 3.7030\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [113/200] Batch 11/12                         Loss D: -6.3817, loss G: 3.7054\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [114/200] Batch 11/12                         Loss D: -6.7133, loss G: 3.7076\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [115/200] Batch 11/12                         Loss D: -7.1789, loss G: 3.7100\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [116/200] Batch 11/12                         Loss D: -7.6498, loss G: 3.7129\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [117/200] Batch 11/12                         Loss D: -8.1654, loss G: 3.7162\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [118/200] Batch 11/12                         Loss D: -8.3670, loss G: 3.7190\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [119/200] Batch 11/12                         Loss D: -8.7059, loss G: 3.7218\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [120/200] Batch 11/12                         Loss D: -8.8062, loss G: 3.7247\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [121/200] Batch 11/12                         Loss D: -9.0565, loss G: 3.7269\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [122/200] Batch 11/12                         Loss D: -9.1764, loss G: 3.7294\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [123/200] Batch 11/12                         Loss D: -9.3213, loss G: 3.7318\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [124/200] Batch 11/12                         Loss D: -9.5874, loss G: 3.7346\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [125/200] Batch 11/12                         Loss D: -9.7430, loss G: 3.7364\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [126/200] Batch 11/12                         Loss D: -9.8331, loss G: 3.7388\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [127/200] Batch 11/12                         Loss D: -10.0613, loss G: 3.7407\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [128/200] Batch 11/12                         Loss D: -10.0938, loss G: 3.7430\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [129/200] Batch 11/12                         Loss D: -10.1854, loss G: 3.7452\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [130/200] Batch 11/12                         Loss D: -10.6189, loss G: 3.7470\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [131/200] Batch 11/12                         Loss D: -10.5795, loss G: 3.7490\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [132/200] Batch 11/12                         Loss D: -10.5268, loss G: 3.7516\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [133/200] Batch 11/12                         Loss D: -10.9397, loss G: 3.7528\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [134/200] Batch 11/12                         Loss D: -11.0801, loss G: 3.7551\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [135/200] Batch 11/12                         Loss D: -11.3893, loss G: 3.7565\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [136/200] Batch 11/12                         Loss D: -11.4333, loss G: 3.7584\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [137/200] Batch 11/12                         Loss D: -11.4562, loss G: 3.7610\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [138/200] Batch 11/12                         Loss D: -11.8330, loss G: 3.7623\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [139/200] Batch 11/12                         Loss D: -11.9277, loss G: 3.7648\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [140/200] Batch 11/12                         Loss D: -12.3051, loss G: 3.7666\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [141/200] Batch 11/12                         Loss D: -12.1657, loss G: 3.7679\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [142/200] Batch 11/12                         Loss D: -12.5559, loss G: 3.7698\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [143/200] Batch 11/12                         Loss D: -12.4494, loss G: 3.7720\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [144/200] Batch 11/12                         Loss D: -12.8787, loss G: 3.7739\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [145/200] Batch 11/12                         Loss D: -12.4584, loss G: 3.7765\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [146/200] Batch 11/12                         Loss D: -13.1624, loss G: 3.7778\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [147/200] Batch 11/12                         Loss D: -12.8803, loss G: 3.7800\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [148/200] Batch 11/12                         Loss D: -13.2992, loss G: 3.7816\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [149/200] Batch 11/12                         Loss D: -13.6389, loss G: 3.7831\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [150/200] Batch 11/12                         Loss D: -13.4923, loss G: 3.7854\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [151/200] Batch 11/12                         Loss D: -13.9387, loss G: 3.7869\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [152/200] Batch 11/12                         Loss D: -14.0096, loss G: 3.7887\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [153/200] Batch 11/12                         Loss D: -14.3181, loss G: 3.7909\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [154/200] Batch 11/12                         Loss D: -14.3174, loss G: 3.7922\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [155/200] Batch 11/12                         Loss D: -14.3410, loss G: 3.7942\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [156/200] Batch 11/12                         Loss D: -14.8457, loss G: 3.7963\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [157/200] Batch 11/12                         Loss D: -14.6810, loss G: 3.7978\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [158/200] Batch 11/12                         Loss D: -14.5623, loss G: 3.8002\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [159/200] Batch 11/12                         Loss D: -15.0908, loss G: 3.8012\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [160/200] Batch 11/12                         Loss D: -14.9075, loss G: 3.8036\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [161/200] Batch 11/12                         Loss D: -15.1151, loss G: 3.8048\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [162/200] Batch 11/12                         Loss D: -15.5670, loss G: 3.8064\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [163/200] Batch 11/12                         Loss D: -15.8880, loss G: 3.8081\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [164/200] Batch 11/12                         Loss D: -15.9069, loss G: 3.8104\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [165/200] Batch 11/12                         Loss D: -16.0621, loss G: 3.8118\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [166/200] Batch 11/12                         Loss D: -16.4670, loss G: 3.8139\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [167/200] Batch 11/12                         Loss D: -16.6402, loss G: 3.8162\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [168/200] Batch 11/12                         Loss D: -16.7600, loss G: 3.8183\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [169/200] Batch 11/12                         Loss D: -16.5512, loss G: 3.8199\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [170/200] Batch 11/12                         Loss D: -16.4710, loss G: 3.8223\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [171/200] Batch 11/12                         Loss D: -17.2480, loss G: 3.8238\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [172/200] Batch 11/12                         Loss D: -17.6794, loss G: 3.8261\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [173/200] Batch 11/12                         Loss D: -17.7677, loss G: 3.8281\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [174/200] Batch 11/12                         Loss D: -17.7706, loss G: 3.8300\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [175/200] Batch 11/12                         Loss D: -17.6949, loss G: 3.8321\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [176/200] Batch 11/12                         Loss D: -18.3035, loss G: 3.8343\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [177/200] Batch 11/12                         Loss D: -18.1503, loss G: 3.8363\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [178/200] Batch 11/12                         Loss D: -18.6772, loss G: 3.8388\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [179/200] Batch 11/12                         Loss D: -18.6323, loss G: 3.8412\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [180/200] Batch 11/12                         Loss D: -18.7731, loss G: 3.8436\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [181/200] Batch 11/12                         Loss D: -19.4487, loss G: 3.8461\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [182/200] Batch 11/12                         Loss D: -19.2276, loss G: 3.8479\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [183/200] Batch 11/12                         Loss D: -19.5381, loss G: 3.8500\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [184/200] Batch 11/12                         Loss D: -19.6208, loss G: 3.8521\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [185/200] Batch 11/12                         Loss D: -19.5045, loss G: 3.8554\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [186/200] Batch 11/12                         Loss D: -19.4189, loss G: 3.8570\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [187/200] Batch 11/12                         Loss D: -19.9802, loss G: 3.8593\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [188/200] Batch 11/12                         Loss D: -20.0132, loss G: 3.8615\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [189/200] Batch 11/12                         Loss D: -20.3436, loss G: 3.8629\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [190/200] Batch 11/12                         Loss D: -20.5784, loss G: 3.8658\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [191/200] Batch 11/12                         Loss D: -20.8959, loss G: 3.8674\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [192/200] Batch 11/12                         Loss D: -20.6530, loss G: 3.8694\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [193/200] Batch 11/12                         Loss D: -21.2392, loss G: 3.8716\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [194/200] Batch 11/12                         Loss D: -21.0563, loss G: 3.8735\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [195/200] Batch 11/12                         Loss D: -21.4419, loss G: 3.8758\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [196/200] Batch 11/12                         Loss D: -21.4894, loss G: 3.8778\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [197/200] Batch 11/12                         Loss D: -22.0723, loss G: 3.8798\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [198/200] Batch 11/12                         Loss D: -20.5895, loss G: 3.8835\n",
      "[lr_G=0.0001, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [199/200] Batch 11/12                         Loss D: -22.3025, loss G: 3.8839\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [0/200] Batch 11/12                         Loss D: 9.0679, loss G: 34.6128\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [1/200] Batch 11/12                         Loss D: 8.9986, loss G: 34.3682\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [2/200] Batch 11/12                         Loss D: 8.9308, loss G: 34.0532\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [3/200] Batch 11/12                         Loss D: 8.8061, loss G: 33.6037\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [4/200] Batch 11/12                         Loss D: 8.6636, loss G: 33.0107\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [5/200] Batch 11/12                         Loss D: 8.5400, loss G: 32.2494\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [6/200] Batch 11/12                         Loss D: 8.4645, loss G: 31.4252\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [7/200] Batch 11/12                         Loss D: 8.3480, loss G: 30.3592\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [8/200] Batch 11/12                         Loss D: 8.4894, loss G: 29.5886\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [9/200] Batch 11/12                         Loss D: 8.6847, loss G: 28.8625\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [10/200] Batch 11/12                         Loss D: 8.8399, loss G: 28.0610\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [11/200] Batch 11/12                         Loss D: 8.9316, loss G: 27.1222\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [12/200] Batch 11/12                         Loss D: 8.9635, loss G: 26.0728\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [13/200] Batch 11/12                         Loss D: 8.9022, loss G: 24.9168\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [14/200] Batch 11/12                         Loss D: 8.7317, loss G: 23.6083\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [15/200] Batch 11/12                         Loss D: 8.3807, loss G: 22.1465\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [16/200] Batch 11/12                         Loss D: 7.8324, loss G: 20.3207\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [17/200] Batch 11/12                         Loss D: 7.0789, loss G: 18.4630\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [18/200] Batch 11/12                         Loss D: 6.0612, loss G: 16.3481\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [19/200] Batch 11/12                         Loss D: 4.7039, loss G: 13.8528\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [20/200] Batch 11/12                         Loss D: 2.7299, loss G: 12.2463\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [21/200] Batch 11/12                         Loss D: 0.1656, loss G: 11.5418\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [22/200] Batch 11/12                         Loss D: -2.7448, loss G: 10.9177\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [23/200] Batch 11/12                         Loss D: -6.5482, loss G: 10.1236\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [24/200] Batch 11/12                         Loss D: -10.6183, loss G: 9.3671\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [25/200] Batch 11/12                         Loss D: -14.9643, loss G: 8.3199\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [26/200] Batch 11/12                         Loss D: -18.2982, loss G: 7.3948\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [27/200] Batch 11/12                         Loss D: -21.2099, loss G: 6.8017\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [28/200] Batch 11/12                         Loss D: -25.0645, loss G: 5.2644\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [29/200] Batch 11/12                         Loss D: -27.9614, loss G: 4.0575\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [30/200] Batch 11/12                         Loss D: -31.5638, loss G: 3.3069\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [31/200] Batch 11/12                         Loss D: -32.1128, loss G: 2.9763\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [32/200] Batch 11/12                         Loss D: -33.8756, loss G: 3.5232\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [33/200] Batch 11/12                         Loss D: -34.3414, loss G: 3.2192\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [34/200] Batch 11/12                         Loss D: -35.6247, loss G: 3.5263\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [35/200] Batch 11/12                         Loss D: -35.5881, loss G: 3.4728\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [36/200] Batch 11/12                         Loss D: -37.2229, loss G: 3.4167\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [37/200] Batch 11/12                         Loss D: -37.8266, loss G: 3.3354\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [38/200] Batch 11/12                         Loss D: -38.6601, loss G: 3.4600\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [39/200] Batch 11/12                         Loss D: -39.3932, loss G: 3.5382\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [40/200] Batch 11/12                         Loss D: -40.6575, loss G: 3.5174\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [41/200] Batch 11/12                         Loss D: -41.8912, loss G: 3.7956\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [42/200] Batch 11/12                         Loss D: -42.5628, loss G: 3.7015\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [43/200] Batch 11/12                         Loss D: -43.4259, loss G: 3.7414\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [44/200] Batch 11/12                         Loss D: -43.6593, loss G: 3.9592\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [45/200] Batch 11/12                         Loss D: -44.9422, loss G: 3.7629\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [46/200] Batch 11/12                         Loss D: -45.6611, loss G: 3.9265\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [47/200] Batch 11/12                         Loss D: -47.3725, loss G: 4.2323\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [48/200] Batch 11/12                         Loss D: -47.8625, loss G: 4.0449\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [49/200] Batch 11/12                         Loss D: -47.6212, loss G: 4.4244\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [50/200] Batch 11/12                         Loss D: -49.9008, loss G: 4.2759\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [51/200] Batch 11/12                         Loss D: -50.4649, loss G: 4.1325\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [52/200] Batch 11/12                         Loss D: -50.8699, loss G: 4.2842\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [53/200] Batch 11/12                         Loss D: -53.0085, loss G: 4.7479\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [54/200] Batch 11/12                         Loss D: -52.8819, loss G: 4.3267\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [55/200] Batch 11/12                         Loss D: -53.1291, loss G: 4.7113\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [56/200] Batch 11/12                         Loss D: -54.4834, loss G: 4.5487\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [57/200] Batch 11/12                         Loss D: -55.8161, loss G: 4.4497\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [58/200] Batch 11/12                         Loss D: -57.1713, loss G: 4.7055\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [59/200] Batch 11/12                         Loss D: -57.7590, loss G: 4.5948\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [60/200] Batch 11/12                         Loss D: -58.3386, loss G: 4.7102\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [61/200] Batch 11/12                         Loss D: -58.6049, loss G: 5.0557\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [62/200] Batch 11/12                         Loss D: -60.7579, loss G: 4.8975\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [63/200] Batch 11/12                         Loss D: -61.7739, loss G: 4.8762\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [64/200] Batch 11/12                         Loss D: -62.1650, loss G: 4.9475\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [65/200] Batch 11/12                         Loss D: -63.7813, loss G: 5.0660\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [66/200] Batch 11/12                         Loss D: -64.1516, loss G: 5.1030\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [67/200] Batch 11/12                         Loss D: -64.7862, loss G: 5.3185\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [68/200] Batch 11/12                         Loss D: -65.4587, loss G: 5.4634\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [69/200] Batch 11/12                         Loss D: -67.3936, loss G: 5.3012\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [70/200] Batch 11/12                         Loss D: -68.1542, loss G: 5.3012\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [71/200] Batch 11/12                         Loss D: -69.3254, loss G: 5.3213\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [72/200] Batch 11/12                         Loss D: -71.2401, loss G: 5.6959\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [73/200] Batch 11/12                         Loss D: -71.1565, loss G: 5.5332\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [74/200] Batch 11/12                         Loss D: -73.1656, loss G: 5.8039\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [75/200] Batch 11/12                         Loss D: -73.3738, loss G: 5.6302\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [76/200] Batch 11/12                         Loss D: -75.0454, loss G: 5.8276\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [77/200] Batch 11/12                         Loss D: -76.0517, loss G: 5.8347\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [78/200] Batch 11/12                         Loss D: -76.9590, loss G: 5.8242\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [79/200] Batch 11/12                         Loss D: -77.4430, loss G: 5.9506\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [80/200] Batch 11/12                         Loss D: -78.6171, loss G: 6.0077\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [81/200] Batch 11/12                         Loss D: -80.3459, loss G: 6.0608\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [82/200] Batch 11/12                         Loss D: -80.9812, loss G: 6.1263\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [83/200] Batch 11/12                         Loss D: -82.9958, loss G: 6.3738\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [84/200] Batch 11/12                         Loss D: -82.7970, loss G: 6.3844\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [85/200] Batch 11/12                         Loss D: -84.6824, loss G: 6.2701\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [86/200] Batch 11/12                         Loss D: -84.7743, loss G: 6.6121\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [87/200] Batch 11/12                         Loss D: -86.7205, loss G: 6.5185\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [88/200] Batch 11/12                         Loss D: -87.3356, loss G: 6.6651\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [89/200] Batch 11/12                         Loss D: -89.1982, loss G: 6.5989\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [90/200] Batch 11/12                         Loss D: -91.4270, loss G: 6.9747\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [91/200] Batch 11/12                         Loss D: -90.9612, loss G: 6.8652\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [92/200] Batch 11/12                         Loss D: -91.7937, loss G: 7.0653\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [93/200] Batch 11/12                         Loss D: -94.4416, loss G: 6.9874\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [94/200] Batch 11/12                         Loss D: -94.4049, loss G: 7.1325\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [95/200] Batch 11/12                         Loss D: -97.9771, loss G: 7.5818\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [96/200] Batch 11/12                         Loss D: -97.5203, loss G: 7.1237\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [97/200] Batch 11/12                         Loss D: -98.9259, loss G: 7.2042\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [98/200] Batch 11/12                         Loss D: -99.7334, loss G: 7.3921\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [99/200] Batch 11/12                         Loss D: -101.4957, loss G: 7.3713\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [100/200] Batch 11/12                         Loss D: -102.7622, loss G: 7.4216\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [101/200] Batch 11/12                         Loss D: -103.2025, loss G: 7.6480\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [102/200] Batch 11/12                         Loss D: -106.2848, loss G: 7.8741\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [103/200] Batch 11/12                         Loss D: -107.3293, loss G: 7.8655\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [104/200] Batch 11/12                         Loss D: -107.1071, loss G: 7.8906\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [105/200] Batch 11/12                         Loss D: -108.5368, loss G: 7.9969\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [106/200] Batch 11/12                         Loss D: -110.4972, loss G: 7.9601\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [107/200] Batch 11/12                         Loss D: -111.1335, loss G: 8.1653\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [108/200] Batch 11/12                         Loss D: -113.8645, loss G: 8.2167\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [109/200] Batch 11/12                         Loss D: -113.9040, loss G: 8.3795\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [110/200] Batch 11/12                         Loss D: -115.4467, loss G: 8.3698\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [111/200] Batch 11/12                         Loss D: -116.8143, loss G: 8.4467\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [112/200] Batch 11/12                         Loss D: -116.9094, loss G: 8.8530\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [113/200] Batch 11/12                         Loss D: -118.8484, loss G: 8.7976\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [114/200] Batch 11/12                         Loss D: -121.6586, loss G: 8.6214\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [115/200] Batch 11/12                         Loss D: -122.7739, loss G: 8.7831\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [116/200] Batch 11/12                         Loss D: -124.9367, loss G: 8.8910\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [117/200] Batch 11/12                         Loss D: -125.9514, loss G: 8.8902\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [118/200] Batch 11/12                         Loss D: -127.2529, loss G: 9.0294\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [119/200] Batch 11/12                         Loss D: -129.7501, loss G: 9.3450\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [120/200] Batch 11/12                         Loss D: -130.0913, loss G: 9.2349\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [121/200] Batch 11/12                         Loss D: -131.8392, loss G: 9.2556\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [122/200] Batch 11/12                         Loss D: -131.1957, loss G: 9.7410\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [123/200] Batch 11/12                         Loss D: -133.3702, loss G: 9.7309\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [124/200] Batch 11/12                         Loss D: -135.6227, loss G: 9.6256\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [125/200] Batch 11/12                         Loss D: -138.9191, loss G: 9.8574\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [126/200] Batch 11/12                         Loss D: -140.8165, loss G: 10.0786\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [127/200] Batch 11/12                         Loss D: -141.6240, loss G: 9.9392\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [128/200] Batch 11/12                         Loss D: -141.9921, loss G: 10.0787\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [129/200] Batch 11/12                         Loss D: -143.8251, loss G: 10.1158\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [130/200] Batch 11/12                         Loss D: -142.5312, loss G: 10.6544\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [131/200] Batch 11/12                         Loss D: -147.3158, loss G: 10.2523\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [132/200] Batch 11/12                         Loss D: -149.6436, loss G: 10.4373\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [133/200] Batch 11/12                         Loss D: -152.3029, loss G: 10.7663\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [134/200] Batch 11/12                         Loss D: -151.7417, loss G: 10.6140\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [135/200] Batch 11/12                         Loss D: -153.1300, loss G: 10.6976\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [136/200] Batch 11/12                         Loss D: -156.0174, loss G: 10.5949\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [137/200] Batch 11/12                         Loss D: -156.8530, loss G: 10.7230\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [138/200] Batch 11/12                         Loss D: -159.1094, loss G: 10.6466\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [139/200] Batch 11/12                         Loss D: -158.8634, loss G: 11.0204\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [140/200] Batch 11/12                         Loss D: -163.5709, loss G: 10.9202\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [141/200] Batch 11/12                         Loss D: -163.9757, loss G: 10.9919\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [142/200] Batch 11/12                         Loss D: -166.0592, loss G: 11.0389\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [143/200] Batch 11/12                         Loss D: -168.7039, loss G: 11.2591\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [144/200] Batch 11/12                         Loss D: -168.5716, loss G: 11.3676\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [145/200] Batch 11/12                         Loss D: -170.7898, loss G: 11.4227\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [146/200] Batch 11/12                         Loss D: -174.4634, loss G: 11.6752\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [147/200] Batch 11/12                         Loss D: -175.5033, loss G: 11.6311\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [148/200] Batch 11/12                         Loss D: -176.8147, loss G: 11.6538\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [149/200] Batch 11/12                         Loss D: -182.2134, loss G: 12.6912\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [150/200] Batch 11/12                         Loss D: -181.4364, loss G: 12.0823\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [151/200] Batch 11/12                         Loss D: -183.0876, loss G: 12.2181\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [152/200] Batch 11/12                         Loss D: -184.4457, loss G: 12.1680\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [153/200] Batch 11/12                         Loss D: -184.9281, loss G: 12.3031\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [154/200] Batch 11/12                         Loss D: -188.1969, loss G: 12.3883\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [155/200] Batch 11/12                         Loss D: -188.4492, loss G: 12.5868\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [156/200] Batch 11/12                         Loss D: -188.8012, loss G: 12.8605\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [157/200] Batch 11/12                         Loss D: -193.3837, loss G: 12.6960\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [158/200] Batch 11/12                         Loss D: -194.8596, loss G: 12.8434\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [159/200] Batch 11/12                         Loss D: -195.7017, loss G: 13.0670\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [160/200] Batch 11/12                         Loss D: -199.3607, loss G: 13.0980\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [161/200] Batch 11/12                         Loss D: -200.2524, loss G: 13.2675\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [162/200] Batch 11/12                         Loss D: -201.3435, loss G: 13.4067\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [163/200] Batch 11/12                         Loss D: -205.0269, loss G: 13.4035\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [164/200] Batch 11/12                         Loss D: -207.9229, loss G: 13.6624\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [165/200] Batch 11/12                         Loss D: -207.5615, loss G: 13.7841\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [166/200] Batch 11/12                         Loss D: -207.4963, loss G: 14.0866\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [167/200] Batch 11/12                         Loss D: -213.9431, loss G: 14.0430\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [168/200] Batch 11/12                         Loss D: -214.6698, loss G: 14.0269\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [169/200] Batch 11/12                         Loss D: -216.0503, loss G: 14.2420\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [170/200] Batch 11/12                         Loss D: -218.7346, loss G: 14.2821\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [171/200] Batch 11/12                         Loss D: -218.5230, loss G: 14.6584\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [172/200] Batch 11/12                         Loss D: -221.6554, loss G: 14.6678\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [173/200] Batch 11/12                         Loss D: -224.8440, loss G: 14.6841\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [174/200] Batch 11/12                         Loss D: -227.3456, loss G: 14.8003\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [175/200] Batch 11/12                         Loss D: -226.3646, loss G: 15.1625\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [176/200] Batch 11/12                         Loss D: -231.0071, loss G: 15.1135\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [177/200] Batch 11/12                         Loss D: -231.3089, loss G: 15.3484\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [178/200] Batch 11/12                         Loss D: -236.7027, loss G: 15.4458\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [179/200] Batch 11/12                         Loss D: -235.8076, loss G: 15.5813\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [180/200] Batch 11/12                         Loss D: -238.7711, loss G: 15.6582\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [181/200] Batch 11/12                         Loss D: -242.4413, loss G: 15.7581\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [182/200] Batch 11/12                         Loss D: -241.2837, loss G: 16.1005\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [183/200] Batch 11/12                         Loss D: -245.9718, loss G: 16.0675\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [184/200] Batch 11/12                         Loss D: -246.2284, loss G: 16.3281\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [185/200] Batch 11/12                         Loss D: -248.6622, loss G: 16.3975\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [186/200] Batch 11/12                         Loss D: -252.6416, loss G: 16.4560\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [187/200] Batch 11/12                         Loss D: -255.9542, loss G: 16.5716\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [188/200] Batch 11/12                         Loss D: -255.7632, loss G: 16.7998\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [189/200] Batch 11/12                         Loss D: -260.2966, loss G: 16.8822\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [190/200] Batch 11/12                         Loss D: -260.8632, loss G: 17.0352\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [191/200] Batch 11/12                         Loss D: -265.7570, loss G: 17.3186\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [192/200] Batch 11/12                         Loss D: -267.6572, loss G: 17.3524\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [193/200] Batch 11/12                         Loss D: -269.6794, loss G: 17.4592\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [194/200] Batch 11/12                         Loss D: -269.0300, loss G: 17.6973\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [195/200] Batch 11/12                         Loss D: -271.9028, loss G: 17.8035\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [196/200] Batch 11/12                         Loss D: -274.3805, loss G: 17.9526\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [197/200] Batch 11/12                         Loss D: -278.0679, loss G: 18.0149\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [198/200] Batch 11/12                         Loss D: -276.2245, loss G: 18.4177\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [199/200] Batch 11/12                         Loss D: -280.2437, loss G: 18.4082\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [0/200] Batch 11/12                         Loss D: 7.9834, loss G: 17.5889\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [1/200] Batch 11/12                         Loss D: 8.8467, loss G: 17.4644\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [2/200] Batch 11/12                         Loss D: 10.2021, loss G: 17.2844\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [3/200] Batch 11/12                         Loss D: 11.7172, loss G: 17.0704\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [4/200] Batch 11/12                         Loss D: 13.3228, loss G: 16.7855\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [5/200] Batch 11/12                         Loss D: 15.2406, loss G: 16.4013\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [6/200] Batch 11/12                         Loss D: 17.1872, loss G: 15.9336\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [7/200] Batch 11/12                         Loss D: 19.0409, loss G: 15.4156\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [8/200] Batch 11/12                         Loss D: 21.0520, loss G: 14.7968\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [9/200] Batch 11/12                         Loss D: 23.0134, loss G: 14.1188\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [10/200] Batch 11/12                         Loss D: 25.2083, loss G: 13.3046\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [11/200] Batch 11/12                         Loss D: 27.9677, loss G: 12.5108\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [12/200] Batch 11/12                         Loss D: 30.8265, loss G: 11.6617\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [13/200] Batch 11/12                         Loss D: 33.5097, loss G: 10.7914\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [14/200] Batch 11/12                         Loss D: 36.4383, loss G: 9.7679\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [15/200] Batch 11/12                         Loss D: 39.3541, loss G: 8.6651\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [16/200] Batch 11/12                         Loss D: 41.6577, loss G: 7.5939\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [17/200] Batch 11/12                         Loss D: 44.2560, loss G: 6.3394\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [18/200] Batch 11/12                         Loss D: 46.8594, loss G: 4.9081\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [19/200] Batch 11/12                         Loss D: 48.9619, loss G: 3.4620\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [20/200] Batch 11/12                         Loss D: 48.8023, loss G: 2.9672\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [21/200] Batch 11/12                         Loss D: 48.7574, loss G: 2.6470\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [22/200] Batch 11/12                         Loss D: 48.1285, loss G: 2.4063\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [23/200] Batch 11/12                         Loss D: 47.3663, loss G: 2.1795\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [24/200] Batch 11/12                         Loss D: 46.1788, loss G: 1.9599\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [25/200] Batch 11/12                         Loss D: 42.8988, loss G: 1.4720\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [26/200] Batch 11/12                         Loss D: 39.4440, loss G: 1.0650\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [27/200] Batch 11/12                         Loss D: 35.7565, loss G: 0.7123\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [28/200] Batch 11/12                         Loss D: 33.1790, loss G: 0.1821\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [29/200] Batch 11/12                         Loss D: 29.8469, loss G: -0.3195\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [30/200] Batch 11/12                         Loss D: 26.1586, loss G: -0.2198\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [31/200] Batch 11/12                         Loss D: 22.7192, loss G: -0.0082\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [32/200] Batch 11/12                         Loss D: 19.4363, loss G: 0.2163\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [33/200] Batch 11/12                         Loss D: 16.0682, loss G: 0.4236\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [34/200] Batch 11/12                         Loss D: 13.0958, loss G: 0.7242\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [35/200] Batch 11/12                         Loss D: 10.0048, loss G: 0.7567\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [36/200] Batch 11/12                         Loss D: 6.9433, loss G: 0.9261\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [37/200] Batch 11/12                         Loss D: 4.0347, loss G: 1.1905\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [38/200] Batch 11/12                         Loss D: 1.1418, loss G: 1.2900\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [39/200] Batch 11/12                         Loss D: -1.7587, loss G: 1.5176\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [40/200] Batch 11/12                         Loss D: -4.5535, loss G: 1.6627\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [41/200] Batch 11/12                         Loss D: -7.3958, loss G: 1.7771\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [42/200] Batch 11/12                         Loss D: -10.2616, loss G: 1.9957\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [43/200] Batch 11/12                         Loss D: -12.8417, loss G: 2.0822\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [44/200] Batch 11/12                         Loss D: -15.8019, loss G: 2.3013\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [45/200] Batch 11/12                         Loss D: -18.4612, loss G: 2.4689\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [46/200] Batch 11/12                         Loss D: -21.4985, loss G: 2.8351\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [47/200] Batch 11/12                         Loss D: -23.3553, loss G: 2.8340\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [48/200] Batch 11/12                         Loss D: -26.2420, loss G: 2.8756\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [49/200] Batch 11/12                         Loss D: -29.2742, loss G: 3.1048\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [50/200] Batch 11/12                         Loss D: -31.1319, loss G: 3.2893\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [51/200] Batch 11/12                         Loss D: -34.1446, loss G: 3.3285\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [52/200] Batch 11/12                         Loss D: -37.0572, loss G: 3.5067\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [53/200] Batch 11/12                         Loss D: -38.9914, loss G: 3.7034\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [54/200] Batch 11/12                         Loss D: -42.3164, loss G: 3.8102\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [55/200] Batch 11/12                         Loss D: -44.3904, loss G: 3.8844\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [56/200] Batch 11/12                         Loss D: -46.7345, loss G: 4.0577\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [57/200] Batch 11/12                         Loss D: -49.4373, loss G: 4.1677\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [58/200] Batch 11/12                         Loss D: -51.7442, loss G: 4.3635\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [59/200] Batch 11/12                         Loss D: -55.0390, loss G: 4.3793\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [60/200] Batch 11/12                         Loss D: -57.3492, loss G: 4.5475\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [61/200] Batch 11/12                         Loss D: -59.5902, loss G: 4.7784\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [62/200] Batch 11/12                         Loss D: -62.8256, loss G: 4.8265\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [63/200] Batch 11/12                         Loss D: -64.7471, loss G: 5.0415\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [64/200] Batch 11/12                         Loss D: -67.0684, loss G: 5.2196\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [65/200] Batch 11/12                         Loss D: -69.9989, loss G: 5.3080\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [66/200] Batch 11/12                         Loss D: -72.4676, loss G: 5.4630\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [67/200] Batch 11/12                         Loss D: -74.9502, loss G: 5.6280\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [68/200] Batch 11/12                         Loss D: -78.3181, loss G: 5.6756\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [69/200] Batch 11/12                         Loss D: -80.0618, loss G: 5.9014\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [70/200] Batch 11/12                         Loss D: -83.2653, loss G: 5.9667\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [71/200] Batch 11/12                         Loss D: -86.5008, loss G: 6.2182\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [72/200] Batch 11/12                         Loss D: -86.9333, loss G: 6.4070\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [73/200] Batch 11/12                         Loss D: -91.4769, loss G: 6.4241\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [74/200] Batch 11/12                         Loss D: -93.3970, loss G: 6.5009\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [75/200] Batch 11/12                         Loss D: -95.8299, loss G: 6.6388\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [76/200] Batch 11/12                         Loss D: -98.5616, loss G: 6.7355\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [77/200] Batch 11/12                         Loss D: -100.3878, loss G: 6.9264\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [78/200] Batch 11/12                         Loss D: -103.5577, loss G: 7.0069\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [79/200] Batch 11/12                         Loss D: -105.9522, loss G: 7.1308\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [80/200] Batch 11/12                         Loss D: -109.4206, loss G: 7.2119\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [81/200] Batch 11/12                         Loss D: -111.8522, loss G: 7.3349\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [82/200] Batch 11/12                         Loss D: -113.3541, loss G: 7.5140\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [83/200] Batch 11/12                         Loss D: -117.4649, loss G: 7.5924\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [84/200] Batch 11/12                         Loss D: -119.9652, loss G: 7.6866\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [85/200] Batch 11/12                         Loss D: -121.5344, loss G: 7.8632\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [86/200] Batch 11/12                         Loss D: -125.8074, loss G: 7.9765\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [87/200] Batch 11/12                         Loss D: -125.9463, loss G: 8.1770\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [88/200] Batch 11/12                         Loss D: -130.2997, loss G: 8.1659\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [89/200] Batch 11/12                         Loss D: -132.6569, loss G: 8.3194\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [90/200] Batch 11/12                         Loss D: -136.5076, loss G: 8.4365\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [91/200] Batch 11/12                         Loss D: -138.3868, loss G: 8.5611\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [92/200] Batch 11/12                         Loss D: -140.4080, loss G: 8.7494\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [93/200] Batch 11/12                         Loss D: -144.4350, loss G: 8.8378\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [94/200] Batch 11/12                         Loss D: -145.2477, loss G: 9.0629\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [95/200] Batch 11/12                         Loss D: -150.2591, loss G: 9.1495\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [96/200] Batch 11/12                         Loss D: -150.8486, loss G: 9.3563\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [97/200] Batch 11/12                         Loss D: -153.1529, loss G: 9.5265\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [98/200] Batch 11/12                         Loss D: -157.8892, loss G: 9.5945\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [99/200] Batch 11/12                         Loss D: -162.6215, loss G: 9.8944\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [100/200] Batch 11/12                         Loss D: -163.2166, loss G: 9.9116\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [101/200] Batch 11/12                         Loss D: -166.6900, loss G: 10.0407\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [102/200] Batch 11/12                         Loss D: -170.2941, loss G: 10.2453\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [103/200] Batch 11/12                         Loss D: -171.5375, loss G: 10.3783\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [104/200] Batch 11/12                         Loss D: -174.1371, loss G: 10.5464\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [105/200] Batch 11/12                         Loss D: -178.8888, loss G: 10.6903\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [106/200] Batch 11/12                         Loss D: -180.9155, loss G: 10.8272\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [107/200] Batch 11/12                         Loss D: -184.3772, loss G: 10.9827\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [108/200] Batch 11/12                         Loss D: -186.0551, loss G: 11.1772\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [109/200] Batch 11/12                         Loss D: -189.5129, loss G: 11.3145\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [110/200] Batch 11/12                         Loss D: -192.0617, loss G: 11.4881\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [111/200] Batch 11/12                         Loss D: -193.8911, loss G: 11.6870\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [112/200] Batch 11/12                         Loss D: -196.4447, loss G: 11.8530\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [113/200] Batch 11/12                         Loss D: -201.7881, loss G: 12.0063\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [114/200] Batch 11/12                         Loss D: -203.5742, loss G: 12.1705\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [115/200] Batch 11/12                         Loss D: -206.1339, loss G: 12.3467\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [116/200] Batch 11/12                         Loss D: -208.7273, loss G: 12.5296\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [117/200] Batch 11/12                         Loss D: -208.7805, loss G: 12.7522\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [118/200] Batch 11/12                         Loss D: -214.3929, loss G: 12.8827\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [119/200] Batch 11/12                         Loss D: -214.3911, loss G: 13.1054\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [120/200] Batch 11/12                         Loss D: -216.7321, loss G: 13.2626\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [121/200] Batch 11/12                         Loss D: -219.9487, loss G: 13.5524\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [122/200] Batch 11/12                         Loss D: -218.7374, loss G: 13.5879\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [123/200] Batch 11/12                         Loss D: -214.3938, loss G: 13.8069\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [124/200] Batch 11/12                         Loss D: -217.6196, loss G: 13.9223\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [125/200] Batch 11/12                         Loss D: -215.9249, loss G: 14.1008\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [126/200] Batch 11/12                         Loss D: -213.8976, loss G: 14.2194\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [127/200] Batch 11/12                         Loss D: -207.7559, loss G: 14.3399\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [128/200] Batch 11/12                         Loss D: -201.1260, loss G: 14.3069\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [129/200] Batch 11/12                         Loss D: -194.5175, loss G: 14.2081\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [130/200] Batch 11/12                         Loss D: -180.9802, loss G: 14.1547\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [131/200] Batch 11/12                         Loss D: -172.2194, loss G: 14.0430\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [132/200] Batch 11/12                         Loss D: -156.5621, loss G: 13.8774\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [133/200] Batch 11/12                         Loss D: -145.1511, loss G: 13.7570\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [134/200] Batch 11/12                         Loss D: -128.7903, loss G: 13.5366\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [135/200] Batch 11/12                         Loss D: -123.2640, loss G: 13.5090\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [136/200] Batch 11/12                         Loss D: -122.6296, loss G: 13.6658\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [137/200] Batch 11/12                         Loss D: -124.6311, loss G: 13.7691\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [138/200] Batch 11/12                         Loss D: -124.6755, loss G: 13.9387\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [139/200] Batch 11/12                         Loss D: -127.4472, loss G: 14.0547\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [140/200] Batch 11/12                         Loss D: -129.2157, loss G: 14.1871\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [141/200] Batch 11/12                         Loss D: -129.6331, loss G: 14.3394\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [142/200] Batch 11/12                         Loss D: -131.0712, loss G: 14.4733\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [143/200] Batch 11/12                         Loss D: -132.0958, loss G: 14.6110\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [144/200] Batch 11/12                         Loss D: -132.4349, loss G: 14.7536\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [145/200] Batch 11/12                         Loss D: -134.2517, loss G: 14.8779\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [146/200] Batch 11/12                         Loss D: -135.6588, loss G: 15.0086\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [147/200] Batch 11/12                         Loss D: -137.0601, loss G: 15.1351\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [148/200] Batch 11/12                         Loss D: -138.3830, loss G: 15.2632\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [149/200] Batch 11/12                         Loss D: -140.3950, loss G: 15.3873\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [150/200] Batch 11/12                         Loss D: -139.2213, loss G: 15.5269\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [151/200] Batch 11/12                         Loss D: -141.4915, loss G: 15.6488\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [152/200] Batch 11/12                         Loss D: -141.2500, loss G: 15.7801\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [153/200] Batch 11/12                         Loss D: -142.3670, loss G: 15.9003\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [154/200] Batch 11/12                         Loss D: -145.2201, loss G: 16.0222\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [155/200] Batch 11/12                         Loss D: -145.2175, loss G: 16.1445\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [156/200] Batch 11/12                         Loss D: -146.6602, loss G: 16.2677\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [157/200] Batch 11/12                         Loss D: -146.7709, loss G: 16.3869\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [158/200] Batch 11/12                         Loss D: -148.5659, loss G: 16.5086\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [159/200] Batch 11/12                         Loss D: -148.5707, loss G: 16.6259\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [160/200] Batch 11/12                         Loss D: -149.1672, loss G: 16.7425\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [161/200] Batch 11/12                         Loss D: -148.4489, loss G: 16.8516\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [162/200] Batch 11/12                         Loss D: -150.4850, loss G: 16.9711\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [163/200] Batch 11/12                         Loss D: -149.4132, loss G: 17.0727\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [164/200] Batch 11/12                         Loss D: -149.2522, loss G: 17.1733\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [165/200] Batch 11/12                         Loss D: -148.3085, loss G: 17.2587\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [166/200] Batch 11/12                         Loss D: -146.9426, loss G: 17.3364\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [167/200] Batch 11/12                         Loss D: -145.4264, loss G: 17.4165\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [168/200] Batch 11/12                         Loss D: -144.4846, loss G: 17.5034\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [169/200] Batch 11/12                         Loss D: -142.7190, loss G: 17.5771\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [170/200] Batch 11/12                         Loss D: -140.6317, loss G: 17.6441\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [171/200] Batch 11/12                         Loss D: -137.8526, loss G: 17.6984\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [172/200] Batch 11/12                         Loss D: -133.5467, loss G: 17.7337\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [173/200] Batch 11/12                         Loss D: -130.5685, loss G: 17.7741\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [174/200] Batch 11/12                         Loss D: -126.6169, loss G: 17.7992\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [175/200] Batch 11/12                         Loss D: -122.6147, loss G: 17.8172\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [176/200] Batch 11/12                         Loss D: -116.9648, loss G: 17.8070\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [177/200] Batch 11/12                         Loss D: -111.8839, loss G: 17.7976\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [178/200] Batch 11/12                         Loss D: -106.8969, loss G: 17.7688\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [179/200] Batch 11/12                         Loss D: -100.6531, loss G: 17.7067\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [180/200] Batch 11/12                         Loss D: -96.4254, loss G: 17.6622\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [181/200] Batch 11/12                         Loss D: -91.1812, loss G: 17.6036\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [182/200] Batch 11/12                         Loss D: -82.3227, loss G: 17.4798\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [183/200] Batch 11/12                         Loss D: -75.5872, loss G: 17.3823\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [184/200] Batch 11/12                         Loss D: -68.5694, loss G: 17.2732\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [185/200] Batch 11/12                         Loss D: -60.0145, loss G: 17.1353\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [186/200] Batch 11/12                         Loss D: -52.7093, loss G: 17.0182\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [187/200] Batch 11/12                         Loss D: -44.4762, loss G: 16.9152\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [188/200] Batch 11/12                         Loss D: -36.9648, loss G: 16.8277\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [189/200] Batch 11/12                         Loss D: -28.9689, loss G: 16.7502\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [190/200] Batch 11/12                         Loss D: -21.0557, loss G: 16.6444\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [191/200] Batch 11/12                         Loss D: -13.2022, loss G: 16.5307\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [192/200] Batch 11/12                         Loss D: 14.4754, loss G: 14.9303\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [193/200] Batch 11/12                         Loss D: 16.9627, loss G: 13.9464\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [194/200] Batch 11/12                         Loss D: 16.7350, loss G: 13.1855\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [195/200] Batch 11/12                         Loss D: 15.0236, loss G: 12.6550\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [196/200] Batch 11/12                         Loss D: 12.0703, loss G: 12.2562\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [197/200] Batch 11/12                         Loss D: 7.5642, loss G: 11.9659\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [198/200] Batch 11/12                         Loss D: 4.4400, loss G: 12.2533\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [199/200] Batch 11/12                         Loss D: 1.4079, loss G: 12.5616\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [0/200] Batch 11/12                         Loss D: 8.0193, loss G: 3.2044\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [1/200] Batch 11/12                         Loss D: 8.4423, loss G: 3.1893\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [2/200] Batch 11/12                         Loss D: 9.0182, loss G: 3.1702\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [3/200] Batch 11/12                         Loss D: 10.5364, loss G: 3.1079\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [4/200] Batch 11/12                         Loss D: 12.7552, loss G: 2.9495\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [5/200] Batch 11/12                         Loss D: 15.3212, loss G: 2.7576\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [6/200] Batch 11/12                         Loss D: 18.5788, loss G: 2.4743\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [7/200] Batch 11/12                         Loss D: 21.7440, loss G: 2.1770\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [8/200] Batch 11/12                         Loss D: 25.5470, loss G: 1.8718\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [9/200] Batch 11/12                         Loss D: 30.4664, loss G: 1.5784\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [10/200] Batch 11/12                         Loss D: 36.4325, loss G: 1.2436\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [11/200] Batch 11/12                         Loss D: 42.2934, loss G: 0.9231\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [12/200] Batch 11/12                         Loss D: 48.3709, loss G: 0.5977\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [13/200] Batch 11/12                         Loss D: 54.0895, loss G: 0.2960\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [14/200] Batch 11/12                         Loss D: 59.9340, loss G: -0.0171\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [15/200] Batch 11/12                         Loss D: 65.0802, loss G: -0.2928\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [16/200] Batch 11/12                         Loss D: 70.4994, loss G: -0.5794\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [17/200] Batch 11/12                         Loss D: 74.2878, loss G: -0.7664\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [18/200] Batch 11/12                         Loss D: 77.0332, loss G: -0.8315\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [19/200] Batch 11/12                         Loss D: 78.3752, loss G: -0.7389\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [20/200] Batch 11/12                         Loss D: 79.1838, loss G: -0.6274\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [21/200] Batch 11/12                         Loss D: 78.3171, loss G: -0.4778\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [22/200] Batch 11/12                         Loss D: 79.2925, loss G: -0.3722\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [23/200] Batch 11/12                         Loss D: 77.5607, loss G: -0.2187\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [24/200] Batch 11/12                         Loss D: 77.0893, loss G: -0.0997\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [25/200] Batch 11/12                         Loss D: 77.1007, loss G: 0.0029\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [26/200] Batch 11/12                         Loss D: 76.4612, loss G: 0.1072\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [27/200] Batch 11/12                         Loss D: 73.2376, loss G: 0.2352\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [28/200] Batch 11/12                         Loss D: 73.0751, loss G: 0.3077\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [29/200] Batch 11/12                         Loss D: 71.3540, loss G: 0.3880\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [30/200] Batch 11/12                         Loss D: 70.6702, loss G: 0.4427\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [31/200] Batch 11/12                         Loss D: 67.6911, loss G: 0.5781\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [32/200] Batch 11/12                         Loss D: 65.2362, loss G: 0.7360\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [33/200] Batch 11/12                         Loss D: 63.0888, loss G: 0.8745\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [34/200] Batch 11/12                         Loss D: 60.2598, loss G: 0.9829\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [35/200] Batch 11/12                         Loss D: 58.2701, loss G: 1.0841\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [36/200] Batch 11/12                         Loss D: 55.2701, loss G: 1.1812\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [37/200] Batch 11/12                         Loss D: 52.8727, loss G: 1.2731\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [38/200] Batch 11/12                         Loss D: 50.4294, loss G: 1.3588\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [39/200] Batch 11/12                         Loss D: 46.8832, loss G: 1.4403\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [40/200] Batch 11/12                         Loss D: 44.5346, loss G: 1.5275\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [41/200] Batch 11/12                         Loss D: 41.8542, loss G: 1.6112\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [42/200] Batch 11/12                         Loss D: 38.6071, loss G: 1.6726\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [43/200] Batch 11/12                         Loss D: 36.2926, loss G: 1.7450\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [44/200] Batch 11/12                         Loss D: 34.0641, loss G: 1.8102\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [45/200] Batch 11/12                         Loss D: 31.8225, loss G: 1.8611\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [46/200] Batch 11/12                         Loss D: 29.2086, loss G: 1.8424\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [47/200] Batch 11/12                         Loss D: 27.8777, loss G: 1.8414\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [48/200] Batch 11/12                         Loss D: 26.6513, loss G: 1.8341\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [49/200] Batch 11/12                         Loss D: 25.4472, loss G: 1.8130\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [50/200] Batch 11/12                         Loss D: 24.4385, loss G: 1.8460\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [51/200] Batch 11/12                         Loss D: 23.6403, loss G: 1.8895\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [52/200] Batch 11/12                         Loss D: 22.5779, loss G: 1.9430\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [53/200] Batch 11/12                         Loss D: 21.5662, loss G: 1.9999\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [54/200] Batch 11/12                         Loss D: 20.7748, loss G: 2.0440\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [55/200] Batch 11/12                         Loss D: 19.3986, loss G: 2.0969\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [56/200] Batch 11/12                         Loss D: 18.5094, loss G: 2.1368\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [57/200] Batch 11/12                         Loss D: 17.4760, loss G: 2.1909\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [58/200] Batch 11/12                         Loss D: 15.9823, loss G: 2.2442\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [59/200] Batch 11/12                         Loss D: 15.0636, loss G: 2.2932\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [60/200] Batch 11/12                         Loss D: 13.5925, loss G: 2.3487\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [61/200] Batch 11/12                         Loss D: 12.4164, loss G: 2.4074\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [62/200] Batch 11/12                         Loss D: 11.0561, loss G: 2.4571\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [63/200] Batch 11/12                         Loss D: 9.7697, loss G: 2.5068\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [64/200] Batch 11/12                         Loss D: 8.3558, loss G: 2.5591\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [65/200] Batch 11/12                         Loss D: 6.6896, loss G: 2.6132\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [66/200] Batch 11/12                         Loss D: 5.3728, loss G: 2.6721\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [67/200] Batch 11/12                         Loss D: 3.9049, loss G: 2.7161\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [68/200] Batch 11/12                         Loss D: 2.3536, loss G: 2.7684\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [69/200] Batch 11/12                         Loss D: 1.1847, loss G: 2.8242\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [70/200] Batch 11/12                         Loss D: -0.2219, loss G: 2.8749\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [71/200] Batch 11/12                         Loss D: -1.5190, loss G: 2.9281\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [72/200] Batch 11/12                         Loss D: -2.8062, loss G: 2.9803\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [73/200] Batch 11/12                         Loss D: -4.1420, loss G: 3.0307\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [74/200] Batch 11/12                         Loss D: -5.5377, loss G: 3.0809\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [75/200] Batch 11/12                         Loss D: -6.8506, loss G: 3.1292\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [76/200] Batch 11/12                         Loss D: -8.1719, loss G: 3.1757\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [77/200] Batch 11/12                         Loss D: -9.4559, loss G: 3.2195\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [78/200] Batch 11/12                         Loss D: -10.7276, loss G: 3.2637\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [79/200] Batch 11/12                         Loss D: -11.9218, loss G: 3.3023\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [80/200] Batch 11/12                         Loss D: -13.0304, loss G: 3.3376\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [81/200] Batch 11/12                         Loss D: -14.1595, loss G: 3.3726\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [82/200] Batch 11/12                         Loss D: -15.1415, loss G: 3.4006\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [83/200] Batch 11/12                         Loss D: -16.0576, loss G: 3.4281\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [84/200] Batch 11/12                         Loss D: -16.9693, loss G: 3.4544\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [85/200] Batch 11/12                         Loss D: -17.6003, loss G: 3.4697\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [86/200] Batch 11/12                         Loss D: -18.0505, loss G: 3.4845\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [87/200] Batch 11/12                         Loss D: -18.1862, loss G: 3.4893\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [88/200] Batch 11/12                         Loss D: -18.3536, loss G: 3.4937\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [89/200] Batch 11/12                         Loss D: -18.1133, loss G: 3.4893\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [90/200] Batch 11/12                         Loss D: -18.4091, loss G: 3.4888\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [91/200] Batch 11/12                         Loss D: -18.7861, loss G: 3.4840\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [92/200] Batch 11/12                         Loss D: -18.9486, loss G: 3.4705\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [93/200] Batch 11/12                         Loss D: -19.3591, loss G: 3.4656\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [94/200] Batch 11/12                         Loss D: -19.5728, loss G: 3.4526\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [95/200] Batch 11/12                         Loss D: -19.3239, loss G: 3.4277\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [96/200] Batch 11/12                         Loss D: -19.1437, loss G: 3.4022\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [97/200] Batch 11/12                         Loss D: -18.8975, loss G: 3.3755\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [98/200] Batch 11/12                         Loss D: -18.5032, loss G: 3.3452\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [99/200] Batch 11/12                         Loss D: -17.3266, loss G: 3.2995\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [100/200] Batch 11/12                         Loss D: -15.5606, loss G: 3.2746\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [101/200] Batch 11/12                         Loss D: -12.5727, loss G: 3.2537\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [102/200] Batch 11/12                         Loss D: -9.1216, loss G: 3.2305\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [103/200] Batch 11/12                         Loss D: -3.9325, loss G: 3.1795\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [104/200] Batch 11/12                         Loss D: 1.6256, loss G: 3.1371\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [105/200] Batch 11/12                         Loss D: 9.7388, loss G: 3.0000\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [106/200] Batch 11/12                         Loss D: 26.7252, loss G: 1.6270\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [107/200] Batch 11/12                         Loss D: 39.8388, loss G: 0.4241\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [108/200] Batch 11/12                         Loss D: 52.0515, loss G: -0.7021\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [109/200] Batch 11/12                         Loss D: 64.2832, loss G: -1.9015\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [110/200] Batch 11/12                         Loss D: 76.2919, loss G: -3.1403\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [111/200] Batch 11/12                         Loss D: 86.6950, loss G: -4.3166\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [112/200] Batch 11/12                         Loss D: 96.8640, loss G: -5.4997\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [113/200] Batch 11/12                         Loss D: 96.7602, loss G: -5.4866\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [114/200] Batch 11/12                         Loss D: 96.7272, loss G: -5.3681\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [115/200] Batch 11/12                         Loss D: 97.5311, loss G: -5.2384\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [116/200] Batch 11/12                         Loss D: 96.1324, loss G: -5.0286\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [117/200] Batch 11/12                         Loss D: 95.5513, loss G: -4.8365\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [118/200] Batch 11/12                         Loss D: 96.4262, loss G: -4.6970\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [119/200] Batch 11/12                         Loss D: 94.8000, loss G: -4.4828\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [120/200] Batch 11/12                         Loss D: 91.9351, loss G: -4.2079\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [121/200] Batch 11/12                         Loss D: 89.9750, loss G: -3.9500\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [122/200] Batch 11/12                         Loss D: 87.1922, loss G: -3.6841\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [123/200] Batch 11/12                         Loss D: 83.8991, loss G: -3.4408\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [124/200] Batch 11/12                         Loss D: 79.8245, loss G: -3.1781\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [125/200] Batch 11/12                         Loss D: 75.4654, loss G: -2.9049\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [126/200] Batch 11/12                         Loss D: 71.3132, loss G: -2.6375\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [127/200] Batch 11/12                         Loss D: 67.5453, loss G: -2.3727\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [128/200] Batch 11/12                         Loss D: 62.6271, loss G: -2.0864\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [129/200] Batch 11/12                         Loss D: 58.0682, loss G: -1.8090\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [130/200] Batch 11/12                         Loss D: 54.2656, loss G: -1.5415\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [131/200] Batch 11/12                         Loss D: 49.2547, loss G: -1.2727\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [132/200] Batch 11/12                         Loss D: 46.4787, loss G: -0.9906\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [133/200] Batch 11/12                         Loss D: 43.9484, loss G: -0.7057\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [134/200] Batch 11/12                         Loss D: 41.4562, loss G: -0.4557\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [135/200] Batch 11/12                         Loss D: 39.5847, loss G: -0.2313\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [136/200] Batch 11/12                         Loss D: 38.0378, loss G: -0.0174\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [137/200] Batch 11/12                         Loss D: 36.1704, loss G: 0.1418\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [138/200] Batch 11/12                         Loss D: 35.1391, loss G: 0.3103\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [139/200] Batch 11/12                         Loss D: 33.8794, loss G: 0.4248\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [140/200] Batch 11/12                         Loss D: 32.9476, loss G: 0.5312\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [141/200] Batch 11/12                         Loss D: 32.3566, loss G: 0.6280\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [142/200] Batch 11/12                         Loss D: 31.9670, loss G: 0.7079\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [143/200] Batch 11/12                         Loss D: 31.2238, loss G: 0.7385\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [144/200] Batch 11/12                         Loss D: 30.6939, loss G: 0.7873\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [145/200] Batch 11/12                         Loss D: 29.5926, loss G: 0.7843\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [146/200] Batch 11/12                         Loss D: 28.6289, loss G: 0.7841\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [147/200] Batch 11/12                         Loss D: 28.0078, loss G: 0.7806\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [148/200] Batch 11/12                         Loss D: 26.3372, loss G: 0.7822\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [149/200] Batch 11/12                         Loss D: 24.6237, loss G: 0.7472\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [150/200] Batch 11/12                         Loss D: 23.2666, loss G: 0.7474\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [151/200] Batch 11/12                         Loss D: 22.0724, loss G: 0.7326\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [152/200] Batch 11/12                         Loss D: 20.6963, loss G: 0.6969\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [153/200] Batch 11/12                         Loss D: 19.5655, loss G: 0.6662\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [154/200] Batch 11/12                         Loss D: 18.2299, loss G: 0.6379\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [155/200] Batch 11/12                         Loss D: 17.2598, loss G: 0.5962\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [156/200] Batch 11/12                         Loss D: 16.4701, loss G: 0.5527\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [157/200] Batch 11/12                         Loss D: 15.6693, loss G: 0.5211\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [158/200] Batch 11/12                         Loss D: 15.2236, loss G: 0.5621\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [159/200] Batch 11/12                         Loss D: 14.9146, loss G: 0.5804\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [160/200] Batch 11/12                         Loss D: 14.6740, loss G: 0.6288\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [161/200] Batch 11/12                         Loss D: 14.2552, loss G: 0.6789\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [162/200] Batch 11/12                         Loss D: 13.8270, loss G: 0.6897\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [163/200] Batch 11/12                         Loss D: 13.5700, loss G: 0.7324\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [164/200] Batch 11/12                         Loss D: 13.2125, loss G: 0.7668\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [165/200] Batch 11/12                         Loss D: 12.9421, loss G: 0.8011\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [166/200] Batch 11/12                         Loss D: 12.7089, loss G: 0.8475\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [167/200] Batch 11/12                         Loss D: 12.3395, loss G: 0.8527\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [168/200] Batch 11/12                         Loss D: 11.9547, loss G: 0.8805\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [169/200] Batch 11/12                         Loss D: 11.6241, loss G: 0.9262\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [170/200] Batch 11/12                         Loss D: 11.4569, loss G: 0.9556\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [171/200] Batch 11/12                         Loss D: 11.2456, loss G: 0.9777\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [172/200] Batch 11/12                         Loss D: 10.9405, loss G: 1.0140\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [173/200] Batch 11/12                         Loss D: 10.5045, loss G: 1.0374\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [174/200] Batch 11/12                         Loss D: 10.3609, loss G: 1.0860\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [175/200] Batch 11/12                         Loss D: 10.0889, loss G: 1.1135\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [176/200] Batch 11/12                         Loss D: 9.7489, loss G: 1.1323\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [177/200] Batch 11/12                         Loss D: 9.4631, loss G: 1.1659\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [178/200] Batch 11/12                         Loss D: 9.2269, loss G: 1.1896\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [179/200] Batch 11/12                         Loss D: 9.0132, loss G: 1.2211\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [180/200] Batch 11/12                         Loss D: 8.7197, loss G: 1.2782\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [181/200] Batch 11/12                         Loss D: 8.4711, loss G: 1.2795\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [182/200] Batch 11/12                         Loss D: 8.3972, loss G: 1.3188\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [183/200] Batch 11/12                         Loss D: 8.2069, loss G: 1.3577\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [184/200] Batch 11/12                         Loss D: 8.1976, loss G: 1.3711\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [185/200] Batch 11/12                         Loss D: 8.3481, loss G: 1.4076\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [186/200] Batch 11/12                         Loss D: 8.5391, loss G: 1.4271\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [187/200] Batch 11/12                         Loss D: 8.7706, loss G: 1.4621\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [188/200] Batch 11/12                         Loss D: 9.2559, loss G: 1.5184\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [189/200] Batch 11/12                         Loss D: 9.7244, loss G: 1.5147\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [190/200] Batch 11/12                         Loss D: 10.2236, loss G: 1.5345\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [191/200] Batch 11/12                         Loss D: 10.6963, loss G: 1.5591\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [192/200] Batch 11/12                         Loss D: 11.0662, loss G: 1.5759\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [193/200] Batch 11/12                         Loss D: 11.3845, loss G: 1.5984\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [194/200] Batch 11/12                         Loss D: 11.8648, loss G: 1.6267\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [195/200] Batch 11/12                         Loss D: 12.2847, loss G: 1.6283\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [196/200] Batch 11/12                         Loss D: 12.6735, loss G: 1.6474\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [197/200] Batch 11/12                         Loss D: 13.3094, loss G: 1.6631\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [198/200] Batch 11/12                         Loss D: 13.9799, loss G: 1.6782\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [199/200] Batch 11/12                         Loss D: 14.4500, loss G: 1.6941\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [0/200] Batch 11/12                         Loss D: 0.4995, loss G: 34.4412\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [1/200] Batch 11/12                         Loss D: 0.2206, loss G: 34.2246\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [2/200] Batch 11/12                         Loss D: -0.0687, loss G: 33.9348\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [3/200] Batch 11/12                         Loss D: -0.3353, loss G: 33.5283\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [4/200] Batch 11/12                         Loss D: -0.6635, loss G: 32.9886\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [5/200] Batch 11/12                         Loss D: -1.1175, loss G: 32.3524\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [6/200] Batch 11/12                         Loss D: -1.7502, loss G: 31.5732\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [7/200] Batch 11/12                         Loss D: -2.5703, loss G: 30.6492\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [8/200] Batch 11/12                         Loss D: -3.3862, loss G: 29.7139\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [9/200] Batch 11/12                         Loss D: -3.9609, loss G: 28.9861\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [10/200] Batch 11/12                         Loss D: -4.6683, loss G: 28.1020\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [11/200] Batch 11/12                         Loss D: -5.5896, loss G: 27.1857\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [12/200] Batch 11/12                         Loss D: -6.5991, loss G: 26.0852\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [13/200] Batch 11/12                         Loss D: -7.8322, loss G: 24.9279\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [14/200] Batch 11/12                         Loss D: -9.3336, loss G: 23.6220\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [15/200] Batch 11/12                         Loss D: -11.2834, loss G: 22.0086\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [16/200] Batch 11/12                         Loss D: -13.3224, loss G: 20.5012\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [17/200] Batch 11/12                         Loss D: -16.0303, loss G: 18.5671\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [18/200] Batch 11/12                         Loss D: -19.1020, loss G: 16.5709\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [19/200] Batch 11/12                         Loss D: -22.6735, loss G: 14.3842\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [20/200] Batch 11/12                         Loss D: -27.2139, loss G: 11.8315\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [21/200] Batch 11/12                         Loss D: -31.0549, loss G: 11.1861\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [22/200] Batch 11/12                         Loss D: -34.3474, loss G: 10.4196\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [23/200] Batch 11/12                         Loss D: -38.4929, loss G: 9.6381\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [24/200] Batch 11/12                         Loss D: -42.4805, loss G: 8.9249\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [25/200] Batch 11/12                         Loss D: -46.5525, loss G: 8.1376\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [26/200] Batch 11/12                         Loss D: -51.7364, loss G: 7.0396\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [27/200] Batch 11/12                         Loss D: -57.5934, loss G: 5.6617\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [28/200] Batch 11/12                         Loss D: -61.6325, loss G: 4.7611\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [29/200] Batch 11/12                         Loss D: -65.9422, loss G: 4.2245\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [30/200] Batch 11/12                         Loss D: -68.4673, loss G: 4.5018\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [31/200] Batch 11/12                         Loss D: -70.9070, loss G: 4.7417\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [32/200] Batch 11/12                         Loss D: -74.2575, loss G: 4.8169\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [33/200] Batch 11/12                         Loss D: -74.2635, loss G: 5.4064\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [34/200] Batch 11/12                         Loss D: -78.2739, loss G: 4.9127\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [35/200] Batch 11/12                         Loss D: -79.6487, loss G: 5.1557\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [36/200] Batch 11/12                         Loss D: -80.8511, loss G: 5.5813\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [37/200] Batch 11/12                         Loss D: -83.5173, loss G: 5.4467\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [38/200] Batch 11/12                         Loss D: -86.8637, loss G: 5.6951\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [39/200] Batch 11/12                         Loss D: -88.5526, loss G: 5.6760\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [40/200] Batch 11/12                         Loss D: -90.0277, loss G: 5.6183\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [41/200] Batch 11/12                         Loss D: -91.0836, loss G: 5.9970\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [42/200] Batch 11/12                         Loss D: -94.1749, loss G: 5.9571\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [43/200] Batch 11/12                         Loss D: -95.9226, loss G: 6.0174\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [44/200] Batch 11/12                         Loss D: -98.1266, loss G: 6.2486\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [45/200] Batch 11/12                         Loss D: -99.8736, loss G: 6.3242\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [46/200] Batch 11/12                         Loss D: -100.1184, loss G: 6.7219\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [47/200] Batch 11/12                         Loss D: -102.4877, loss G: 6.7171\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [48/200] Batch 11/12                         Loss D: -105.0258, loss G: 6.6635\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [49/200] Batch 11/12                         Loss D: -107.4954, loss G: 6.7453\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [50/200] Batch 11/12                         Loss D: -109.7220, loss G: 6.9644\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [51/200] Batch 11/12                         Loss D: -111.9094, loss G: 7.1217\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [52/200] Batch 11/12                         Loss D: -112.9945, loss G: 7.0488\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [53/200] Batch 11/12                         Loss D: -115.8008, loss G: 7.3798\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [54/200] Batch 11/12                         Loss D: -116.2869, loss G: 7.3931\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [55/200] Batch 11/12                         Loss D: -116.8753, loss G: 7.8701\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [56/200] Batch 11/12                         Loss D: -121.0103, loss G: 7.6306\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [57/200] Batch 11/12                         Loss D: -122.4669, loss G: 7.7163\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [58/200] Batch 11/12                         Loss D: -125.3046, loss G: 7.9332\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [59/200] Batch 11/12                         Loss D: -125.9551, loss G: 8.0155\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [60/200] Batch 11/12                         Loss D: -129.2290, loss G: 8.1652\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [61/200] Batch 11/12                         Loss D: -130.5325, loss G: 8.1394\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [62/200] Batch 11/12                         Loss D: -134.0299, loss G: 8.6663\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [63/200] Batch 11/12                         Loss D: -133.1624, loss G: 8.6764\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [64/200] Batch 11/12                         Loss D: -134.3532, loss G: 8.9271\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [65/200] Batch 11/12                         Loss D: -138.1411, loss G: 8.7558\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [66/200] Batch 11/12                         Loss D: -140.2839, loss G: 8.8173\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [67/200] Batch 11/12                         Loss D: -141.6245, loss G: 9.0838\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [68/200] Batch 11/12                         Loss D: -144.0076, loss G: 9.1747\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [69/200] Batch 11/12                         Loss D: -146.7275, loss G: 9.1831\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [70/200] Batch 11/12                         Loss D: -148.9713, loss G: 9.3129\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [71/200] Batch 11/12                         Loss D: -150.8490, loss G: 9.4415\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [72/200] Batch 11/12                         Loss D: -154.3456, loss G: 9.7670\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [73/200] Batch 11/12                         Loss D: -152.9967, loss G: 10.0421\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [74/200] Batch 11/12                         Loss D: -156.8899, loss G: 9.8814\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [75/200] Batch 11/12                         Loss D: -159.9772, loss G: 9.9865\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [76/200] Batch 11/12                         Loss D: -162.0124, loss G: 10.1254\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [77/200] Batch 11/12                         Loss D: -163.6262, loss G: 10.2407\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [78/200] Batch 11/12                         Loss D: -163.8119, loss G: 10.6654\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [79/200] Batch 11/12                         Loss D: -168.8925, loss G: 10.5527\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [80/200] Batch 11/12                         Loss D: -168.1546, loss G: 10.9158\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [81/200] Batch 11/12                         Loss D: -173.3608, loss G: 10.8404\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [82/200] Batch 11/12                         Loss D: -173.9150, loss G: 10.9983\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [83/200] Batch 11/12                         Loss D: -177.7819, loss G: 11.0530\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [84/200] Batch 11/12                         Loss D: -179.7374, loss G: 11.1649\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [85/200] Batch 11/12                         Loss D: -183.8982, loss G: 11.7122\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [86/200] Batch 11/12                         Loss D: -183.1184, loss G: 11.5638\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [87/200] Batch 11/12                         Loss D: -186.6636, loss G: 11.5545\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [88/200] Batch 11/12                         Loss D: -187.7147, loss G: 11.8272\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [89/200] Batch 11/12                         Loss D: -190.9590, loss G: 11.8959\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [90/200] Batch 11/12                         Loss D: -191.8942, loss G: 12.1699\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [91/200] Batch 11/12                         Loss D: -197.0976, loss G: 12.3606\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [92/200] Batch 11/12                         Loss D: -197.0083, loss G: 12.4896\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [93/200] Batch 11/12                         Loss D: -202.0300, loss G: 12.6820\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [94/200] Batch 11/12                         Loss D: -202.7079, loss G: 12.6119\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [95/200] Batch 11/12                         Loss D: -205.9262, loss G: 12.7900\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [96/200] Batch 11/12                         Loss D: -207.0320, loss G: 12.9936\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [97/200] Batch 11/12                         Loss D: -211.4984, loss G: 13.1912\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [98/200] Batch 11/12                         Loss D: -214.1381, loss G: 13.4179\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [99/200] Batch 11/12                         Loss D: -213.5034, loss G: 13.5342\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [100/200] Batch 11/12                         Loss D: -215.0915, loss G: 13.7603\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [101/200] Batch 11/12                         Loss D: -219.7761, loss G: 13.7225\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [102/200] Batch 11/12                         Loss D: -221.9471, loss G: 13.9065\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [103/200] Batch 11/12                         Loss D: -224.2337, loss G: 14.0802\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [104/200] Batch 11/12                         Loss D: -227.4259, loss G: 14.1914\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [105/200] Batch 11/12                         Loss D: -230.9948, loss G: 14.2738\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [106/200] Batch 11/12                         Loss D: -230.7604, loss G: 14.6590\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [107/200] Batch 11/12                         Loss D: -235.8557, loss G: 14.6154\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [108/200] Batch 11/12                         Loss D: -237.8347, loss G: 14.8396\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [109/200] Batch 11/12                         Loss D: -237.8673, loss G: 15.2294\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [110/200] Batch 11/12                         Loss D: -241.9904, loss G: 15.2627\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [111/200] Batch 11/12                         Loss D: -246.0840, loss G: 15.3251\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [112/200] Batch 11/12                         Loss D: -248.4154, loss G: 15.5044\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [113/200] Batch 11/12                         Loss D: -254.6694, loss G: 15.9471\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [114/200] Batch 11/12                         Loss D: -253.2661, loss G: 15.8979\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [115/200] Batch 11/12                         Loss D: -259.3367, loss G: 16.1201\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [116/200] Batch 11/12                         Loss D: -261.9584, loss G: 16.2653\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [117/200] Batch 11/12                         Loss D: -260.9442, loss G: 16.4866\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [118/200] Batch 11/12                         Loss D: -262.4822, loss G: 16.7246\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [119/200] Batch 11/12                         Loss D: -270.6476, loss G: 16.8111\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [120/200] Batch 11/12                         Loss D: -270.1570, loss G: 16.9562\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [121/200] Batch 11/12                         Loss D: -272.2364, loss G: 17.1756\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [122/200] Batch 11/12                         Loss D: -277.2089, loss G: 17.2169\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [123/200] Batch 11/12                         Loss D: -280.5891, loss G: 17.3732\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [124/200] Batch 11/12                         Loss D: -283.3615, loss G: 17.5698\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [125/200] Batch 11/12                         Loss D: -288.0697, loss G: 17.8713\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [126/200] Batch 11/12                         Loss D: -290.4805, loss G: 17.9561\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [127/200] Batch 11/12                         Loss D: -290.1883, loss G: 18.2375\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [128/200] Batch 11/12                         Loss D: -297.2829, loss G: 18.4436\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [129/200] Batch 11/12                         Loss D: -298.7641, loss G: 18.4752\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [130/200] Batch 11/12                         Loss D: -302.3356, loss G: 18.6696\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [131/200] Batch 11/12                         Loss D: -304.1433, loss G: 18.8845\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [132/200] Batch 11/12                         Loss D: -306.3993, loss G: 19.1473\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [133/200] Batch 11/12                         Loss D: -311.7366, loss G: 19.2119\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [134/200] Batch 11/12                         Loss D: -316.3854, loss G: 19.5891\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [135/200] Batch 11/12                         Loss D: -316.0984, loss G: 19.6853\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [136/200] Batch 11/12                         Loss D: -320.7540, loss G: 19.8307\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [137/200] Batch 11/12                         Loss D: -322.7162, loss G: 20.0837\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [138/200] Batch 11/12                         Loss D: -327.2998, loss G: 20.2311\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [139/200] Batch 11/12                         Loss D: -327.9545, loss G: 20.5500\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [140/200] Batch 11/12                         Loss D: -332.6841, loss G: 20.6678\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [141/200] Batch 11/12                         Loss D: -332.5604, loss G: 21.0326\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [142/200] Batch 11/12                         Loss D: -342.3845, loss G: 21.1321\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [143/200] Batch 11/12                         Loss D: -341.7393, loss G: 21.3230\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [144/200] Batch 11/12                         Loss D: -345.8203, loss G: 21.5046\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [145/200] Batch 11/12                         Loss D: -344.6805, loss G: 21.8878\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [146/200] Batch 11/12                         Loss D: -353.4652, loss G: 21.8842\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [147/200] Batch 11/12                         Loss D: -357.0709, loss G: 22.0861\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [148/200] Batch 11/12                         Loss D: -358.3656, loss G: 22.3924\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [149/200] Batch 11/12                         Loss D: -361.6375, loss G: 22.5899\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [150/200] Batch 11/12                         Loss D: -367.3882, loss G: 22.7193\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [151/200] Batch 11/12                         Loss D: -367.5040, loss G: 23.0295\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [152/200] Batch 11/12                         Loss D: -374.0354, loss G: 23.1453\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [153/200] Batch 11/12                         Loss D: -373.3366, loss G: 23.4844\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [154/200] Batch 11/12                         Loss D: -383.1396, loss G: 23.7480\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [155/200] Batch 11/12                         Loss D: -382.7717, loss G: 23.8062\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [156/200] Batch 11/12                         Loss D: -386.4868, loss G: 23.9885\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [157/200] Batch 11/12                         Loss D: -387.8041, loss G: 24.2582\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [158/200] Batch 11/12                         Loss D: -395.2693, loss G: 24.5790\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [159/200] Batch 11/12                         Loss D: -392.1418, loss G: 24.7018\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [160/200] Batch 11/12                         Loss D: -400.5235, loss G: 24.8603\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [161/200] Batch 11/12                         Loss D: -400.8360, loss G: 25.0396\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [162/200] Batch 11/12                         Loss D: -405.2589, loss G: 25.2003\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [163/200] Batch 11/12                         Loss D: -405.5212, loss G: 25.4599\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [164/200] Batch 11/12                         Loss D: -412.5333, loss G: 25.7344\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [165/200] Batch 11/12                         Loss D: -413.0110, loss G: 25.8173\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [166/200] Batch 11/12                         Loss D: -417.2443, loss G: 26.0615\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [167/200] Batch 11/12                         Loss D: -418.5198, loss G: 26.2083\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [168/200] Batch 11/12                         Loss D: -421.5068, loss G: 26.3884\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [169/200] Batch 11/12                         Loss D: -423.8673, loss G: 26.5876\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [170/200] Batch 11/12                         Loss D: -421.6219, loss G: 26.8594\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [171/200] Batch 11/12                         Loss D: -429.0449, loss G: 26.9992\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [172/200] Batch 11/12                         Loss D: -422.7312, loss G: 27.2767\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [173/200] Batch 11/12                         Loss D: -427.5392, loss G: 27.3789\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [174/200] Batch 11/12                         Loss D: -429.0522, loss G: 27.5332\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [175/200] Batch 11/12                         Loss D: -427.1603, loss G: 27.7384\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [176/200] Batch 11/12                         Loss D: -432.9445, loss G: 27.7985\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [177/200] Batch 11/12                         Loss D: -436.0170, loss G: 27.9409\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [178/200] Batch 11/12                         Loss D: -435.1974, loss G: 28.1061\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [179/200] Batch 11/12                         Loss D: -434.5913, loss G: 28.2246\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [180/200] Batch 11/12                         Loss D: -435.6502, loss G: 28.3463\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [181/200] Batch 11/12                         Loss D: -434.0216, loss G: 28.4717\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [182/200] Batch 11/12                         Loss D: -434.5065, loss G: 28.5883\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [183/200] Batch 11/12                         Loss D: -434.4530, loss G: 28.6885\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [184/200] Batch 11/12                         Loss D: -431.6657, loss G: 28.8302\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [185/200] Batch 11/12                         Loss D: -434.0923, loss G: 28.8654\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [186/200] Batch 11/12                         Loss D: -431.9017, loss G: 28.9529\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [187/200] Batch 11/12                         Loss D: -432.2828, loss G: 29.0359\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [188/200] Batch 11/12                         Loss D: -423.6559, loss G: 29.1545\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [189/200] Batch 11/12                         Loss D: -427.7961, loss G: 29.1688\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [190/200] Batch 11/12                         Loss D: -421.8381, loss G: 29.2436\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [191/200] Batch 11/12                         Loss D: -422.9585, loss G: 29.2352\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [192/200] Batch 11/12                         Loss D: -420.2615, loss G: 29.3154\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [193/200] Batch 11/12                         Loss D: -416.0734, loss G: 29.4252\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [194/200] Batch 11/12                         Loss D: -419.4154, loss G: 29.6441\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [195/200] Batch 11/12                         Loss D: -419.3556, loss G: 29.9016\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [196/200] Batch 11/12                         Loss D: -422.2514, loss G: 30.0877\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [197/200] Batch 11/12                         Loss D: -427.7052, loss G: 30.2480\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [198/200] Batch 11/12                         Loss D: -427.4177, loss G: 30.4775\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [199/200] Batch 11/12                         Loss D: -430.8086, loss G: 30.6740\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [0/200] Batch 11/12                         Loss D: 1.1579, loss G: 17.2805\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [1/200] Batch 11/12                         Loss D: 1.1206, loss G: 17.1506\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [2/200] Batch 11/12                         Loss D: 1.0994, loss G: 16.9880\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [3/200] Batch 11/12                         Loss D: 1.1179, loss G: 16.7557\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [4/200] Batch 11/12                         Loss D: 1.1643, loss G: 16.4506\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [5/200] Batch 11/12                         Loss D: 1.2351, loss G: 16.0975\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [6/200] Batch 11/12                         Loss D: 1.2665, loss G: 15.6901\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [7/200] Batch 11/12                         Loss D: 0.9730, loss G: 15.2002\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [8/200] Batch 11/12                         Loss D: 0.6289, loss G: 14.7617\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [9/200] Batch 11/12                         Loss D: 0.2936, loss G: 14.3412\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [10/200] Batch 11/12                         Loss D: -0.1231, loss G: 13.9132\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [11/200] Batch 11/12                         Loss D: -0.6513, loss G: 13.3842\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [12/200] Batch 11/12                         Loss D: -1.2910, loss G: 12.8637\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [13/200] Batch 11/12                         Loss D: -2.2589, loss G: 12.2390\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [14/200] Batch 11/12                         Loss D: -3.5766, loss G: 11.5554\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [15/200] Batch 11/12                         Loss D: -5.1917, loss G: 10.7764\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [16/200] Batch 11/12                         Loss D: -7.2079, loss G: 9.8744\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [17/200] Batch 11/12                         Loss D: -9.5153, loss G: 8.9637\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [18/200] Batch 11/12                         Loss D: -12.0656, loss G: 8.0086\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [19/200] Batch 11/12                         Loss D: -15.0776, loss G: 6.9241\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [20/200] Batch 11/12                         Loss D: -17.9519, loss G: 5.8843\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [21/200] Batch 11/12                         Loss D: -19.1510, loss G: 5.4233\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [22/200] Batch 11/12                         Loss D: -20.5190, loss G: 4.9937\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [23/200] Batch 11/12                         Loss D: -21.4446, loss G: 4.4108\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [24/200] Batch 11/12                         Loss D: -22.2534, loss G: 3.8023\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [25/200] Batch 11/12                         Loss D: -24.3399, loss G: 3.2283\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [26/200] Batch 11/12                         Loss D: -25.3447, loss G: 2.8795\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [27/200] Batch 11/12                         Loss D: -26.6663, loss G: 2.5068\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [28/200] Batch 11/12                         Loss D: -28.2032, loss G: 2.1636\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [29/200] Batch 11/12                         Loss D: -30.0489, loss G: 2.1326\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [30/200] Batch 11/12                         Loss D: -31.9169, loss G: 2.2407\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [31/200] Batch 11/12                         Loss D: -33.2643, loss G: 2.3542\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [32/200] Batch 11/12                         Loss D: -35.0848, loss G: 2.4228\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [33/200] Batch 11/12                         Loss D: -36.7547, loss G: 2.4900\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [34/200] Batch 11/12                         Loss D: -38.5954, loss G: 2.6853\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [35/200] Batch 11/12                         Loss D: -39.4705, loss G: 2.7725\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [36/200] Batch 11/12                         Loss D: -41.6145, loss G: 2.8671\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [37/200] Batch 11/12                         Loss D: -42.4860, loss G: 2.9382\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [38/200] Batch 11/12                         Loss D: -44.1363, loss G: 2.9512\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [39/200] Batch 11/12                         Loss D: -46.3709, loss G: 3.1617\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [40/200] Batch 11/12                         Loss D: -46.9547, loss G: 3.1273\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [41/200] Batch 11/12                         Loss D: -48.4666, loss G: 3.1537\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [42/200] Batch 11/12                         Loss D: -49.9219, loss G: 3.2258\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [43/200] Batch 11/12                         Loss D: -51.1573, loss G: 3.2987\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [44/200] Batch 11/12                         Loss D: -53.3610, loss G: 3.5325\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [45/200] Batch 11/12                         Loss D: -53.4531, loss G: 3.5315\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [46/200] Batch 11/12                         Loss D: -56.0889, loss G: 3.6261\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [47/200] Batch 11/12                         Loss D: -57.0498, loss G: 3.5570\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [48/200] Batch 11/12                         Loss D: -57.6397, loss G: 3.6810\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [49/200] Batch 11/12                         Loss D: -59.1740, loss G: 3.7046\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [50/200] Batch 11/12                         Loss D: -60.4285, loss G: 3.7925\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [51/200] Batch 11/12                         Loss D: -61.8592, loss G: 3.8441\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [52/200] Batch 11/12                         Loss D: -64.3241, loss G: 3.9846\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [53/200] Batch 11/12                         Loss D: -65.6417, loss G: 4.0451\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [54/200] Batch 11/12                         Loss D: -65.8083, loss G: 4.0870\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [55/200] Batch 11/12                         Loss D: -68.3350, loss G: 4.1967\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [56/200] Batch 11/12                         Loss D: -68.8439, loss G: 4.1803\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [57/200] Batch 11/12                         Loss D: -70.5301, loss G: 4.1952\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [58/200] Batch 11/12                         Loss D: -72.6405, loss G: 4.4418\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [59/200] Batch 11/12                         Loss D: -74.1935, loss G: 4.5209\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [60/200] Batch 11/12                         Loss D: -74.3600, loss G: 4.4797\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [61/200] Batch 11/12                         Loss D: -76.4356, loss G: 4.5050\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [62/200] Batch 11/12                         Loss D: -78.3816, loss G: 4.6894\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [63/200] Batch 11/12                         Loss D: -77.9934, loss G: 4.8009\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [64/200] Batch 11/12                         Loss D: -79.8228, loss G: 4.8157\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [65/200] Batch 11/12                         Loss D: -82.5435, loss G: 4.8575\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [66/200] Batch 11/12                         Loss D: -82.6954, loss G: 4.9412\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [67/200] Batch 11/12                         Loss D: -83.8511, loss G: 5.0328\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [68/200] Batch 11/12                         Loss D: -85.5389, loss G: 5.0760\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [69/200] Batch 11/12                         Loss D: -87.0199, loss G: 5.0996\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [70/200] Batch 11/12                         Loss D: -88.7192, loss G: 5.1522\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [71/200] Batch 11/12                         Loss D: -88.8864, loss G: 5.3429\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [72/200] Batch 11/12                         Loss D: -89.8924, loss G: 5.4425\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [73/200] Batch 11/12                         Loss D: -91.3293, loss G: 5.4795\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [74/200] Batch 11/12                         Loss D: -92.9711, loss G: 5.4998\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [75/200] Batch 11/12                         Loss D: -93.7769, loss G: 5.6176\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [76/200] Batch 11/12                         Loss D: -94.7005, loss G: 5.7337\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [77/200] Batch 11/12                         Loss D: -98.1533, loss G: 5.6797\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [78/200] Batch 11/12                         Loss D: -98.8798, loss G: 5.6930\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [79/200] Batch 11/12                         Loss D: -100.4669, loss G: 5.7639\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [80/200] Batch 11/12                         Loss D: -102.2998, loss G: 5.8869\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [81/200] Batch 11/12                         Loss D: -102.1849, loss G: 5.9395\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [82/200] Batch 11/12                         Loss D: -105.6151, loss G: 6.1474\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [83/200] Batch 11/12                         Loss D: -105.1395, loss G: 6.0598\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [84/200] Batch 11/12                         Loss D: -106.6987, loss G: 6.0965\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [85/200] Batch 11/12                         Loss D: -109.0063, loss G: 6.2171\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [86/200] Batch 11/12                         Loss D: -111.5168, loss G: 6.4615\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [87/200] Batch 11/12                         Loss D: -111.4723, loss G: 6.3620\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [88/200] Batch 11/12                         Loss D: -111.8680, loss G: 6.4389\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [89/200] Batch 11/12                         Loss D: -114.5757, loss G: 6.4934\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [90/200] Batch 11/12                         Loss D: -114.6471, loss G: 6.6066\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [91/200] Batch 11/12                         Loss D: -115.7728, loss G: 6.7171\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [92/200] Batch 11/12                         Loss D: -119.6100, loss G: 6.7741\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [93/200] Batch 11/12                         Loss D: -119.0847, loss G: 6.8233\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [94/200] Batch 11/12                         Loss D: -122.0674, loss G: 6.8508\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [95/200] Batch 11/12                         Loss D: -122.8597, loss G: 6.9165\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [96/200] Batch 11/12                         Loss D: -124.5650, loss G: 6.9772\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [97/200] Batch 11/12                         Loss D: -126.1887, loss G: 7.0418\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [98/200] Batch 11/12                         Loss D: -127.3914, loss G: 7.1447\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [99/200] Batch 11/12                         Loss D: -129.9915, loss G: 7.3255\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [100/200] Batch 11/12                         Loss D: -130.1978, loss G: 7.3138\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [101/200] Batch 11/12                         Loss D: -132.8007, loss G: 7.4677\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [102/200] Batch 11/12                         Loss D: -133.1000, loss G: 7.4788\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [103/200] Batch 11/12                         Loss D: -134.8865, loss G: 7.5617\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [104/200] Batch 11/12                         Loss D: -135.3881, loss G: 7.7102\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [105/200] Batch 11/12                         Loss D: -136.9199, loss G: 7.8000\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [106/200] Batch 11/12                         Loss D: -138.3211, loss G: 7.8959\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [107/200] Batch 11/12                         Loss D: -139.4195, loss G: 8.0165\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [108/200] Batch 11/12                         Loss D: -142.4312, loss G: 8.0728\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [109/200] Batch 11/12                         Loss D: -141.6762, loss G: 8.2956\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [110/200] Batch 11/12                         Loss D: -143.9392, loss G: 8.3671\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [111/200] Batch 11/12                         Loss D: -146.0112, loss G: 8.4597\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [112/200] Batch 11/12                         Loss D: -146.8980, loss G: 8.6302\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [113/200] Batch 11/12                         Loss D: -149.8884, loss G: 8.8391\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [114/200] Batch 11/12                         Loss D: -150.1079, loss G: 8.8800\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [115/200] Batch 11/12                         Loss D: -150.6471, loss G: 9.0652\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [116/200] Batch 11/12                         Loss D: -153.7529, loss G: 9.1618\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [117/200] Batch 11/12                         Loss D: -155.6411, loss G: 9.2981\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [118/200] Batch 11/12                         Loss D: -156.5961, loss G: 9.3815\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [119/200] Batch 11/12                         Loss D: -158.9389, loss G: 9.5391\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [120/200] Batch 11/12                         Loss D: -159.2498, loss G: 9.6633\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [121/200] Batch 11/12                         Loss D: -162.3186, loss G: 9.8119\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [122/200] Batch 11/12                         Loss D: -163.9904, loss G: 9.9478\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [123/200] Batch 11/12                         Loss D: -164.8034, loss G: 10.0301\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [124/200] Batch 11/12                         Loss D: -167.0526, loss G: 10.1664\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [125/200] Batch 11/12                         Loss D: -167.6607, loss G: 10.3117\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [126/200] Batch 11/12                         Loss D: -168.1264, loss G: 10.4995\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [127/200] Batch 11/12                         Loss D: -174.1250, loss G: 10.7498\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [128/200] Batch 11/12                         Loss D: -174.6902, loss G: 10.7430\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [129/200] Batch 11/12                         Loss D: -175.8067, loss G: 10.8160\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [130/200] Batch 11/12                         Loss D: -174.7432, loss G: 11.0521\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [131/200] Batch 11/12                         Loss D: -179.1077, loss G: 11.0870\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [132/200] Batch 11/12                         Loss D: -182.5132, loss G: 11.3386\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [133/200] Batch 11/12                         Loss D: -182.8666, loss G: 11.3701\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [134/200] Batch 11/12                         Loss D: -183.5965, loss G: 11.5412\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [135/200] Batch 11/12                         Loss D: -187.1550, loss G: 11.6921\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [136/200] Batch 11/12                         Loss D: -189.0058, loss G: 11.8351\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [137/200] Batch 11/12                         Loss D: -191.5089, loss G: 12.0175\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [138/200] Batch 11/12                         Loss D: -191.5145, loss G: 12.0813\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [139/200] Batch 11/12                         Loss D: -193.3543, loss G: 12.2185\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [140/200] Batch 11/12                         Loss D: -194.2937, loss G: 12.3817\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [141/200] Batch 11/12                         Loss D: -195.5262, loss G: 12.5307\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [142/200] Batch 11/12                         Loss D: -199.4512, loss G: 12.6216\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [143/200] Batch 11/12                         Loss D: -199.7218, loss G: 12.7837\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [144/200] Batch 11/12                         Loss D: -200.4130, loss G: 12.9420\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [145/200] Batch 11/12                         Loss D: -203.0257, loss G: 13.0581\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [146/200] Batch 11/12                         Loss D: -208.6198, loss G: 13.3164\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [147/200] Batch 11/12                         Loss D: -207.0714, loss G: 13.2976\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [148/200] Batch 11/12                         Loss D: -206.7925, loss G: 13.4655\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [149/200] Batch 11/12                         Loss D: -210.4272, loss G: 13.5558\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [150/200] Batch 11/12                         Loss D: -214.5605, loss G: 13.7211\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [151/200] Batch 11/12                         Loss D: -213.1588, loss G: 13.8104\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [152/200] Batch 11/12                         Loss D: -215.5334, loss G: 13.9113\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [153/200] Batch 11/12                         Loss D: -219.1584, loss G: 14.0355\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [154/200] Batch 11/12                         Loss D: -219.1345, loss G: 14.1265\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [155/200] Batch 11/12                         Loss D: -219.6060, loss G: 14.2481\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [156/200] Batch 11/12                         Loss D: -220.8161, loss G: 14.3519\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [157/200] Batch 11/12                         Loss D: -225.5553, loss G: 14.4560\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [158/200] Batch 11/12                         Loss D: -223.9039, loss G: 14.5325\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [159/200] Batch 11/12                         Loss D: -225.3020, loss G: 14.6105\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [160/200] Batch 11/12                         Loss D: -226.5094, loss G: 14.6885\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [161/200] Batch 11/12                         Loss D: -228.9211, loss G: 14.7479\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [162/200] Batch 11/12                         Loss D: -228.4084, loss G: 14.8262\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [163/200] Batch 11/12                         Loss D: -232.1391, loss G: 14.8606\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [164/200] Batch 11/12                         Loss D: -231.2252, loss G: 14.9314\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [165/200] Batch 11/12                         Loss D: -232.3790, loss G: 14.9753\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [166/200] Batch 11/12                         Loss D: -230.3250, loss G: 15.0361\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [167/200] Batch 11/12                         Loss D: -232.8357, loss G: 15.0618\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [168/200] Batch 11/12                         Loss D: -233.2547, loss G: 15.0915\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [169/200] Batch 11/12                         Loss D: -233.1758, loss G: 15.1183\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [170/200] Batch 11/12                         Loss D: -235.4032, loss G: 15.1321\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [171/200] Batch 11/12                         Loss D: -233.4361, loss G: 15.1636\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [172/200] Batch 11/12                         Loss D: -235.7372, loss G: 15.1711\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [173/200] Batch 11/12                         Loss D: -233.3492, loss G: 15.1950\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [174/200] Batch 11/12                         Loss D: -234.7097, loss G: 15.2019\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [175/200] Batch 11/12                         Loss D: -233.0717, loss G: 15.2113\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [176/200] Batch 11/12                         Loss D: -233.7403, loss G: 15.2097\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [177/200] Batch 11/12                         Loss D: -230.8898, loss G: 15.2106\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [178/200] Batch 11/12                         Loss D: -229.0804, loss G: 15.1574\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [179/200] Batch 11/12                         Loss D: -225.7975, loss G: 15.0980\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [180/200] Batch 11/12                         Loss D: -226.5135, loss G: 15.0019\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [181/200] Batch 11/12                         Loss D: -227.8080, loss G: 15.0754\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [182/200] Batch 11/12                         Loss D: -231.3556, loss G: 15.1917\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [183/200] Batch 11/12                         Loss D: -228.9179, loss G: 15.2853\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [184/200] Batch 11/12                         Loss D: -228.7197, loss G: 15.2731\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [185/200] Batch 11/12                         Loss D: -225.4406, loss G: 15.2480\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [186/200] Batch 11/12                         Loss D: -222.5520, loss G: 15.3269\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [187/200] Batch 11/12                         Loss D: -222.5668, loss G: 15.4167\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [188/200] Batch 11/12                         Loss D: -222.9138, loss G: 15.4918\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [189/200] Batch 11/12                         Loss D: -223.9132, loss G: 15.5845\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [190/200] Batch 11/12                         Loss D: -222.1480, loss G: 15.7133\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [191/200] Batch 11/12                         Loss D: -222.3621, loss G: 15.8188\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [192/200] Batch 11/12                         Loss D: -222.3503, loss G: 15.9373\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [193/200] Batch 11/12                         Loss D: -219.7839, loss G: 16.0660\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [194/200] Batch 11/12                         Loss D: -218.2808, loss G: 16.1846\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [195/200] Batch 11/12                         Loss D: -214.0595, loss G: 16.3132\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [196/200] Batch 11/12                         Loss D: -214.3961, loss G: 16.4356\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [197/200] Batch 11/12                         Loss D: -215.4624, loss G: 16.6028\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [198/200] Batch 11/12                         Loss D: -218.1259, loss G: 16.7656\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [199/200] Batch 11/12                         Loss D: -218.6613, loss G: 16.9291\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [0/200] Batch 11/12                         Loss D: 0.9054, loss G: 3.3316\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [1/200] Batch 11/12                         Loss D: 0.8560, loss G: 3.3106\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [2/200] Batch 11/12                         Loss D: 0.8025, loss G: 3.2868\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [3/200] Batch 11/12                         Loss D: 0.7332, loss G: 3.2556\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [4/200] Batch 11/12                         Loss D: 0.6477, loss G: 3.2173\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [5/200] Batch 11/12                         Loss D: 0.5355, loss G: 3.1704\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [6/200] Batch 11/12                         Loss D: 0.3860, loss G: 3.1116\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [7/200] Batch 11/12                         Loss D: 0.1723, loss G: 3.0433\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [8/200] Batch 11/12                         Loss D: -0.1693, loss G: 2.9670\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [9/200] Batch 11/12                         Loss D: -0.2668, loss G: 2.8987\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [10/200] Batch 11/12                         Loss D: -0.3143, loss G: 2.8388\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [11/200] Batch 11/12                         Loss D: -0.3556, loss G: 2.7752\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [12/200] Batch 11/12                         Loss D: -0.3949, loss G: 2.6975\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [13/200] Batch 11/12                         Loss D: -0.4301, loss G: 2.6048\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [14/200] Batch 11/12                         Loss D: -0.4635, loss G: 2.5133\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [15/200] Batch 11/12                         Loss D: -0.4949, loss G: 2.4117\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [16/200] Batch 11/12                         Loss D: -0.5335, loss G: 2.2960\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [17/200] Batch 11/12                         Loss D: -0.5643, loss G: 2.1631\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [18/200] Batch 11/12                         Loss D: -0.5928, loss G: 2.0094\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [19/200] Batch 11/12                         Loss D: -0.6240, loss G: 1.8532\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [20/200] Batch 11/12                         Loss D: -0.6533, loss G: 1.8062\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [21/200] Batch 11/12                         Loss D: -0.6879, loss G: 1.8170\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [22/200] Batch 11/12                         Loss D: -0.7167, loss G: 1.8202\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [23/200] Batch 11/12                         Loss D: -0.7528, loss G: 1.8140\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [24/200] Batch 11/12                         Loss D: -0.7811, loss G: 1.8285\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [25/200] Batch 11/12                         Loss D: 0.5667, loss G: 1.5632\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [26/200] Batch 11/12                         Loss D: 2.2076, loss G: 1.3382\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [27/200] Batch 11/12                         Loss D: 3.6272, loss G: 1.1362\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [28/200] Batch 11/12                         Loss D: 5.0462, loss G: 0.9371\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [29/200] Batch 11/12                         Loss D: 6.5162, loss G: 0.7147\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [30/200] Batch 11/12                         Loss D: 8.0816, loss G: 0.4936\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [31/200] Batch 11/12                         Loss D: 9.6588, loss G: 0.2324\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [32/200] Batch 11/12                         Loss D: 11.2699, loss G: -0.0378\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [33/200] Batch 11/12                         Loss D: 12.9292, loss G: -0.3055\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [34/200] Batch 11/12                         Loss D: 14.7235, loss G: -0.6618\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [35/200] Batch 11/12                         Loss D: 16.2054, loss G: -0.9629\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [36/200] Batch 11/12                         Loss D: 17.4347, loss G: -1.2059\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [37/200] Batch 11/12                         Loss D: 16.4750, loss G: -1.1500\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [38/200] Batch 11/12                         Loss D: 15.9326, loss G: -1.0991\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [39/200] Batch 11/12                         Loss D: 15.2288, loss G: -1.0623\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [40/200] Batch 11/12                         Loss D: 14.6471, loss G: -1.0260\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [41/200] Batch 11/12                         Loss D: 14.0581, loss G: -0.9859\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [42/200] Batch 11/12                         Loss D: 13.6118, loss G: -0.9463\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [43/200] Batch 11/12                         Loss D: 13.0721, loss G: -0.9040\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [44/200] Batch 11/12                         Loss D: 12.6998, loss G: -0.8799\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [45/200] Batch 11/12                         Loss D: 12.3002, loss G: -0.8441\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [46/200] Batch 11/12                         Loss D: 11.8258, loss G: -0.8152\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [47/200] Batch 11/12                         Loss D: 11.3368, loss G: -0.7895\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [48/200] Batch 11/12                         Loss D: 10.9827, loss G: -0.7695\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [49/200] Batch 11/12                         Loss D: 10.5461, loss G: -0.7223\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [50/200] Batch 11/12                         Loss D: 10.3927, loss G: -0.6844\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [51/200] Batch 11/12                         Loss D: 10.1003, loss G: -0.6599\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [52/200] Batch 11/12                         Loss D: 9.6414, loss G: -0.6582\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [53/200] Batch 11/12                         Loss D: 9.1500, loss G: -0.6339\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [54/200] Batch 11/12                         Loss D: 8.8742, loss G: -0.6203\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [55/200] Batch 11/12                         Loss D: 8.6236, loss G: -0.5990\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [56/200] Batch 11/12                         Loss D: 8.2443, loss G: -0.5655\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [57/200] Batch 11/12                         Loss D: 7.9115, loss G: -0.5282\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [58/200] Batch 11/12                         Loss D: 7.6593, loss G: -0.5168\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [59/200] Batch 11/12                         Loss D: 7.3323, loss G: -0.4952\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [60/200] Batch 11/12                         Loss D: 7.0409, loss G: -0.4507\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [61/200] Batch 11/12                         Loss D: 6.8718, loss G: -0.4619\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [62/200] Batch 11/12                         Loss D: 6.5422, loss G: -0.4520\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [63/200] Batch 11/12                         Loss D: 6.3116, loss G: -0.4146\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [64/200] Batch 11/12                         Loss D: 6.0091, loss G: -0.4176\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [65/200] Batch 11/12                         Loss D: 5.7893, loss G: -0.3686\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [66/200] Batch 11/12                         Loss D: 5.4402, loss G: -0.3721\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [67/200] Batch 11/12                         Loss D: 5.2468, loss G: -0.3500\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [68/200] Batch 11/12                         Loss D: 4.9730, loss G: -0.3459\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [69/200] Batch 11/12                         Loss D: 4.7528, loss G: -0.3082\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [70/200] Batch 11/12                         Loss D: 4.4781, loss G: -0.2883\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [71/200] Batch 11/12                         Loss D: 4.2596, loss G: -0.2786\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [72/200] Batch 11/12                         Loss D: 3.9853, loss G: -0.2580\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [73/200] Batch 11/12                         Loss D: 3.7549, loss G: -0.2548\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [74/200] Batch 11/12                         Loss D: 3.5383, loss G: -0.2248\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [75/200] Batch 11/12                         Loss D: 3.2936, loss G: -0.2213\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [76/200] Batch 11/12                         Loss D: 3.0348, loss G: -0.1903\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [77/200] Batch 11/12                         Loss D: 2.8253, loss G: -0.1896\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [78/200] Batch 11/12                         Loss D: 2.5992, loss G: -0.1730\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [79/200] Batch 11/12                         Loss D: 2.3841, loss G: -0.1094\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [80/200] Batch 11/12                         Loss D: 2.1397, loss G: -0.1367\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [81/200] Batch 11/12                         Loss D: 1.9208, loss G: -0.1208\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [82/200] Batch 11/12                         Loss D: 1.7048, loss G: -0.0919\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [83/200] Batch 11/12                         Loss D: 1.4874, loss G: -0.0316\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [84/200] Batch 11/12                         Loss D: 1.2619, loss G: -0.0562\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [85/200] Batch 11/12                         Loss D: 1.0386, loss G: -0.0511\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [86/200] Batch 11/12                         Loss D: 0.8175, loss G: -0.0309\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [87/200] Batch 11/12                         Loss D: 0.5980, loss G: -0.0312\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [88/200] Batch 11/12                         Loss D: 0.3738, loss G: -0.0106\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [89/200] Batch 11/12                         Loss D: 0.1603, loss G: 0.0193\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [90/200] Batch 11/12                         Loss D: -0.0588, loss G: 0.0239\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [91/200] Batch 11/12                         Loss D: -0.2880, loss G: 0.0375\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [92/200] Batch 11/12                         Loss D: -0.5113, loss G: 0.0714\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [93/200] Batch 11/12                         Loss D: -0.7440, loss G: 0.0977\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [94/200] Batch 11/12                         Loss D: -0.9386, loss G: 0.0780\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [95/200] Batch 11/12                         Loss D: -1.1526, loss G: 0.0978\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [96/200] Batch 11/12                         Loss D: -1.3895, loss G: 0.1208\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [97/200] Batch 11/12                         Loss D: -1.6083, loss G: 0.1398\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [98/200] Batch 11/12                         Loss D: -1.8115, loss G: 0.1471\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [99/200] Batch 11/12                         Loss D: -2.0521, loss G: 0.1605\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [100/200] Batch 11/12                         Loss D: -2.2471, loss G: 0.1860\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [101/200] Batch 11/12                         Loss D: -2.4882, loss G: 0.1918\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [102/200] Batch 11/12                         Loss D: -2.7273, loss G: 0.2205\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [103/200] Batch 11/12                         Loss D: -2.9215, loss G: 0.2331\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [104/200] Batch 11/12                         Loss D: -3.2006, loss G: 0.2614\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [105/200] Batch 11/12                         Loss D: -3.3770, loss G: 0.2617\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [106/200] Batch 11/12                         Loss D: -3.6226, loss G: 0.2740\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [107/200] Batch 11/12                         Loss D: -3.8450, loss G: 0.3037\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [108/200] Batch 11/12                         Loss D: -4.0952, loss G: 0.3052\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [109/200] Batch 11/12                         Loss D: -4.3279, loss G: 0.3262\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [110/200] Batch 11/12                         Loss D: -4.5942, loss G: 0.3403\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [111/200] Batch 11/12                         Loss D: -4.8429, loss G: 0.3600\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [112/200] Batch 11/12                         Loss D: -5.0624, loss G: 0.3822\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [113/200] Batch 11/12                         Loss D: -5.2969, loss G: 0.3923\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [114/200] Batch 11/12                         Loss D: -5.5681, loss G: 0.4104\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [115/200] Batch 11/12                         Loss D: -5.7910, loss G: 0.4399\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [116/200] Batch 11/12                         Loss D: -5.9602, loss G: 0.4724\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [117/200] Batch 11/12                         Loss D: -6.2949, loss G: 0.4713\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [118/200] Batch 11/12                         Loss D: -6.5504, loss G: 0.4875\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [119/200] Batch 11/12                         Loss D: -6.8417, loss G: 0.5011\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [120/200] Batch 11/12                         Loss D: -7.1013, loss G: 0.5202\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [121/200] Batch 11/12                         Loss D: -7.3320, loss G: 0.5418\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [122/200] Batch 11/12                         Loss D: -7.6535, loss G: 0.5611\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [123/200] Batch 11/12                         Loss D: -7.9561, loss G: 0.5776\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [124/200] Batch 11/12                         Loss D: -8.2163, loss G: 0.5946\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [125/200] Batch 11/12                         Loss D: -8.4580, loss G: 0.6176\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [126/200] Batch 11/12                         Loss D: -8.7053, loss G: 0.6474\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [127/200] Batch 11/12                         Loss D: -9.1726, loss G: 0.6818\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [128/200] Batch 11/12                         Loss D: -9.2872, loss G: 0.6881\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [129/200] Batch 11/12                         Loss D: -9.6717, loss G: 0.7043\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [130/200] Batch 11/12                         Loss D: -9.8722, loss G: 0.7276\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [131/200] Batch 11/12                         Loss D: -10.1788, loss G: 0.7500\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [132/200] Batch 11/12                         Loss D: -10.5477, loss G: 0.7589\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [133/200] Batch 11/12                         Loss D: -10.9487, loss G: 0.8002\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [134/200] Batch 11/12                         Loss D: -11.2264, loss G: 0.8041\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [135/200] Batch 11/12                         Loss D: -11.4364, loss G: 0.8316\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [136/200] Batch 11/12                         Loss D: -11.7852, loss G: 0.8553\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [137/200] Batch 11/12                         Loss D: -12.2224, loss G: 0.8882\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [138/200] Batch 11/12                         Loss D: -12.5835, loss G: 0.9030\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [139/200] Batch 11/12                         Loss D: -12.8090, loss G: 0.9149\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [140/200] Batch 11/12                         Loss D: -13.1672, loss G: 0.9323\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [141/200] Batch 11/12                         Loss D: -13.5216, loss G: 0.9565\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [142/200] Batch 11/12                         Loss D: -13.8927, loss G: 0.9872\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [143/200] Batch 11/12                         Loss D: -13.9852, loss G: 1.0192\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [144/200] Batch 11/12                         Loss D: -14.4472, loss G: 1.0370\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [145/200] Batch 11/12                         Loss D: -14.8626, loss G: 1.0531\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [146/200] Batch 11/12                         Loss D: -15.2121, loss G: 1.0779\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [147/200] Batch 11/12                         Loss D: -15.4563, loss G: 1.1205\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [148/200] Batch 11/12                         Loss D: -15.9730, loss G: 1.1286\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [149/200] Batch 11/12                         Loss D: -16.0885, loss G: 1.1694\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [150/200] Batch 11/12                         Loss D: -16.9481, loss G: 1.2031\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [151/200] Batch 11/12                         Loss D: -16.8818, loss G: 1.2221\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [152/200] Batch 11/12                         Loss D: -17.3835, loss G: 1.2411\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [153/200] Batch 11/12                         Loss D: -17.7219, loss G: 1.2562\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [154/200] Batch 11/12                         Loss D: -18.1751, loss G: 1.2845\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [155/200] Batch 11/12                         Loss D: -18.7420, loss G: 1.3035\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [156/200] Batch 11/12                         Loss D: -18.8440, loss G: 1.3453\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [157/200] Batch 11/12                         Loss D: -19.5750, loss G: 1.3684\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [158/200] Batch 11/12                         Loss D: -19.8662, loss G: 1.3887\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [159/200] Batch 11/12                         Loss D: -20.0471, loss G: 1.4146\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [160/200] Batch 11/12                         Loss D: -20.6838, loss G: 1.4372\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [161/200] Batch 11/12                         Loss D: -20.8576, loss G: 1.4704\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [162/200] Batch 11/12                         Loss D: -21.5337, loss G: 1.4982\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [163/200] Batch 11/12                         Loss D: -21.9412, loss G: 1.5234\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [164/200] Batch 11/12                         Loss D: -22.4396, loss G: 1.5489\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [165/200] Batch 11/12                         Loss D: -22.5345, loss G: 1.5844\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [166/200] Batch 11/12                         Loss D: -23.1554, loss G: 1.6055\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [167/200] Batch 11/12                         Loss D: -23.7419, loss G: 1.6341\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [168/200] Batch 11/12                         Loss D: -23.8188, loss G: 1.6660\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [169/200] Batch 11/12                         Loss D: -24.2926, loss G: 1.7000\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [170/200] Batch 11/12                         Loss D: -24.6491, loss G: 1.7265\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [171/200] Batch 11/12                         Loss D: -25.2213, loss G: 1.7553\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [172/200] Batch 11/12                         Loss D: -25.4462, loss G: 1.7822\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [173/200] Batch 11/12                         Loss D: -26.0700, loss G: 1.8201\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [174/200] Batch 11/12                         Loss D: -26.6354, loss G: 1.8460\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [175/200] Batch 11/12                         Loss D: -26.6528, loss G: 1.8725\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [176/200] Batch 11/12                         Loss D: -27.3676, loss G: 1.9045\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [177/200] Batch 11/12                         Loss D: -27.7793, loss G: 1.9364\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [178/200] Batch 11/12                         Loss D: -28.0960, loss G: 1.9628\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [179/200] Batch 11/12                         Loss D: -28.6244, loss G: 1.9935\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [180/200] Batch 11/12                         Loss D: -28.9452, loss G: 2.0231\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [181/200] Batch 11/12                         Loss D: -29.2393, loss G: 2.0530\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [182/200] Batch 11/12                         Loss D: -29.8704, loss G: 2.0894\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [183/200] Batch 11/12                         Loss D: -30.2324, loss G: 2.1215\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [184/200] Batch 11/12                         Loss D: -30.1341, loss G: 2.1563\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [185/200] Batch 11/12                         Loss D: -30.9543, loss G: 2.1821\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [186/200] Batch 11/12                         Loss D: -31.1665, loss G: 2.2108\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [187/200] Batch 11/12                         Loss D: -31.3155, loss G: 2.2336\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [188/200] Batch 11/12                         Loss D: -31.2214, loss G: 2.2578\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [189/200] Batch 11/12                         Loss D: -31.2462, loss G: 2.2804\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [190/200] Batch 11/12                         Loss D: -31.4938, loss G: 2.3127\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [191/200] Batch 11/12                         Loss D: -31.3657, loss G: 2.3264\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [192/200] Batch 11/12                         Loss D: -31.3285, loss G: 2.3533\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [193/200] Batch 11/12                         Loss D: -31.3011, loss G: 2.3695\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [194/200] Batch 11/12                         Loss D: -31.2247, loss G: 2.3881\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [195/200] Batch 11/12                         Loss D: -31.0674, loss G: 2.4109\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [196/200] Batch 11/12                         Loss D: -31.1688, loss G: 2.4246\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [197/200] Batch 11/12                         Loss D: -30.6455, loss G: 2.4411\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [198/200] Batch 11/12                         Loss D: -30.7164, loss G: 2.4578\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [199/200] Batch 11/12                         Loss D: -30.2943, loss G: 2.4668\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [0/200] Batch 11/12                         Loss D: 0.1736, loss G: 34.5970\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [1/200] Batch 11/12                         Loss D: 0.2836, loss G: 34.3536\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [2/200] Batch 11/12                         Loss D: 0.4161, loss G: 34.0426\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [3/200] Batch 11/12                         Loss D: 0.5852, loss G: 33.6269\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [4/200] Batch 11/12                         Loss D: 0.8103, loss G: 33.0212\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [5/200] Batch 11/12                         Loss D: 1.0559, loss G: 32.3069\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [6/200] Batch 11/12                         Loss D: 1.3392, loss G: 31.4151\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [7/200] Batch 11/12                         Loss D: 1.6287, loss G: 30.3919\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [8/200] Batch 11/12                         Loss D: 1.8719, loss G: 29.4559\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [9/200] Batch 11/12                         Loss D: 2.0513, loss G: 28.7282\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [10/200] Batch 11/12                         Loss D: 2.1932, loss G: 27.9071\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [11/200] Batch 11/12                         Loss D: 2.3414, loss G: 26.9420\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [12/200] Batch 11/12                         Loss D: 2.4279, loss G: 25.9521\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [13/200] Batch 11/12                         Loss D: 2.5084, loss G: 24.7414\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [14/200] Batch 11/12                         Loss D: 2.5324, loss G: 23.3701\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [15/200] Batch 11/12                         Loss D: 2.4696, loss G: 21.8942\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [16/200] Batch 11/12                         Loss D: 2.3313, loss G: 20.2124\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [17/200] Batch 11/12                         Loss D: 2.1164, loss G: 18.2542\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [18/200] Batch 11/12                         Loss D: 1.7481, loss G: 16.1791\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [19/200] Batch 11/12                         Loss D: 1.2311, loss G: 13.9823\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [20/200] Batch 11/12                         Loss D: 0.5391, loss G: 11.5941\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [21/200] Batch 11/12                         Loss D: -0.3247, loss G: 9.5220\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [22/200] Batch 11/12                         Loss D: -1.1944, loss G: 8.6718\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [23/200] Batch 11/12                         Loss D: -2.1461, loss G: 7.6150\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [24/200] Batch 11/12                         Loss D: -3.2068, loss G: 6.6744\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [25/200] Batch 11/12                         Loss D: -4.3135, loss G: 5.7188\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [26/200] Batch 11/12                         Loss D: -5.5403, loss G: 4.5312\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [27/200] Batch 11/12                         Loss D: -6.9513, loss G: 3.4684\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [28/200] Batch 11/12                         Loss D: -8.4403, loss G: 2.3227\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [29/200] Batch 11/12                         Loss D: -10.2190, loss G: 0.8886\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [30/200] Batch 11/12                         Loss D: -11.5196, loss G: 0.9628\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [31/200] Batch 11/12                         Loss D: -12.6468, loss G: 1.5137\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [32/200] Batch 11/12                         Loss D: -14.1011, loss G: 1.0757\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [33/200] Batch 11/12                         Loss D: -15.3039, loss G: 1.1997\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [34/200] Batch 11/12                         Loss D: -16.5063, loss G: 1.3030\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [35/200] Batch 11/12                         Loss D: -17.6054, loss G: 1.4969\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [36/200] Batch 11/12                         Loss D: -19.1027, loss G: 1.7351\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [37/200] Batch 11/12                         Loss D: -20.0539, loss G: 1.5123\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [38/200] Batch 11/12                         Loss D: -21.2680, loss G: 1.5592\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [39/200] Batch 11/12                         Loss D: -22.3105, loss G: 1.7252\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [40/200] Batch 11/12                         Loss D: -23.6191, loss G: 1.8223\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [41/200] Batch 11/12                         Loss D: -24.6410, loss G: 1.8499\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [42/200] Batch 11/12                         Loss D: -25.6172, loss G: 2.0923\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [43/200] Batch 11/12                         Loss D: -27.1563, loss G: 2.0944\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [44/200] Batch 11/12                         Loss D: -28.6110, loss G: 2.5418\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [45/200] Batch 11/12                         Loss D: -29.0848, loss G: 2.2903\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [46/200] Batch 11/12                         Loss D: -30.7920, loss G: 2.4725\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [47/200] Batch 11/12                         Loss D: -31.3408, loss G: 2.4794\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [48/200] Batch 11/12                         Loss D: -32.5204, loss G: 2.5435\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [49/200] Batch 11/12                         Loss D: -34.1125, loss G: 2.4670\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [50/200] Batch 11/12                         Loss D: -35.1392, loss G: 2.4215\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [51/200] Batch 11/12                         Loss D: -35.8567, loss G: 2.8993\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [52/200] Batch 11/12                         Loss D: -37.0353, loss G: 3.0036\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [53/200] Batch 11/12                         Loss D: -38.9850, loss G: 2.8352\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [54/200] Batch 11/12                         Loss D: -39.8828, loss G: 2.7659\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [55/200] Batch 11/12                         Loss D: -40.9744, loss G: 2.9207\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [56/200] Batch 11/12                         Loss D: -42.2842, loss G: 2.9877\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [57/200] Batch 11/12                         Loss D: -43.3942, loss G: 3.1246\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [58/200] Batch 11/12                         Loss D: -44.9656, loss G: 3.0452\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [59/200] Batch 11/12                         Loss D: -46.2992, loss G: 3.1751\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [60/200] Batch 11/12                         Loss D: -47.4253, loss G: 3.1857\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [61/200] Batch 11/12                         Loss D: -49.4044, loss G: 3.7324\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [62/200] Batch 11/12                         Loss D: -50.2918, loss G: 3.5069\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [63/200] Batch 11/12                         Loss D: -52.0960, loss G: 3.9595\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [64/200] Batch 11/12                         Loss D: -53.0925, loss G: 3.7901\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [65/200] Batch 11/12                         Loss D: -54.3978, loss G: 3.8482\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [66/200] Batch 11/12                         Loss D: -54.9728, loss G: 3.8060\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [67/200] Batch 11/12                         Loss D: -56.1400, loss G: 3.9728\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [68/200] Batch 11/12                         Loss D: -57.8337, loss G: 3.8687\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [69/200] Batch 11/12                         Loss D: -59.6225, loss G: 4.0432\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [70/200] Batch 11/12                         Loss D: -60.7257, loss G: 3.9508\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [71/200] Batch 11/12                         Loss D: -62.3591, loss G: 4.1812\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [72/200] Batch 11/12                         Loss D: -64.2623, loss G: 4.5469\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [73/200] Batch 11/12                         Loss D: -65.5121, loss G: 4.5331\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [74/200] Batch 11/12                         Loss D: -66.5546, loss G: 4.3908\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [75/200] Batch 11/12                         Loss D: -67.5058, loss G: 4.5109\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [76/200] Batch 11/12                         Loss D: -69.8380, loss G: 4.7874\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [77/200] Batch 11/12                         Loss D: -69.9221, loss G: 4.8897\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [78/200] Batch 11/12                         Loss D: -72.0111, loss G: 4.7088\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [79/200] Batch 11/12                         Loss D: -73.8242, loss G: 4.7915\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [80/200] Batch 11/12                         Loss D: -74.8493, loss G: 4.9452\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [81/200] Batch 11/12                         Loss D: -76.0058, loss G: 5.1661\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [82/200] Batch 11/12                         Loss D: -77.9966, loss G: 5.0671\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [83/200] Batch 11/12                         Loss D: -78.7118, loss G: 5.4670\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [84/200] Batch 11/12                         Loss D: -82.0474, loss G: 5.5607\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [85/200] Batch 11/12                         Loss D: -81.2936, loss G: 5.8271\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [86/200] Batch 11/12                         Loss D: -84.8017, loss G: 5.5526\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [87/200] Batch 11/12                         Loss D: -86.7659, loss G: 5.8244\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [88/200] Batch 11/12                         Loss D: -86.6290, loss G: 5.8616\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [89/200] Batch 11/12                         Loss D: -89.1671, loss G: 5.6730\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [90/200] Batch 11/12                         Loss D: -90.9532, loss G: 5.8233\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [91/200] Batch 11/12                         Loss D: -91.6071, loss G: 6.0887\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [92/200] Batch 11/12                         Loss D: -93.3980, loss G: 6.1394\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [93/200] Batch 11/12                         Loss D: -95.7364, loss G: 6.0606\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [94/200] Batch 11/12                         Loss D: -97.3021, loss G: 6.1647\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [95/200] Batch 11/12                         Loss D: -98.1819, loss G: 6.4957\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [96/200] Batch 11/12                         Loss D: -100.8557, loss G: 6.3938\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [97/200] Batch 11/12                         Loss D: -102.7659, loss G: 6.5776\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [98/200] Batch 11/12                         Loss D: -104.5264, loss G: 6.7048\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [99/200] Batch 11/12                         Loss D: -105.5413, loss G: 6.7764\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [100/200] Batch 11/12                         Loss D: -107.0395, loss G: 6.9133\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [101/200] Batch 11/12                         Loss D: -109.5891, loss G: 6.9685\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [102/200] Batch 11/12                         Loss D: -108.8574, loss G: 7.5373\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [103/200] Batch 11/12                         Loss D: -113.8940, loss G: 7.4157\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [104/200] Batch 11/12                         Loss D: -115.2335, loss G: 7.3559\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [105/200] Batch 11/12                         Loss D: -115.6031, loss G: 7.5174\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [106/200] Batch 11/12                         Loss D: -117.3720, loss G: 7.6247\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [107/200] Batch 11/12                         Loss D: -120.4792, loss G: 7.6192\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [108/200] Batch 11/12                         Loss D: -120.5594, loss G: 7.9487\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [109/200] Batch 11/12                         Loss D: -124.1419, loss G: 7.8035\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [110/200] Batch 11/12                         Loss D: -125.7480, loss G: 7.8746\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [111/200] Batch 11/12                         Loss D: -127.7957, loss G: 7.9952\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [112/200] Batch 11/12                         Loss D: -129.7161, loss G: 8.1250\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [113/200] Batch 11/12                         Loss D: -131.0004, loss G: 8.2981\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [114/200] Batch 11/12                         Loss D: -133.0905, loss G: 8.3721\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [115/200] Batch 11/12                         Loss D: -135.0856, loss G: 8.4521\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [116/200] Batch 11/12                         Loss D: -138.1174, loss G: 8.6530\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [117/200] Batch 11/12                         Loss D: -138.7978, loss G: 8.6743\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [118/200] Batch 11/12                         Loss D: -140.4336, loss G: 8.8029\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [119/200] Batch 11/12                         Loss D: -142.7258, loss G: 8.8372\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [120/200] Batch 11/12                         Loss D: -145.6771, loss G: 8.8780\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [121/200] Batch 11/12                         Loss D: -147.8939, loss G: 9.0401\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [122/200] Batch 11/12                         Loss D: -148.0782, loss G: 9.2926\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [123/200] Batch 11/12                         Loss D: -150.3296, loss G: 9.3768\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [124/200] Batch 11/12                         Loss D: -152.9252, loss G: 9.4070\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [125/200] Batch 11/12                         Loss D: -156.9503, loss G: 9.7249\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [126/200] Batch 11/12                         Loss D: -157.4922, loss G: 9.6035\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [127/200] Batch 11/12                         Loss D: -159.5723, loss G: 9.7256\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [128/200] Batch 11/12                         Loss D: -161.6478, loss G: 9.8359\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [129/200] Batch 11/12                         Loss D: -163.7045, loss G: 9.9961\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [130/200] Batch 11/12                         Loss D: -166.7440, loss G: 10.1281\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [131/200] Batch 11/12                         Loss D: -168.5437, loss G: 10.1782\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [132/200] Batch 11/12                         Loss D: -169.4925, loss G: 10.4444\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [133/200] Batch 11/12                         Loss D: -171.5931, loss G: 10.5856\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [134/200] Batch 11/12                         Loss D: -173.2333, loss G: 10.7873\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [135/200] Batch 11/12                         Loss D: -176.3889, loss G: 10.7847\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [136/200] Batch 11/12                         Loss D: -178.6602, loss G: 10.9142\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [137/200] Batch 11/12                         Loss D: -181.8495, loss G: 10.9528\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [138/200] Batch 11/12                         Loss D: -186.0412, loss G: 11.5029\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [139/200] Batch 11/12                         Loss D: -186.6074, loss G: 11.2344\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [140/200] Batch 11/12                         Loss D: -189.2846, loss G: 11.4874\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [141/200] Batch 11/12                         Loss D: -190.6196, loss G: 11.4812\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [142/200] Batch 11/12                         Loss D: -193.0615, loss G: 11.6295\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [143/200] Batch 11/12                         Loss D: -193.7150, loss G: 11.9296\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [144/200] Batch 11/12                         Loss D: -199.6008, loss G: 12.2127\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [145/200] Batch 11/12                         Loss D: -202.1674, loss G: 12.4294\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [146/200] Batch 11/12                         Loss D: -200.7404, loss G: 12.3405\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [147/200] Batch 11/12                         Loss D: -205.8511, loss G: 12.4250\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [148/200] Batch 11/12                         Loss D: -206.8304, loss G: 12.5063\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [149/200] Batch 11/12                         Loss D: -209.5988, loss G: 12.5647\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [150/200] Batch 11/12                         Loss D: -211.9416, loss G: 12.7663\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [151/200] Batch 11/12                         Loss D: -213.4484, loss G: 12.9533\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [152/200] Batch 11/12                         Loss D: -216.0902, loss G: 13.0857\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [153/200] Batch 11/12                         Loss D: -219.7419, loss G: 13.1623\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [154/200] Batch 11/12                         Loss D: -219.9704, loss G: 13.4632\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [155/200] Batch 11/12                         Loss D: -222.4416, loss G: 13.6218\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [156/200] Batch 11/12                         Loss D: -226.2930, loss G: 13.6475\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [157/200] Batch 11/12                         Loss D: -232.3426, loss G: 14.2222\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [158/200] Batch 11/12                         Loss D: -230.2145, loss G: 14.0368\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [159/200] Batch 11/12                         Loss D: -237.2306, loss G: 14.4568\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [160/200] Batch 11/12                         Loss D: -235.6734, loss G: 14.2919\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [161/200] Batch 11/12                         Loss D: -237.8174, loss G: 14.4751\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [162/200] Batch 11/12                         Loss D: -242.6266, loss G: 14.4554\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [163/200] Batch 11/12                         Loss D: -243.8348, loss G: 14.7263\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [164/200] Batch 11/12                         Loss D: -247.8480, loss G: 14.7557\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [165/200] Batch 11/12                         Loss D: -249.3829, loss G: 14.9991\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [166/200] Batch 11/12                         Loss D: -252.7483, loss G: 15.0890\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [167/200] Batch 11/12                         Loss D: -253.4675, loss G: 15.3918\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [168/200] Batch 11/12                         Loss D: -256.6645, loss G: 15.5397\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [169/200] Batch 11/12                         Loss D: -258.6791, loss G: 15.7224\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [170/200] Batch 11/12                         Loss D: -265.5218, loss G: 15.9421\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [171/200] Batch 11/12                         Loss D: -262.8531, loss G: 16.1139\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [172/200] Batch 11/12                         Loss D: -269.3914, loss G: 16.0405\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [173/200] Batch 11/12                         Loss D: -271.7128, loss G: 16.2252\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [174/200] Batch 11/12                         Loss D: -273.3134, loss G: 16.4454\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [175/200] Batch 11/12                         Loss D: -276.8519, loss G: 16.5625\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [176/200] Batch 11/12                         Loss D: -279.4135, loss G: 16.7340\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [177/200] Batch 11/12                         Loss D: -281.7204, loss G: 16.9338\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [178/200] Batch 11/12                         Loss D: -287.9917, loss G: 17.2537\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [179/200] Batch 11/12                         Loss D: -290.0562, loss G: 17.2592\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [180/200] Batch 11/12                         Loss D: -294.6696, loss G: 17.6952\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [181/200] Batch 11/12                         Loss D: -293.1611, loss G: 17.6050\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [182/200] Batch 11/12                         Loss D: -294.2184, loss G: 17.8592\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [183/200] Batch 11/12                         Loss D: -299.2042, loss G: 17.9070\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [184/200] Batch 11/12                         Loss D: -302.0060, loss G: 18.0899\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [185/200] Batch 11/12                         Loss D: -305.4730, loss G: 18.2285\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [186/200] Batch 11/12                         Loss D: -309.2720, loss G: 18.3746\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [187/200] Batch 11/12                         Loss D: -312.4089, loss G: 18.5501\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [188/200] Batch 11/12                         Loss D: -313.3704, loss G: 18.7972\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [189/200] Batch 11/12                         Loss D: -314.6477, loss G: 19.0508\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [190/200] Batch 11/12                         Loss D: -320.0793, loss G: 19.1114\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [191/200] Batch 11/12                         Loss D: -325.4360, loss G: 19.2654\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [192/200] Batch 11/12                         Loss D: -327.4446, loss G: 19.3981\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [193/200] Batch 11/12                         Loss D: -330.0178, loss G: 19.5901\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [194/200] Batch 11/12                         Loss D: -331.8528, loss G: 19.8314\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [195/200] Batch 11/12                         Loss D: -336.7961, loss G: 19.9217\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [196/200] Batch 11/12                         Loss D: -339.8536, loss G: 20.1244\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [197/200] Batch 11/12                         Loss D: -343.8810, loss G: 20.3410\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [198/200] Batch 11/12                         Loss D: -343.6580, loss G: 20.5529\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [199/200] Batch 11/12                         Loss D: -342.8037, loss G: 20.9194\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [0/200] Batch 11/12                         Loss D: 0.3953, loss G: 17.0629\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [1/200] Batch 11/12                         Loss D: 0.3317, loss G: 16.9007\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [2/200] Batch 11/12                         Loss D: 0.9907, loss G: 16.7247\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [3/200] Batch 11/12                         Loss D: 1.8989, loss G: 16.5126\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [4/200] Batch 11/12                         Loss D: 2.9225, loss G: 16.2505\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [5/200] Batch 11/12                         Loss D: 3.7167, loss G: 15.9585\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [6/200] Batch 11/12                         Loss D: 4.3086, loss G: 15.5740\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [7/200] Batch 11/12                         Loss D: 4.2467, loss G: 15.1109\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [8/200] Batch 11/12                         Loss D: 2.5897, loss G: 14.4864\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [9/200] Batch 11/12                         Loss D: 1.7983, loss G: 14.0278\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [10/200] Batch 11/12                         Loss D: 1.7710, loss G: 13.5553\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [11/200] Batch 11/12                         Loss D: 1.6431, loss G: 13.0571\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [12/200] Batch 11/12                         Loss D: 1.3689, loss G: 12.4920\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [13/200] Batch 11/12                         Loss D: 1.0520, loss G: 11.8090\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [14/200] Batch 11/12                         Loss D: 0.9821, loss G: 11.1242\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [15/200] Batch 11/12                         Loss D: 1.0016, loss G: 10.3408\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [16/200] Batch 11/12                         Loss D: 1.0567, loss G: 9.4179\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [17/200] Batch 11/12                         Loss D: 1.0503, loss G: 8.4371\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [18/200] Batch 11/12                         Loss D: 1.0815, loss G: 7.2474\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [19/200] Batch 11/12                         Loss D: 1.2116, loss G: 5.9446\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [20/200] Batch 11/12                         Loss D: 3.0122, loss G: 4.1500\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [21/200] Batch 11/12                         Loss D: 11.3578, loss G: 2.5299\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [22/200] Batch 11/12                         Loss D: 21.5020, loss G: 0.3898\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [23/200] Batch 11/12                         Loss D: 31.6261, loss G: -1.6743\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [24/200] Batch 11/12                         Loss D: 40.9411, loss G: -3.6580\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [25/200] Batch 11/12                         Loss D: 41.3336, loss G: -3.4707\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [26/200] Batch 11/12                         Loss D: 39.4313, loss G: -3.2823\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [27/200] Batch 11/12                         Loss D: 36.8895, loss G: -3.1095\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [28/200] Batch 11/12                         Loss D: 35.1127, loss G: -2.9391\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [29/200] Batch 11/12                         Loss D: 31.4390, loss G: -2.8296\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [30/200] Batch 11/12                         Loss D: 28.3437, loss G: -2.7124\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [31/200] Batch 11/12                         Loss D: 27.5060, loss G: -2.5855\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [32/200] Batch 11/12                         Loss D: 24.6148, loss G: -2.5078\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [33/200] Batch 11/12                         Loss D: 24.1122, loss G: -2.3944\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [34/200] Batch 11/12                         Loss D: 22.7498, loss G: -2.2594\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [35/200] Batch 11/12                         Loss D: 21.1728, loss G: -2.0911\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [36/200] Batch 11/12                         Loss D: 20.9981, loss G: -1.9492\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [37/200] Batch 11/12                         Loss D: 19.4805, loss G: -2.0478\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [38/200] Batch 11/12                         Loss D: 18.6228, loss G: -1.9796\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [39/200] Batch 11/12                         Loss D: 17.5454, loss G: -1.8585\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [40/200] Batch 11/12                         Loss D: 16.1262, loss G: -1.6270\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [41/200] Batch 11/12                         Loss D: 15.3747, loss G: -1.7682\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [42/200] Batch 11/12                         Loss D: 15.8889, loss G: -1.6561\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [43/200] Batch 11/12                         Loss D: 14.2243, loss G: -1.6073\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [44/200] Batch 11/12                         Loss D: 13.5568, loss G: -1.4657\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [45/200] Batch 11/12                         Loss D: 12.6903, loss G: -1.4792\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [46/200] Batch 11/12                         Loss D: 12.0714, loss G: -1.3806\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [47/200] Batch 11/12                         Loss D: 10.9852, loss G: -1.3828\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [48/200] Batch 11/12                         Loss D: 11.0100, loss G: -1.2674\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [49/200] Batch 11/12                         Loss D: 10.7436, loss G: -1.1680\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [50/200] Batch 11/12                         Loss D: 8.8746, loss G: -1.0501\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [51/200] Batch 11/12                         Loss D: 8.8045, loss G: -1.1029\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [52/200] Batch 11/12                         Loss D: 7.8969, loss G: -1.0748\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [53/200] Batch 11/12                         Loss D: 7.0434, loss G: -1.0297\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [54/200] Batch 11/12                         Loss D: 6.7238, loss G: -0.9472\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [55/200] Batch 11/12                         Loss D: 5.8079, loss G: -0.6913\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [56/200] Batch 11/12                         Loss D: 5.4075, loss G: -0.7973\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [57/200] Batch 11/12                         Loss D: 5.1116, loss G: -0.7678\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [58/200] Batch 11/12                         Loss D: 4.1910, loss G: -0.6071\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [59/200] Batch 11/12                         Loss D: 3.8553, loss G: -0.5995\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [60/200] Batch 11/12                         Loss D: 3.0886, loss G: -0.6239\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [61/200] Batch 11/12                         Loss D: 2.8265, loss G: -0.5379\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [62/200] Batch 11/12                         Loss D: 1.8921, loss G: -0.5413\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [63/200] Batch 11/12                         Loss D: 1.5687, loss G: -0.4276\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [64/200] Batch 11/12                         Loss D: 0.5332, loss G: -0.4283\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [65/200] Batch 11/12                         Loss D: 0.4421, loss G: -0.2395\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [66/200] Batch 11/12                         Loss D: -0.4551, loss G: -0.3134\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [67/200] Batch 11/12                         Loss D: -1.0492, loss G: -0.1435\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [68/200] Batch 11/12                         Loss D: -1.9895, loss G: -0.1978\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [69/200] Batch 11/12                         Loss D: -1.9434, loss G: -0.1224\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [70/200] Batch 11/12                         Loss D: -2.6834, loss G: -0.1133\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [71/200] Batch 11/12                         Loss D: -3.4250, loss G: -0.0049\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [72/200] Batch 11/12                         Loss D: -3.9328, loss G: 0.0324\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [73/200] Batch 11/12                         Loss D: -4.7310, loss G: 0.1127\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [74/200] Batch 11/12                         Loss D: -5.3563, loss G: 0.2551\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [75/200] Batch 11/12                         Loss D: -5.8123, loss G: 0.1687\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [76/200] Batch 11/12                         Loss D: -6.4355, loss G: 0.2641\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [77/200] Batch 11/12                         Loss D: -6.8759, loss G: 0.2937\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [78/200] Batch 11/12                         Loss D: -7.7400, loss G: 0.3715\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [79/200] Batch 11/12                         Loss D: -8.2512, loss G: 0.4820\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [80/200] Batch 11/12                         Loss D: -8.9423, loss G: 0.5193\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [81/200] Batch 11/12                         Loss D: -9.6480, loss G: 0.5382\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [82/200] Batch 11/12                         Loss D: -10.3049, loss G: 0.6483\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [83/200] Batch 11/12                         Loss D: -10.9951, loss G: 0.7378\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [84/200] Batch 11/12                         Loss D: -11.5582, loss G: 0.7421\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [85/200] Batch 11/12                         Loss D: -12.4211, loss G: 0.7343\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [86/200] Batch 11/12                         Loss D: -13.1702, loss G: 0.9758\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [87/200] Batch 11/12                         Loss D: -13.6749, loss G: 0.8307\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [88/200] Batch 11/12                         Loss D: -14.4578, loss G: 0.8923\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [89/200] Batch 11/12                         Loss D: -15.2508, loss G: 1.0827\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [90/200] Batch 11/12                         Loss D: -15.9422, loss G: 0.9966\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [91/200] Batch 11/12                         Loss D: -16.6710, loss G: 1.0611\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [92/200] Batch 11/12                         Loss D: -17.4924, loss G: 1.1270\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [93/200] Batch 11/12                         Loss D: -18.0509, loss G: 1.3002\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [94/200] Batch 11/12                         Loss D: -19.2592, loss G: 1.4432\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [95/200] Batch 11/12                         Loss D: -19.9743, loss G: 1.4332\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [96/200] Batch 11/12                         Loss D: -20.6075, loss G: 1.4085\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [97/200] Batch 11/12                         Loss D: -21.5053, loss G: 1.4662\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [98/200] Batch 11/12                         Loss D: -22.2444, loss G: 1.5599\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [99/200] Batch 11/12                         Loss D: -23.3541, loss G: 1.7394\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [100/200] Batch 11/12                         Loss D: -23.6705, loss G: 1.8996\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [101/200] Batch 11/12                         Loss D: -24.9086, loss G: 1.7611\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [102/200] Batch 11/12                         Loss D: -25.8920, loss G: 1.8696\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [103/200] Batch 11/12                         Loss D: -27.1382, loss G: 2.1891\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [104/200] Batch 11/12                         Loss D: -27.2466, loss G: 2.1803\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [105/200] Batch 11/12                         Loss D: -28.4832, loss G: 2.0837\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [106/200] Batch 11/12                         Loss D: -29.1820, loss G: 2.2835\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [107/200] Batch 11/12                         Loss D: -30.3077, loss G: 2.3180\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [108/200] Batch 11/12                         Loss D: -31.4174, loss G: 2.3149\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [109/200] Batch 11/12                         Loss D: -32.5106, loss G: 2.3932\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [110/200] Batch 11/12                         Loss D: -33.5554, loss G: 2.4548\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [111/200] Batch 11/12                         Loss D: -34.6281, loss G: 2.5519\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [112/200] Batch 11/12                         Loss D: -35.3339, loss G: 2.6699\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [113/200] Batch 11/12                         Loss D: -36.6907, loss G: 2.7207\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [114/200] Batch 11/12                         Loss D: -37.5608, loss G: 2.8102\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [115/200] Batch 11/12                         Loss D: -38.6035, loss G: 2.9888\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [116/200] Batch 11/12                         Loss D: -39.5746, loss G: 3.0251\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [117/200] Batch 11/12                         Loss D: -40.7755, loss G: 3.1664\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [118/200] Batch 11/12                         Loss D: -42.4835, loss G: 3.1999\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [119/200] Batch 11/12                         Loss D: -43.1388, loss G: 3.2592\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [120/200] Batch 11/12                         Loss D: -44.6036, loss G: 3.3286\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [121/200] Batch 11/12                         Loss D: -44.9712, loss G: 3.5308\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [122/200] Batch 11/12                         Loss D: -47.2773, loss G: 3.5087\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [123/200] Batch 11/12                         Loss D: -47.9565, loss G: 3.6835\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [124/200] Batch 11/12                         Loss D: -49.4774, loss G: 3.7550\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [125/200] Batch 11/12                         Loss D: -50.6414, loss G: 3.8784\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [126/200] Batch 11/12                         Loss D: -51.6886, loss G: 3.9223\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [127/200] Batch 11/12                         Loss D: -53.7535, loss G: 4.0548\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [128/200] Batch 11/12                         Loss D: -54.4413, loss G: 4.1139\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [129/200] Batch 11/12                         Loss D: -55.6073, loss G: 4.3138\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [130/200] Batch 11/12                         Loss D: -57.1883, loss G: 4.3309\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [131/200] Batch 11/12                         Loss D: -59.1593, loss G: 4.5438\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [132/200] Batch 11/12                         Loss D: -59.9298, loss G: 4.5699\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [133/200] Batch 11/12                         Loss D: -61.5957, loss G: 4.6733\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [134/200] Batch 11/12                         Loss D: -62.7965, loss G: 4.7751\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [135/200] Batch 11/12                         Loss D: -63.1122, loss G: 4.9046\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [136/200] Batch 11/12                         Loss D: -65.9060, loss G: 4.9882\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [137/200] Batch 11/12                         Loss D: -67.3680, loss G: 5.1680\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [138/200] Batch 11/12                         Loss D: -68.7657, loss G: 5.2420\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [139/200] Batch 11/12                         Loss D: -70.1172, loss G: 5.3391\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [140/200] Batch 11/12                         Loss D: -72.2016, loss G: 5.4488\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [141/200] Batch 11/12                         Loss D: -73.8290, loss G: 5.5777\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [142/200] Batch 11/12                         Loss D: -75.6592, loss G: 5.7396\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [143/200] Batch 11/12                         Loss D: -76.7738, loss G: 5.8036\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [144/200] Batch 11/12                         Loss D: -77.4940, loss G: 5.9826\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [145/200] Batch 11/12                         Loss D: -79.4733, loss G: 6.0640\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [146/200] Batch 11/12                         Loss D: -80.1367, loss G: 6.2448\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [147/200] Batch 11/12                         Loss D: -82.7436, loss G: 6.3137\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [148/200] Batch 11/12                         Loss D: -83.9216, loss G: 6.5006\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [149/200] Batch 11/12                         Loss D: -85.7779, loss G: 6.5852\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [150/200] Batch 11/12                         Loss D: -89.0774, loss G: 6.6884\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [151/200] Batch 11/12                         Loss D: -90.3361, loss G: 6.8335\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [152/200] Batch 11/12                         Loss D: -92.2310, loss G: 6.9682\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [153/200] Batch 11/12                         Loss D: -93.1210, loss G: 7.0887\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [154/200] Batch 11/12                         Loss D: -93.5492, loss G: 7.2228\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [155/200] Batch 11/12                         Loss D: -96.7852, loss G: 7.3489\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [156/200] Batch 11/12                         Loss D: -98.5948, loss G: 7.5015\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [157/200] Batch 11/12                         Loss D: -101.1338, loss G: 7.6043\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [158/200] Batch 11/12                         Loss D: -103.3761, loss G: 7.7279\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [159/200] Batch 11/12                         Loss D: -103.0055, loss G: 7.8580\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [160/200] Batch 11/12                         Loss D: -104.9986, loss G: 8.0129\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [161/200] Batch 11/12                         Loss D: -106.7050, loss G: 8.1485\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [162/200] Batch 11/12                         Loss D: -108.6845, loss G: 8.2869\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [163/200] Batch 11/12                         Loss D: -108.6753, loss G: 8.3701\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [164/200] Batch 11/12                         Loss D: -109.9367, loss G: 8.5504\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [165/200] Batch 11/12                         Loss D: -111.0350, loss G: 8.6427\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [166/200] Batch 11/12                         Loss D: -111.1020, loss G: 8.7372\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [167/200] Batch 11/12                         Loss D: -111.1001, loss G: 8.8628\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [168/200] Batch 11/12                         Loss D: -111.9406, loss G: 9.0199\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [169/200] Batch 11/12                         Loss D: -112.2771, loss G: 9.1332\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [170/200] Batch 11/12                         Loss D: -111.6908, loss G: 9.1919\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [171/200] Batch 11/12                         Loss D: -111.2453, loss G: 9.3434\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [172/200] Batch 11/12                         Loss D: -111.2421, loss G: 9.4099\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [173/200] Batch 11/12                         Loss D: -109.7502, loss G: 9.4756\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [174/200] Batch 11/12                         Loss D: -106.9347, loss G: 9.5152\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [175/200] Batch 11/12                         Loss D: -104.7953, loss G: 9.5900\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [176/200] Batch 11/12                         Loss D: -102.4176, loss G: 9.5871\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [177/200] Batch 11/12                         Loss D: -98.3184, loss G: 9.5895\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [178/200] Batch 11/12                         Loss D: -94.4517, loss G: 9.6125\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [179/200] Batch 11/12                         Loss D: -90.1277, loss G: 9.5844\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [180/200] Batch 11/12                         Loss D: -85.0459, loss G: 9.5601\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [181/200] Batch 11/12                         Loss D: -77.3409, loss G: 9.4588\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [182/200] Batch 11/12                         Loss D: -70.5695, loss G: 9.3682\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [183/200] Batch 11/12                         Loss D: -61.1488, loss G: 9.2210\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [184/200] Batch 11/12                         Loss D: -49.8156, loss G: 9.0009\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [185/200] Batch 11/12                         Loss D: -39.1001, loss G: 8.7822\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [186/200] Batch 11/12                         Loss D: -31.1254, loss G: 8.5215\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [187/200] Batch 11/12                         Loss D: -27.2849, loss G: 8.4621\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [188/200] Batch 11/12                         Loss D: -26.8258, loss G: 8.5011\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [189/200] Batch 11/12                         Loss D: -26.8712, loss G: 8.5241\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [190/200] Batch 11/12                         Loss D: -27.2282, loss G: 8.5504\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [191/200] Batch 11/12                         Loss D: -26.9411, loss G: 8.5652\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [192/200] Batch 11/12                         Loss D: -27.1203, loss G: 8.5673\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [193/200] Batch 11/12                         Loss D: -26.2008, loss G: 8.5834\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [194/200] Batch 11/12                         Loss D: -25.5476, loss G: 8.6376\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [195/200] Batch 11/12                         Loss D: -25.8644, loss G: 8.6304\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [196/200] Batch 11/12                         Loss D: -25.2079, loss G: 8.6880\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [197/200] Batch 11/12                         Loss D: -24.9635, loss G: 8.6816\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [198/200] Batch 11/12                         Loss D: -23.8903, loss G: 8.6757\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [199/200] Batch 11/12                         Loss D: -23.3227, loss G: 8.7338\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [0/200] Batch 11/12                         Loss D: 0.5707, loss G: 3.5729\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [1/200] Batch 11/12                         Loss D: 0.8945, loss G: 3.5414\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [2/200] Batch 11/12                         Loss D: 0.8798, loss G: 3.5226\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [3/200] Batch 11/12                         Loss D: 0.8753, loss G: 3.5053\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [4/200] Batch 11/12                         Loss D: 0.7236, loss G: 3.4908\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [5/200] Batch 11/12                         Loss D: 0.4818, loss G: 3.4792\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [6/200] Batch 11/12                         Loss D: 0.0641, loss G: 3.4653\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [7/200] Batch 11/12                         Loss D: -0.5288, loss G: 3.4516\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [8/200] Batch 11/12                         Loss D: -1.2460, loss G: 3.4410\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [9/200] Batch 11/12                         Loss D: -1.6922, loss G: 3.4334\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [10/200] Batch 11/12                         Loss D: -2.1841, loss G: 3.4267\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [11/200] Batch 11/12                         Loss D: -2.6355, loss G: 3.4253\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [12/200] Batch 11/12                         Loss D: -3.1083, loss G: 3.4443\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [13/200] Batch 11/12                         Loss D: -3.1086, loss G: 3.4622\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [14/200] Batch 11/12                         Loss D: -2.9972, loss G: 3.4753\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [15/200] Batch 11/12                         Loss D: -2.8062, loss G: 3.4867\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [16/200] Batch 11/12                         Loss D: -2.4988, loss G: 3.4938\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [17/200] Batch 11/12                         Loss D: -2.1417, loss G: 3.4969\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [18/200] Batch 11/12                         Loss D: -1.7012, loss G: 3.4992\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [19/200] Batch 11/12                         Loss D: -1.3464, loss G: 3.4970\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [20/200] Batch 11/12                         Loss D: -0.8500, loss G: 3.4938\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [21/200] Batch 11/12                         Loss D: -0.4394, loss G: 3.4907\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [22/200] Batch 11/12                         Loss D: 0.3367, loss G: 3.4843\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [23/200] Batch 11/12                         Loss D: 1.6169, loss G: 3.4802\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [24/200] Batch 11/12                         Loss D: 2.0504, loss G: 3.4803\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [25/200] Batch 11/12                         Loss D: 2.3851, loss G: 3.4775\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [26/200] Batch 11/12                         Loss D: 2.5948, loss G: 3.4776\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [27/200] Batch 11/12                         Loss D: 3.0398, loss G: 3.4757\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [28/200] Batch 11/12                         Loss D: 3.3439, loss G: 3.4766\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [29/200] Batch 11/12                         Loss D: 3.6983, loss G: 3.4779\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [30/200] Batch 11/12                         Loss D: 3.7721, loss G: 3.4745\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [31/200] Batch 11/12                         Loss D: 3.6457, loss G: 3.4748\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [32/200] Batch 11/12                         Loss D: 3.6063, loss G: 3.4731\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [33/200] Batch 11/12                         Loss D: 3.3675, loss G: 3.4737\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [34/200] Batch 11/12                         Loss D: 2.9931, loss G: 3.4740\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [35/200] Batch 11/12                         Loss D: 2.4822, loss G: 3.4722\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [36/200] Batch 11/12                         Loss D: 2.0427, loss G: 3.4742\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [37/200] Batch 11/12                         Loss D: 1.8214, loss G: 3.4720\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [38/200] Batch 11/12                         Loss D: 1.7123, loss G: 3.4710\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [39/200] Batch 11/12                         Loss D: 1.5752, loss G: 3.4715\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [40/200] Batch 11/12                         Loss D: 1.5211, loss G: 3.4707\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [41/200] Batch 11/12                         Loss D: 1.4282, loss G: 3.4718\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [42/200] Batch 11/12                         Loss D: 1.3270, loss G: 3.4703\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [43/200] Batch 11/12                         Loss D: 1.2405, loss G: 3.4697\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [44/200] Batch 11/12                         Loss D: 1.1435, loss G: 3.4703\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [45/200] Batch 11/12                         Loss D: 1.0659, loss G: 3.4692\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [46/200] Batch 11/12                         Loss D: 0.9262, loss G: 3.4713\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [47/200] Batch 11/12                         Loss D: 0.8344, loss G: 3.4688\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [48/200] Batch 11/12                         Loss D: 0.7516, loss G: 3.4695\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [49/200] Batch 11/12                         Loss D: 0.6163, loss G: 3.4681\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [50/200] Batch 11/12                         Loss D: 0.5311, loss G: 3.4679\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [51/200] Batch 11/12                         Loss D: 0.4289, loss G: 3.4679\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [52/200] Batch 11/12                         Loss D: 0.3027, loss G: 3.4687\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [53/200] Batch 11/12                         Loss D: 0.2042, loss G: 3.4705\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [54/200] Batch 11/12                         Loss D: 0.1770, loss G: 3.4686\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [55/200] Batch 11/12                         Loss D: 0.1149, loss G: 3.4686\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [56/200] Batch 11/12                         Loss D: 0.0340, loss G: 3.4673\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [57/200] Batch 11/12                         Loss D: 0.0268, loss G: 3.4682\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [58/200] Batch 11/12                         Loss D: -0.1248, loss G: 3.4679\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [59/200] Batch 11/12                         Loss D: -0.4879, loss G: 3.4647\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [60/200] Batch 11/12                         Loss D: -0.9372, loss G: 3.4644\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [61/200] Batch 11/12                         Loss D: -1.4328, loss G: 3.4642\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [62/200] Batch 11/12                         Loss D: -1.6820, loss G: 3.4650\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [63/200] Batch 11/12                         Loss D: -1.8702, loss G: 3.4675\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [64/200] Batch 11/12                         Loss D: -1.9413, loss G: 3.4750\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [65/200] Batch 11/12                         Loss D: -1.9783, loss G: 3.4791\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [66/200] Batch 11/12                         Loss D: -2.1972, loss G: 3.4849\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [67/200] Batch 11/12                         Loss D: -2.1883, loss G: 3.4905\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [68/200] Batch 11/12                         Loss D: -2.2774, loss G: 3.4979\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [69/200] Batch 11/12                         Loss D: -2.1403, loss G: 3.5040\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [70/200] Batch 11/12                         Loss D: -2.1249, loss G: 3.5118\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [71/200] Batch 11/12                         Loss D: -2.0622, loss G: 3.5143\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [72/200] Batch 11/12                         Loss D: -1.9362, loss G: 3.5197\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [73/200] Batch 11/12                         Loss D: -1.7461, loss G: 3.5199\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [74/200] Batch 11/12                         Loss D: -1.6432, loss G: 3.5213\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [75/200] Batch 11/12                         Loss D: -1.2917, loss G: 3.5214\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [76/200] Batch 11/12                         Loss D: -0.8524, loss G: 3.5199\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [77/200] Batch 11/12                         Loss D: -0.2755, loss G: 3.5192\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [78/200] Batch 11/12                         Loss D: 0.5207, loss G: 3.5193\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [79/200] Batch 11/12                         Loss D: 1.2624, loss G: 3.5162\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [80/200] Batch 11/12                         Loss D: 1.3052, loss G: 3.5159\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [81/200] Batch 11/12                         Loss D: 1.3199, loss G: 3.5155\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [82/200] Batch 11/12                         Loss D: 1.4451, loss G: 3.5133\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [83/200] Batch 11/12                         Loss D: 1.4308, loss G: 3.5124\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [84/200] Batch 11/12                         Loss D: 1.3864, loss G: 3.5108\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [85/200] Batch 11/12                         Loss D: 1.3185, loss G: 3.5098\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [86/200] Batch 11/12                         Loss D: 1.1720, loss G: 3.5095\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [87/200] Batch 11/12                         Loss D: 0.9375, loss G: 3.5094\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [88/200] Batch 11/12                         Loss D: 0.6441, loss G: 3.5076\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [89/200] Batch 11/12                         Loss D: 0.1401, loss G: 3.5074\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [90/200] Batch 11/12                         Loss D: -0.2421, loss G: 3.5058\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [91/200] Batch 11/12                         Loss D: -0.3418, loss G: 3.5053\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [92/200] Batch 11/12                         Loss D: -0.5151, loss G: 3.5062\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [93/200] Batch 11/12                         Loss D: -0.6134, loss G: 3.5036\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [94/200] Batch 11/12                         Loss D: -0.7443, loss G: 3.5026\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [95/200] Batch 11/12                         Loss D: -0.8559, loss G: 3.5029\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [96/200] Batch 11/12                         Loss D: -0.9649, loss G: 3.5012\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [97/200] Batch 11/12                         Loss D: -1.0304, loss G: 3.5011\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [98/200] Batch 11/12                         Loss D: -1.0218, loss G: 3.5001\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [99/200] Batch 11/12                         Loss D: -1.0235, loss G: 3.5003\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [100/200] Batch 11/12                         Loss D: -1.0612, loss G: 3.4996\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [101/200] Batch 11/12                         Loss D: -1.6375, loss G: 3.4882\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [102/200] Batch 11/12                         Loss D: -1.1700, loss G: 3.4803\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [103/200] Batch 11/12                         Loss D: -0.4935, loss G: 3.4736\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [104/200] Batch 11/12                         Loss D: 0.2031, loss G: 3.4729\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [105/200] Batch 11/12                         Loss D: 1.2221, loss G: 3.4756\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [106/200] Batch 11/12                         Loss D: 2.3885, loss G: 3.4863\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [107/200] Batch 11/12                         Loss D: 3.6908, loss G: 3.5024\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [108/200] Batch 11/12                         Loss D: 4.7077, loss G: 3.5230\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [109/200] Batch 11/12                         Loss D: 5.1584, loss G: 3.5439\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [110/200] Batch 11/12                         Loss D: 4.6727, loss G: 3.5637\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [111/200] Batch 11/12                         Loss D: 4.3272, loss G: 3.5801\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [112/200] Batch 11/12                         Loss D: 3.9480, loss G: 3.5882\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [113/200] Batch 11/12                         Loss D: 3.5136, loss G: 3.5921\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [114/200] Batch 11/12                         Loss D: 2.9153, loss G: 3.5936\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [115/200] Batch 11/12                         Loss D: 2.3243, loss G: 3.5916\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [116/200] Batch 11/12                         Loss D: 1.8076, loss G: 3.5872\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [117/200] Batch 11/12                         Loss D: 1.4111, loss G: 3.5802\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [118/200] Batch 11/12                         Loss D: 0.9224, loss G: 3.5773\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [119/200] Batch 11/12                         Loss D: 0.4325, loss G: 3.5766\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [120/200] Batch 11/12                         Loss D: 0.0380, loss G: 3.5772\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [121/200] Batch 11/12                         Loss D: 0.0001, loss G: 3.5768\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [122/200] Batch 11/12                         Loss D: 0.0120, loss G: 3.5768\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [123/200] Batch 11/12                         Loss D: 0.0382, loss G: 3.5761\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [124/200] Batch 11/12                         Loss D: 0.1814, loss G: 3.5733\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [125/200] Batch 11/12                         Loss D: 0.5239, loss G: 3.5693\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [126/200] Batch 11/12                         Loss D: 0.8921, loss G: 3.5655\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [127/200] Batch 11/12                         Loss D: 0.7160, loss G: 3.5649\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [128/200] Batch 11/12                         Loss D: 0.6232, loss G: 3.5640\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [129/200] Batch 11/12                         Loss D: 0.4493, loss G: 3.5636\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [130/200] Batch 11/12                         Loss D: 0.3322, loss G: 3.5638\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [131/200] Batch 11/12                         Loss D: 0.3510, loss G: 3.5624\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [132/200] Batch 11/12                         Loss D: 0.1300, loss G: 3.5621\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [133/200] Batch 11/12                         Loss D: 0.0149, loss G: 3.5618\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [134/200] Batch 11/12                         Loss D: -0.0838, loss G: 3.5612\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [135/200] Batch 11/12                         Loss D: -0.1834, loss G: 3.5622\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [136/200] Batch 11/12                         Loss D: -0.3319, loss G: 3.5602\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [137/200] Batch 11/12                         Loss D: -0.4606, loss G: 3.5602\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [138/200] Batch 11/12                         Loss D: -0.5306, loss G: 3.5590\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [139/200] Batch 11/12                         Loss D: -0.6865, loss G: 3.5583\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [140/200] Batch 11/12                         Loss D: -0.8001, loss G: 3.5580\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [141/200] Batch 11/12                         Loss D: -0.9081, loss G: 3.5577\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [142/200] Batch 11/12                         Loss D: -1.0318, loss G: 3.5568\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [143/200] Batch 11/12                         Loss D: -1.2007, loss G: 3.5569\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [144/200] Batch 11/12                         Loss D: -1.2852, loss G: 3.5563\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [145/200] Batch 11/12                         Loss D: -1.4178, loss G: 3.5558\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [146/200] Batch 11/12                         Loss D: -1.5289, loss G: 3.5550\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [147/200] Batch 11/12                         Loss D: -1.6800, loss G: 3.5546\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [148/200] Batch 11/12                         Loss D: -1.7388, loss G: 3.5533\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [149/200] Batch 11/12                         Loss D: -1.8357, loss G: 3.5529\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [150/200] Batch 11/12                         Loss D: -1.9431, loss G: 3.5530\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [151/200] Batch 11/12                         Loss D: -2.0734, loss G: 3.5525\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [152/200] Batch 11/12                         Loss D: -2.1420, loss G: 3.5518\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [153/200] Batch 11/12                         Loss D: -2.1620, loss G: 3.5510\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [154/200] Batch 11/12                         Loss D: -2.2377, loss G: 3.5497\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [155/200] Batch 11/12                         Loss D: -2.2684, loss G: 3.5496\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [156/200] Batch 11/12                         Loss D: -2.2441, loss G: 3.5484\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [157/200] Batch 11/12                         Loss D: -2.1842, loss G: 3.5494\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [158/200] Batch 11/12                         Loss D: -2.1765, loss G: 3.5470\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [159/200] Batch 11/12                         Loss D: -2.1463, loss G: 3.5469\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [160/200] Batch 11/12                         Loss D: -2.0604, loss G: 3.5485\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [161/200] Batch 11/12                         Loss D: -2.1264, loss G: 3.5380\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [162/200] Batch 11/12                         Loss D: 0.2335, loss G: 3.5136\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [163/200] Batch 11/12                         Loss D: 2.3532, loss G: 3.4965\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [164/200] Batch 11/12                         Loss D: 4.5676, loss G: 3.4786\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [165/200] Batch 11/12                         Loss D: 11.1720, loss G: 3.1268\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [166/200] Batch 11/12                         Loss D: 20.8606, loss G: 2.6100\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [167/200] Batch 11/12                         Loss D: 25.1471, loss G: 2.3259\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [168/200] Batch 11/12                         Loss D: 23.4452, loss G: 2.2667\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [169/200] Batch 11/12                         Loss D: 16.9778, loss G: 2.5623\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [170/200] Batch 11/12                         Loss D: 10.6292, loss G: 2.9270\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [171/200] Batch 11/12                         Loss D: 5.1852, loss G: 3.2160\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [172/200] Batch 11/12                         Loss D: -0.3978, loss G: 3.4828\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [173/200] Batch 11/12                         Loss D: -5.8111, loss G: 3.6794\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [174/200] Batch 11/12                         Loss D: -10.9434, loss G: 3.8111\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [175/200] Batch 11/12                         Loss D: -10.1508, loss G: 3.0268\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [176/200] Batch 11/12                         Loss D: -10.3450, loss G: 2.9621\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [177/200] Batch 11/12                         Loss D: -10.4777, loss G: 2.9445\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [178/200] Batch 11/12                         Loss D: -12.5783, loss G: 3.0349\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [179/200] Batch 11/12                         Loss D: -14.5086, loss G: 3.1446\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [180/200] Batch 11/12                         Loss D: -16.4278, loss G: 3.2448\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [181/200] Batch 11/12                         Loss D: -15.9876, loss G: 3.3376\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [182/200] Batch 11/12                         Loss D: -16.2220, loss G: 3.4020\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [183/200] Batch 11/12                         Loss D: -14.3117, loss G: 3.4492\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [184/200] Batch 11/12                         Loss D: -14.3920, loss G: 3.5018\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [185/200] Batch 11/12                         Loss D: -15.9563, loss G: 3.5792\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [186/200] Batch 11/12                         Loss D: -17.1393, loss G: 3.6518\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [187/200] Batch 11/12                         Loss D: -18.5037, loss G: 3.7192\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [188/200] Batch 11/12                         Loss D: -19.3449, loss G: 3.7788\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [189/200] Batch 11/12                         Loss D: -19.4356, loss G: 3.8300\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [190/200] Batch 11/12                         Loss D: -19.7235, loss G: 3.8743\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [191/200] Batch 11/12                         Loss D: -20.0234, loss G: 3.9134\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [192/200] Batch 11/12                         Loss D: -19.9910, loss G: 3.9464\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [193/200] Batch 11/12                         Loss D: -19.3139, loss G: 3.9636\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [194/200] Batch 11/12                         Loss D: -19.4586, loss G: 3.9889\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [195/200] Batch 11/12                         Loss D: -18.8583, loss G: 4.0038\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [196/200] Batch 11/12                         Loss D: -17.6179, loss G: 4.0062\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [197/200] Batch 11/12                         Loss D: -16.7842, loss G: 4.0069\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [198/200] Batch 11/12                         Loss D: -15.8332, loss G: 4.0078\n",
      "[lr_G=0.0001, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [199/200] Batch 11/12                         Loss D: -14.8883, loss G: 4.0044\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [0/200] Batch 11/12                         Loss D: 9.0479, loss G: 34.7509\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [1/200] Batch 11/12                         Loss D: 8.9929, loss G: 34.6363\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [2/200] Batch 11/12                         Loss D: 8.9292, loss G: 34.5199\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [3/200] Batch 11/12                         Loss D: 8.8714, loss G: 34.3805\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [4/200] Batch 11/12                         Loss D: 8.8131, loss G: 34.2326\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [5/200] Batch 11/12                         Loss D: 8.7582, loss G: 34.0571\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [6/200] Batch 11/12                         Loss D: 8.6838, loss G: 33.8522\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [7/200] Batch 11/12                         Loss D: 8.5356, loss G: 33.6164\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [8/200] Batch 11/12                         Loss D: 8.3763, loss G: 33.3482\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [9/200] Batch 11/12                         Loss D: 8.1742, loss G: 33.0382\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [10/200] Batch 11/12                         Loss D: 7.9121, loss G: 32.6979\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [11/200] Batch 11/12                         Loss D: 7.6220, loss G: 32.3152\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [12/200] Batch 11/12                         Loss D: 7.4368, loss G: 31.8856\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [13/200] Batch 11/12                         Loss D: 7.1627, loss G: 31.4348\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [14/200] Batch 11/12                         Loss D: 6.8900, loss G: 30.9358\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [15/200] Batch 11/12                         Loss D: 6.6445, loss G: 30.3825\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [16/200] Batch 11/12                         Loss D: 6.1769, loss G: 30.0317\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [17/200] Batch 11/12                         Loss D: 5.7758, loss G: 29.6928\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [18/200] Batch 11/12                         Loss D: 5.4165, loss G: 29.4260\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [19/200] Batch 11/12                         Loss D: 5.0244, loss G: 29.0271\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [20/200] Batch 11/12                         Loss D: 4.7969, loss G: 28.6735\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [21/200] Batch 11/12                         Loss D: 4.5021, loss G: 28.2614\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [22/200] Batch 11/12                         Loss D: 4.0738, loss G: 27.8402\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [23/200] Batch 11/12                         Loss D: 3.7890, loss G: 27.3318\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [24/200] Batch 11/12                         Loss D: 3.4948, loss G: 26.7755\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [25/200] Batch 11/12                         Loss D: 2.7894, loss G: 26.2702\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [26/200] Batch 11/12                         Loss D: 2.5253, loss G: 25.6827\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [27/200] Batch 11/12                         Loss D: 2.1092, loss G: 25.0264\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [28/200] Batch 11/12                         Loss D: 1.5010, loss G: 24.4843\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [29/200] Batch 11/12                         Loss D: 1.0015, loss G: 23.8317\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [30/200] Batch 11/12                         Loss D: 0.4747, loss G: 23.0243\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [31/200] Batch 11/12                         Loss D: -0.1753, loss G: 22.4614\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [32/200] Batch 11/12                         Loss D: -0.8795, loss G: 21.5186\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [33/200] Batch 11/12                         Loss D: -1.4568, loss G: 20.6146\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [34/200] Batch 11/12                         Loss D: -2.0217, loss G: 19.8285\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [35/200] Batch 11/12                         Loss D: -2.8235, loss G: 18.9575\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [36/200] Batch 11/12                         Loss D: -3.6926, loss G: 17.7255\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [37/200] Batch 11/12                         Loss D: -4.7221, loss G: 16.8882\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [38/200] Batch 11/12                         Loss D: -5.3398, loss G: 15.5167\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [39/200] Batch 11/12                         Loss D: -6.1504, loss G: 14.2041\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [40/200] Batch 11/12                         Loss D: -6.4798, loss G: 12.8509\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [41/200] Batch 11/12                         Loss D: -7.3982, loss G: 11.2612\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [42/200] Batch 11/12                         Loss D: -7.8048, loss G: 9.7221\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [43/200] Batch 11/12                         Loss D: -8.5759, loss G: 8.3622\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [44/200] Batch 11/12                         Loss D: -9.2734, loss G: 6.1977\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [45/200] Batch 11/12                         Loss D: -9.2872, loss G: 4.8127\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [46/200] Batch 11/12                         Loss D: -9.4183, loss G: 3.4945\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [47/200] Batch 11/12                         Loss D: -8.9867, loss G: 2.7566\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [48/200] Batch 11/12                         Loss D: -8.5124, loss G: 1.0039\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [49/200] Batch 11/12                         Loss D: -8.1853, loss G: 0.0042\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [50/200] Batch 11/12                         Loss D: -8.3242, loss G: -1.1684\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [51/200] Batch 11/12                         Loss D: -7.8576, loss G: -2.1539\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [52/200] Batch 11/12                         Loss D: -7.2217, loss G: -3.5511\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [53/200] Batch 11/12                         Loss D: -7.1929, loss G: -4.1895\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [54/200] Batch 11/12                         Loss D: -7.1390, loss G: -3.8345\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [55/200] Batch 11/12                         Loss D: -7.2849, loss G: -3.4670\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [56/200] Batch 11/12                         Loss D: -7.4606, loss G: -3.0649\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [57/200] Batch 11/12                         Loss D: -7.5621, loss G: -2.7722\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [58/200] Batch 11/12                         Loss D: -7.8670, loss G: -2.1588\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [59/200] Batch 11/12                         Loss D: -7.8338, loss G: -1.7797\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [60/200] Batch 11/12                         Loss D: -8.0010, loss G: -1.2983\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [61/200] Batch 11/12                         Loss D: -7.9863, loss G: -0.6793\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [62/200] Batch 11/12                         Loss D: -8.4060, loss G: -0.1356\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [63/200] Batch 11/12                         Loss D: -8.8346, loss G: 0.3673\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [64/200] Batch 11/12                         Loss D: -9.4047, loss G: 0.9542\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [65/200] Batch 11/12                         Loss D: -10.1714, loss G: 1.5619\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [66/200] Batch 11/12                         Loss D: -10.6006, loss G: 2.0830\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [67/200] Batch 11/12                         Loss D: -11.9393, loss G: 2.4999\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [68/200] Batch 11/12                         Loss D: -12.5563, loss G: 2.9707\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [69/200] Batch 11/12                         Loss D: -13.5736, loss G: 3.3821\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [70/200] Batch 11/12                         Loss D: -15.2679, loss G: 3.5215\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [71/200] Batch 11/12                         Loss D: -15.4295, loss G: 3.8062\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [72/200] Batch 11/12                         Loss D: -15.3493, loss G: 3.5832\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [73/200] Batch 11/12                         Loss D: -14.6226, loss G: 3.6946\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [74/200] Batch 11/12                         Loss D: -13.4037, loss G: 3.1719\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [75/200] Batch 11/12                         Loss D: -11.2392, loss G: 2.4062\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [76/200] Batch 11/12                         Loss D: -9.7381, loss G: 1.9591\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [77/200] Batch 11/12                         Loss D: -7.5503, loss G: 1.2560\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [78/200] Batch 11/12                         Loss D: -6.3774, loss G: 0.7208\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [79/200] Batch 11/12                         Loss D: -5.0613, loss G: -0.1267\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [80/200] Batch 11/12                         Loss D: -3.7976, loss G: -0.7293\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [81/200] Batch 11/12                         Loss D: -2.7572, loss G: -1.4414\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [82/200] Batch 11/12                         Loss D: -1.8043, loss G: -2.0619\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [83/200] Batch 11/12                         Loss D: -1.1208, loss G: -2.7543\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [84/200] Batch 11/12                         Loss D: 0.0149, loss G: -3.2841\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [85/200] Batch 11/12                         Loss D: 0.4372, loss G: -4.0868\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [86/200] Batch 11/12                         Loss D: 1.3862, loss G: -4.5708\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [87/200] Batch 11/12                         Loss D: 1.9420, loss G: -5.3566\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [88/200] Batch 11/12                         Loss D: 2.2806, loss G: -5.6886\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [89/200] Batch 11/12                         Loss D: 2.6727, loss G: -6.4686\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [90/200] Batch 11/12                         Loss D: 2.7210, loss G: -7.4303\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [91/200] Batch 11/12                         Loss D: 2.5691, loss G: -8.3743\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [92/200] Batch 11/12                         Loss D: 2.9831, loss G: -9.0979\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [93/200] Batch 11/12                         Loss D: 2.9276, loss G: -10.1904\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [94/200] Batch 11/12                         Loss D: 2.8325, loss G: -11.1566\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [95/200] Batch 11/12                         Loss D: 2.6775, loss G: -11.7509\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [96/200] Batch 11/12                         Loss D: 2.4338, loss G: -13.1587\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [97/200] Batch 11/12                         Loss D: 1.7110, loss G: -14.2455\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [98/200] Batch 11/12                         Loss D: 1.6541, loss G: -14.1306\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [99/200] Batch 11/12                         Loss D: 2.1106, loss G: -14.6685\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [100/200] Batch 11/12                         Loss D: 2.0831, loss G: -14.9198\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [101/200] Batch 11/12                         Loss D: 2.3788, loss G: -14.6794\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [102/200] Batch 11/12                         Loss D: 2.3212, loss G: -15.4432\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [103/200] Batch 11/12                         Loss D: 2.2770, loss G: -15.5484\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [104/200] Batch 11/12                         Loss D: 2.5229, loss G: -15.6608\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [105/200] Batch 11/12                         Loss D: 2.6505, loss G: -15.7725\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [106/200] Batch 11/12                         Loss D: 2.8240, loss G: -15.8303\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [107/200] Batch 11/12                         Loss D: 3.0321, loss G: -16.0614\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [108/200] Batch 11/12                         Loss D: 2.7345, loss G: -16.2120\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [109/200] Batch 11/12                         Loss D: 3.0524, loss G: -16.7043\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [110/200] Batch 11/12                         Loss D: 2.9796, loss G: -16.4505\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [111/200] Batch 11/12                         Loss D: 2.6735, loss G: -16.5180\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [112/200] Batch 11/12                         Loss D: 3.0244, loss G: -16.1490\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [113/200] Batch 11/12                         Loss D: 3.0430, loss G: -15.9623\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [114/200] Batch 11/12                         Loss D: 2.9114, loss G: -16.3644\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [115/200] Batch 11/12                         Loss D: 3.0664, loss G: -16.1722\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [116/200] Batch 11/12                         Loss D: 2.8590, loss G: -16.4487\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [117/200] Batch 11/12                         Loss D: 2.7972, loss G: -16.0825\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [118/200] Batch 11/12                         Loss D: 3.0854, loss G: -15.8973\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [119/200] Batch 11/12                         Loss D: 2.9431, loss G: -15.8661\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [120/200] Batch 11/12                         Loss D: 2.7320, loss G: -15.3641\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [121/200] Batch 11/12                         Loss D: 2.7862, loss G: -14.8978\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [122/200] Batch 11/12                         Loss D: 2.6425, loss G: -14.4222\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [123/200] Batch 11/12                         Loss D: 2.9404, loss G: -13.8269\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [124/200] Batch 11/12                         Loss D: 2.9208, loss G: -12.6506\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [125/200] Batch 11/12                         Loss D: 2.9321, loss G: -11.8300\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [126/200] Batch 11/12                         Loss D: 3.0012, loss G: -11.3201\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [127/200] Batch 11/12                         Loss D: 2.7749, loss G: -10.1510\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [128/200] Batch 11/12                         Loss D: 2.8961, loss G: -8.8172\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [129/200] Batch 11/12                         Loss D: 2.9589, loss G: -7.5459\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [130/200] Batch 11/12                         Loss D: 2.8996, loss G: -5.8610\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [131/200] Batch 11/12                         Loss D: 3.4626, loss G: -4.7699\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [132/200] Batch 11/12                         Loss D: 3.0238, loss G: -3.1037\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [133/200] Batch 11/12                         Loss D: 3.2592, loss G: -1.1834\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [134/200] Batch 11/12                         Loss D: 3.2560, loss G: 1.0917\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [135/200] Batch 11/12                         Loss D: 4.1147, loss G: 3.0838\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [136/200] Batch 11/12                         Loss D: 4.2940, loss G: 5.5189\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [137/200] Batch 11/12                         Loss D: 4.9379, loss G: 8.3809\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [138/200] Batch 11/12                         Loss D: 5.7774, loss G: 11.5587\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [139/200] Batch 11/12                         Loss D: 7.0698, loss G: 14.9500\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [140/200] Batch 11/12                         Loss D: 9.4784, loss G: 18.5720\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [141/200] Batch 11/12                         Loss D: 12.4603, loss G: 22.3937\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [142/200] Batch 11/12                         Loss D: 16.1317, loss G: 26.4993\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [143/200] Batch 11/12                         Loss D: 21.7774, loss G: 30.7174\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [144/200] Batch 11/12                         Loss D: 26.0930, loss G: 35.0753\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [145/200] Batch 11/12                         Loss D: 30.6264, loss G: 39.3943\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [146/200] Batch 11/12                         Loss D: 34.4039, loss G: 43.4894\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [147/200] Batch 11/12                         Loss D: 37.7863, loss G: 47.2475\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [148/200] Batch 11/12                         Loss D: 41.3186, loss G: 50.9332\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [149/200] Batch 11/12                         Loss D: 39.4252, loss G: 53.6987\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [150/200] Batch 11/12                         Loss D: 38.9217, loss G: 56.3970\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [151/200] Batch 11/12                         Loss D: 35.9250, loss G: 58.4658\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [152/200] Batch 11/12                         Loss D: 35.9304, loss G: 61.0044\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [153/200] Batch 11/12                         Loss D: 30.9000, loss G: 62.0340\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [154/200] Batch 11/12                         Loss D: 24.1864, loss G: 63.1713\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [155/200] Batch 11/12                         Loss D: 18.0893, loss G: 64.0249\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [156/200] Batch 11/12                         Loss D: 11.7430, loss G: 63.6820\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [157/200] Batch 11/12                         Loss D: 8.1181, loss G: 63.7268\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [158/200] Batch 11/12                         Loss D: 4.8236, loss G: 63.9276\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [159/200] Batch 11/12                         Loss D: 2.0745, loss G: 63.7462\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [160/200] Batch 11/12                         Loss D: -0.5279, loss G: 63.3739\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [161/200] Batch 11/12                         Loss D: -2.8018, loss G: 62.9485\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [162/200] Batch 11/12                         Loss D: -4.5492, loss G: 62.7845\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [163/200] Batch 11/12                         Loss D: -6.2491, loss G: 62.0091\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [164/200] Batch 11/12                         Loss D: -7.3110, loss G: 61.7772\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [165/200] Batch 11/12                         Loss D: -8.5542, loss G: 61.0598\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [166/200] Batch 11/12                         Loss D: -9.6751, loss G: 60.7053\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [167/200] Batch 11/12                         Loss D: -10.7728, loss G: 59.7621\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [168/200] Batch 11/12                         Loss D: -12.0034, loss G: 59.3321\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [169/200] Batch 11/12                         Loss D: -13.3614, loss G: 58.8195\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [170/200] Batch 11/12                         Loss D: -14.6113, loss G: 58.4958\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [171/200] Batch 11/12                         Loss D: -16.0541, loss G: 57.6705\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [172/200] Batch 11/12                         Loss D: -17.6331, loss G: 56.9950\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [173/200] Batch 11/12                         Loss D: -19.0444, loss G: 56.7719\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [174/200] Batch 11/12                         Loss D: -20.6285, loss G: 56.2543\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [175/200] Batch 11/12                         Loss D: -22.1487, loss G: 55.6710\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [176/200] Batch 11/12                         Loss D: -24.1339, loss G: 55.0238\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [177/200] Batch 11/12                         Loss D: -25.5808, loss G: 54.6734\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [178/200] Batch 11/12                         Loss D: -27.5365, loss G: 54.4091\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [179/200] Batch 11/12                         Loss D: -29.0166, loss G: 53.9939\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [180/200] Batch 11/12                         Loss D: -30.6321, loss G: 53.6273\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [181/200] Batch 11/12                         Loss D: -32.1712, loss G: 53.2154\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [182/200] Batch 11/12                         Loss D: -32.8752, loss G: 52.9076\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [183/200] Batch 11/12                         Loss D: -33.6588, loss G: 52.8581\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [184/200] Batch 11/12                         Loss D: -34.8510, loss G: 52.5151\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [185/200] Batch 11/12                         Loss D: -36.8494, loss G: 52.3088\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [186/200] Batch 11/12                         Loss D: -38.7943, loss G: 52.1315\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [187/200] Batch 11/12                         Loss D: -41.5923, loss G: 51.7571\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [188/200] Batch 11/12                         Loss D: -44.9055, loss G: 51.5237\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [189/200] Batch 11/12                         Loss D: -47.8723, loss G: 51.2920\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [190/200] Batch 11/12                         Loss D: -50.9192, loss G: 51.1470\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [191/200] Batch 11/12                         Loss D: -54.4558, loss G: 50.9993\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [192/200] Batch 11/12                         Loss D: -58.0427, loss G: 50.7126\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [193/200] Batch 11/12                         Loss D: -62.5699, loss G: 50.1756\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [194/200] Batch 11/12                         Loss D: -67.2655, loss G: 49.8688\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [195/200] Batch 11/12                         Loss D: -71.6277, loss G: 49.7435\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [196/200] Batch 11/12                         Loss D: -76.9281, loss G: 49.3722\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [197/200] Batch 11/12                         Loss D: -82.4473, loss G: 49.0026\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [198/200] Batch 11/12                         Loss D: -88.2165, loss G: 48.6961\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=1]                         Epoch [199/200] Batch 11/12                         Loss D: -94.4761, loss G: 48.2001\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [0/200] Batch 11/12                         Loss D: 8.2617, loss G: 17.6495\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [1/200] Batch 11/12                         Loss D: 8.1115, loss G: 17.6054\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [2/200] Batch 11/12                         Loss D: 7.9605, loss G: 17.5525\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [3/200] Batch 11/12                         Loss D: 7.7598, loss G: 17.4969\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [4/200] Batch 11/12                         Loss D: 7.5385, loss G: 17.4290\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [5/200] Batch 11/12                         Loss D: 7.2833, loss G: 17.3602\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [6/200] Batch 11/12                         Loss D: 6.9690, loss G: 17.2756\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [7/200] Batch 11/12                         Loss D: 6.5473, loss G: 17.1801\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [8/200] Batch 11/12                         Loss D: 6.0249, loss G: 17.0798\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [9/200] Batch 11/12                         Loss D: 5.3395, loss G: 16.9537\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [10/200] Batch 11/12                         Loss D: 4.3974, loss G: 16.8016\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [11/200] Batch 11/12                         Loss D: 3.2946, loss G: 16.6484\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [12/200] Batch 11/12                         Loss D: 2.0324, loss G: 16.4895\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [13/200] Batch 11/12                         Loss D: 0.5046, loss G: 16.3127\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [14/200] Batch 11/12                         Loss D: -1.3471, loss G: 16.1959\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [15/200] Batch 11/12                         Loss D: -3.5393, loss G: 16.1696\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [16/200] Batch 11/12                         Loss D: -5.8644, loss G: 16.1576\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [17/200] Batch 11/12                         Loss D: -8.5074, loss G: 16.1581\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [18/200] Batch 11/12                         Loss D: -11.0493, loss G: 16.1887\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [19/200] Batch 11/12                         Loss D: -14.2090, loss G: 16.1943\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [20/200] Batch 11/12                         Loss D: -17.4974, loss G: 16.2244\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [21/200] Batch 11/12                         Loss D: -20.6618, loss G: 16.2761\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [22/200] Batch 11/12                         Loss D: -23.9367, loss G: 16.3350\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [23/200] Batch 11/12                         Loss D: -26.8127, loss G: 16.4266\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [24/200] Batch 11/12                         Loss D: -29.4445, loss G: 16.5015\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [25/200] Batch 11/12                         Loss D: -31.9532, loss G: 16.5891\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [26/200] Batch 11/12                         Loss D: -33.6869, loss G: 16.6764\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [27/200] Batch 11/12                         Loss D: -35.6501, loss G: 16.7644\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [28/200] Batch 11/12                         Loss D: -37.7098, loss G: 16.8574\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [29/200] Batch 11/12                         Loss D: -38.9887, loss G: 16.9352\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [30/200] Batch 11/12                         Loss D: -39.8614, loss G: 17.0133\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [31/200] Batch 11/12                         Loss D: -40.5814, loss G: 17.0806\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [32/200] Batch 11/12                         Loss D: -41.1022, loss G: 17.1391\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [33/200] Batch 11/12                         Loss D: -40.3356, loss G: 17.1935\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [34/200] Batch 11/12                         Loss D: -40.7190, loss G: 17.2339\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [35/200] Batch 11/12                         Loss D: -39.8246, loss G: 17.2654\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [36/200] Batch 11/12                         Loss D: -38.4934, loss G: 17.2844\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [37/200] Batch 11/12                         Loss D: -36.4730, loss G: 17.3025\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [38/200] Batch 11/12                         Loss D: -35.3238, loss G: 17.3099\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [39/200] Batch 11/12                         Loss D: -33.2949, loss G: 17.3073\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [40/200] Batch 11/12                         Loss D: -30.2659, loss G: 17.2862\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [41/200] Batch 11/12                         Loss D: -27.1023, loss G: 17.2715\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [42/200] Batch 11/12                         Loss D: -22.0380, loss G: 17.1949\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [43/200] Batch 11/12                         Loss D: -14.3326, loss G: 16.9302\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [44/200] Batch 11/12                         Loss D: -6.5237, loss G: 16.5907\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [45/200] Batch 11/12                         Loss D: 1.4444, loss G: 16.3170\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [46/200] Batch 11/12                         Loss D: 8.2231, loss G: 16.1435\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [47/200] Batch 11/12                         Loss D: 8.6819, loss G: 16.2404\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [48/200] Batch 11/12                         Loss D: 8.4225, loss G: 16.3562\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [49/200] Batch 11/12                         Loss D: 9.2179, loss G: 16.4666\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [50/200] Batch 11/12                         Loss D: 9.5602, loss G: 16.5635\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [51/200] Batch 11/12                         Loss D: 8.9002, loss G: 16.6628\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [52/200] Batch 11/12                         Loss D: 7.5899, loss G: 16.7641\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [53/200] Batch 11/12                         Loss D: 6.1981, loss G: 16.8576\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [54/200] Batch 11/12                         Loss D: 4.4230, loss G: 16.9405\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [55/200] Batch 11/12                         Loss D: 2.5799, loss G: 17.0341\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [56/200] Batch 11/12                         Loss D: 0.7313, loss G: 17.0998\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [57/200] Batch 11/12                         Loss D: -1.3335, loss G: 17.1623\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [58/200] Batch 11/12                         Loss D: -3.4395, loss G: 17.2152\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [59/200] Batch 11/12                         Loss D: -5.9267, loss G: 17.2596\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [60/200] Batch 11/12                         Loss D: -7.9692, loss G: 17.3000\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [61/200] Batch 11/12                         Loss D: -10.2162, loss G: 17.3338\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [62/200] Batch 11/12                         Loss D: -12.5091, loss G: 17.3636\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [63/200] Batch 11/12                         Loss D: -14.6354, loss G: 17.3916\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [64/200] Batch 11/12                         Loss D: -15.4997, loss G: 17.4244\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [65/200] Batch 11/12                         Loss D: -16.0131, loss G: 17.4494\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [66/200] Batch 11/12                         Loss D: -16.3685, loss G: 17.4772\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [67/200] Batch 11/12                         Loss D: -16.3884, loss G: 17.5102\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [68/200] Batch 11/12                         Loss D: -16.1737, loss G: 17.5418\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [69/200] Batch 11/12                         Loss D: -15.9922, loss G: 17.5569\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [70/200] Batch 11/12                         Loss D: -15.6289, loss G: 17.5913\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [71/200] Batch 11/12                         Loss D: -14.8419, loss G: 17.5952\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [72/200] Batch 11/12                         Loss D: -13.7548, loss G: 17.6107\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [73/200] Batch 11/12                         Loss D: -12.7089, loss G: 17.6210\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [74/200] Batch 11/12                         Loss D: -10.8928, loss G: 17.6161\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [75/200] Batch 11/12                         Loss D: -8.9060, loss G: 17.6091\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [76/200] Batch 11/12                         Loss D: -6.6892, loss G: 17.5913\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [77/200] Batch 11/12                         Loss D: -3.6770, loss G: 17.5252\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [78/200] Batch 11/12                         Loss D: 0.5512, loss G: 17.4495\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [79/200] Batch 11/12                         Loss D: 3.6685, loss G: 17.4281\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [80/200] Batch 11/12                         Loss D: 4.2391, loss G: 17.4400\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [81/200] Batch 11/12                         Loss D: 4.2290, loss G: 17.4524\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [82/200] Batch 11/12                         Loss D: 4.3082, loss G: 17.4647\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [83/200] Batch 11/12                         Loss D: 4.1794, loss G: 17.4854\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [84/200] Batch 11/12                         Loss D: 4.0608, loss G: 17.4878\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [85/200] Batch 11/12                         Loss D: 4.0729, loss G: 17.5051\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [86/200] Batch 11/12                         Loss D: 4.0463, loss G: 17.5141\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [87/200] Batch 11/12                         Loss D: 4.0800, loss G: 17.5284\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [88/200] Batch 11/12                         Loss D: 3.9116, loss G: 17.5412\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [89/200] Batch 11/12                         Loss D: 3.9631, loss G: 17.5557\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [90/200] Batch 11/12                         Loss D: 3.8680, loss G: 17.5708\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [91/200] Batch 11/12                         Loss D: 3.8924, loss G: 17.5845\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [92/200] Batch 11/12                         Loss D: 3.6190, loss G: 17.5978\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [93/200] Batch 11/12                         Loss D: 3.7288, loss G: 17.6111\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [94/200] Batch 11/12                         Loss D: 3.6785, loss G: 17.6262\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [95/200] Batch 11/12                         Loss D: 3.7057, loss G: 17.6429\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [96/200] Batch 11/12                         Loss D: 3.5106, loss G: 17.6541\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [97/200] Batch 11/12                         Loss D: 3.5213, loss G: 17.6686\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [98/200] Batch 11/12                         Loss D: 3.3778, loss G: 17.6832\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [99/200] Batch 11/12                         Loss D: 3.2088, loss G: 17.6981\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [100/200] Batch 11/12                         Loss D: 3.1433, loss G: 17.7144\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [101/200] Batch 11/12                         Loss D: 3.0512, loss G: 17.7294\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [102/200] Batch 11/12                         Loss D: 2.8719, loss G: 17.7437\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [103/200] Batch 11/12                         Loss D: 2.7463, loss G: 17.7601\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [104/200] Batch 11/12                         Loss D: 2.5020, loss G: 17.7760\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [105/200] Batch 11/12                         Loss D: 2.4736, loss G: 17.7925\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [106/200] Batch 11/12                         Loss D: 2.1210, loss G: 17.8090\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [107/200] Batch 11/12                         Loss D: 1.9915, loss G: 17.8255\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [108/200] Batch 11/12                         Loss D: 1.8699, loss G: 17.8425\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [109/200] Batch 11/12                         Loss D: 1.6202, loss G: 17.8595\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [110/200] Batch 11/12                         Loss D: 1.3920, loss G: 17.8772\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [111/200] Batch 11/12                         Loss D: 1.2968, loss G: 17.8943\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [112/200] Batch 11/12                         Loss D: 1.0575, loss G: 17.9104\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [113/200] Batch 11/12                         Loss D: 0.8560, loss G: 17.9281\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [114/200] Batch 11/12                         Loss D: 0.5463, loss G: 17.9427\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [115/200] Batch 11/12                         Loss D: 0.3156, loss G: 17.9585\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [116/200] Batch 11/12                         Loss D: 0.0700, loss G: 17.9746\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [117/200] Batch 11/12                         Loss D: -0.1768, loss G: 17.9887\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [118/200] Batch 11/12                         Loss D: -0.3834, loss G: 18.0026\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [119/200] Batch 11/12                         Loss D: -0.7217, loss G: 18.0148\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [120/200] Batch 11/12                         Loss D: -1.0821, loss G: 18.0276\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [121/200] Batch 11/12                         Loss D: -1.3698, loss G: 18.0353\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [122/200] Batch 11/12                         Loss D: -1.6348, loss G: 18.0459\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [123/200] Batch 11/12                         Loss D: -1.7862, loss G: 18.0527\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [124/200] Batch 11/12                         Loss D: -1.9628, loss G: 18.0554\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [125/200] Batch 11/12                         Loss D: -2.1047, loss G: 18.0569\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [126/200] Batch 11/12                         Loss D: -2.1473, loss G: 18.0553\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [127/200] Batch 11/12                         Loss D: -1.8599, loss G: 18.0461\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [128/200] Batch 11/12                         Loss D: -1.1443, loss G: 18.0306\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [129/200] Batch 11/12                         Loss D: -0.0641, loss G: 18.0071\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [130/200] Batch 11/12                         Loss D: 1.1719, loss G: 17.9809\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [131/200] Batch 11/12                         Loss D: 1.1978, loss G: 17.9405\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [132/200] Batch 11/12                         Loss D: -0.6591, loss G: 17.9238\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [133/200] Batch 11/12                         Loss D: -2.1518, loss G: 17.9069\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [134/200] Batch 11/12                         Loss D: -2.8708, loss G: 17.9072\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [135/200] Batch 11/12                         Loss D: -3.6008, loss G: 17.9058\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [136/200] Batch 11/12                         Loss D: -4.3173, loss G: 17.9059\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [137/200] Batch 11/12                         Loss D: -4.9990, loss G: 17.9073\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [138/200] Batch 11/12                         Loss D: -5.6353, loss G: 17.9080\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [139/200] Batch 11/12                         Loss D: -6.3608, loss G: 17.9098\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [140/200] Batch 11/12                         Loss D: -6.9942, loss G: 17.9137\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [141/200] Batch 11/12                         Loss D: -9.0043, loss G: 17.8788\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [142/200] Batch 11/12                         Loss D: -10.1623, loss G: 17.8319\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [143/200] Batch 11/12                         Loss D: -10.4459, loss G: 17.8386\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [144/200] Batch 11/12                         Loss D: -10.7024, loss G: 17.8538\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [145/200] Batch 11/12                         Loss D: -11.3571, loss G: 17.8738\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [146/200] Batch 11/12                         Loss D: -11.9177, loss G: 17.8948\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [147/200] Batch 11/12                         Loss D: -12.6039, loss G: 17.9205\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [148/200] Batch 11/12                         Loss D: -13.3526, loss G: 17.9465\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [149/200] Batch 11/12                         Loss D: -14.4187, loss G: 17.9770\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [150/200] Batch 11/12                         Loss D: -15.5013, loss G: 18.0088\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [151/200] Batch 11/12                         Loss D: -16.5315, loss G: 18.0390\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [152/200] Batch 11/12                         Loss D: -17.7648, loss G: 18.0687\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [153/200] Batch 11/12                         Loss D: -18.9669, loss G: 18.0956\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [154/200] Batch 11/12                         Loss D: -19.8964, loss G: 18.1183\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [155/200] Batch 11/12                         Loss D: -20.4668, loss G: 18.1386\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [156/200] Batch 11/12                         Loss D: -19.9657, loss G: 18.1587\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [157/200] Batch 11/12                         Loss D: -18.7164, loss G: 18.1737\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [158/200] Batch 11/12                         Loss D: -17.0905, loss G: 18.1860\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [159/200] Batch 11/12                         Loss D: -16.0930, loss G: 18.2009\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [160/200] Batch 11/12                         Loss D: -15.6383, loss G: 18.2156\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [161/200] Batch 11/12                         Loss D: -15.4025, loss G: 18.2301\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [162/200] Batch 11/12                         Loss D: -15.1921, loss G: 18.2458\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [163/200] Batch 11/12                         Loss D: -14.7350, loss G: 18.2605\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [164/200] Batch 11/12                         Loss D: -14.4526, loss G: 18.2734\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [165/200] Batch 11/12                         Loss D: -13.6992, loss G: 18.2858\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [166/200] Batch 11/12                         Loss D: -11.8713, loss G: 18.2945\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [167/200] Batch 11/12                         Loss D: -5.9941, loss G: 18.2649\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [168/200] Batch 11/12                         Loss D: 1.5633, loss G: 18.2194\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [169/200] Batch 11/12                         Loss D: 1.8896, loss G: 18.2244\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [170/200] Batch 11/12                         Loss D: 1.8188, loss G: 18.2311\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [171/200] Batch 11/12                         Loss D: 1.6349, loss G: 18.2370\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [172/200] Batch 11/12                         Loss D: 1.5736, loss G: 18.2429\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [173/200] Batch 11/12                         Loss D: 1.5355, loss G: 18.2478\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [174/200] Batch 11/12                         Loss D: 1.4640, loss G: 18.2545\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [175/200] Batch 11/12                         Loss D: 1.2940, loss G: 18.2583\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [176/200] Batch 11/12                         Loss D: 1.2980, loss G: 18.2644\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [177/200] Batch 11/12                         Loss D: 1.1411, loss G: 18.2694\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [178/200] Batch 11/12                         Loss D: 1.1288, loss G: 18.2749\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [179/200] Batch 11/12                         Loss D: 1.0086, loss G: 18.2799\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [180/200] Batch 11/12                         Loss D: 1.0454, loss G: 18.2840\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [181/200] Batch 11/12                         Loss D: 0.9817, loss G: 18.2897\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [182/200] Batch 11/12                         Loss D: 0.8833, loss G: 18.2935\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [183/200] Batch 11/12                         Loss D: 0.7241, loss G: 18.2983\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [184/200] Batch 11/12                         Loss D: 0.6851, loss G: 18.3026\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [185/200] Batch 11/12                         Loss D: 0.6455, loss G: 18.3068\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [186/200] Batch 11/12                         Loss D: 0.5926, loss G: 18.3108\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [187/200] Batch 11/12                         Loss D: 0.4641, loss G: 18.3156\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [188/200] Batch 11/12                         Loss D: 0.3546, loss G: 18.3205\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [189/200] Batch 11/12                         Loss D: 0.3333, loss G: 18.3248\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [190/200] Batch 11/12                         Loss D: 0.3576, loss G: 18.3291\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [191/200] Batch 11/12                         Loss D: 0.2806, loss G: 18.3334\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [192/200] Batch 11/12                         Loss D: 0.1656, loss G: 18.3377\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [193/200] Batch 11/12                         Loss D: 0.1003, loss G: 18.3428\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [194/200] Batch 11/12                         Loss D: 0.1058, loss G: 18.3478\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [195/200] Batch 11/12                         Loss D: -0.0200, loss G: 18.3522\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [196/200] Batch 11/12                         Loss D: -0.1028, loss G: 18.3562\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [197/200] Batch 11/12                         Loss D: -0.0738, loss G: 18.3610\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [198/200] Batch 11/12                         Loss D: -0.2046, loss G: 18.3659\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.5]                         Epoch [199/200] Batch 11/12                         Loss D: -0.2756, loss G: 18.3710\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [0/200] Batch 11/12                         Loss D: 9.1926, loss G: 3.2397\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [1/200] Batch 11/12                         Loss D: 8.9635, loss G: 3.2308\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [2/200] Batch 11/12                         Loss D: 8.8023, loss G: 3.2214\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [3/200] Batch 11/12                         Loss D: 8.7368, loss G: 3.2118\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [4/200] Batch 11/12                         Loss D: 8.5014, loss G: 3.2007\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [5/200] Batch 11/12                         Loss D: 8.3183, loss G: 3.1890\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [6/200] Batch 11/12                         Loss D: 8.0389, loss G: 3.1758\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [7/200] Batch 11/12                         Loss D: 7.7195, loss G: 3.1612\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [8/200] Batch 11/12                         Loss D: 7.4392, loss G: 3.1458\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [9/200] Batch 11/12                         Loss D: 6.9323, loss G: 3.1268\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [10/200] Batch 11/12                         Loss D: 6.4077, loss G: 3.1054\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [11/200] Batch 11/12                         Loss D: 5.9490, loss G: 3.0862\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [12/200] Batch 11/12                         Loss D: 5.3595, loss G: 3.0661\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [13/200] Batch 11/12                         Loss D: 4.8831, loss G: 3.0466\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [14/200] Batch 11/12                         Loss D: 4.2708, loss G: 3.0257\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [15/200] Batch 11/12                         Loss D: 3.6290, loss G: 3.0036\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [16/200] Batch 11/12                         Loss D: 2.8027, loss G: 2.9718\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [17/200] Batch 11/12                         Loss D: 1.6458, loss G: 2.9288\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [18/200] Batch 11/12                         Loss D: 0.2982, loss G: 2.8939\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [19/200] Batch 11/12                         Loss D: -1.3085, loss G: 2.8639\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [20/200] Batch 11/12                         Loss D: -3.2099, loss G: 2.8400\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [21/200] Batch 11/12                         Loss D: -5.3622, loss G: 2.8265\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [22/200] Batch 11/12                         Loss D: -7.7809, loss G: 2.8169\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [23/200] Batch 11/12                         Loss D: -10.7791, loss G: 2.8006\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [24/200] Batch 11/12                         Loss D: -14.1204, loss G: 2.7854\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [25/200] Batch 11/12                         Loss D: -17.7934, loss G: 2.7770\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [26/200] Batch 11/12                         Loss D: -21.7048, loss G: 2.7750\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [27/200] Batch 11/12                         Loss D: -26.1993, loss G: 2.7768\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [28/200] Batch 11/12                         Loss D: -30.1076, loss G: 2.7971\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [29/200] Batch 11/12                         Loss D: -34.0650, loss G: 2.8090\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [30/200] Batch 11/12                         Loss D: -37.6936, loss G: 2.7910\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [31/200] Batch 11/12                         Loss D: -43.8279, loss G: 2.7407\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [32/200] Batch 11/12                         Loss D: -50.3106, loss G: 2.7531\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [33/200] Batch 11/12                         Loss D: -56.3140, loss G: 2.8264\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [34/200] Batch 11/12                         Loss D: -60.6272, loss G: 2.9294\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [35/200] Batch 11/12                         Loss D: -63.6171, loss G: 3.0400\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [36/200] Batch 11/12                         Loss D: -64.2912, loss G: 3.1549\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [37/200] Batch 11/12                         Loss D: -61.6340, loss G: 3.2874\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [38/200] Batch 11/12                         Loss D: -58.9820, loss G: 3.4243\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [39/200] Batch 11/12                         Loss D: -54.8195, loss G: 3.6227\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [40/200] Batch 11/12                         Loss D: -49.4167, loss G: 3.8179\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [41/200] Batch 11/12                         Loss D: -43.0114, loss G: 3.9939\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [42/200] Batch 11/12                         Loss D: -41.4337, loss G: 4.1457\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [43/200] Batch 11/12                         Loss D: -40.2481, loss G: 4.2952\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [44/200] Batch 11/12                         Loss D: -38.5030, loss G: 4.4078\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [45/200] Batch 11/12                         Loss D: -36.2189, loss G: 4.4804\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [46/200] Batch 11/12                         Loss D: -34.7706, loss G: 4.5505\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [47/200] Batch 11/12                         Loss D: -32.1653, loss G: 4.5611\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [48/200] Batch 11/12                         Loss D: -28.9959, loss G: 4.5267\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [49/200] Batch 11/12                         Loss D: -27.2000, loss G: 4.5122\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [50/200] Batch 11/12                         Loss D: -25.0763, loss G: 4.4643\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [51/200] Batch 11/12                         Loss D: -22.9228, loss G: 4.4115\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [52/200] Batch 11/12                         Loss D: -20.5325, loss G: 4.3306\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [53/200] Batch 11/12                         Loss D: -18.2674, loss G: 4.2498\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [54/200] Batch 11/12                         Loss D: -15.4594, loss G: 4.1414\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [55/200] Batch 11/12                         Loss D: -12.1570, loss G: 4.0243\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [56/200] Batch 11/12                         Loss D: -8.2439, loss G: 3.8891\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [57/200] Batch 11/12                         Loss D: 3.6302, loss G: 3.1787\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [58/200] Batch 11/12                         Loss D: 18.0872, loss G: 2.3937\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [59/200] Batch 11/12                         Loss D: 26.3302, loss G: 1.6844\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [60/200] Batch 11/12                         Loss D: 29.3752, loss G: 1.5655\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [61/200] Batch 11/12                         Loss D: 29.7807, loss G: 1.7617\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [62/200] Batch 11/12                         Loss D: 29.6996, loss G: 2.0025\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [63/200] Batch 11/12                         Loss D: 29.2963, loss G: 2.2445\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [64/200] Batch 11/12                         Loss D: 28.6604, loss G: 2.4148\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [65/200] Batch 11/12                         Loss D: 27.2341, loss G: 2.5209\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [66/200] Batch 11/12                         Loss D: 23.7059, loss G: 2.6206\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [67/200] Batch 11/12                         Loss D: 21.0616, loss G: 2.7687\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [68/200] Batch 11/12                         Loss D: 18.5760, loss G: 2.9168\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [69/200] Batch 11/12                         Loss D: 16.0626, loss G: 3.0666\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [70/200] Batch 11/12                         Loss D: 14.2165, loss G: 3.2122\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [71/200] Batch 11/12                         Loss D: 13.6438, loss G: 3.3331\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [72/200] Batch 11/12                         Loss D: 13.5948, loss G: 3.4288\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [73/200] Batch 11/12                         Loss D: 13.5725, loss G: 3.5174\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [74/200] Batch 11/12                         Loss D: 13.8468, loss G: 3.5882\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [75/200] Batch 11/12                         Loss D: 14.5132, loss G: 3.5780\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [76/200] Batch 11/12                         Loss D: 14.9175, loss G: 3.5425\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [77/200] Batch 11/12                         Loss D: 15.3432, loss G: 3.4721\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [78/200] Batch 11/12                         Loss D: 15.1317, loss G: 3.4241\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [79/200] Batch 11/12                         Loss D: 14.2757, loss G: 3.3661\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [80/200] Batch 11/12                         Loss D: 14.0429, loss G: 3.3198\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [81/200] Batch 11/12                         Loss D: 13.8208, loss G: 3.2673\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [82/200] Batch 11/12                         Loss D: 13.6890, loss G: 3.2328\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [83/200] Batch 11/12                         Loss D: 13.4964, loss G: 3.1886\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [84/200] Batch 11/12                         Loss D: 13.1971, loss G: 3.1438\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [85/200] Batch 11/12                         Loss D: 13.1620, loss G: 3.1031\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [86/200] Batch 11/12                         Loss D: 13.0282, loss G: 3.0584\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [87/200] Batch 11/12                         Loss D: 12.9176, loss G: 3.0311\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [88/200] Batch 11/12                         Loss D: 12.7645, loss G: 3.0054\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [89/200] Batch 11/12                         Loss D: 12.8967, loss G: 2.9742\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [90/200] Batch 11/12                         Loss D: 12.7736, loss G: 2.9416\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [91/200] Batch 11/12                         Loss D: 12.6875, loss G: 2.9141\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [92/200] Batch 11/12                         Loss D: 12.4763, loss G: 2.9044\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [93/200] Batch 11/12                         Loss D: 12.2521, loss G: 2.9009\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [94/200] Batch 11/12                         Loss D: 11.9845, loss G: 2.8962\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [95/200] Batch 11/12                         Loss D: 11.6808, loss G: 2.8909\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [96/200] Batch 11/12                         Loss D: 11.4353, loss G: 2.8844\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [97/200] Batch 11/12                         Loss D: 11.1288, loss G: 2.8775\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [98/200] Batch 11/12                         Loss D: 10.7824, loss G: 2.8678\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [99/200] Batch 11/12                         Loss D: 10.5413, loss G: 2.8645\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [100/200] Batch 11/12                         Loss D: 10.4989, loss G: 2.8590\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [101/200] Batch 11/12                         Loss D: 10.6640, loss G: 2.8524\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [102/200] Batch 11/12                         Loss D: 10.7475, loss G: 2.8455\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [103/200] Batch 11/12                         Loss D: 10.8810, loss G: 2.8369\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [104/200] Batch 11/12                         Loss D: 10.9619, loss G: 2.8271\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [105/200] Batch 11/12                         Loss D: 11.1583, loss G: 2.8143\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [106/200] Batch 11/12                         Loss D: 11.2420, loss G: 2.7991\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [107/200] Batch 11/12                         Loss D: 11.3144, loss G: 2.7854\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [108/200] Batch 11/12                         Loss D: 11.1736, loss G: 2.7747\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [109/200] Batch 11/12                         Loss D: 11.0905, loss G: 2.7630\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [110/200] Batch 11/12                         Loss D: 11.0363, loss G: 2.7585\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [111/200] Batch 11/12                         Loss D: 10.8533, loss G: 2.7532\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [112/200] Batch 11/12                         Loss D: 10.7121, loss G: 2.7558\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [113/200] Batch 11/12                         Loss D: 10.4889, loss G: 2.7500\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [114/200] Batch 11/12                         Loss D: 10.3032, loss G: 2.7500\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [115/200] Batch 11/12                         Loss D: 9.9386, loss G: 2.7600\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [116/200] Batch 11/12                         Loss D: 9.6619, loss G: 2.7630\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [117/200] Batch 11/12                         Loss D: 9.2403, loss G: 2.7693\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [118/200] Batch 11/12                         Loss D: 8.8436, loss G: 2.7781\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [119/200] Batch 11/12                         Loss D: 8.3829, loss G: 2.7879\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [120/200] Batch 11/12                         Loss D: 7.7787, loss G: 2.7985\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [121/200] Batch 11/12                         Loss D: 7.3186, loss G: 2.8248\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [122/200] Batch 11/12                         Loss D: 6.6547, loss G: 2.8404\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [123/200] Batch 11/12                         Loss D: 5.9788, loss G: 2.8644\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [124/200] Batch 11/12                         Loss D: 5.3666, loss G: 2.8954\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [125/200] Batch 11/12                         Loss D: 4.9604, loss G: 2.9269\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [126/200] Batch 11/12                         Loss D: 4.6744, loss G: 2.9523\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [127/200] Batch 11/12                         Loss D: 4.5511, loss G: 2.9700\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [128/200] Batch 11/12                         Loss D: 4.5860, loss G: 2.9827\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [129/200] Batch 11/12                         Loss D: 4.6800, loss G: 2.9915\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [130/200] Batch 11/12                         Loss D: 4.7378, loss G: 2.9987\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [131/200] Batch 11/12                         Loss D: 4.7735, loss G: 3.0045\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [132/200] Batch 11/12                         Loss D: 4.8200, loss G: 3.0056\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [133/200] Batch 11/12                         Loss D: 4.9980, loss G: 3.0076\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [134/200] Batch 11/12                         Loss D: 5.2128, loss G: 3.0026\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [135/200] Batch 11/12                         Loss D: 5.5602, loss G: 2.9962\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [136/200] Batch 11/12                         Loss D: 5.9471, loss G: 2.9888\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [137/200] Batch 11/12                         Loss D: 5.8602, loss G: 2.9955\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [138/200] Batch 11/12                         Loss D: 5.3693, loss G: 3.0120\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [139/200] Batch 11/12                         Loss D: 4.8008, loss G: 3.0259\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [140/200] Batch 11/12                         Loss D: 4.1953, loss G: 3.0419\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [141/200] Batch 11/12                         Loss D: 3.6061, loss G: 3.0629\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [142/200] Batch 11/12                         Loss D: 2.9560, loss G: 3.0844\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [143/200] Batch 11/12                         Loss D: 2.2358, loss G: 3.1065\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [144/200] Batch 11/12                         Loss D: 1.5635, loss G: 3.1324\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [145/200] Batch 11/12                         Loss D: 0.7875, loss G: 3.1589\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [146/200] Batch 11/12                         Loss D: 0.0319, loss G: 3.1883\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [147/200] Batch 11/12                         Loss D: -0.7014, loss G: 3.2208\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [148/200] Batch 11/12                         Loss D: -1.5043, loss G: 3.2535\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [149/200] Batch 11/12                         Loss D: -2.2915, loss G: 3.2884\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [150/200] Batch 11/12                         Loss D: -3.0629, loss G: 3.3249\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [151/200] Batch 11/12                         Loss D: -3.7496, loss G: 3.3623\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [152/200] Batch 11/12                         Loss D: -4.5467, loss G: 3.4005\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [153/200] Batch 11/12                         Loss D: -5.0987, loss G: 3.4234\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [154/200] Batch 11/12                         Loss D: -6.9085, loss G: 3.4468\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [155/200] Batch 11/12                         Loss D: -8.1769, loss G: 3.4837\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [156/200] Batch 11/12                         Loss D: -8.5533, loss G: 3.5298\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [157/200] Batch 11/12                         Loss D: -9.0104, loss G: 3.5770\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [158/200] Batch 11/12                         Loss D: -9.1410, loss G: 3.6179\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [159/200] Batch 11/12                         Loss D: -9.4590, loss G: 3.6607\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [160/200] Batch 11/12                         Loss D: -9.5140, loss G: 3.6964\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [161/200] Batch 11/12                         Loss D: -9.5597, loss G: 3.7268\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [162/200] Batch 11/12                         Loss D: -9.5097, loss G: 3.7545\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [163/200] Batch 11/12                         Loss D: -9.6328, loss G: 3.7843\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [164/200] Batch 11/12                         Loss D: -9.5919, loss G: 3.8080\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [165/200] Batch 11/12                         Loss D: -9.3239, loss G: 3.8193\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [166/200] Batch 11/12                         Loss D: -9.3725, loss G: 3.8403\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [167/200] Batch 11/12                         Loss D: -9.0796, loss G: 3.8463\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [168/200] Batch 11/12                         Loss D: -8.7770, loss G: 3.8510\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [169/200] Batch 11/12                         Loss D: -8.6513, loss G: 3.8598\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [170/200] Batch 11/12                         Loss D: -8.2295, loss G: 3.8534\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [171/200] Batch 11/12                         Loss D: -7.8553, loss G: 3.8478\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [172/200] Batch 11/12                         Loss D: -7.5613, loss G: 3.8443\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [173/200] Batch 11/12                         Loss D: -7.2046, loss G: 3.8361\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [174/200] Batch 11/12                         Loss D: -6.8656, loss G: 3.8269\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [175/200] Batch 11/12                         Loss D: -6.3722, loss G: 3.8074\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [176/200] Batch 11/12                         Loss D: -6.0191, loss G: 3.7967\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [177/200] Batch 11/12                         Loss D: -5.5570, loss G: 3.7782\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [178/200] Batch 11/12                         Loss D: -5.3056, loss G: 3.7670\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [179/200] Batch 11/12                         Loss D: -4.9220, loss G: 3.7459\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [180/200] Batch 11/12                         Loss D: -4.9152, loss G: 3.7350\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [181/200] Batch 11/12                         Loss D: -4.8161, loss G: 3.7198\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [182/200] Batch 11/12                         Loss D: -4.8803, loss G: 3.7033\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [183/200] Batch 11/12                         Loss D: -4.9962, loss G: 3.6937\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [184/200] Batch 11/12                         Loss D: -4.9723, loss G: 3.6771\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [185/200] Batch 11/12                         Loss D: -5.0461, loss G: 3.6624\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [186/200] Batch 11/12                         Loss D: -5.1633, loss G: 3.6480\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [187/200] Batch 11/12                         Loss D: -5.2766, loss G: 3.6311\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [188/200] Batch 11/12                         Loss D: -5.4131, loss G: 3.6171\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [189/200] Batch 11/12                         Loss D: -5.5021, loss G: 3.6025\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [190/200] Batch 11/12                         Loss D: -5.5904, loss G: 3.5864\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [191/200] Batch 11/12                         Loss D: -4.8412, loss G: 3.5719\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [192/200] Batch 11/12                         Loss D: -3.3339, loss G: 3.5569\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [193/200] Batch 11/12                         Loss D: -1.6502, loss G: 3.5421\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [194/200] Batch 11/12                         Loss D: 0.9977, loss G: 3.5259\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [195/200] Batch 11/12                         Loss D: 4.0302, loss G: 3.5106\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [196/200] Batch 11/12                         Loss D: 7.5066, loss G: 3.4929\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [197/200] Batch 11/12                         Loss D: 9.3113, loss G: 3.2662\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [198/200] Batch 11/12                         Loss D: 8.6080, loss G: 3.2081\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=10, lambda_mean=0.1]                         Epoch [199/200] Batch 11/12                         Loss D: 8.2402, loss G: 3.2083\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [0/200] Batch 11/12                         Loss D: 0.9472, loss G: 34.5392\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [1/200] Batch 11/12                         Loss D: 1.0439, loss G: 34.4222\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [2/200] Batch 11/12                         Loss D: 1.1279, loss G: 34.3060\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [3/200] Batch 11/12                         Loss D: 1.1622, loss G: 34.1932\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [4/200] Batch 11/12                         Loss D: 1.1501, loss G: 34.0554\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [5/200] Batch 11/12                         Loss D: 1.0531, loss G: 33.9011\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [6/200] Batch 11/12                         Loss D: 0.8423, loss G: 33.6994\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [7/200] Batch 11/12                         Loss D: 0.5168, loss G: 33.4996\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [8/200] Batch 11/12                         Loss D: 0.0460, loss G: 33.2299\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [9/200] Batch 11/12                         Loss D: -0.5850, loss G: 32.9509\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [10/200] Batch 11/12                         Loss D: -1.4242, loss G: 32.6460\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [11/200] Batch 11/12                         Loss D: -2.4915, loss G: 32.3316\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [12/200] Batch 11/12                         Loss D: -3.8827, loss G: 31.9867\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [13/200] Batch 11/12                         Loss D: -5.5442, loss G: 31.6645\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [14/200] Batch 11/12                         Loss D: -7.5193, loss G: 31.3529\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [15/200] Batch 11/12                         Loss D: -10.0595, loss G: 30.9857\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [16/200] Batch 11/12                         Loss D: -12.9918, loss G: 30.6549\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [17/200] Batch 11/12                         Loss D: -16.0382, loss G: 30.5481\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [18/200] Batch 11/12                         Loss D: -19.1230, loss G: 30.5124\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [19/200] Batch 11/12                         Loss D: -23.0016, loss G: 30.4008\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [20/200] Batch 11/12                         Loss D: -27.0335, loss G: 30.3444\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [21/200] Batch 11/12                         Loss D: -30.9798, loss G: 30.3770\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [22/200] Batch 11/12                         Loss D: -36.4023, loss G: 30.2992\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [23/200] Batch 11/12                         Loss D: -41.2045, loss G: 30.3310\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [24/200] Batch 11/12                         Loss D: -47.0434, loss G: 30.3614\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [25/200] Batch 11/12                         Loss D: -53.2384, loss G: 30.4121\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [26/200] Batch 11/12                         Loss D: -59.5415, loss G: 30.5192\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [27/200] Batch 11/12                         Loss D: -65.0067, loss G: 30.6858\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [28/200] Batch 11/12                         Loss D: -72.8903, loss G: 30.7713\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [29/200] Batch 11/12                         Loss D: -79.4941, loss G: 30.9582\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [30/200] Batch 11/12                         Loss D: -87.3190, loss G: 31.1601\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [31/200] Batch 11/12                         Loss D: -95.6260, loss G: 31.3714\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [32/200] Batch 11/12                         Loss D: -101.0594, loss G: 31.6525\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [33/200] Batch 11/12                         Loss D: -110.1974, loss G: 31.9161\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [34/200] Batch 11/12                         Loss D: -116.7502, loss G: 32.2017\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [35/200] Batch 11/12                         Loss D: -123.7098, loss G: 32.5059\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [36/200] Batch 11/12                         Loss D: -130.8746, loss G: 32.8329\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [37/200] Batch 11/12                         Loss D: -134.6463, loss G: 33.1322\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [38/200] Batch 11/12                         Loss D: -140.7890, loss G: 33.4463\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [39/200] Batch 11/12                         Loss D: -144.4690, loss G: 33.7249\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [40/200] Batch 11/12                         Loss D: -146.8734, loss G: 33.9874\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [41/200] Batch 11/12                         Loss D: -146.9968, loss G: 34.2096\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [42/200] Batch 11/12                         Loss D: -149.5888, loss G: 34.4388\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [43/200] Batch 11/12                         Loss D: -146.7290, loss G: 34.5827\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [44/200] Batch 11/12                         Loss D: -146.1890, loss G: 34.7203\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [45/200] Batch 11/12                         Loss D: -146.6306, loss G: 34.8661\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [46/200] Batch 11/12                         Loss D: -141.6762, loss G: 34.8980\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [47/200] Batch 11/12                         Loss D: -138.4830, loss G: 34.9559\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [48/200] Batch 11/12                         Loss D: -136.6136, loss G: 35.0451\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [49/200] Batch 11/12                         Loss D: -130.8949, loss G: 35.0258\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [50/200] Batch 11/12                         Loss D: -125.7641, loss G: 34.9915\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [51/200] Batch 11/12                         Loss D: -121.5159, loss G: 34.9735\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [52/200] Batch 11/12                         Loss D: -115.5599, loss G: 34.8812\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [53/200] Batch 11/12                         Loss D: -109.8580, loss G: 34.7895\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [54/200] Batch 11/12                         Loss D: -102.8053, loss G: 34.6553\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [55/200] Batch 11/12                         Loss D: -95.7993, loss G: 34.5020\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [56/200] Batch 11/12                         Loss D: -87.0238, loss G: 34.2930\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [57/200] Batch 11/12                         Loss D: -78.1178, loss G: 34.0695\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [58/200] Batch 11/12                         Loss D: -66.1274, loss G: 33.7565\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [59/200] Batch 11/12                         Loss D: -54.6316, loss G: 33.4457\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [60/200] Batch 11/12                         Loss D: -41.1492, loss G: 33.0844\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [61/200] Batch 11/12                         Loss D: -28.8168, loss G: 32.7705\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [62/200] Batch 11/12                         Loss D: -24.0246, loss G: 32.7685\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [63/200] Batch 11/12                         Loss D: -20.9135, loss G: 32.7527\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [64/200] Batch 11/12                         Loss D: -17.4356, loss G: 32.7430\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [65/200] Batch 11/12                         Loss D: -14.5727, loss G: 32.7280\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [66/200] Batch 11/12                         Loss D: -13.1152, loss G: 32.7336\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [67/200] Batch 11/12                         Loss D: -12.9142, loss G: 32.7423\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [68/200] Batch 11/12                         Loss D: -13.3567, loss G: 32.7588\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [69/200] Batch 11/12                         Loss D: -13.6165, loss G: 32.7542\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [70/200] Batch 11/12                         Loss D: -13.8957, loss G: 32.7621\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [71/200] Batch 11/12                         Loss D: -14.3736, loss G: 32.7781\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [72/200] Batch 11/12                         Loss D: -14.9193, loss G: 32.7805\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [73/200] Batch 11/12                         Loss D: -14.8574, loss G: 32.7877\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [74/200] Batch 11/12                         Loss D: -15.2995, loss G: 32.8141\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [75/200] Batch 11/12                         Loss D: -15.4543, loss G: 32.8098\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [76/200] Batch 11/12                         Loss D: -15.3812, loss G: 32.8194\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [77/200] Batch 11/12                         Loss D: -15.6128, loss G: 32.8179\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [78/200] Batch 11/12                         Loss D: -16.2827, loss G: 32.8300\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [79/200] Batch 11/12                         Loss D: -16.3699, loss G: 32.8372\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [80/200] Batch 11/12                         Loss D: -17.1243, loss G: 32.8508\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [81/200] Batch 11/12                         Loss D: -17.9069, loss G: 32.8473\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [82/200] Batch 11/12                         Loss D: -18.6611, loss G: 32.8509\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [83/200] Batch 11/12                         Loss D: -19.4118, loss G: 32.8630\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [84/200] Batch 11/12                         Loss D: -20.0069, loss G: 32.8794\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [85/200] Batch 11/12                         Loss D: -21.2172, loss G: 32.8775\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [86/200] Batch 11/12                         Loss D: -21.8075, loss G: 32.8784\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [87/200] Batch 11/12                         Loss D: -22.7808, loss G: 32.8862\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [88/200] Batch 11/12                         Loss D: -23.4746, loss G: 32.8986\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [89/200] Batch 11/12                         Loss D: -24.8127, loss G: 32.9405\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [90/200] Batch 11/12                         Loss D: -25.5082, loss G: 32.9113\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [91/200] Batch 11/12                         Loss D: -26.5047, loss G: 32.9186\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [92/200] Batch 11/12                         Loss D: -27.5136, loss G: 32.9148\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [93/200] Batch 11/12                         Loss D: -28.6694, loss G: 32.9325\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [94/200] Batch 11/12                         Loss D: -29.4826, loss G: 32.9486\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [95/200] Batch 11/12                         Loss D: -30.4843, loss G: 32.9498\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [96/200] Batch 11/12                         Loss D: -31.4798, loss G: 32.9932\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [97/200] Batch 11/12                         Loss D: -32.7495, loss G: 32.9761\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [98/200] Batch 11/12                         Loss D: -33.7677, loss G: 32.9933\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [99/200] Batch 11/12                         Loss D: -35.0090, loss G: 33.0170\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [100/200] Batch 11/12                         Loss D: -36.1301, loss G: 33.0347\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [101/200] Batch 11/12                         Loss D: -37.6958, loss G: 33.0360\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [102/200] Batch 11/12                         Loss D: -39.3174, loss G: 33.0616\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [103/200] Batch 11/12                         Loss D: -40.4299, loss G: 33.0989\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [104/200] Batch 11/12                         Loss D: -41.5610, loss G: 33.1051\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [105/200] Batch 11/12                         Loss D: -43.0566, loss G: 33.1197\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [106/200] Batch 11/12                         Loss D: -44.1881, loss G: 33.1322\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [107/200] Batch 11/12                         Loss D: -45.9097, loss G: 33.1561\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [108/200] Batch 11/12                         Loss D: -46.8689, loss G: 33.1857\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [109/200] Batch 11/12                         Loss D: -48.6084, loss G: 33.1983\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [110/200] Batch 11/12                         Loss D: -50.3751, loss G: 33.2365\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [111/200] Batch 11/12                         Loss D: -51.3660, loss G: 33.2538\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [112/200] Batch 11/12                         Loss D: -52.9963, loss G: 33.2748\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [113/200] Batch 11/12                         Loss D: -54.3254, loss G: 33.3082\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [114/200] Batch 11/12                         Loss D: -55.8324, loss G: 33.3326\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [115/200] Batch 11/12                         Loss D: -57.5990, loss G: 33.3559\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [116/200] Batch 11/12                         Loss D: -58.9489, loss G: 33.3932\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [117/200] Batch 11/12                         Loss D: -60.4448, loss G: 33.4243\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [118/200] Batch 11/12                         Loss D: -62.2812, loss G: 33.4627\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [119/200] Batch 11/12                         Loss D: -63.9020, loss G: 33.5055\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [120/200] Batch 11/12                         Loss D: -65.6247, loss G: 33.5471\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [121/200] Batch 11/12                         Loss D: -67.1284, loss G: 33.5865\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [122/200] Batch 11/12                         Loss D: -68.9094, loss G: 33.6267\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [123/200] Batch 11/12                         Loss D: -70.6604, loss G: 33.6632\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [124/200] Batch 11/12                         Loss D: -72.0125, loss G: 33.7047\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [125/200] Batch 11/12                         Loss D: -74.3440, loss G: 33.7394\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [126/200] Batch 11/12                         Loss D: -75.9464, loss G: 33.7802\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [127/200] Batch 11/12                         Loss D: -77.7362, loss G: 33.8175\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [128/200] Batch 11/12                         Loss D: -79.9912, loss G: 33.8580\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [129/200] Batch 11/12                         Loss D: -81.7393, loss G: 33.9002\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [130/200] Batch 11/12                         Loss D: -83.1635, loss G: 33.9478\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [131/200] Batch 11/12                         Loss D: -84.5719, loss G: 33.9905\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [132/200] Batch 11/12                         Loss D: -86.7000, loss G: 34.0311\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [133/200] Batch 11/12                         Loss D: -88.4646, loss G: 34.0723\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [134/200] Batch 11/12                         Loss D: -89.9551, loss G: 34.1155\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [135/200] Batch 11/12                         Loss D: -92.3119, loss G: 34.1541\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [136/200] Batch 11/12                         Loss D: -94.0536, loss G: 34.1966\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [137/200] Batch 11/12                         Loss D: -95.1567, loss G: 34.2421\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [138/200] Batch 11/12                         Loss D: -97.3630, loss G: 34.2809\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [139/200] Batch 11/12                         Loss D: -99.5838, loss G: 34.3211\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [140/200] Batch 11/12                         Loss D: -101.0763, loss G: 34.3641\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [141/200] Batch 11/12                         Loss D: -103.3539, loss G: 34.4064\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [142/200] Batch 11/12                         Loss D: -104.5595, loss G: 34.4486\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [143/200] Batch 11/12                         Loss D: -107.0348, loss G: 34.4911\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [144/200] Batch 11/12                         Loss D: -108.9571, loss G: 34.5325\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [145/200] Batch 11/12                         Loss D: -110.1469, loss G: 34.5725\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [146/200] Batch 11/12                         Loss D: -110.8411, loss G: 34.6124\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [147/200] Batch 11/12                         Loss D: -112.4631, loss G: 34.6515\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [148/200] Batch 11/12                         Loss D: -114.5217, loss G: 34.6925\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [149/200] Batch 11/12                         Loss D: -113.4293, loss G: 34.7242\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [150/200] Batch 11/12                         Loss D: -115.0526, loss G: 34.7602\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [151/200] Batch 11/12                         Loss D: -115.0755, loss G: 34.7918\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [152/200] Batch 11/12                         Loss D: -114.8397, loss G: 34.8203\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [153/200] Batch 11/12                         Loss D: -115.5294, loss G: 34.8494\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [154/200] Batch 11/12                         Loss D: -115.0061, loss G: 34.8755\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [155/200] Batch 11/12                         Loss D: -113.1639, loss G: 34.8934\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [156/200] Batch 11/12                         Loss D: -111.9452, loss G: 34.9123\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [157/200] Batch 11/12                         Loss D: -110.3050, loss G: 34.9257\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [158/200] Batch 11/12                         Loss D: -107.1862, loss G: 34.9333\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [159/200] Batch 11/12                         Loss D: -102.6065, loss G: 34.9332\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [160/200] Batch 11/12                         Loss D: -99.0367, loss G: 34.9320\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [161/200] Batch 11/12                         Loss D: -94.3719, loss G: 34.9219\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [162/200] Batch 11/12                         Loss D: -89.5447, loss G: 34.9102\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [163/200] Batch 11/12                         Loss D: -81.3334, loss G: 34.8796\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [164/200] Batch 11/12                         Loss D: -71.4922, loss G: 34.8482\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [165/200] Batch 11/12                         Loss D: -59.6573, loss G: 34.8165\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [166/200] Batch 11/12                         Loss D: -44.7738, loss G: 34.7737\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [167/200] Batch 11/12                         Loss D: 52.4746, loss G: 29.6130\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [168/200] Batch 11/12                         Loss D: 197.6834, loss G: 18.3301\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [169/200] Batch 11/12                         Loss D: 312.6911, loss G: 8.7132\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [170/200] Batch 11/12                         Loss D: 414.2040, loss G: -0.8275\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [171/200] Batch 11/12                         Loss D: 483.7809, loss G: -8.7967\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [172/200] Batch 11/12                         Loss D: 542.3890, loss G: -17.0699\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [173/200] Batch 11/12                         Loss D: 560.4464, loss G: -23.1218\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [174/200] Batch 11/12                         Loss D: 567.3710, loss G: -29.8759\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [175/200] Batch 11/12                         Loss D: 528.9976, loss G: -33.7674\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [176/200] Batch 11/12                         Loss D: 474.3101, loss G: -38.0463\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [177/200] Batch 11/12                         Loss D: 366.8823, loss G: -37.5307\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [178/200] Batch 11/12                         Loss D: 274.9251, loss G: -36.6325\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [179/200] Batch 11/12                         Loss D: 186.3619, loss G: -35.6245\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [180/200] Batch 11/12                         Loss D: 95.8167, loss G: -34.0827\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [181/200] Batch 11/12                         Loss D: -12.9326, loss G: -31.8410\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [182/200] Batch 11/12                         Loss D: -129.1165, loss G: -28.8793\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [183/200] Batch 11/12                         Loss D: -249.5070, loss G: -25.3908\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [184/200] Batch 11/12                         Loss D: -381.1959, loss G: -21.3829\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [185/200] Batch 11/12                         Loss D: -509.7285, loss G: -16.6752\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [186/200] Batch 11/12                         Loss D: -633.0203, loss G: -11.9211\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [187/200] Batch 11/12                         Loss D: -730.2310, loss G: -6.5974\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [188/200] Batch 11/12                         Loss D: -821.7250, loss G: -2.1240\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [189/200] Batch 11/12                         Loss D: -868.9120, loss G: 3.1244\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [190/200] Batch 11/12                         Loss D: -903.8728, loss G: 7.5599\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [191/200] Batch 11/12                         Loss D: -928.2194, loss G: 14.1503\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [192/200] Batch 11/12                         Loss D: -954.7582, loss G: 22.1195\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [193/200] Batch 11/12                         Loss D: -947.2509, loss G: 29.0740\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [194/200] Batch 11/12                         Loss D: -906.7949, loss G: 35.0008\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [195/200] Batch 11/12                         Loss D: -856.3893, loss G: 39.9697\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [196/200] Batch 11/12                         Loss D: -770.3908, loss G: 43.9925\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [197/200] Batch 11/12                         Loss D: -684.3959, loss G: 47.4731\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [198/200] Batch 11/12                         Loss D: -571.2286, loss G: 50.2232\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=1]                         Epoch [199/200] Batch 11/12                         Loss D: -454.5574, loss G: 52.2134\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [0/200] Batch 11/12                         Loss D: 0.7654, loss G: 17.6527\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [1/200] Batch 11/12                         Loss D: 0.7878, loss G: 17.6057\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [2/200] Batch 11/12                         Loss D: 0.7512, loss G: 17.5534\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [3/200] Batch 11/12                         Loss D: 0.6717, loss G: 17.5001\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [4/200] Batch 11/12                         Loss D: 0.5290, loss G: 17.4437\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [5/200] Batch 11/12                         Loss D: 0.3415, loss G: 17.3766\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [6/200] Batch 11/12                         Loss D: 0.0821, loss G: 17.3022\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [7/200] Batch 11/12                         Loss D: -0.3146, loss G: 17.2235\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [8/200] Batch 11/12                         Loss D: -0.9242, loss G: 17.1423\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [9/200] Batch 11/12                         Loss D: -1.6946, loss G: 17.0633\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [10/200] Batch 11/12                         Loss D: -2.4416, loss G: 16.9769\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [11/200] Batch 11/12                         Loss D: -3.2353, loss G: 16.8858\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [12/200] Batch 11/12                         Loss D: -4.1914, loss G: 16.8015\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [13/200] Batch 11/12                         Loss D: -5.3146, loss G: 16.7103\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [14/200] Batch 11/12                         Loss D: -6.5106, loss G: 16.6370\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [15/200] Batch 11/12                         Loss D: -7.7904, loss G: 16.5944\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [16/200] Batch 11/12                         Loss D: -9.6166, loss G: 16.5230\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [17/200] Batch 11/12                         Loss D: -11.3354, loss G: 16.4902\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [18/200] Batch 11/12                         Loss D: -13.2442, loss G: 16.4435\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [19/200] Batch 11/12                         Loss D: -14.4921, loss G: 16.4530\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [20/200] Batch 11/12                         Loss D: -15.8145, loss G: 16.4226\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [21/200] Batch 11/12                         Loss D: -17.6508, loss G: 16.4171\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [22/200] Batch 11/12                         Loss D: -19.5133, loss G: 16.4182\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [23/200] Batch 11/12                         Loss D: -21.3058, loss G: 16.4523\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [24/200] Batch 11/12                         Loss D: -23.8486, loss G: 16.4724\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [25/200] Batch 11/12                         Loss D: -26.7487, loss G: 16.4948\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [26/200] Batch 11/12                         Loss D: -28.9083, loss G: 16.5669\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [27/200] Batch 11/12                         Loss D: -31.6492, loss G: 16.6272\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [28/200] Batch 11/12                         Loss D: -34.6884, loss G: 16.6950\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [29/200] Batch 11/12                         Loss D: -37.3064, loss G: 16.7900\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [30/200] Batch 11/12                         Loss D: -40.2036, loss G: 16.8934\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [31/200] Batch 11/12                         Loss D: -43.6328, loss G: 16.9986\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [32/200] Batch 11/12                         Loss D: -45.6647, loss G: 17.0734\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [33/200] Batch 11/12                         Loss D: -48.0950, loss G: 17.1647\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [34/200] Batch 11/12                         Loss D: -50.6780, loss G: 17.2811\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [35/200] Batch 11/12                         Loss D: -54.1025, loss G: 17.4200\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [36/200] Batch 11/12                         Loss D: -56.5234, loss G: 17.5783\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [37/200] Batch 11/12                         Loss D: -59.7115, loss G: 17.7480\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [38/200] Batch 11/12                         Loss D: -61.2084, loss G: 17.9207\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [39/200] Batch 11/12                         Loss D: -63.3476, loss G: 18.1027\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [40/200] Batch 11/12                         Loss D: -64.6722, loss G: 18.2853\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [41/200] Batch 11/12                         Loss D: -66.3717, loss G: 18.4797\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [42/200] Batch 11/12                         Loss D: -65.9554, loss G: 18.5886\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [43/200] Batch 11/12                         Loss D: -66.0016, loss G: 18.7174\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [44/200] Batch 11/12                         Loss D: -64.8672, loss G: 18.8137\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [45/200] Batch 11/12                         Loss D: -63.9061, loss G: 18.8905\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [46/200] Batch 11/12                         Loss D: -61.8429, loss G: 18.9330\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [47/200] Batch 11/12                         Loss D: -59.8691, loss G: 18.9648\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [48/200] Batch 11/12                         Loss D: -58.0425, loss G: 18.9857\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [49/200] Batch 11/12                         Loss D: -55.1248, loss G: 18.9643\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [50/200] Batch 11/12                         Loss D: -52.7675, loss G: 18.9506\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [51/200] Batch 11/12                         Loss D: -51.0828, loss G: 18.9426\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [52/200] Batch 11/12                         Loss D: -48.9507, loss G: 18.9113\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [53/200] Batch 11/12                         Loss D: -46.7794, loss G: 18.8754\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [54/200] Batch 11/12                         Loss D: -42.8728, loss G: 18.7990\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [55/200] Batch 11/12                         Loss D: -39.0146, loss G: 18.7301\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [56/200] Batch 11/12                         Loss D: -33.9566, loss G: 18.6382\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [57/200] Batch 11/12                         Loss D: -26.5383, loss G: 18.4986\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [58/200] Batch 11/12                         Loss D: -15.5721, loss G: 18.2713\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [59/200] Batch 11/12                         Loss D: 1.0679, loss G: 17.3664\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [60/200] Batch 11/12                         Loss D: 3.3326, loss G: 16.6999\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [61/200] Batch 11/12                         Loss D: 4.3786, loss G: 16.5400\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [62/200] Batch 11/12                         Loss D: 5.4561, loss G: 16.4730\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [63/200] Batch 11/12                         Loss D: 5.5482, loss G: 16.5854\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [64/200] Batch 11/12                         Loss D: 5.2044, loss G: 16.7767\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [65/200] Batch 11/12                         Loss D: 3.3306, loss G: 17.0839\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [66/200] Batch 11/12                         Loss D: 0.0329, loss G: 17.4544\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [67/200] Batch 11/12                         Loss D: -3.9230, loss G: 17.8416\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [68/200] Batch 11/12                         Loss D: -7.8986, loss G: 18.2037\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [69/200] Batch 11/12                         Loss D: -11.0568, loss G: 18.4923\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [70/200] Batch 11/12                         Loss D: -12.9043, loss G: 18.6771\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [71/200] Batch 11/12                         Loss D: -13.8068, loss G: 18.7742\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [72/200] Batch 11/12                         Loss D: -13.3838, loss G: 18.7660\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [73/200] Batch 11/12                         Loss D: -11.9104, loss G: 18.6749\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [74/200] Batch 11/12                         Loss D: -9.9013, loss G: 18.5213\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [75/200] Batch 11/12                         Loss D: -9.5361, loss G: 18.3458\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [76/200] Batch 11/12                         Loss D: -9.9162, loss G: 18.1487\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [77/200] Batch 11/12                         Loss D: -9.9780, loss G: 17.9081\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [78/200] Batch 11/12                         Loss D: -10.6114, loss G: 17.8784\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [79/200] Batch 11/12                         Loss D: -11.3888, loss G: 17.8697\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [80/200] Batch 11/12                         Loss D: -11.8579, loss G: 17.8660\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [81/200] Batch 11/12                         Loss D: -12.6627, loss G: 17.8571\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [82/200] Batch 11/12                         Loss D: -13.5160, loss G: 17.8476\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [83/200] Batch 11/12                         Loss D: -14.1901, loss G: 17.8427\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [84/200] Batch 11/12                         Loss D: -15.0087, loss G: 17.8403\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [85/200] Batch 11/12                         Loss D: -15.6748, loss G: 17.8415\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [86/200] Batch 11/12                         Loss D: -16.3628, loss G: 17.8419\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [87/200] Batch 11/12                         Loss D: -17.0366, loss G: 17.8462\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [88/200] Batch 11/12                         Loss D: -17.5284, loss G: 17.8528\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [89/200] Batch 11/12                         Loss D: -18.4581, loss G: 17.8605\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [90/200] Batch 11/12                         Loss D: -19.4058, loss G: 17.8744\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [91/200] Batch 11/12                         Loss D: -19.9354, loss G: 17.8952\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [92/200] Batch 11/12                         Loss D: -20.4049, loss G: 17.9175\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [93/200] Batch 11/12                         Loss D: -20.5284, loss G: 17.9383\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [94/200] Batch 11/12                         Loss D: -20.6598, loss G: 17.9616\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [95/200] Batch 11/12                         Loss D: -20.0700, loss G: 17.9770\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [96/200] Batch 11/12                         Loss D: -20.2227, loss G: 17.9947\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [97/200] Batch 11/12                         Loss D: -19.7721, loss G: 18.0097\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [98/200] Batch 11/12                         Loss D: -19.4664, loss G: 18.0229\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [99/200] Batch 11/12                         Loss D: -19.1707, loss G: 18.0345\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [100/200] Batch 11/12                         Loss D: -18.9992, loss G: 18.0471\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [101/200] Batch 11/12                         Loss D: -18.4127, loss G: 18.0572\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [102/200] Batch 11/12                         Loss D: -18.0824, loss G: 18.0680\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [103/200] Batch 11/12                         Loss D: -17.9940, loss G: 18.0781\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [104/200] Batch 11/12                         Loss D: -17.7649, loss G: 18.0878\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [105/200] Batch 11/12                         Loss D: -17.2553, loss G: 18.0965\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [106/200] Batch 11/12                         Loss D: -17.3818, loss G: 18.1065\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [107/200] Batch 11/12                         Loss D: -16.7400, loss G: 18.1138\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [108/200] Batch 11/12                         Loss D: -16.7084, loss G: 18.1222\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [109/200] Batch 11/12                         Loss D: -16.3889, loss G: 18.1303\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [110/200] Batch 11/12                         Loss D: -16.3880, loss G: 18.1381\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [111/200] Batch 11/12                         Loss D: -15.9459, loss G: 18.1451\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [112/200] Batch 11/12                         Loss D: -15.7187, loss G: 18.1514\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [113/200] Batch 11/12                         Loss D: -15.4479, loss G: 18.1583\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [114/200] Batch 11/12                         Loss D: -15.0510, loss G: 18.1657\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [115/200] Batch 11/12                         Loss D: -14.8869, loss G: 18.1721\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [116/200] Batch 11/12                         Loss D: -14.6457, loss G: 18.1774\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [117/200] Batch 11/12                         Loss D: -14.2167, loss G: 18.1828\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [118/200] Batch 11/12                         Loss D: -14.0251, loss G: 18.1885\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [119/200] Batch 11/12                         Loss D: -13.5165, loss G: 18.1938\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [120/200] Batch 11/12                         Loss D: -13.1601, loss G: 18.1987\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [121/200] Batch 11/12                         Loss D: -12.7947, loss G: 18.2032\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [122/200] Batch 11/12                         Loss D: -11.9817, loss G: 18.2059\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [123/200] Batch 11/12                         Loss D: -10.9956, loss G: 18.2072\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [124/200] Batch 11/12                         Loss D: -10.0106, loss G: 18.2079\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [125/200] Batch 11/12                         Loss D: -9.1440, loss G: 18.2078\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [126/200] Batch 11/12                         Loss D: -7.6309, loss G: 18.2035\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [127/200] Batch 11/12                         Loss D: -6.1406, loss G: 18.1972\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [128/200] Batch 11/12                         Loss D: -4.9449, loss G: 18.1934\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [129/200] Batch 11/12                         Loss D: -3.5366, loss G: 18.1893\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [130/200] Batch 11/12                         Loss D: -2.5936, loss G: 18.1890\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [131/200] Batch 11/12                         Loss D: -2.0437, loss G: 18.1883\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [132/200] Batch 11/12                         Loss D: -1.7884, loss G: 18.1887\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [133/200] Batch 11/12                         Loss D: -1.7895, loss G: 18.1902\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [134/200] Batch 11/12                         Loss D: -1.8100, loss G: 18.1912\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [135/200] Batch 11/12                         Loss D: -1.7027, loss G: 18.1923\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [136/200] Batch 11/12                         Loss D: -1.5728, loss G: 18.1934\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [137/200] Batch 11/12                         Loss D: -1.6018, loss G: 18.1947\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [138/200] Batch 11/12                         Loss D: -1.5187, loss G: 18.1955\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [139/200] Batch 11/12                         Loss D: -1.5564, loss G: 18.1972\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [140/200] Batch 11/12                         Loss D: -1.5232, loss G: 18.1980\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [141/200] Batch 11/12                         Loss D: -1.5530, loss G: 18.1989\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [142/200] Batch 11/12                         Loss D: -1.4405, loss G: 18.2002\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [143/200] Batch 11/12                         Loss D: -1.4753, loss G: 18.2013\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [144/200] Batch 11/12                         Loss D: -1.3718, loss G: 18.2029\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [145/200] Batch 11/12                         Loss D: -1.4562, loss G: 18.2038\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [146/200] Batch 11/12                         Loss D: -1.3360, loss G: 18.2053\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [147/200] Batch 11/12                         Loss D: -1.3593, loss G: 18.2064\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [148/200] Batch 11/12                         Loss D: -1.3116, loss G: 18.2066\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [149/200] Batch 11/12                         Loss D: -1.2205, loss G: 18.2083\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [150/200] Batch 11/12                         Loss D: -1.2655, loss G: 18.2097\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [151/200] Batch 11/12                         Loss D: -1.2213, loss G: 18.2107\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [152/200] Batch 11/12                         Loss D: -1.2309, loss G: 18.2119\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [153/200] Batch 11/12                         Loss D: -1.2051, loss G: 18.2138\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [154/200] Batch 11/12                         Loss D: -1.2511, loss G: 18.2144\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [155/200] Batch 11/12                         Loss D: -0.9917, loss G: 18.2159\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [156/200] Batch 11/12                         Loss D: -1.2249, loss G: 18.2170\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [157/200] Batch 11/12                         Loss D: -1.0014, loss G: 18.2177\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [158/200] Batch 11/12                         Loss D: -1.1241, loss G: 18.2197\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [159/200] Batch 11/12                         Loss D: -1.0740, loss G: 18.2207\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [160/200] Batch 11/12                         Loss D: -1.1883, loss G: 18.2216\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [161/200] Batch 11/12                         Loss D: -1.0943, loss G: 18.2222\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [162/200] Batch 11/12                         Loss D: -1.0625, loss G: 18.2235\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [163/200] Batch 11/12                         Loss D: -0.9572, loss G: 18.2249\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [164/200] Batch 11/12                         Loss D: -1.2349, loss G: 18.2259\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [165/200] Batch 11/12                         Loss D: -1.3705, loss G: 18.2272\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [166/200] Batch 11/12                         Loss D: -1.2342, loss G: 18.2279\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [167/200] Batch 11/12                         Loss D: -1.4213, loss G: 18.2282\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [168/200] Batch 11/12                         Loss D: -1.5372, loss G: 18.2283\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [169/200] Batch 11/12                         Loss D: -1.6916, loss G: 18.2285\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [170/200] Batch 11/12                         Loss D: -1.8890, loss G: 18.2282\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [171/200] Batch 11/12                         Loss D: -1.9152, loss G: 18.2271\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [172/200] Batch 11/12                         Loss D: -2.1962, loss G: 18.2271\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [173/200] Batch 11/12                         Loss D: -2.3401, loss G: 18.2268\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [174/200] Batch 11/12                         Loss D: -2.5486, loss G: 18.2253\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [175/200] Batch 11/12                         Loss D: -3.0388, loss G: 18.2235\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [176/200] Batch 11/12                         Loss D: -3.0925, loss G: 18.2239\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [177/200] Batch 11/12                         Loss D: -3.1050, loss G: 18.2242\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [178/200] Batch 11/12                         Loss D: -3.1327, loss G: 18.2231\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [179/200] Batch 11/12                         Loss D: -3.1400, loss G: 18.2228\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [180/200] Batch 11/12                         Loss D: -3.2856, loss G: 18.2232\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [181/200] Batch 11/12                         Loss D: -3.0300, loss G: 18.2232\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [182/200] Batch 11/12                         Loss D: -3.2178, loss G: 18.2227\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [183/200] Batch 11/12                         Loss D: -3.2192, loss G: 18.2230\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [184/200] Batch 11/12                         Loss D: -3.4135, loss G: 18.2227\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [185/200] Batch 11/12                         Loss D: -3.2278, loss G: 18.2230\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [186/200] Batch 11/12                         Loss D: -3.3550, loss G: 18.2226\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [187/200] Batch 11/12                         Loss D: -3.3451, loss G: 18.2230\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [188/200] Batch 11/12                         Loss D: -3.3453, loss G: 18.2229\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [189/200] Batch 11/12                         Loss D: -3.4555, loss G: 18.2224\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [190/200] Batch 11/12                         Loss D: -3.3117, loss G: 18.2220\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [191/200] Batch 11/12                         Loss D: -3.4195, loss G: 18.2225\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [192/200] Batch 11/12                         Loss D: -3.4078, loss G: 18.2232\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [193/200] Batch 11/12                         Loss D: -3.4977, loss G: 18.2217\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [194/200] Batch 11/12                         Loss D: -3.6209, loss G: 18.2225\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [195/200] Batch 11/12                         Loss D: -3.5343, loss G: 18.2227\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [196/200] Batch 11/12                         Loss D: -3.6069, loss G: 18.2229\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [197/200] Batch 11/12                         Loss D: -3.4907, loss G: 18.2216\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [198/200] Batch 11/12                         Loss D: -3.4119, loss G: 18.2227\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.5]                         Epoch [199/200] Batch 11/12                         Loss D: -3.5164, loss G: 18.2222\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [0/200] Batch 11/12                         Loss D: 0.9345, loss G: 3.4878\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [1/200] Batch 11/12                         Loss D: 0.9018, loss G: 3.4662\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [2/200] Batch 11/12                         Loss D: 0.8487, loss G: 3.4507\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [3/200] Batch 11/12                         Loss D: 0.7936, loss G: 3.4375\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [4/200] Batch 11/12                         Loss D: 0.7265, loss G: 3.4243\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [5/200] Batch 11/12                         Loss D: 0.6251, loss G: 3.4138\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [6/200] Batch 11/12                         Loss D: 0.5449, loss G: 3.4034\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [7/200] Batch 11/12                         Loss D: 0.4522, loss G: 3.3937\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [8/200] Batch 11/12                         Loss D: 0.3714, loss G: 3.3864\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [9/200] Batch 11/12                         Loss D: 0.2918, loss G: 3.3726\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [10/200] Batch 11/12                         Loss D: 0.1724, loss G: 3.3594\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [11/200] Batch 11/12                         Loss D: 0.0366, loss G: 3.3504\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [12/200] Batch 11/12                         Loss D: -0.1713, loss G: 3.3402\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [13/200] Batch 11/12                         Loss D: -0.4042, loss G: 3.3356\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [14/200] Batch 11/12                         Loss D: -0.6837, loss G: 3.3323\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [15/200] Batch 11/12                         Loss D: -0.9813, loss G: 3.3322\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [16/200] Batch 11/12                         Loss D: -1.3554, loss G: 3.3324\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [17/200] Batch 11/12                         Loss D: -1.7695, loss G: 3.3365\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [18/200] Batch 11/12                         Loss D: -2.2159, loss G: 3.3437\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [19/200] Batch 11/12                         Loss D: -2.6910, loss G: 3.3544\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [20/200] Batch 11/12                         Loss D: -3.1923, loss G: 3.3675\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [21/200] Batch 11/12                         Loss D: -3.7288, loss G: 3.3837\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [22/200] Batch 11/12                         Loss D: -4.2684, loss G: 3.4017\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [23/200] Batch 11/12                         Loss D: -4.8327, loss G: 3.4205\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [24/200] Batch 11/12                         Loss D: -5.2031, loss G: 3.4403\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [25/200] Batch 11/12                         Loss D: -5.5876, loss G: 3.4586\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [26/200] Batch 11/12                         Loss D: -5.7785, loss G: 3.4745\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [27/200] Batch 11/12                         Loss D: -5.7691, loss G: 3.4869\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [28/200] Batch 11/12                         Loss D: -5.4675, loss G: 3.4857\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [29/200] Batch 11/12                         Loss D: -5.0205, loss G: 3.4667\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [30/200] Batch 11/12                         Loss D: -4.1385, loss G: 3.3569\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [31/200] Batch 11/12                         Loss D: -4.8122, loss G: 3.3304\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [32/200] Batch 11/12                         Loss D: -6.0104, loss G: 3.3241\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [33/200] Batch 11/12                         Loss D: -7.1447, loss G: 3.3240\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [34/200] Batch 11/12                         Loss D: -8.7396, loss G: 3.3344\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [35/200] Batch 11/12                         Loss D: -10.4388, loss G: 3.3852\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [36/200] Batch 11/12                         Loss D: -12.0351, loss G: 3.4653\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [37/200] Batch 11/12                         Loss D: -13.7140, loss G: 3.5647\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [38/200] Batch 11/12                         Loss D: -15.4199, loss G: 3.6853\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [39/200] Batch 11/12                         Loss D: -16.6114, loss G: 3.7790\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [40/200] Batch 11/12                         Loss D: -17.5992, loss G: 3.8575\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [41/200] Batch 11/12                         Loss D: -17.5773, loss G: 3.9174\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [42/200] Batch 11/12                         Loss D: -17.4224, loss G: 3.9537\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [43/200] Batch 11/12                         Loss D: -16.8966, loss G: 3.9696\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [44/200] Batch 11/12                         Loss D: -16.4130, loss G: 3.9784\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [45/200] Batch 11/12                         Loss D: -15.5012, loss G: 3.9712\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [46/200] Batch 11/12                         Loss D: -14.8187, loss G: 3.9666\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [47/200] Batch 11/12                         Loss D: -13.5299, loss G: 3.9437\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [48/200] Batch 11/12                         Loss D: -12.3875, loss G: 3.9194\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [49/200] Batch 11/12                         Loss D: -10.8496, loss G: 3.8740\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [50/200] Batch 11/12                         Loss D: -4.4887, loss G: 3.4433\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [51/200] Batch 11/12                         Loss D: -1.1401, loss G: 3.3153\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [52/200] Batch 11/12                         Loss D: -0.8546, loss G: 3.2984\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [53/200] Batch 11/12                         Loss D: -0.4566, loss G: 3.2932\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [54/200] Batch 11/12                         Loss D: -0.4629, loss G: 3.3146\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [55/200] Batch 11/12                         Loss D: -0.5408, loss G: 3.3315\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [56/200] Batch 11/12                         Loss D: -0.6123, loss G: 3.3378\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [57/200] Batch 11/12                         Loss D: -0.7131, loss G: 3.3448\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [58/200] Batch 11/12                         Loss D: -0.8297, loss G: 3.3526\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [59/200] Batch 11/12                         Loss D: -0.9214, loss G: 3.3605\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [60/200] Batch 11/12                         Loss D: -1.0819, loss G: 3.3681\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [61/200] Batch 11/12                         Loss D: -1.2853, loss G: 3.3912\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [62/200] Batch 11/12                         Loss D: -1.7101, loss G: 3.4193\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [63/200] Batch 11/12                         Loss D: -2.0141, loss G: 3.4409\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [64/200] Batch 11/12                         Loss D: -2.2985, loss G: 3.4608\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [65/200] Batch 11/12                         Loss D: -2.3842, loss G: 3.4767\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [66/200] Batch 11/12                         Loss D: -2.5597, loss G: 3.4911\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [67/200] Batch 11/12                         Loss D: -2.7550, loss G: 3.5029\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [68/200] Batch 11/12                         Loss D: -2.9332, loss G: 3.5108\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [69/200] Batch 11/12                         Loss D: -3.0214, loss G: 3.5163\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [70/200] Batch 11/12                         Loss D: -3.0001, loss G: 3.5224\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [71/200] Batch 11/12                         Loss D: -2.9712, loss G: 3.5294\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [72/200] Batch 11/12                         Loss D: -2.8328, loss G: 3.5344\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [73/200] Batch 11/12                         Loss D: -2.6737, loss G: 3.5395\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [74/200] Batch 11/12                         Loss D: -2.5111, loss G: 3.5434\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [75/200] Batch 11/12                         Loss D: -2.1942, loss G: 3.5456\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [76/200] Batch 11/12                         Loss D: -1.7389, loss G: 3.5455\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [77/200] Batch 11/12                         Loss D: -0.9239, loss G: 3.5295\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [78/200] Batch 11/12                         Loss D: 0.5742, loss G: 3.4194\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [79/200] Batch 11/12                         Loss D: 1.2820, loss G: 3.2750\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [80/200] Batch 11/12                         Loss D: 1.8368, loss G: 3.1580\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [81/200] Batch 11/12                         Loss D: 1.8806, loss G: 3.0637\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [82/200] Batch 11/12                         Loss D: 1.1529, loss G: 2.9859\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [83/200] Batch 11/12                         Loss D: -0.2562, loss G: 2.9259\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [84/200] Batch 11/12                         Loss D: -2.2856, loss G: 2.8800\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [85/200] Batch 11/12                         Loss D: -5.5250, loss G: 2.8734\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [86/200] Batch 11/12                         Loss D: -7.7653, loss G: 2.8431\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [87/200] Batch 11/12                         Loss D: -9.7860, loss G: 2.8072\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [88/200] Batch 11/12                         Loss D: -12.7308, loss G: 2.7930\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [89/200] Batch 11/12                         Loss D: -16.0464, loss G: 2.8122\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [90/200] Batch 11/12                         Loss D: -20.0041, loss G: 2.8315\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [91/200] Batch 11/12                         Loss D: -23.7821, loss G: 2.8714\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [92/200] Batch 11/12                         Loss D: -27.6730, loss G: 2.9135\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [93/200] Batch 11/12                         Loss D: -31.2165, loss G: 2.9768\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [94/200] Batch 11/12                         Loss D: -35.8906, loss G: 3.0574\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [95/200] Batch 11/12                         Loss D: -40.6628, loss G: 3.1477\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [96/200] Batch 11/12                         Loss D: -43.8511, loss G: 3.2489\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [97/200] Batch 11/12                         Loss D: -46.6905, loss G: 3.3433\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [98/200] Batch 11/12                         Loss D: -47.2168, loss G: 3.4281\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [99/200] Batch 11/12                         Loss D: -47.2807, loss G: 3.5061\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [100/200] Batch 11/12                         Loss D: -47.6020, loss G: 3.5818\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [101/200] Batch 11/12                         Loss D: -45.9293, loss G: 3.6411\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [102/200] Batch 11/12                         Loss D: -42.6536, loss G: 3.6821\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [103/200] Batch 11/12                         Loss D: -38.6853, loss G: 3.7120\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [104/200] Batch 11/12                         Loss D: -35.2366, loss G: 3.7398\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [105/200] Batch 11/12                         Loss D: -31.7861, loss G: 3.7628\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [106/200] Batch 11/12                         Loss D: -29.5785, loss G: 3.7778\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [107/200] Batch 11/12                         Loss D: -27.5419, loss G: 3.7882\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [108/200] Batch 11/12                         Loss D: -25.3507, loss G: 3.7895\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [109/200] Batch 11/12                         Loss D: -19.5972, loss G: 3.7627\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [110/200] Batch 11/12                         Loss D: -12.5525, loss G: 3.7211\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [111/200] Batch 11/12                         Loss D: -10.3503, loss G: 3.7247\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [112/200] Batch 11/12                         Loss D: -10.2679, loss G: 3.7322\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [113/200] Batch 11/12                         Loss D: -9.9523, loss G: 3.7347\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [114/200] Batch 11/12                         Loss D: -9.4461, loss G: 3.7336\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [115/200] Batch 11/12                         Loss D: -9.2280, loss G: 3.7356\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [116/200] Batch 11/12                         Loss D: -8.8464, loss G: 3.7315\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [117/200] Batch 11/12                         Loss D: -8.3324, loss G: 3.7257\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [118/200] Batch 11/12                         Loss D: -8.1915, loss G: 3.7264\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [119/200] Batch 11/12                         Loss D: -7.8759, loss G: 3.7223\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [120/200] Batch 11/12                         Loss D: -7.3906, loss G: 3.7150\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [121/200] Batch 11/12                         Loss D: -7.2015, loss G: 3.7112\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [122/200] Batch 11/12                         Loss D: -6.9034, loss G: 3.7057\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [123/200] Batch 11/12                         Loss D: -6.5399, loss G: 3.6984\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [124/200] Batch 11/12                         Loss D: -6.2196, loss G: 3.6902\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [125/200] Batch 11/12                         Loss D: -6.0260, loss G: 3.6872\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [126/200] Batch 11/12                         Loss D: -5.6678, loss G: 3.6781\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [127/200] Batch 11/12                         Loss D: -5.6141, loss G: 3.6737\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [128/200] Batch 11/12                         Loss D: -5.3555, loss G: 3.6663\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [129/200] Batch 11/12                         Loss D: -5.1127, loss G: 3.6600\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [130/200] Batch 11/12                         Loss D: -4.7830, loss G: 3.6520\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [131/200] Batch 11/12                         Loss D: -4.5705, loss G: 3.6435\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [132/200] Batch 11/12                         Loss D: -4.3468, loss G: 3.6345\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [133/200] Batch 11/12                         Loss D: -4.1761, loss G: 3.6281\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [134/200] Batch 11/12                         Loss D: -3.9724, loss G: 3.6210\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [135/200] Batch 11/12                         Loss D: -3.6031, loss G: 3.6133\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [136/200] Batch 11/12                         Loss D: -3.4519, loss G: 3.6081\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [137/200] Batch 11/12                         Loss D: -3.2421, loss G: 3.6017\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [138/200] Batch 11/12                         Loss D: -2.9968, loss G: 3.5954\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [139/200] Batch 11/12                         Loss D: -2.6537, loss G: 3.5896\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [140/200] Batch 11/12                         Loss D: -2.6865, loss G: 3.5818\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [141/200] Batch 11/12                         Loss D: -2.4944, loss G: 3.5751\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [142/200] Batch 11/12                         Loss D: -2.1140, loss G: 3.5677\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [143/200] Batch 11/12                         Loss D: -1.9096, loss G: 3.5602\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [144/200] Batch 11/12                         Loss D: -1.6052, loss G: 3.5550\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [145/200] Batch 11/12                         Loss D: -1.6846, loss G: 3.5490\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [146/200] Batch 11/12                         Loss D: -1.1495, loss G: 3.5425\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [147/200] Batch 11/12                         Loss D: -1.0662, loss G: 3.5356\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [148/200] Batch 11/12                         Loss D: -0.9573, loss G: 3.5295\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [149/200] Batch 11/12                         Loss D: -0.6625, loss G: 3.5240\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [150/200] Batch 11/12                         Loss D: -0.1903, loss G: 3.5234\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [151/200] Batch 11/12                         Loss D: -0.2832, loss G: 3.5178\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [152/200] Batch 11/12                         Loss D: -0.2644, loss G: 3.5171\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [153/200] Batch 11/12                         Loss D: -0.1337, loss G: 3.5201\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [154/200] Batch 11/12                         Loss D: -0.3561, loss G: 3.5152\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [155/200] Batch 11/12                         Loss D: -0.3166, loss G: 3.5155\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [156/200] Batch 11/12                         Loss D: -0.4366, loss G: 3.5137\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [157/200] Batch 11/12                         Loss D: -0.5513, loss G: 3.5128\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [158/200] Batch 11/12                         Loss D: -0.4006, loss G: 3.5129\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [159/200] Batch 11/12                         Loss D: -0.3788, loss G: 3.5132\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [160/200] Batch 11/12                         Loss D: -0.6530, loss G: 3.5114\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [161/200] Batch 11/12                         Loss D: -0.6647, loss G: 3.5109\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [162/200] Batch 11/12                         Loss D: -0.6360, loss G: 3.5099\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [163/200] Batch 11/12                         Loss D: -0.5920, loss G: 3.5092\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [164/200] Batch 11/12                         Loss D: -0.5833, loss G: 3.5086\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [165/200] Batch 11/12                         Loss D: -0.7221, loss G: 3.5084\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [166/200] Batch 11/12                         Loss D: -0.7526, loss G: 3.5081\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [167/200] Batch 11/12                         Loss D: -0.6594, loss G: 3.5066\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [168/200] Batch 11/12                         Loss D: -0.7868, loss G: 3.5061\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [169/200] Batch 11/12                         Loss D: -0.6741, loss G: 3.5052\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [170/200] Batch 11/12                         Loss D: -0.7952, loss G: 3.5050\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [171/200] Batch 11/12                         Loss D: -0.7942, loss G: 3.5040\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [172/200] Batch 11/12                         Loss D: -0.8786, loss G: 3.5044\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [173/200] Batch 11/12                         Loss D: -0.8870, loss G: 3.5035\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [174/200] Batch 11/12                         Loss D: -0.8548, loss G: 3.5023\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [175/200] Batch 11/12                         Loss D: -0.8853, loss G: 3.5013\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [176/200] Batch 11/12                         Loss D: -0.8540, loss G: 3.5009\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [177/200] Batch 11/12                         Loss D: -0.8803, loss G: 3.5003\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [178/200] Batch 11/12                         Loss D: -0.8101, loss G: 3.5011\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [179/200] Batch 11/12                         Loss D: -0.8558, loss G: 3.4993\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [180/200] Batch 11/12                         Loss D: -0.8045, loss G: 3.5003\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [181/200] Batch 11/12                         Loss D: -0.7653, loss G: 3.5008\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [182/200] Batch 11/12                         Loss D: -0.9807, loss G: 3.4974\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [183/200] Batch 11/12                         Loss D: -0.8978, loss G: 3.4978\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [184/200] Batch 11/12                         Loss D: -1.0626, loss G: 3.4963\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [185/200] Batch 11/12                         Loss D: -1.0738, loss G: 3.4957\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [186/200] Batch 11/12                         Loss D: -1.1387, loss G: 3.4958\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [187/200] Batch 11/12                         Loss D: -1.0296, loss G: 3.4949\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [188/200] Batch 11/12                         Loss D: -1.0498, loss G: 3.4945\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [189/200] Batch 11/12                         Loss D: -1.0346, loss G: 3.4940\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [190/200] Batch 11/12                         Loss D: -1.1262, loss G: 3.4931\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [191/200] Batch 11/12                         Loss D: -1.1544, loss G: 3.4922\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [192/200] Batch 11/12                         Loss D: -1.1781, loss G: 3.4924\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [193/200] Batch 11/12                         Loss D: -1.1493, loss G: 3.4919\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [194/200] Batch 11/12                         Loss D: -1.2159, loss G: 3.4910\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [195/200] Batch 11/12                         Loss D: -1.1736, loss G: 3.4905\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [196/200] Batch 11/12                         Loss D: -1.2261, loss G: 3.4899\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [197/200] Batch 11/12                         Loss D: -1.2595, loss G: 3.4892\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [198/200] Batch 11/12                         Loss D: -1.2533, loss G: 3.4888\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=1, lambda_mean=0.1]                         Epoch [199/200] Batch 11/12                         Loss D: -1.3494, loss G: 3.4881\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [0/200] Batch 11/12                         Loss D: 0.1048, loss G: 34.5890\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [1/200] Batch 11/12                         Loss D: 0.0514, loss G: 34.4894\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [2/200] Batch 11/12                         Loss D: -0.0386, loss G: 34.3742\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [3/200] Batch 11/12                         Loss D: -0.1678, loss G: 34.2522\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [4/200] Batch 11/12                         Loss D: -0.3420, loss G: 34.1114\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [5/200] Batch 11/12                         Loss D: -0.5957, loss G: 33.9467\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [6/200] Batch 11/12                         Loss D: -0.9421, loss G: 33.7565\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [7/200] Batch 11/12                         Loss D: -1.3961, loss G: 33.5316\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [8/200] Batch 11/12                         Loss D: -2.0225, loss G: 33.2912\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [9/200] Batch 11/12                         Loss D: -2.8246, loss G: 33.0392\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [10/200] Batch 11/12                         Loss D: -3.8895, loss G: 32.7533\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [11/200] Batch 11/12                         Loss D: -5.2678, loss G: 32.4280\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [12/200] Batch 11/12                         Loss D: -6.8612, loss G: 32.1218\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [13/200] Batch 11/12                         Loss D: -8.9559, loss G: 31.7448\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [14/200] Batch 11/12                         Loss D: -11.3721, loss G: 31.3865\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [15/200] Batch 11/12                         Loss D: -14.1772, loss G: 31.0464\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [16/200] Batch 11/12                         Loss D: -17.3527, loss G: 30.7655\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [17/200] Batch 11/12                         Loss D: -20.3464, loss G: 30.6261\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [18/200] Batch 11/12                         Loss D: -23.6660, loss G: 30.5330\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [19/200] Batch 11/12                         Loss D: -26.8524, loss G: 30.5081\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [20/200] Batch 11/12                         Loss D: -30.9435, loss G: 30.4350\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [21/200] Batch 11/12                         Loss D: -35.3787, loss G: 30.3859\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [22/200] Batch 11/12                         Loss D: -39.7430, loss G: 30.4030\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [23/200] Batch 11/12                         Loss D: -44.5909, loss G: 30.4314\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [24/200] Batch 11/12                         Loss D: -50.2284, loss G: 30.4469\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [25/200] Batch 11/12                         Loss D: -56.5191, loss G: 30.4873\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [26/200] Batch 11/12                         Loss D: -63.0231, loss G: 30.5761\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [27/200] Batch 11/12                         Loss D: -69.8459, loss G: 30.6723\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [28/200] Batch 11/12                         Loss D: -77.0607, loss G: 30.8241\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [29/200] Batch 11/12                         Loss D: -85.1023, loss G: 30.9741\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [30/200] Batch 11/12                         Loss D: -91.9216, loss G: 31.2117\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [31/200] Batch 11/12                         Loss D: -99.9485, loss G: 31.4542\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [32/200] Batch 11/12                         Loss D: -108.8793, loss G: 31.7164\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [33/200] Batch 11/12                         Loss D: -117.1446, loss G: 31.9992\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [34/200] Batch 11/12                         Loss D: -126.0407, loss G: 32.3310\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [35/200] Batch 11/12                         Loss D: -131.7282, loss G: 32.6666\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [36/200] Batch 11/12                         Loss D: -140.5786, loss G: 33.0285\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [37/200] Batch 11/12                         Loss D: -144.1894, loss G: 33.4080\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [38/200] Batch 11/12                         Loss D: -152.6396, loss G: 33.7726\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [39/200] Batch 11/12                         Loss D: -156.7618, loss G: 34.1156\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [40/200] Batch 11/12                         Loss D: -160.2287, loss G: 34.4676\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [41/200] Batch 11/12                         Loss D: -161.1216, loss G: 34.7901\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [42/200] Batch 11/12                         Loss D: -162.3335, loss G: 35.0816\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [43/200] Batch 11/12                         Loss D: -163.8821, loss G: 35.3609\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [44/200] Batch 11/12                         Loss D: -162.5425, loss G: 35.5960\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [45/200] Batch 11/12                         Loss D: -161.7886, loss G: 35.8297\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [46/200] Batch 11/12                         Loss D: -158.6111, loss G: 35.9920\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [47/200] Batch 11/12                         Loss D: -154.7500, loss G: 36.1173\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [48/200] Batch 11/12                         Loss D: -149.8530, loss G: 36.2142\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [49/200] Batch 11/12                         Loss D: -143.1337, loss G: 36.2602\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [50/200] Batch 11/12                         Loss D: -139.8216, loss G: 36.3348\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [51/200] Batch 11/12                         Loss D: -133.0194, loss G: 36.3155\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [52/200] Batch 11/12                         Loss D: -126.1276, loss G: 36.2863\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [53/200] Batch 11/12                         Loss D: -120.7853, loss G: 36.2697\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [54/200] Batch 11/12                         Loss D: -114.1562, loss G: 36.2226\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [55/200] Batch 11/12                         Loss D: -106.3174, loss G: 36.1235\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [56/200] Batch 11/12                         Loss D: -97.5047, loss G: 35.9993\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [57/200] Batch 11/12                         Loss D: -88.9622, loss G: 35.8521\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [58/200] Batch 11/12                         Loss D: -79.6202, loss G: 35.6826\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [59/200] Batch 11/12                         Loss D: -68.7142, loss G: 35.4762\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [60/200] Batch 11/12                         Loss D: -56.5128, loss G: 35.2146\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [61/200] Batch 11/12                         Loss D: -44.0297, loss G: 34.9410\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [62/200] Batch 11/12                         Loss D: -30.9481, loss G: 34.6491\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [63/200] Batch 11/12                         Loss D: -23.4694, loss G: 34.5547\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [64/200] Batch 11/12                         Loss D: -23.9635, loss G: 34.5796\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [65/200] Batch 11/12                         Loss D: -23.9184, loss G: 34.5989\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [66/200] Batch 11/12                         Loss D: -24.1179, loss G: 34.6226\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [67/200] Batch 11/12                         Loss D: -24.4530, loss G: 34.6454\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [68/200] Batch 11/12                         Loss D: -24.6742, loss G: 34.6630\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [69/200] Batch 11/12                         Loss D: -24.8240, loss G: 34.6802\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [70/200] Batch 11/12                         Loss D: -24.9733, loss G: 34.6982\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [71/200] Batch 11/12                         Loss D: -25.4028, loss G: 34.7143\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [72/200] Batch 11/12                         Loss D: -26.0345, loss G: 34.7333\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [73/200] Batch 11/12                         Loss D: -25.8573, loss G: 34.7519\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [74/200] Batch 11/12                         Loss D: -26.3129, loss G: 34.7678\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [75/200] Batch 11/12                         Loss D: -26.6510, loss G: 34.7832\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [76/200] Batch 11/12                         Loss D: -27.0574, loss G: 34.7974\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [77/200] Batch 11/12                         Loss D: -27.5722, loss G: 34.8126\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [78/200] Batch 11/12                         Loss D: -27.8478, loss G: 34.8299\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [79/200] Batch 11/12                         Loss D: -28.3707, loss G: 34.8457\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [80/200] Batch 11/12                         Loss D: -28.7721, loss G: 34.8630\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [81/200] Batch 11/12                         Loss D: -29.3546, loss G: 34.8782\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [82/200] Batch 11/12                         Loss D: -29.9573, loss G: 34.8955\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [83/200] Batch 11/12                         Loss D: -30.5227, loss G: 34.9116\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [84/200] Batch 11/12                         Loss D: -30.8384, loss G: 34.9280\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [85/200] Batch 11/12                         Loss D: -31.5254, loss G: 34.9457\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [86/200] Batch 11/12                         Loss D: -32.0123, loss G: 34.9615\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [87/200] Batch 11/12                         Loss D: -32.6316, loss G: 34.9781\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [88/200] Batch 11/12                         Loss D: -33.2452, loss G: 34.9928\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [89/200] Batch 11/12                         Loss D: -34.0531, loss G: 35.0078\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [90/200] Batch 11/12                         Loss D: -34.5883, loss G: 35.0222\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [91/200] Batch 11/12                         Loss D: -35.2055, loss G: 35.0314\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [92/200] Batch 11/12                         Loss D: -35.7293, loss G: 35.0405\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [93/200] Batch 11/12                         Loss D: -36.5508, loss G: 35.0485\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [94/200] Batch 11/12                         Loss D: -37.3242, loss G: 35.0574\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [95/200] Batch 11/12                         Loss D: -38.3146, loss G: 35.0680\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [96/200] Batch 11/12                         Loss D: -38.9166, loss G: 35.0759\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [97/200] Batch 11/12                         Loss D: -39.4318, loss G: 35.0830\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [98/200] Batch 11/12                         Loss D: -39.5910, loss G: 35.0868\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [99/200] Batch 11/12                         Loss D: -39.3683, loss G: 35.0873\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [100/200] Batch 11/12                         Loss D: -39.6633, loss G: 35.0893\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [101/200] Batch 11/12                         Loss D: -39.1151, loss G: 35.0867\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [102/200] Batch 11/12                         Loss D: -37.6637, loss G: 35.0768\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [103/200] Batch 11/12                         Loss D: -37.0252, loss G: 35.0702\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [104/200] Batch 11/12                         Loss D: -35.7629, loss G: 35.0553\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [105/200] Batch 11/12                         Loss D: -34.0196, loss G: 35.0359\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [106/200] Batch 11/12                         Loss D: -31.1085, loss G: 35.0084\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [107/200] Batch 11/12                         Loss D: -28.4350, loss G: 34.9694\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [108/200] Batch 11/12                         Loss D: -24.4289, loss G: 34.9256\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [109/200] Batch 11/12                         Loss D: -17.9157, loss G: 34.7662\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [110/200] Batch 11/12                         Loss D: -9.2795, loss G: 33.1266\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [111/200] Batch 11/12                         Loss D: -13.7903, loss G: 32.0451\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [112/200] Batch 11/12                         Loss D: -21.4064, loss G: 31.1809\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [113/200] Batch 11/12                         Loss D: -32.8505, loss G: 30.4042\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [114/200] Batch 11/12                         Loss D: -47.4597, loss G: 29.8542\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [115/200] Batch 11/12                         Loss D: -66.2678, loss G: 29.3262\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [116/200] Batch 11/12                         Loss D: -87.9332, loss G: 28.9459\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [117/200] Batch 11/12                         Loss D: -112.9315, loss G: 28.5491\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [118/200] Batch 11/12                         Loss D: -136.1259, loss G: 28.5170\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [119/200] Batch 11/12                         Loss D: -162.1476, loss G: 28.6599\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [120/200] Batch 11/12                         Loss D: -183.6323, loss G: 29.1711\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [121/200] Batch 11/12                         Loss D: -198.6910, loss G: 29.8025\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [122/200] Batch 11/12                         Loss D: -208.9082, loss G: 30.5380\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [123/200] Batch 11/12                         Loss D: -213.2980, loss G: 31.3697\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [124/200] Batch 11/12                         Loss D: -213.1891, loss G: 32.2231\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [125/200] Batch 11/12                         Loss D: -213.2101, loss G: 33.2017\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [126/200] Batch 11/12                         Loss D: -212.2472, loss G: 34.1458\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [127/200] Batch 11/12                         Loss D: -206.7736, loss G: 35.0058\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [128/200] Batch 11/12                         Loss D: -197.3228, loss G: 35.7490\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [129/200] Batch 11/12                         Loss D: -186.8992, loss G: 36.3961\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [130/200] Batch 11/12                         Loss D: -178.5916, loss G: 37.0021\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [131/200] Batch 11/12                         Loss D: -163.4337, loss G: 37.4394\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [132/200] Batch 11/12                         Loss D: -146.6443, loss G: 37.7717\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [133/200] Batch 11/12                         Loss D: -129.5322, loss G: 38.0498\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [134/200] Batch 11/12                         Loss D: -107.7625, loss G: 38.1512\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [135/200] Batch 11/12                         Loss D: -87.6747, loss G: 38.2970\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [136/200] Batch 11/12                         Loss D: -65.0627, loss G: 38.2844\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [137/200] Batch 11/12                         Loss D: -54.8831, loss G: 38.3099\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [138/200] Batch 11/12                         Loss D: -45.8972, loss G: 38.2622\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [139/200] Batch 11/12                         Loss D: -38.5963, loss G: 38.1854\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [140/200] Batch 11/12                         Loss D: -31.4214, loss G: 38.0556\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [141/200] Batch 11/12                         Loss D: -25.9307, loss G: 37.8471\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [142/200] Batch 11/12                         Loss D: -28.8140, loss G: 37.6265\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [143/200] Batch 11/12                         Loss D: -31.7660, loss G: 37.4535\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [144/200] Batch 11/12                         Loss D: -34.7401, loss G: 37.2740\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [145/200] Batch 11/12                         Loss D: -37.3949, loss G: 37.0630\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [146/200] Batch 11/12                         Loss D: -39.3948, loss G: 36.7985\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [147/200] Batch 11/12                         Loss D: -39.9830, loss G: 36.5593\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [148/200] Batch 11/12                         Loss D: -39.2658, loss G: 36.3032\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [149/200] Batch 11/12                         Loss D: -38.9498, loss G: 36.0624\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [150/200] Batch 11/12                         Loss D: -39.3776, loss G: 35.8076\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [151/200] Batch 11/12                         Loss D: -39.5710, loss G: 35.5227\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [152/200] Batch 11/12                         Loss D: -39.7044, loss G: 35.2423\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [153/200] Batch 11/12                         Loss D: -37.6773, loss G: 35.1484\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [154/200] Batch 11/12                         Loss D: -35.4496, loss G: 35.1688\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [155/200] Batch 11/12                         Loss D: -32.6938, loss G: 35.1519\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [156/200] Batch 11/12                         Loss D: -29.7806, loss G: 35.1277\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [157/200] Batch 11/12                         Loss D: -26.5909, loss G: 35.1001\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [158/200] Batch 11/12                         Loss D: -23.4916, loss G: 35.0592\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [159/200] Batch 11/12                         Loss D: -20.4130, loss G: 35.0108\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [160/200] Batch 11/12                         Loss D: -16.7869, loss G: 34.9609\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [161/200] Batch 11/12                         Loss D: -13.0784, loss G: 34.9111\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [162/200] Batch 11/12                         Loss D: -9.7477, loss G: 34.8622\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [163/200] Batch 11/12                         Loss D: -6.7730, loss G: 34.8097\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [164/200] Batch 11/12                         Loss D: -3.9874, loss G: 34.7830\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [165/200] Batch 11/12                         Loss D: -1.8054, loss G: 34.7755\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [166/200] Batch 11/12                         Loss D: -0.6704, loss G: 34.7769\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [167/200] Batch 11/12                         Loss D: -0.1242, loss G: 34.7796\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [168/200] Batch 11/12                         Loss D: 0.5181, loss G: 34.7806\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [169/200] Batch 11/12                         Loss D: 0.5177, loss G: 34.7836\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [170/200] Batch 11/12                         Loss D: 0.3994, loss G: 34.7869\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [171/200] Batch 11/12                         Loss D: 0.5671, loss G: 34.7903\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [172/200] Batch 11/12                         Loss D: 0.5442, loss G: 34.7944\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [173/200] Batch 11/12                         Loss D: 0.4076, loss G: 34.7973\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [174/200] Batch 11/12                         Loss D: 0.6568, loss G: 34.8003\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [175/200] Batch 11/12                         Loss D: 0.3941, loss G: 34.8031\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [176/200] Batch 11/12                         Loss D: 0.5764, loss G: 34.8057\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [177/200] Batch 11/12                         Loss D: 0.4482, loss G: 34.8064\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [178/200] Batch 11/12                         Loss D: 0.5335, loss G: 34.8068\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [179/200] Batch 11/12                         Loss D: 0.6636, loss G: 34.8086\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [180/200] Batch 11/12                         Loss D: 0.6238, loss G: 34.8092\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [181/200] Batch 11/12                         Loss D: 0.9956, loss G: 34.8098\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [182/200] Batch 11/12                         Loss D: 0.6090, loss G: 34.8099\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [183/200] Batch 11/12                         Loss D: 0.3650, loss G: 34.8107\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [184/200] Batch 11/12                         Loss D: 0.5110, loss G: 34.8113\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [185/200] Batch 11/12                         Loss D: 0.6709, loss G: 34.8111\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [186/200] Batch 11/12                         Loss D: 0.7843, loss G: 34.8118\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [187/200] Batch 11/12                         Loss D: 0.5915, loss G: 34.8132\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [188/200] Batch 11/12                         Loss D: 0.4645, loss G: 34.8139\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [189/200] Batch 11/12                         Loss D: 0.8195, loss G: 34.8137\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [190/200] Batch 11/12                         Loss D: 0.6094, loss G: 34.8140\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [191/200] Batch 11/12                         Loss D: 0.6895, loss G: 34.8148\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [192/200] Batch 11/12                         Loss D: 0.3931, loss G: 34.8157\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [193/200] Batch 11/12                         Loss D: 0.4598, loss G: 34.8165\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [194/200] Batch 11/12                         Loss D: 0.6655, loss G: 34.8152\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [195/200] Batch 11/12                         Loss D: 0.3997, loss G: 34.8171\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [196/200] Batch 11/12                         Loss D: 0.3243, loss G: 34.8177\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [197/200] Batch 11/12                         Loss D: 0.7534, loss G: 34.8181\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [198/200] Batch 11/12                         Loss D: 1.0223, loss G: 34.8185\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=1]                         Epoch [199/200] Batch 11/12                         Loss D: 0.6359, loss G: 34.8195\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [0/200] Batch 11/12                         Loss D: 0.1273, loss G: 17.2845\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [1/200] Batch 11/12                         Loss D: 0.0820, loss G: 17.2303\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [2/200] Batch 11/12                         Loss D: 0.0124, loss G: 17.1793\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [3/200] Batch 11/12                         Loss D: -0.1086, loss G: 17.1171\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [4/200] Batch 11/12                         Loss D: -0.2650, loss G: 17.0567\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [5/200] Batch 11/12                         Loss D: -0.4954, loss G: 16.9795\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [6/200] Batch 11/12                         Loss D: -0.8241, loss G: 16.8974\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [7/200] Batch 11/12                         Loss D: -1.2019, loss G: 16.8173\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [8/200] Batch 11/12                         Loss D: -1.7163, loss G: 16.7359\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [9/200] Batch 11/12                         Loss D: -2.3505, loss G: 16.6696\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [10/200] Batch 11/12                         Loss D: -3.2326, loss G: 16.5864\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [11/200] Batch 11/12                         Loss D: -4.3698, loss G: 16.5076\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [12/200] Batch 11/12                         Loss D: -5.7608, loss G: 16.4455\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [13/200] Batch 11/12                         Loss D: -7.4451, loss G: 16.3958\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [14/200] Batch 11/12                         Loss D: -9.5556, loss G: 16.3534\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [15/200] Batch 11/12                         Loss D: -11.8605, loss G: 16.3433\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [16/200] Batch 11/12                         Loss D: -14.6183, loss G: 16.3495\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [17/200] Batch 11/12                         Loss D: -17.6142, loss G: 16.3844\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [18/200] Batch 11/12                         Loss D: -21.2739, loss G: 16.4287\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [19/200] Batch 11/12                         Loss D: -24.7845, loss G: 16.5292\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [20/200] Batch 11/12                         Loss D: -28.3020, loss G: 16.6649\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [21/200] Batch 11/12                         Loss D: -31.5262, loss G: 16.8227\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [22/200] Batch 11/12                         Loss D: -34.4935, loss G: 16.9908\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [23/200] Batch 11/12                         Loss D: -37.3795, loss G: 17.1572\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [24/200] Batch 11/12                         Loss D: -40.2137, loss G: 17.3154\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [25/200] Batch 11/12                         Loss D: -42.6221, loss G: 17.4614\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [26/200] Batch 11/12                         Loss D: -43.3130, loss G: 17.5904\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [27/200] Batch 11/12                         Loss D: -44.3963, loss G: 17.7117\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [28/200] Batch 11/12                         Loss D: -44.4475, loss G: 17.8090\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [29/200] Batch 11/12                         Loss D: -43.8199, loss G: 17.8839\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [30/200] Batch 11/12                         Loss D: -42.9564, loss G: 17.9379\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [31/200] Batch 11/12                         Loss D: -41.8247, loss G: 17.9741\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [32/200] Batch 11/12                         Loss D: -39.5025, loss G: 17.9702\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [33/200] Batch 11/12                         Loss D: -37.1443, loss G: 17.9499\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [34/200] Batch 11/12                         Loss D: -34.3595, loss G: 17.8993\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [35/200] Batch 11/12                         Loss D: -31.1477, loss G: 17.8166\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [36/200] Batch 11/12                         Loss D: -28.2465, loss G: 17.7204\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [37/200] Batch 11/12                         Loss D: -24.9956, loss G: 17.6030\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [38/200] Batch 11/12                         Loss D: -21.9226, loss G: 17.5023\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [39/200] Batch 11/12                         Loss D: -19.6088, loss G: 17.4429\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [40/200] Batch 11/12                         Loss D: -17.5454, loss G: 17.4014\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [41/200] Batch 11/12                         Loss D: -15.5177, loss G: 17.3630\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [42/200] Batch 11/12                         Loss D: -13.5189, loss G: 17.3255\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [43/200] Batch 11/12                         Loss D: -12.0840, loss G: 17.3065\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [44/200] Batch 11/12                         Loss D: -12.0094, loss G: 17.3003\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [45/200] Batch 11/12                         Loss D: -11.8285, loss G: 17.2900\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [46/200] Batch 11/12                         Loss D: -11.7561, loss G: 17.2810\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [47/200] Batch 11/12                         Loss D: -11.5463, loss G: 17.2685\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [48/200] Batch 11/12                         Loss D: -11.2005, loss G: 17.2543\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [49/200] Batch 11/12                         Loss D: -10.7972, loss G: 17.2384\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [50/200] Batch 11/12                         Loss D: -10.0499, loss G: 17.2199\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [51/200] Batch 11/12                         Loss D: -9.4144, loss G: 17.2009\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [52/200] Batch 11/12                         Loss D: -8.6660, loss G: 17.1826\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [53/200] Batch 11/12                         Loss D: -7.2389, loss G: 17.1403\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [54/200] Batch 11/12                         Loss D: -4.5627, loss G: 17.0682\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [55/200] Batch 11/12                         Loss D: -0.7455, loss G: 17.0094\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [56/200] Batch 11/12                         Loss D: 6.2914, loss G: 16.8546\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [57/200] Batch 11/12                         Loss D: 13.0802, loss G: 16.6363\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [58/200] Batch 11/12                         Loss D: 13.8253, loss G: 16.5792\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [59/200] Batch 11/12                         Loss D: 13.6691, loss G: 16.5848\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [60/200] Batch 11/12                         Loss D: 11.8780, loss G: 16.6600\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [61/200] Batch 11/12                         Loss D: 9.0424, loss G: 16.7901\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [62/200] Batch 11/12                         Loss D: 5.9955, loss G: 16.9399\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [63/200] Batch 11/12                         Loss D: 3.1645, loss G: 17.0969\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [64/200] Batch 11/12                         Loss D: 0.7634, loss G: 17.2365\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [65/200] Batch 11/12                         Loss D: -1.0742, loss G: 17.3394\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [66/200] Batch 11/12                         Loss D: -2.3601, loss G: 17.3966\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [67/200] Batch 11/12                         Loss D: -3.0524, loss G: 17.4047\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [68/200] Batch 11/12                         Loss D: -3.0337, loss G: 17.3697\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [69/200] Batch 11/12                         Loss D: -2.5045, loss G: 17.3053\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [70/200] Batch 11/12                         Loss D: -1.6837, loss G: 17.2190\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [71/200] Batch 11/12                         Loss D: -0.9680, loss G: 17.1361\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [72/200] Batch 11/12                         Loss D: -0.1239, loss G: 17.1079\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [73/200] Batch 11/12                         Loss D: 0.0721, loss G: 17.0986\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [74/200] Batch 11/12                         Loss D: -0.2002, loss G: 17.0905\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [75/200] Batch 11/12                         Loss D: -0.4326, loss G: 17.0825\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [76/200] Batch 11/12                         Loss D: -0.6913, loss G: 17.0741\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [77/200] Batch 11/12                         Loss D: -1.0202, loss G: 17.0638\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [78/200] Batch 11/12                         Loss D: -1.3508, loss G: 17.0518\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [79/200] Batch 11/12                         Loss D: -1.6883, loss G: 17.0440\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [80/200] Batch 11/12                         Loss D: -2.0255, loss G: 17.0365\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [81/200] Batch 11/12                         Loss D: -2.3875, loss G: 17.0299\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [82/200] Batch 11/12                         Loss D: -2.7106, loss G: 17.0230\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [83/200] Batch 11/12                         Loss D: -2.9892, loss G: 17.0163\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [84/200] Batch 11/12                         Loss D: -3.3004, loss G: 17.0095\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [85/200] Batch 11/12                         Loss D: -3.5897, loss G: 17.0024\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [86/200] Batch 11/12                         Loss D: -3.8336, loss G: 16.9948\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [87/200] Batch 11/12                         Loss D: -4.1061, loss G: 16.9876\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [88/200] Batch 11/12                         Loss D: -4.4401, loss G: 16.9801\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [89/200] Batch 11/12                         Loss D: -4.7592, loss G: 16.9743\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [90/200] Batch 11/12                         Loss D: -5.3286, loss G: 16.9675\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [91/200] Batch 11/12                         Loss D: -5.7615, loss G: 16.9625\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [92/200] Batch 11/12                         Loss D: -6.1790, loss G: 16.9586\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [93/200] Batch 11/12                         Loss D: -6.5967, loss G: 16.9550\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [94/200] Batch 11/12                         Loss D: -7.0343, loss G: 16.9518\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [95/200] Batch 11/12                         Loss D: -7.4146, loss G: 16.9489\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [96/200] Batch 11/12                         Loss D: -7.7400, loss G: 16.9465\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [97/200] Batch 11/12                         Loss D: -8.0181, loss G: 16.9431\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [98/200] Batch 11/12                         Loss D: -8.3735, loss G: 16.9420\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [99/200] Batch 11/12                         Loss D: -8.6186, loss G: 16.9398\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [100/200] Batch 11/12                         Loss D: -9.1149, loss G: 16.9214\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [101/200] Batch 11/12                         Loss D: -9.9544, loss G: 16.8835\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [102/200] Batch 11/12                         Loss D: -10.4803, loss G: 16.8709\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [103/200] Batch 11/12                         Loss D: -10.7490, loss G: 16.8649\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [104/200] Batch 11/12                         Loss D: -10.5041, loss G: 16.8604\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [105/200] Batch 11/12                         Loss D: -10.6937, loss G: 16.8600\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [106/200] Batch 11/12                         Loss D: -11.0951, loss G: 16.8693\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [107/200] Batch 11/12                         Loss D: -11.2345, loss G: 16.8852\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [108/200] Batch 11/12                         Loss D: -11.2768, loss G: 16.9042\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [109/200] Batch 11/12                         Loss D: -11.1198, loss G: 16.9267\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [110/200] Batch 11/12                         Loss D: -10.7878, loss G: 16.9475\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [111/200] Batch 11/12                         Loss D: -10.4984, loss G: 16.9678\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [112/200] Batch 11/12                         Loss D: -9.9436, loss G: 16.9840\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [113/200] Batch 11/12                         Loss D: -9.6151, loss G: 17.0014\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [114/200] Batch 11/12                         Loss D: -9.6921, loss G: 17.0171\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [115/200] Batch 11/12                         Loss D: -9.8355, loss G: 17.0336\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [116/200] Batch 11/12                         Loss D: -10.2335, loss G: 17.0481\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [117/200] Batch 11/12                         Loss D: -10.6157, loss G: 17.0627\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [118/200] Batch 11/12                         Loss D: -10.8764, loss G: 17.0768\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [119/200] Batch 11/12                         Loss D: -11.5743, loss G: 17.0911\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [120/200] Batch 11/12                         Loss D: -12.2619, loss G: 17.1054\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [121/200] Batch 11/12                         Loss D: -12.7579, loss G: 17.1192\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [122/200] Batch 11/12                         Loss D: -13.4607, loss G: 17.1331\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [123/200] Batch 11/12                         Loss D: -13.9380, loss G: 17.1472\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [124/200] Batch 11/12                         Loss D: -14.6500, loss G: 17.1602\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [125/200] Batch 11/12                         Loss D: -14.8720, loss G: 17.1713\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [126/200] Batch 11/12                         Loss D: -15.2597, loss G: 17.1821\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [127/200] Batch 11/12                         Loss D: -15.0129, loss G: 17.1897\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [128/200] Batch 11/12                         Loss D: -14.8440, loss G: 17.1971\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [129/200] Batch 11/12                         Loss D: -14.4928, loss G: 17.2027\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [130/200] Batch 11/12                         Loss D: -13.5917, loss G: 17.2056\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [131/200] Batch 11/12                         Loss D: -12.8023, loss G: 17.2086\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [132/200] Batch 11/12                         Loss D: -11.8018, loss G: 17.2092\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [133/200] Batch 11/12                         Loss D: -10.5637, loss G: 17.2072\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [134/200] Batch 11/12                         Loss D: -9.6130, loss G: 17.2052\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [135/200] Batch 11/12                         Loss D: -8.4234, loss G: 17.2015\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [136/200] Batch 11/12                         Loss D: -6.9370, loss G: 17.1973\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [137/200] Batch 11/12                         Loss D: -5.6240, loss G: 17.1918\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [138/200] Batch 11/12                         Loss D: -4.3479, loss G: 17.1846\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [139/200] Batch 11/12                         Loss D: -2.9259, loss G: 17.1771\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [140/200] Batch 11/12                         Loss D: 2.7465, loss G: 17.0384\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [141/200] Batch 11/12                         Loss D: 15.0579, loss G: 16.2304\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [142/200] Batch 11/12                         Loss D: 24.6626, loss G: 15.0725\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [143/200] Batch 11/12                         Loss D: 30.9900, loss G: 14.2586\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [144/200] Batch 11/12                         Loss D: 33.1917, loss G: 13.6896\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [145/200] Batch 11/12                         Loss D: 31.3513, loss G: 13.3277\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [146/200] Batch 11/12                         Loss D: 25.0272, loss G: 13.2311\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [147/200] Batch 11/12                         Loss D: 14.9064, loss G: 13.3371\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [148/200] Batch 11/12                         Loss D: 1.5514, loss G: 13.6039\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [149/200] Batch 11/12                         Loss D: -14.6040, loss G: 13.9620\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [150/200] Batch 11/12                         Loss D: -32.1375, loss G: 14.4871\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [151/200] Batch 11/12                         Loss D: -49.2642, loss G: 15.0418\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [152/200] Batch 11/12                         Loss D: -64.4135, loss G: 15.5232\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [153/200] Batch 11/12                         Loss D: -73.9097, loss G: 15.8697\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [154/200] Batch 11/12                         Loss D: -86.2344, loss G: 16.1737\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [155/200] Batch 11/12                         Loss D: -95.9445, loss G: 16.3797\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [156/200] Batch 11/12                         Loss D: -99.7787, loss G: 16.4571\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [157/200] Batch 11/12                         Loss D: -95.8698, loss G: 16.4027\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [158/200] Batch 11/12                         Loss D: -86.7435, loss G: 16.3887\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [159/200] Batch 11/12                         Loss D: -94.2792, loss G: 16.6404\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [160/200] Batch 11/12                         Loss D: -99.2041, loss G: 16.8915\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [161/200] Batch 11/12                         Loss D: -105.1316, loss G: 17.1301\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [162/200] Batch 11/12                         Loss D: -109.3418, loss G: 17.3579\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [163/200] Batch 11/12                         Loss D: -113.2069, loss G: 17.5723\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [164/200] Batch 11/12                         Loss D: -114.3195, loss G: 17.7681\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [165/200] Batch 11/12                         Loss D: -118.1876, loss G: 17.9689\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [166/200] Batch 11/12                         Loss D: -118.5820, loss G: 18.1364\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [167/200] Batch 11/12                         Loss D: -118.1857, loss G: 18.2817\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [168/200] Batch 11/12                         Loss D: -119.1602, loss G: 18.4234\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [169/200] Batch 11/12                         Loss D: -116.8641, loss G: 18.5238\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [170/200] Batch 11/12                         Loss D: -115.1101, loss G: 18.6112\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [171/200] Batch 11/12                         Loss D: -111.6516, loss G: 18.6664\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [172/200] Batch 11/12                         Loss D: -107.1409, loss G: 18.6987\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [173/200] Batch 11/12                         Loss D: -103.0559, loss G: 18.7178\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [174/200] Batch 11/12                         Loss D: -100.5189, loss G: 18.7550\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [175/200] Batch 11/12                         Loss D: -94.2335, loss G: 18.7246\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [176/200] Batch 11/12                         Loss D: -89.9691, loss G: 18.7118\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [177/200] Batch 11/12                         Loss D: -84.8080, loss G: 18.6788\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [178/200] Batch 11/12                         Loss D: -78.8830, loss G: 18.6234\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [179/200] Batch 11/12                         Loss D: -73.0436, loss G: 18.5636\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [180/200] Batch 11/12                         Loss D: -67.3945, loss G: 18.4964\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [181/200] Batch 11/12                         Loss D: -62.8490, loss G: 18.4404\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [182/200] Batch 11/12                         Loss D: -58.1897, loss G: 18.3448\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [183/200] Batch 11/12                         Loss D: -53.5690, loss G: 18.2511\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [184/200] Batch 11/12                         Loss D: -52.1832, loss G: 18.2316\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [185/200] Batch 11/12                         Loss D: -50.1066, loss G: 18.2117\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [186/200] Batch 11/12                         Loss D: -47.8302, loss G: 18.1976\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [187/200] Batch 11/12                         Loss D: -47.4492, loss G: 18.1995\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [188/200] Batch 11/12                         Loss D: -45.9295, loss G: 18.1820\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [189/200] Batch 11/12                         Loss D: -44.9607, loss G: 18.1760\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [190/200] Batch 11/12                         Loss D: -43.4210, loss G: 18.1580\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [191/200] Batch 11/12                         Loss D: -42.2391, loss G: 18.1472\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [192/200] Batch 11/12                         Loss D: -40.4723, loss G: 18.1265\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [193/200] Batch 11/12                         Loss D: -39.0097, loss G: 18.1081\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [194/200] Batch 11/12                         Loss D: -37.1412, loss G: 18.0858\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [195/200] Batch 11/12                         Loss D: -35.2929, loss G: 18.0601\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [196/200] Batch 11/12                         Loss D: -34.2916, loss G: 18.0532\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [197/200] Batch 11/12                         Loss D: -32.1530, loss G: 18.0198\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [198/200] Batch 11/12                         Loss D: -30.1741, loss G: 17.9954\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [199/200] Batch 11/12                         Loss D: -28.6760, loss G: 17.9749\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [0/200] Batch 11/12                         Loss D: 0.1888, loss G: 3.3268\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [1/200] Batch 11/12                         Loss D: 0.2012, loss G: 3.3007\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [2/200] Batch 11/12                         Loss D: 0.2195, loss G: 3.2747\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [3/200] Batch 11/12                         Loss D: 0.2194, loss G: 3.2545\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [4/200] Batch 11/12                         Loss D: 0.1970, loss G: 3.2340\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [5/200] Batch 11/12                         Loss D: 0.1494, loss G: 3.2083\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [6/200] Batch 11/12                         Loss D: 0.0681, loss G: 3.1768\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [7/200] Batch 11/12                         Loss D: -0.0413, loss G: 3.1329\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [8/200] Batch 11/12                         Loss D: -0.1991, loss G: 3.0881\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [9/200] Batch 11/12                         Loss D: -0.3891, loss G: 3.0569\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [10/200] Batch 11/12                         Loss D: -0.5879, loss G: 3.0161\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [11/200] Batch 11/12                         Loss D: -0.8107, loss G: 2.9732\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [12/200] Batch 11/12                         Loss D: -1.0993, loss G: 2.8916\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [13/200] Batch 11/12                         Loss D: -1.4174, loss G: 2.8004\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [14/200] Batch 11/12                         Loss D: -1.6882, loss G: 2.7005\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [15/200] Batch 11/12                         Loss D: -1.8710, loss G: 2.6521\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [16/200] Batch 11/12                         Loss D: -2.0153, loss G: 2.6297\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [17/200] Batch 11/12                         Loss D: -2.1402, loss G: 2.5989\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [18/200] Batch 11/12                         Loss D: -2.2633, loss G: 2.5745\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [19/200] Batch 11/12                         Loss D: -2.3855, loss G: 2.5429\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [20/200] Batch 11/12                         Loss D: -2.5403, loss G: 2.5104\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [21/200] Batch 11/12                         Loss D: -2.6629, loss G: 2.4641\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [22/200] Batch 11/12                         Loss D: -2.5372, loss G: 2.4457\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [23/200] Batch 11/12                         Loss D: -2.4253, loss G: 2.4150\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [24/200] Batch 11/12                         Loss D: -2.2464, loss G: 2.4070\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [25/200] Batch 11/12                         Loss D: -1.9415, loss G: 2.4236\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [26/200] Batch 11/12                         Loss D: -1.4496, loss G: 2.4501\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [27/200] Batch 11/12                         Loss D: -0.7827, loss G: 2.5014\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [28/200] Batch 11/12                         Loss D: -0.1031, loss G: 2.5639\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [29/200] Batch 11/12                         Loss D: -0.0562, loss G: 2.6618\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [30/200] Batch 11/12                         Loss D: -0.5179, loss G: 2.8261\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [31/200] Batch 11/12                         Loss D: -1.2949, loss G: 2.9645\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [32/200] Batch 11/12                         Loss D: -1.9880, loss G: 3.0590\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [33/200] Batch 11/12                         Loss D: -2.6073, loss G: 3.1509\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [34/200] Batch 11/12                         Loss D: -3.2079, loss G: 3.2481\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [35/200] Batch 11/12                         Loss D: -3.7863, loss G: 3.3318\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [36/200] Batch 11/12                         Loss D: -4.3144, loss G: 3.4217\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [37/200] Batch 11/12                         Loss D: -4.8169, loss G: 3.4971\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [38/200] Batch 11/12                         Loss D: -5.2336, loss G: 3.5540\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [39/200] Batch 11/12                         Loss D: -5.6214, loss G: 3.6104\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [40/200] Batch 11/12                         Loss D: -5.9608, loss G: 3.6464\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [41/200] Batch 11/12                         Loss D: -6.3012, loss G: 3.6804\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [42/200] Batch 11/12                         Loss D: -6.5319, loss G: 3.6987\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [43/200] Batch 11/12                         Loss D: -6.8470, loss G: 3.7210\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [44/200] Batch 11/12                         Loss D: -7.0858, loss G: 3.7351\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [45/200] Batch 11/12                         Loss D: -7.3482, loss G: 3.7450\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [46/200] Batch 11/12                         Loss D: -7.4732, loss G: 3.7447\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [47/200] Batch 11/12                         Loss D: -7.6416, loss G: 3.7403\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [48/200] Batch 11/12                         Loss D: -7.7906, loss G: 3.7340\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [49/200] Batch 11/12                         Loss D: -7.9732, loss G: 3.7297\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [50/200] Batch 11/12                         Loss D: -7.9808, loss G: 3.7130\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [51/200] Batch 11/12                         Loss D: -7.8941, loss G: 3.6904\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [52/200] Batch 11/12                         Loss D: -7.6903, loss G: 3.6632\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [53/200] Batch 11/12                         Loss D: -7.8887, loss G: 3.6542\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [54/200] Batch 11/12                         Loss D: -8.4158, loss G: 3.6692\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [55/200] Batch 11/12                         Loss D: -8.7769, loss G: 3.6906\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [56/200] Batch 11/12                         Loss D: -9.2198, loss G: 3.7071\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [57/200] Batch 11/12                         Loss D: -9.2865, loss G: 3.7153\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [58/200] Batch 11/12                         Loss D: -9.1431, loss G: 3.7161\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [59/200] Batch 11/12                         Loss D: -8.6628, loss G: 3.7088\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [60/200] Batch 11/12                         Loss D: -7.6432, loss G: 3.6890\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [61/200] Batch 11/12                         Loss D: -6.0719, loss G: 3.6538\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [62/200] Batch 11/12                         Loss D: -4.1160, loss G: 3.6122\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [63/200] Batch 11/12                         Loss D: -1.8055, loss G: 3.5651\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [64/200] Batch 11/12                         Loss D: 1.0983, loss G: 3.3591\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [65/200] Batch 11/12                         Loss D: 3.3572, loss G: 2.9653\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [66/200] Batch 11/12                         Loss D: 4.4086, loss G: 2.8355\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [67/200] Batch 11/12                         Loss D: 4.9221, loss G: 2.7450\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [68/200] Batch 11/12                         Loss D: 4.8762, loss G: 2.6865\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [69/200] Batch 11/12                         Loss D: 4.0839, loss G: 2.6852\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [70/200] Batch 11/12                         Loss D: 2.7196, loss G: 2.7289\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [71/200] Batch 11/12                         Loss D: 0.8995, loss G: 2.8155\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [72/200] Batch 11/12                         Loss D: -1.1574, loss G: 2.9201\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [73/200] Batch 11/12                         Loss D: -3.3036, loss G: 3.0426\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [74/200] Batch 11/12                         Loss D: -5.8316, loss G: 3.1986\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [75/200] Batch 11/12                         Loss D: -8.0030, loss G: 3.3457\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [76/200] Batch 11/12                         Loss D: -9.3003, loss G: 3.4577\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [77/200] Batch 11/12                         Loss D: -9.9814, loss G: 3.5384\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [78/200] Batch 11/12                         Loss D: -9.9448, loss G: 3.5838\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [79/200] Batch 11/12                         Loss D: -9.5023, loss G: 3.6042\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [80/200] Batch 11/12                         Loss D: -8.2786, loss G: 3.5850\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [81/200] Batch 11/12                         Loss D: -6.9796, loss G: 3.5566\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [82/200] Batch 11/12                         Loss D: -5.1569, loss G: 3.4962\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [83/200] Batch 11/12                         Loss D: -4.5415, loss G: 3.4806\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [84/200] Batch 11/12                         Loss D: -4.2999, loss G: 3.4694\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [85/200] Batch 11/12                         Loss D: -3.8920, loss G: 3.4472\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [86/200] Batch 11/12                         Loss D: -3.5573, loss G: 3.4238\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [87/200] Batch 11/12                         Loss D: -3.2038, loss G: 3.4004\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [88/200] Batch 11/12                         Loss D: -2.9032, loss G: 3.3766\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [89/200] Batch 11/12                         Loss D: -2.5347, loss G: 3.3526\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [90/200] Batch 11/12                         Loss D: -2.3699, loss G: 3.3431\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [91/200] Batch 11/12                         Loss D: -2.3433, loss G: 3.3451\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [92/200] Batch 11/12                         Loss D: -2.4017, loss G: 3.3475\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [93/200] Batch 11/12                         Loss D: -2.4022, loss G: 3.3504\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [94/200] Batch 11/12                         Loss D: -2.4132, loss G: 3.3535\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [95/200] Batch 11/12                         Loss D: -2.3932, loss G: 3.3567\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [96/200] Batch 11/12                         Loss D: -2.3244, loss G: 3.3588\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [97/200] Batch 11/12                         Loss D: -2.3080, loss G: 3.3615\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [98/200] Batch 11/12                         Loss D: -2.1658, loss G: 3.3645\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [99/200] Batch 11/12                         Loss D: -2.1118, loss G: 3.3662\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [100/200] Batch 11/12                         Loss D: -2.0036, loss G: 3.3679\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [101/200] Batch 11/12                         Loss D: -1.7627, loss G: 3.3686\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [102/200] Batch 11/12                         Loss D: -1.6021, loss G: 3.3689\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [103/200] Batch 11/12                         Loss D: -1.3946, loss G: 3.3695\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [104/200] Batch 11/12                         Loss D: -1.1615, loss G: 3.3694\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [105/200] Batch 11/12                         Loss D: -0.8939, loss G: 3.3687\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [106/200] Batch 11/12                         Loss D: -0.6363, loss G: 3.3673\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [107/200] Batch 11/12                         Loss D: -0.3103, loss G: 3.3651\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [108/200] Batch 11/12                         Loss D: -0.0178, loss G: 3.3621\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [109/200] Batch 11/12                         Loss D: 0.3500, loss G: 3.3600\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [110/200] Batch 11/12                         Loss D: 0.6829, loss G: 3.3567\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [111/200] Batch 11/12                         Loss D: 1.0188, loss G: 3.3535\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [112/200] Batch 11/12                         Loss D: 1.3837, loss G: 3.3494\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [113/200] Batch 11/12                         Loss D: 1.7070, loss G: 3.3473\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [114/200] Batch 11/12                         Loss D: 2.0013, loss G: 3.3450\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [115/200] Batch 11/12                         Loss D: 2.2520, loss G: 3.3438\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [116/200] Batch 11/12                         Loss D: 2.4117, loss G: 3.3439\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [117/200] Batch 11/12                         Loss D: 2.5020, loss G: 3.3430\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [118/200] Batch 11/12                         Loss D: 2.5873, loss G: 3.3449\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [119/200] Batch 11/12                         Loss D: 2.6068, loss G: 3.3462\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [120/200] Batch 11/12                         Loss D: 2.5669, loss G: 3.3473\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [121/200] Batch 11/12                         Loss D: 2.5689, loss G: 3.3491\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [122/200] Batch 11/12                         Loss D: 2.5600, loss G: 3.3492\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [123/200] Batch 11/12                         Loss D: 2.5527, loss G: 3.3503\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [124/200] Batch 11/12                         Loss D: 2.5332, loss G: 3.3519\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [125/200] Batch 11/12                         Loss D: 2.4903, loss G: 3.3537\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [126/200] Batch 11/12                         Loss D: 2.5018, loss G: 3.3544\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [127/200] Batch 11/12                         Loss D: 2.4818, loss G: 3.3558\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [128/200] Batch 11/12                         Loss D: 2.4493, loss G: 3.3585\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [129/200] Batch 11/12                         Loss D: 2.4181, loss G: 3.3584\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [130/200] Batch 11/12                         Loss D: 2.3737, loss G: 3.3604\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [131/200] Batch 11/12                         Loss D: 2.2887, loss G: 3.3620\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [132/200] Batch 11/12                         Loss D: 2.2421, loss G: 3.3634\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [133/200] Batch 11/12                         Loss D: 2.1314, loss G: 3.3657\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [134/200] Batch 11/12                         Loss D: 2.0331, loss G: 3.3657\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [135/200] Batch 11/12                         Loss D: 1.9465, loss G: 3.3669\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [136/200] Batch 11/12                         Loss D: 1.8623, loss G: 3.3684\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [137/200] Batch 11/12                         Loss D: 1.7501, loss G: 3.3681\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [138/200] Batch 11/12                         Loss D: 1.6169, loss G: 3.3687\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [139/200] Batch 11/12                         Loss D: 1.4988, loss G: 3.3688\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [140/200] Batch 11/12                         Loss D: 1.4053, loss G: 3.3687\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [141/200] Batch 11/12                         Loss D: 1.2506, loss G: 3.3685\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [142/200] Batch 11/12                         Loss D: 1.1364, loss G: 3.3655\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [143/200] Batch 11/12                         Loss D: 1.0078, loss G: 3.3654\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [144/200] Batch 11/12                         Loss D: 0.8923, loss G: 3.3655\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [145/200] Batch 11/12                         Loss D: 0.7557, loss G: 3.3645\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [146/200] Batch 11/12                         Loss D: 0.6257, loss G: 3.3638\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [147/200] Batch 11/12                         Loss D: 0.5094, loss G: 3.3635\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [148/200] Batch 11/12                         Loss D: 0.3828, loss G: 3.3622\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [149/200] Batch 11/12                         Loss D: 0.2471, loss G: 3.3618\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [150/200] Batch 11/12                         Loss D: 0.1653, loss G: 3.3617\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [151/200] Batch 11/12                         Loss D: 0.0214, loss G: 3.3589\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [152/200] Batch 11/12                         Loss D: -0.1101, loss G: 3.3583\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [153/200] Batch 11/12                         Loss D: -0.2479, loss G: 3.3588\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [154/200] Batch 11/12                         Loss D: -0.3623, loss G: 3.3593\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [155/200] Batch 11/12                         Loss D: -0.4944, loss G: 3.3584\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [156/200] Batch 11/12                         Loss D: -0.6236, loss G: 3.3595\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [157/200] Batch 11/12                         Loss D: -0.7637, loss G: 3.3603\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [158/200] Batch 11/12                         Loss D: -0.9008, loss G: 3.3615\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [159/200] Batch 11/12                         Loss D: -1.0440, loss G: 3.3632\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [160/200] Batch 11/12                         Loss D: -1.1731, loss G: 3.3648\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [161/200] Batch 11/12                         Loss D: -1.2883, loss G: 3.3676\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [162/200] Batch 11/12                         Loss D: -1.4348, loss G: 3.3708\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [163/200] Batch 11/12                         Loss D: -1.5247, loss G: 3.3740\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [164/200] Batch 11/12                         Loss D: -1.6471, loss G: 3.3787\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [165/200] Batch 11/12                         Loss D: -1.7553, loss G: 3.3824\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [166/200] Batch 11/12                         Loss D: -1.8117, loss G: 3.3869\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [167/200] Batch 11/12                         Loss D: -1.8237, loss G: 3.3922\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [168/200] Batch 11/12                         Loss D: -1.8940, loss G: 3.3967\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [169/200] Batch 11/12                         Loss D: -1.9069, loss G: 3.4015\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [170/200] Batch 11/12                         Loss D: -1.8724, loss G: 3.4058\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [171/200] Batch 11/12                         Loss D: -1.8208, loss G: 3.4100\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [172/200] Batch 11/12                         Loss D: -1.7333, loss G: 3.4142\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [173/200] Batch 11/12                         Loss D: -1.6352, loss G: 3.4171\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [174/200] Batch 11/12                         Loss D: -1.4938, loss G: 3.4207\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [175/200] Batch 11/12                         Loss D: -1.3607, loss G: 3.4225\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [176/200] Batch 11/12                         Loss D: -1.1708, loss G: 3.4242\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [177/200] Batch 11/12                         Loss D: -0.9920, loss G: 3.4256\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [178/200] Batch 11/12                         Loss D: -0.7515, loss G: 3.4267\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [179/200] Batch 11/12                         Loss D: -0.5332, loss G: 3.4266\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [180/200] Batch 11/12                         Loss D: -0.2990, loss G: 3.4257\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [181/200] Batch 11/12                         Loss D: 0.0071, loss G: 3.4247\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [182/200] Batch 11/12                         Loss D: 0.2967, loss G: 3.4237\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [183/200] Batch 11/12                         Loss D: 0.6074, loss G: 3.4225\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [184/200] Batch 11/12                         Loss D: 0.8188, loss G: 3.4219\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [185/200] Batch 11/12                         Loss D: 1.0881, loss G: 3.4217\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [186/200] Batch 11/12                         Loss D: 1.2783, loss G: 3.4226\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [187/200] Batch 11/12                         Loss D: 1.4123, loss G: 3.4233\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [188/200] Batch 11/12                         Loss D: 1.5494, loss G: 3.4244\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [189/200] Batch 11/12                         Loss D: 1.5811, loss G: 3.4273\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [190/200] Batch 11/12                         Loss D: 1.5986, loss G: 3.4305\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [191/200] Batch 11/12                         Loss D: 1.5956, loss G: 3.4335\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [192/200] Batch 11/12                         Loss D: 1.5367, loss G: 3.4366\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [193/200] Batch 11/12                         Loss D: 1.4556, loss G: 3.4403\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [194/200] Batch 11/12                         Loss D: 1.3605, loss G: 3.4435\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [195/200] Batch 11/12                         Loss D: 1.2097, loss G: 3.4446\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [196/200] Batch 11/12                         Loss D: 1.0541, loss G: 3.4466\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [197/200] Batch 11/12                         Loss D: 0.9098, loss G: 3.4485\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [198/200] Batch 11/12                         Loss D: 0.7503, loss G: 3.4498\n",
      "[lr_G=5e-05, lr_D=0.0002, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [199/200] Batch 11/12                         Loss D: 0.5731, loss G: 3.4506\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [0/200] Batch 11/12                         Loss D: 9.1147, loss G: 34.6443\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [1/200] Batch 11/12                         Loss D: 8.9058, loss G: 34.5407\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [2/200] Batch 11/12                         Loss D: 8.4908, loss G: 34.4248\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [3/200] Batch 11/12                         Loss D: 8.0262, loss G: 34.2969\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [4/200] Batch 11/12                         Loss D: 7.5558, loss G: 34.1371\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [5/200] Batch 11/12                         Loss D: 7.0525, loss G: 33.9755\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [6/200] Batch 11/12                         Loss D: 6.6652, loss G: 33.7866\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [7/200] Batch 11/12                         Loss D: 5.9610, loss G: 33.5841\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [8/200] Batch 11/12                         Loss D: 5.3604, loss G: 33.3886\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [9/200] Batch 11/12                         Loss D: 4.5830, loss G: 33.1135\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [10/200] Batch 11/12                         Loss D: 3.6156, loss G: 32.8249\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [11/200] Batch 11/12                         Loss D: 2.6802, loss G: 32.5281\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [12/200] Batch 11/12                         Loss D: 1.6459, loss G: 32.2032\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [13/200] Batch 11/12                         Loss D: 0.3192, loss G: 31.8268\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [14/200] Batch 11/12                         Loss D: -1.1770, loss G: 31.4167\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [15/200] Batch 11/12                         Loss D: -2.6527, loss G: 31.0312\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [16/200] Batch 11/12                         Loss D: -4.4291, loss G: 30.6393\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [17/200] Batch 11/12                         Loss D: -5.4453, loss G: 30.4049\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [18/200] Batch 11/12                         Loss D: -6.8648, loss G: 30.1199\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [19/200] Batch 11/12                         Loss D: -8.3237, loss G: 29.8397\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [20/200] Batch 11/12                         Loss D: -9.8214, loss G: 29.5829\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [21/200] Batch 11/12                         Loss D: -11.6653, loss G: 29.3072\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [22/200] Batch 11/12                         Loss D: -13.3785, loss G: 28.9797\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [23/200] Batch 11/12                         Loss D: -15.4147, loss G: 28.6703\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [24/200] Batch 11/12                         Loss D: -17.4261, loss G: 28.3604\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [25/200] Batch 11/12                         Loss D: -19.5298, loss G: 28.0734\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [26/200] Batch 11/12                         Loss D: -22.0725, loss G: 27.7186\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [27/200] Batch 11/12                         Loss D: -25.3333, loss G: 27.2637\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [28/200] Batch 11/12                         Loss D: -28.3219, loss G: 26.8927\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [29/200] Batch 11/12                         Loss D: -31.7459, loss G: 26.4804\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [30/200] Batch 11/12                         Loss D: -35.2552, loss G: 26.1343\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [31/200] Batch 11/12                         Loss D: -39.5012, loss G: 25.6520\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [32/200] Batch 11/12                         Loss D: -43.9387, loss G: 25.2123\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [33/200] Batch 11/12                         Loss D: -48.6028, loss G: 24.7684\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [34/200] Batch 11/12                         Loss D: -53.7206, loss G: 24.3535\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [35/200] Batch 11/12                         Loss D: -59.0443, loss G: 23.9173\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [36/200] Batch 11/12                         Loss D: -65.0123, loss G: 23.4363\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [37/200] Batch 11/12                         Loss D: -71.8596, loss G: 22.9191\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [38/200] Batch 11/12                         Loss D: -79.6995, loss G: 22.3430\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [39/200] Batch 11/12                         Loss D: -86.0724, loss G: 22.0333\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [40/200] Batch 11/12                         Loss D: -94.3822, loss G: 21.5335\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [41/200] Batch 11/12                         Loss D: -103.3771, loss G: 21.0313\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [42/200] Batch 11/12                         Loss D: -112.3386, loss G: 20.6203\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [43/200] Batch 11/12                         Loss D: -121.7591, loss G: 20.2222\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [44/200] Batch 11/12                         Loss D: -134.1792, loss G: 19.5779\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [45/200] Batch 11/12                         Loss D: -146.4253, loss G: 18.9906\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [46/200] Batch 11/12                         Loss D: -158.2115, loss G: 18.5994\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [47/200] Batch 11/12                         Loss D: -170.3242, loss G: 18.2518\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [48/200] Batch 11/12                         Loss D: -187.5505, loss G: 17.5628\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [49/200] Batch 11/12                         Loss D: -200.0511, loss G: 17.2577\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [50/200] Batch 11/12                         Loss D: -208.6792, loss G: 17.3876\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [51/200] Batch 11/12                         Loss D: -220.4180, loss G: 17.2775\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [52/200] Batch 11/12                         Loss D: -230.1729, loss G: 17.3071\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [53/200] Batch 11/12                         Loss D: -243.2780, loss G: 17.3446\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [54/200] Batch 11/12                         Loss D: -256.2215, loss G: 17.3118\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [55/200] Batch 11/12                         Loss D: -263.7497, loss G: 17.5268\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [56/200] Batch 11/12                         Loss D: -277.6910, loss G: 17.4864\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [57/200] Batch 11/12                         Loss D: -291.2017, loss G: 17.4254\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [58/200] Batch 11/12                         Loss D: -301.9673, loss G: 17.5255\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [59/200] Batch 11/12                         Loss D: -312.6074, loss G: 18.0307\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [60/200] Batch 11/12                         Loss D: -318.0764, loss G: 18.7226\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [61/200] Batch 11/12                         Loss D: -323.1433, loss G: 19.3893\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [62/200] Batch 11/12                         Loss D: -334.4595, loss G: 19.7420\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [63/200] Batch 11/12                         Loss D: -341.1901, loss G: 20.2618\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [64/200] Batch 11/12                         Loss D: -347.1450, loss G: 20.7564\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [65/200] Batch 11/12                         Loss D: -353.3170, loss G: 21.2339\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [66/200] Batch 11/12                         Loss D: -358.2740, loss G: 21.7146\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [67/200] Batch 11/12                         Loss D: -364.0641, loss G: 22.1491\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [68/200] Batch 11/12                         Loss D: -368.2066, loss G: 22.6284\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [69/200] Batch 11/12                         Loss D: -370.2507, loss G: 23.1630\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [70/200] Batch 11/12                         Loss D: -377.6379, loss G: 23.5212\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [71/200] Batch 11/12                         Loss D: -383.8548, loss G: 23.9638\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [72/200] Batch 11/12                         Loss D: -393.9213, loss G: 24.9321\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [73/200] Batch 11/12                         Loss D: -386.0414, loss G: 24.9778\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [74/200] Batch 11/12                         Loss D: -397.7413, loss G: 25.3985\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [75/200] Batch 11/12                         Loss D: -401.4303, loss G: 25.8076\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [76/200] Batch 11/12                         Loss D: -404.0768, loss G: 26.2493\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [77/200] Batch 11/12                         Loss D: -409.3616, loss G: 26.7139\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [78/200] Batch 11/12                         Loss D: -415.9941, loss G: 27.2975\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [79/200] Batch 11/12                         Loss D: -415.7968, loss G: 27.7278\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [80/200] Batch 11/12                         Loss D: -416.5349, loss G: 28.2595\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [81/200] Batch 11/12                         Loss D: -421.6048, loss G: 28.6881\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [82/200] Batch 11/12                         Loss D: -432.3652, loss G: 29.0329\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [83/200] Batch 11/12                         Loss D: -431.0832, loss G: 29.5297\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [84/200] Batch 11/12                         Loss D: -434.5231, loss G: 29.9634\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [85/200] Batch 11/12                         Loss D: -440.7556, loss G: 30.4036\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [86/200] Batch 11/12                         Loss D: -449.8026, loss G: 30.8271\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [87/200] Batch 11/12                         Loss D: -455.4588, loss G: 31.2945\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [88/200] Batch 11/12                         Loss D: -460.8744, loss G: 31.7795\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [89/200] Batch 11/12                         Loss D: -463.3144, loss G: 32.2974\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [90/200] Batch 11/12                         Loss D: -464.9984, loss G: 32.8110\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [91/200] Batch 11/12                         Loss D: -471.3637, loss G: 33.3171\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [92/200] Batch 11/12                         Loss D: -480.6120, loss G: 33.8291\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [93/200] Batch 11/12                         Loss D: -484.4463, loss G: 34.3476\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [94/200] Batch 11/12                         Loss D: -483.2360, loss G: 34.8701\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [95/200] Batch 11/12                         Loss D: -486.8911, loss G: 35.3934\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [96/200] Batch 11/12                         Loss D: -491.0682, loss G: 35.9173\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [97/200] Batch 11/12                         Loss D: -489.1882, loss G: 36.4090\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [98/200] Batch 11/12                         Loss D: -486.9334, loss G: 36.9137\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [99/200] Batch 11/12                         Loss D: -491.8255, loss G: 37.4931\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [100/200] Batch 11/12                         Loss D: -490.1271, loss G: 38.0227\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [101/200] Batch 11/12                         Loss D: -488.8250, loss G: 38.5065\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [102/200] Batch 11/12                         Loss D: -488.6501, loss G: 38.9221\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [103/200] Batch 11/12                         Loss D: -482.5212, loss G: 39.2878\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [104/200] Batch 11/12                         Loss D: -489.8473, loss G: 39.7756\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [105/200] Batch 11/12                         Loss D: -487.2841, loss G: 40.1360\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [106/200] Batch 11/12                         Loss D: -487.7890, loss G: 40.5107\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [107/200] Batch 11/12                         Loss D: -484.9729, loss G: 40.8226\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [108/200] Batch 11/12                         Loss D: -489.9532, loss G: 41.2219\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [109/200] Batch 11/12                         Loss D: -480.0798, loss G: 41.3931\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [110/200] Batch 11/12                         Loss D: -479.5866, loss G: 41.6819\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [111/200] Batch 11/12                         Loss D: -476.9167, loss G: 41.9275\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [112/200] Batch 11/12                         Loss D: -473.6693, loss G: 42.1617\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [113/200] Batch 11/12                         Loss D: -465.0006, loss G: 42.2957\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [114/200] Batch 11/12                         Loss D: -459.1875, loss G: 42.4582\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [115/200] Batch 11/12                         Loss D: -448.9340, loss G: 42.5236\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [116/200] Batch 11/12                         Loss D: -445.6183, loss G: 42.7012\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [117/200] Batch 11/12                         Loss D: -434.3609, loss G: 42.7026\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [118/200] Batch 11/12                         Loss D: -422.9251, loss G: 42.6823\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [119/200] Batch 11/12                         Loss D: -416.7748, loss G: 42.7436\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [120/200] Batch 11/12                         Loss D: -408.1343, loss G: 42.7487\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [121/200] Batch 11/12                         Loss D: -397.5778, loss G: 42.6868\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [122/200] Batch 11/12                         Loss D: -384.6050, loss G: 42.5518\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [123/200] Batch 11/12                         Loss D: -375.6814, loss G: 42.4967\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [124/200] Batch 11/12                         Loss D: -361.1838, loss G: 42.3015\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [125/200] Batch 11/12                         Loss D: -348.4820, loss G: 42.1337\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [126/200] Batch 11/12                         Loss D: -331.6448, loss G: 41.8491\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [127/200] Batch 11/12                         Loss D: -319.5456, loss G: 41.6641\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [128/200] Batch 11/12                         Loss D: -306.9331, loss G: 41.4459\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [129/200] Batch 11/12                         Loss D: -287.5928, loss G: 41.0536\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [130/200] Batch 11/12                         Loss D: -273.4132, loss G: 40.7693\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [131/200] Batch 11/12                         Loss D: -257.3959, loss G: 40.4371\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [132/200] Batch 11/12                         Loss D: -239.5270, loss G: 40.0367\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [133/200] Batch 11/12                         Loss D: -222.7726, loss G: 39.6479\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [134/200] Batch 11/12                         Loss D: -207.9496, loss G: 39.2805\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [135/200] Batch 11/12                         Loss D: -190.1839, loss G: 38.8294\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [136/200] Batch 11/12                         Loss D: -174.8822, loss G: 38.4497\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [137/200] Batch 11/12                         Loss D: -156.0756, loss G: 37.9619\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [138/200] Batch 11/12                         Loss D: -139.7242, loss G: 37.5389\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [139/200] Batch 11/12                         Loss D: -120.4140, loss G: 37.0452\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [140/200] Batch 11/12                         Loss D: -99.5882, loss G: 36.4928\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [141/200] Batch 11/12                         Loss D: -75.0353, loss G: 35.8164\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [142/200] Batch 11/12                         Loss D: -46.8291, loss G: 35.0861\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [143/200] Batch 11/12                         Loss D: -17.1616, loss G: 34.1224\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [144/200] Batch 11/12                         Loss D: 7.6892, loss G: 29.9438\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [145/200] Batch 11/12                         Loss D: 11.7062, loss G: 25.5439\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [146/200] Batch 11/12                         Loss D: -4.9531, loss G: 24.3930\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [147/200] Batch 11/12                         Loss D: -11.1780, loss G: 23.5401\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [148/200] Batch 11/12                         Loss D: -15.4250, loss G: 22.9699\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [149/200] Batch 11/12                         Loss D: -19.8825, loss G: 22.6519\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [150/200] Batch 11/12                         Loss D: -25.4554, loss G: 22.6003\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [151/200] Batch 11/12                         Loss D: -30.8486, loss G: 22.6381\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [152/200] Batch 11/12                         Loss D: -35.0189, loss G: 22.8914\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [153/200] Batch 11/12                         Loss D: -38.8272, loss G: 23.2288\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [154/200] Batch 11/12                         Loss D: -42.4730, loss G: 23.5172\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [155/200] Batch 11/12                         Loss D: -44.1776, loss G: 24.1195\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [156/200] Batch 11/12                         Loss D: -46.0309, loss G: 24.6040\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [157/200] Batch 11/12                         Loss D: -46.4061, loss G: 25.2303\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [158/200] Batch 11/12                         Loss D: -46.1946, loss G: 25.8861\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [159/200] Batch 11/12                         Loss D: -46.0355, loss G: 26.4988\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [160/200] Batch 11/12                         Loss D: -44.6796, loss G: 27.1649\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [161/200] Batch 11/12                         Loss D: -42.0536, loss G: 27.8488\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [162/200] Batch 11/12                         Loss D: -39.2273, loss G: 28.5134\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [163/200] Batch 11/12                         Loss D: -37.1341, loss G: 29.1354\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [164/200] Batch 11/12                         Loss D: -32.7913, loss G: 29.7654\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [165/200] Batch 11/12                         Loss D: -28.0712, loss G: 30.3532\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [166/200] Batch 11/12                         Loss D: -22.3795, loss G: 30.9064\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [167/200] Batch 11/12                         Loss D: -15.8378, loss G: 31.4137\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [168/200] Batch 11/12                         Loss D: -8.6930, loss G: 31.8940\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [169/200] Batch 11/12                         Loss D: -0.0739, loss G: 32.3320\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [170/200] Batch 11/12                         Loss D: 8.7848, loss G: 32.6924\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [171/200] Batch 11/12                         Loss D: 18.0059, loss G: 33.0130\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [172/200] Batch 11/12                         Loss D: 27.1603, loss G: 33.3129\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [173/200] Batch 11/12                         Loss D: 37.0314, loss G: 33.5787\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [174/200] Batch 11/12                         Loss D: 45.1509, loss G: 33.7978\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [175/200] Batch 11/12                         Loss D: 52.2022, loss G: 33.9889\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [176/200] Batch 11/12                         Loss D: 55.2716, loss G: 34.1385\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [177/200] Batch 11/12                         Loss D: 53.6421, loss G: 34.2449\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [178/200] Batch 11/12                         Loss D: 52.3083, loss G: 34.3650\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [179/200] Batch 11/12                         Loss D: 51.1285, loss G: 34.4332\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [180/200] Batch 11/12                         Loss D: 48.3242, loss G: 34.4375\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [181/200] Batch 11/12                         Loss D: 45.8554, loss G: 34.4678\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [182/200] Batch 11/12                         Loss D: 43.2034, loss G: 34.4140\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [183/200] Batch 11/12                         Loss D: 40.9300, loss G: 34.4039\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [184/200] Batch 11/12                         Loss D: 37.4377, loss G: 34.3740\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [185/200] Batch 11/12                         Loss D: 33.8765, loss G: 34.3108\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [186/200] Batch 11/12                         Loss D: 29.2860, loss G: 34.1682\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [187/200] Batch 11/12                         Loss D: 25.8150, loss G: 34.1170\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [188/200] Batch 11/12                         Loss D: 21.5055, loss G: 33.9899\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [189/200] Batch 11/12                         Loss D: 16.3526, loss G: 33.7785\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [190/200] Batch 11/12                         Loss D: 12.3418, loss G: 33.6225\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [191/200] Batch 11/12                         Loss D: 7.9021, loss G: 33.4728\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [192/200] Batch 11/12                         Loss D: 4.6308, loss G: 33.2562\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [193/200] Batch 11/12                         Loss D: 2.3811, loss G: 33.1059\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [194/200] Batch 11/12                         Loss D: 0.1550, loss G: 32.9156\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [195/200] Batch 11/12                         Loss D: -2.9521, loss G: 32.7219\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [196/200] Batch 11/12                         Loss D: -5.7974, loss G: 32.5365\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [197/200] Batch 11/12                         Loss D: -8.1741, loss G: 32.3245\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [198/200] Batch 11/12                         Loss D: -8.2858, loss G: 32.1317\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=1]                         Epoch [199/200] Batch 11/12                         Loss D: -5.8325, loss G: 32.0535\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [0/200] Batch 11/12                         Loss D: 9.4246, loss G: 17.1930\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [1/200] Batch 11/12                         Loss D: 9.3562, loss G: 17.1383\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [2/200] Batch 11/12                         Loss D: 9.2820, loss G: 17.0778\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [3/200] Batch 11/12                         Loss D: 9.1886, loss G: 17.0054\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [4/200] Batch 11/12                         Loss D: 9.0765, loss G: 16.9247\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [5/200] Batch 11/12                         Loss D: 8.9459, loss G: 16.8456\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [6/200] Batch 11/12                         Loss D: 8.8088, loss G: 16.7536\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [7/200] Batch 11/12                         Loss D: 8.6127, loss G: 16.6509\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [8/200] Batch 11/12                         Loss D: 8.3782, loss G: 16.5227\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [9/200] Batch 11/12                         Loss D: 8.1146, loss G: 16.3962\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [10/200] Batch 11/12                         Loss D: 7.8234, loss G: 16.2409\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [11/200] Batch 11/12                         Loss D: 7.4635, loss G: 16.0744\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [12/200] Batch 11/12                         Loss D: 7.0918, loss G: 15.8948\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [13/200] Batch 11/12                         Loss D: 6.6520, loss G: 15.6922\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [14/200] Batch 11/12                         Loss D: 6.1304, loss G: 15.4906\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [15/200] Batch 11/12                         Loss D: 5.5834, loss G: 15.2670\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [16/200] Batch 11/12                         Loss D: 4.8674, loss G: 15.0087\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [17/200] Batch 11/12                         Loss D: 4.0398, loss G: 14.7734\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [18/200] Batch 11/12                         Loss D: 3.0913, loss G: 14.6629\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [19/200] Batch 11/12                         Loss D: 1.9447, loss G: 14.5444\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [20/200] Batch 11/12                         Loss D: 0.7906, loss G: 14.4414\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [21/200] Batch 11/12                         Loss D: -0.5299, loss G: 14.3306\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [22/200] Batch 11/12                         Loss D: -1.9986, loss G: 14.2285\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [23/200] Batch 11/12                         Loss D: -3.4204, loss G: 14.1468\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [24/200] Batch 11/12                         Loss D: -5.1228, loss G: 14.0399\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [25/200] Batch 11/12                         Loss D: -6.7050, loss G: 13.9639\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [26/200] Batch 11/12                         Loss D: -8.5740, loss G: 13.8681\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [27/200] Batch 11/12                         Loss D: -10.1879, loss G: 13.8119\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [28/200] Batch 11/12                         Loss D: -12.0387, loss G: 13.7281\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [29/200] Batch 11/12                         Loss D: -13.7206, loss G: 13.6766\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [30/200] Batch 11/12                         Loss D: -15.8140, loss G: 13.6013\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [31/200] Batch 11/12                         Loss D: -17.9815, loss G: 13.5356\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [32/200] Batch 11/12                         Loss D: -20.0531, loss G: 13.5003\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [33/200] Batch 11/12                         Loss D: -22.2434, loss G: 13.4711\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [34/200] Batch 11/12                         Loss D: -24.7125, loss G: 13.4187\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [35/200] Batch 11/12                         Loss D: -27.1488, loss G: 13.3940\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [36/200] Batch 11/12                         Loss D: -29.8709, loss G: 13.3697\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [37/200] Batch 11/12                         Loss D: -32.5724, loss G: 13.3602\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [38/200] Batch 11/12                         Loss D: -35.6715, loss G: 13.3429\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [39/200] Batch 11/12                         Loss D: -38.8042, loss G: 13.3389\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [40/200] Batch 11/12                         Loss D: -42.1592, loss G: 13.3412\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [41/200] Batch 11/12                         Loss D: -44.9705, loss G: 13.3903\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [42/200] Batch 11/12                         Loss D: -48.9175, loss G: 13.3932\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [43/200] Batch 11/12                         Loss D: -51.7558, loss G: 13.4585\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [44/200] Batch 11/12                         Loss D: -55.7789, loss G: 13.4976\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [45/200] Batch 11/12                         Loss D: -58.5364, loss G: 13.5856\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [46/200] Batch 11/12                         Loss D: -61.4027, loss G: 13.6318\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [47/200] Batch 11/12                         Loss D: -63.6809, loss G: 13.6851\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [48/200] Batch 11/12                         Loss D: -65.8086, loss G: 13.7594\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [49/200] Batch 11/12                         Loss D: -69.0865, loss G: 13.8541\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [50/200] Batch 11/12                         Loss D: -73.1911, loss G: 13.9628\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [51/200] Batch 11/12                         Loss D: -77.5231, loss G: 14.0831\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [52/200] Batch 11/12                         Loss D: -82.4777, loss G: 14.2090\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [53/200] Batch 11/12                         Loss D: -85.6547, loss G: 14.3726\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [54/200] Batch 11/12                         Loss D: -87.2068, loss G: 14.5528\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [55/200] Batch 11/12                         Loss D: -90.7564, loss G: 14.7079\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [56/200] Batch 11/12                         Loss D: -93.9685, loss G: 14.8711\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [57/200] Batch 11/12                         Loss D: -98.2306, loss G: 15.1220\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [58/200] Batch 11/12                         Loss D: -100.2380, loss G: 15.2027\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [59/200] Batch 11/12                         Loss D: -102.6266, loss G: 15.3713\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [60/200] Batch 11/12                         Loss D: -103.6389, loss G: 15.5438\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [61/200] Batch 11/12                         Loss D: -108.0925, loss G: 15.7076\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [62/200] Batch 11/12                         Loss D: -108.2926, loss G: 15.8738\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [63/200] Batch 11/12                         Loss D: -111.1019, loss G: 16.0384\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [64/200] Batch 11/12                         Loss D: -113.6442, loss G: 16.2029\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [65/200] Batch 11/12                         Loss D: -114.6492, loss G: 16.3647\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [66/200] Batch 11/12                         Loss D: -118.9481, loss G: 16.5373\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [67/200] Batch 11/12                         Loss D: -120.3371, loss G: 16.6947\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [68/200] Batch 11/12                         Loss D: -122.1899, loss G: 16.8513\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [69/200] Batch 11/12                         Loss D: -123.0464, loss G: 16.9953\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [70/200] Batch 11/12                         Loss D: -122.3214, loss G: 17.1154\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [71/200] Batch 11/12                         Loss D: -123.3829, loss G: 17.2517\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [72/200] Batch 11/12                         Loss D: -124.1129, loss G: 17.3814\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [73/200] Batch 11/12                         Loss D: -121.2965, loss G: 17.4527\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [74/200] Batch 11/12                         Loss D: -121.6780, loss G: 17.5636\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [75/200] Batch 11/12                         Loss D: -120.5578, loss G: 17.6456\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [76/200] Batch 11/12                         Loss D: -118.9934, loss G: 17.7169\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [77/200] Batch 11/12                         Loss D: -117.4610, loss G: 17.7783\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [78/200] Batch 11/12                         Loss D: -115.9342, loss G: 17.8331\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [79/200] Batch 11/12                         Loss D: -110.6856, loss G: 17.8112\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [80/200] Batch 11/12                         Loss D: -108.5432, loss G: 17.8393\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [81/200] Batch 11/12                         Loss D: -108.9506, loss G: 17.9130\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [82/200] Batch 11/12                         Loss D: -103.5912, loss G: 17.8631\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [83/200] Batch 11/12                         Loss D: -99.2267, loss G: 17.8265\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [84/200] Batch 11/12                         Loss D: -97.5710, loss G: 17.8410\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [85/200] Batch 11/12                         Loss D: -93.7218, loss G: 17.8033\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [86/200] Batch 11/12                         Loss D: -89.6867, loss G: 17.7553\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [87/200] Batch 11/12                         Loss D: -86.1299, loss G: 17.7125\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [88/200] Batch 11/12                         Loss D: -82.9283, loss G: 17.6730\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [89/200] Batch 11/12                         Loss D: -78.4509, loss G: 17.6002\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [90/200] Batch 11/12                         Loss D: -73.1731, loss G: 17.5019\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [91/200] Batch 11/12                         Loss D: -68.6882, loss G: 17.4047\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [92/200] Batch 11/12                         Loss D: -63.9331, loss G: 17.2661\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [93/200] Batch 11/12                         Loss D: -57.8534, loss G: 17.1373\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [94/200] Batch 11/12                         Loss D: -51.4668, loss G: 17.0163\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [95/200] Batch 11/12                         Loss D: -45.9051, loss G: 16.9274\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [96/200] Batch 11/12                         Loss D: -40.1638, loss G: 16.8351\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [97/200] Batch 11/12                         Loss D: -34.0983, loss G: 16.7362\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [98/200] Batch 11/12                         Loss D: -28.0136, loss G: 16.6117\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [99/200] Batch 11/12                         Loss D: -23.0911, loss G: 16.5005\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [100/200] Batch 11/12                         Loss D: -17.2592, loss G: 16.3616\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [101/200] Batch 11/12                         Loss D: -12.8015, loss G: 16.2357\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [102/200] Batch 11/12                         Loss D: -10.8037, loss G: 16.1415\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [103/200] Batch 11/12                         Loss D: -10.8488, loss G: 16.1069\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [104/200] Batch 11/12                         Loss D: -10.6774, loss G: 16.1087\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [105/200] Batch 11/12                         Loss D: -10.5590, loss G: 16.1160\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [106/200] Batch 11/12                         Loss D: -10.1302, loss G: 16.1083\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [107/200] Batch 11/12                         Loss D: -9.7675, loss G: 16.1101\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [108/200] Batch 11/12                         Loss D: -9.5568, loss G: 16.1013\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [109/200] Batch 11/12                         Loss D: -9.2191, loss G: 16.0988\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [110/200] Batch 11/12                         Loss D: -8.9648, loss G: 16.0999\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [111/200] Batch 11/12                         Loss D: -8.4560, loss G: 16.0967\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [112/200] Batch 11/12                         Loss D: -8.0433, loss G: 16.0965\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [113/200] Batch 11/12                         Loss D: -7.5800, loss G: 16.0883\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [114/200] Batch 11/12                         Loss D: -7.3748, loss G: 16.0839\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [115/200] Batch 11/12                         Loss D: -7.0701, loss G: 16.0855\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [116/200] Batch 11/12                         Loss D: -6.7046, loss G: 16.0833\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [117/200] Batch 11/12                         Loss D: -6.3323, loss G: 16.0863\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [118/200] Batch 11/12                         Loss D: -5.9586, loss G: 16.0862\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [119/200] Batch 11/12                         Loss D: -5.7300, loss G: 16.0871\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [120/200] Batch 11/12                         Loss D: -5.1971, loss G: 16.1018\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [121/200] Batch 11/12                         Loss D: -4.9076, loss G: 16.0944\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [122/200] Batch 11/12                         Loss D: -4.8276, loss G: 16.0993\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [123/200] Batch 11/12                         Loss D: -4.4042, loss G: 16.1016\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [124/200] Batch 11/12                         Loss D: -3.8244, loss G: 16.1011\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [125/200] Batch 11/12                         Loss D: -3.8022, loss G: 16.1094\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [126/200] Batch 11/12                         Loss D: -3.5283, loss G: 16.1118\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [127/200] Batch 11/12                         Loss D: -3.1505, loss G: 16.1169\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [128/200] Batch 11/12                         Loss D: -2.8536, loss G: 16.1216\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [129/200] Batch 11/12                         Loss D: -2.8141, loss G: 16.1360\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [130/200] Batch 11/12                         Loss D: -2.4061, loss G: 16.1459\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [131/200] Batch 11/12                         Loss D: -2.2317, loss G: 16.1467\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [132/200] Batch 11/12                         Loss D: -2.0200, loss G: 16.1548\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [133/200] Batch 11/12                         Loss D: -1.7178, loss G: 16.1626\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [134/200] Batch 11/12                         Loss D: -1.7990, loss G: 16.1741\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [135/200] Batch 11/12                         Loss D: -1.6167, loss G: 16.1743\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [136/200] Batch 11/12                         Loss D: -1.5467, loss G: 16.1863\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [137/200] Batch 11/12                         Loss D: -1.3489, loss G: 16.1902\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [138/200] Batch 11/12                         Loss D: -1.2816, loss G: 16.1991\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [139/200] Batch 11/12                         Loss D: -1.2846, loss G: 16.2175\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [140/200] Batch 11/12                         Loss D: -1.2300, loss G: 16.2137\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [141/200] Batch 11/12                         Loss D: -1.1281, loss G: 16.2204\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [142/200] Batch 11/12                         Loss D: -1.1921, loss G: 16.2353\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [143/200] Batch 11/12                         Loss D: -1.1272, loss G: 16.2332\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [144/200] Batch 11/12                         Loss D: -1.1053, loss G: 16.2389\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [145/200] Batch 11/12                         Loss D: -1.1805, loss G: 16.2476\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [146/200] Batch 11/12                         Loss D: -1.3652, loss G: 16.2580\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [147/200] Batch 11/12                         Loss D: -1.2795, loss G: 16.2579\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [148/200] Batch 11/12                         Loss D: -1.4663, loss G: 16.2615\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [149/200] Batch 11/12                         Loss D: -1.4688, loss G: 16.2680\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [150/200] Batch 11/12                         Loss D: -1.5502, loss G: 16.2731\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [151/200] Batch 11/12                         Loss D: -1.6859, loss G: 16.2762\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [152/200] Batch 11/12                         Loss D: -1.6152, loss G: 16.2867\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [153/200] Batch 11/12                         Loss D: -1.9458, loss G: 16.2838\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [154/200] Batch 11/12                         Loss D: -2.1147, loss G: 16.2893\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [155/200] Batch 11/12                         Loss D: -2.1679, loss G: 16.2915\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [156/200] Batch 11/12                         Loss D: -2.3746, loss G: 16.2919\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [157/200] Batch 11/12                         Loss D: -2.6343, loss G: 16.2926\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [158/200] Batch 11/12                         Loss D: -2.7944, loss G: 16.2966\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [159/200] Batch 11/12                         Loss D: -2.8767, loss G: 16.3023\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [160/200] Batch 11/12                         Loss D: -3.2471, loss G: 16.3021\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [161/200] Batch 11/12                         Loss D: -3.3492, loss G: 16.3009\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [162/200] Batch 11/12                         Loss D: -3.5133, loss G: 16.3067\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [163/200] Batch 11/12                         Loss D: -3.6595, loss G: 16.3064\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [164/200] Batch 11/12                         Loss D: -3.9693, loss G: 16.3048\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [165/200] Batch 11/12                         Loss D: -4.0672, loss G: 16.3078\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [166/200] Batch 11/12                         Loss D: -4.3940, loss G: 16.3029\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [167/200] Batch 11/12                         Loss D: -4.5929, loss G: 16.3014\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [168/200] Batch 11/12                         Loss D: -4.8333, loss G: 16.3023\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [169/200] Batch 11/12                         Loss D: -5.0190, loss G: 16.2999\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [170/200] Batch 11/12                         Loss D: -5.2771, loss G: 16.3066\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [171/200] Batch 11/12                         Loss D: -5.5827, loss G: 16.3034\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [172/200] Batch 11/12                         Loss D: -5.8497, loss G: 16.3083\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [173/200] Batch 11/12                         Loss D: -6.0382, loss G: 16.3063\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [174/200] Batch 11/12                         Loss D: -6.2001, loss G: 16.2980\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [175/200] Batch 11/12                         Loss D: -6.4048, loss G: 16.2975\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [176/200] Batch 11/12                         Loss D: -6.5529, loss G: 16.2993\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [177/200] Batch 11/12                         Loss D: -6.8192, loss G: 16.2973\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [178/200] Batch 11/12                         Loss D: -6.9581, loss G: 16.3002\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [179/200] Batch 11/12                         Loss D: -7.1226, loss G: 16.3052\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [180/200] Batch 11/12                         Loss D: -7.5637, loss G: 16.2831\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [181/200] Batch 11/12                         Loss D: -8.7562, loss G: 16.1935\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [182/200] Batch 11/12                         Loss D: -9.0548, loss G: 16.1836\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [183/200] Batch 11/12                         Loss D: -9.1837, loss G: 16.1868\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [184/200] Batch 11/12                         Loss D: -9.4730, loss G: 16.1789\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [185/200] Batch 11/12                         Loss D: -9.4568, loss G: 16.1825\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [186/200] Batch 11/12                         Loss D: -9.5123, loss G: 16.1924\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [187/200] Batch 11/12                         Loss D: -9.6575, loss G: 16.1895\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [188/200] Batch 11/12                         Loss D: -9.7120, loss G: 16.1943\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [189/200] Batch 11/12                         Loss D: -9.6718, loss G: 16.1999\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [190/200] Batch 11/12                         Loss D: -9.7100, loss G: 16.1910\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [191/200] Batch 11/12                         Loss D: -9.6035, loss G: 16.1997\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [192/200] Batch 11/12                         Loss D: -9.6258, loss G: 16.1946\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [193/200] Batch 11/12                         Loss D: -9.6807, loss G: 16.2032\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [194/200] Batch 11/12                         Loss D: -9.5639, loss G: 16.1980\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [195/200] Batch 11/12                         Loss D: -9.6170, loss G: 16.1985\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [196/200] Batch 11/12                         Loss D: -9.6650, loss G: 16.2033\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [197/200] Batch 11/12                         Loss D: -9.4922, loss G: 16.1983\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [198/200] Batch 11/12                         Loss D: -9.6071, loss G: 16.2006\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.5]                         Epoch [199/200] Batch 11/12                         Loss D: -9.5606, loss G: 16.2030\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [0/200] Batch 11/12                         Loss D: 9.3829, loss G: 3.4244\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [1/200] Batch 11/12                         Loss D: 9.4170, loss G: 3.3684\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [2/200] Batch 11/12                         Loss D: 9.4579, loss G: 3.3253\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [3/200] Batch 11/12                         Loss D: 9.5121, loss G: 3.2919\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [4/200] Batch 11/12                         Loss D: 9.5542, loss G: 3.2638\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [5/200] Batch 11/12                         Loss D: 9.6111, loss G: 3.2353\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [6/200] Batch 11/12                         Loss D: 9.6952, loss G: 3.1998\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [7/200] Batch 11/12                         Loss D: 9.7576, loss G: 3.1639\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [8/200] Batch 11/12                         Loss D: 9.8386, loss G: 3.1205\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [9/200] Batch 11/12                         Loss D: 9.8890, loss G: 3.0860\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [10/200] Batch 11/12                         Loss D: 9.9058, loss G: 3.0607\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [11/200] Batch 11/12                         Loss D: 9.8755, loss G: 3.0440\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [12/200] Batch 11/12                         Loss D: 9.8206, loss G: 3.0309\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [13/200] Batch 11/12                         Loss D: 9.7296, loss G: 3.0184\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [14/200] Batch 11/12                         Loss D: 9.5607, loss G: 3.0096\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [15/200] Batch 11/12                         Loss D: 9.3685, loss G: 3.0048\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [16/200] Batch 11/12                         Loss D: 9.1545, loss G: 3.0003\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [17/200] Batch 11/12                         Loss D: 8.9219, loss G: 2.9899\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [18/200] Batch 11/12                         Loss D: 8.6341, loss G: 2.9833\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [19/200] Batch 11/12                         Loss D: 8.3253, loss G: 2.9901\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [20/200] Batch 11/12                         Loss D: 7.9809, loss G: 3.0180\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [21/200] Batch 11/12                         Loss D: 7.5806, loss G: 3.0491\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [22/200] Batch 11/12                         Loss D: 7.1302, loss G: 3.0832\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [23/200] Batch 11/12                         Loss D: 6.5889, loss G: 3.1177\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [24/200] Batch 11/12                         Loss D: 6.1212, loss G: 3.1520\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [25/200] Batch 11/12                         Loss D: 5.6284, loss G: 3.1866\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [26/200] Batch 11/12                         Loss D: 5.1602, loss G: 3.2207\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [27/200] Batch 11/12                         Loss D: 4.6721, loss G: 3.2550\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [28/200] Batch 11/12                         Loss D: 4.2599, loss G: 3.2872\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [29/200] Batch 11/12                         Loss D: 3.9716, loss G: 3.3129\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [30/200] Batch 11/12                         Loss D: 3.7159, loss G: 3.3399\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [31/200] Batch 11/12                         Loss D: 3.4083, loss G: 3.3632\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [32/200] Batch 11/12                         Loss D: 3.3404, loss G: 3.3841\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [33/200] Batch 11/12                         Loss D: 3.1249, loss G: 3.4009\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [34/200] Batch 11/12                         Loss D: 3.1511, loss G: 3.4148\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [35/200] Batch 11/12                         Loss D: 3.1278, loss G: 3.4253\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [36/200] Batch 11/12                         Loss D: 3.1018, loss G: 3.4331\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [37/200] Batch 11/12                         Loss D: 3.2174, loss G: 3.4375\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [38/200] Batch 11/12                         Loss D: 3.4038, loss G: 3.4388\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [39/200] Batch 11/12                         Loss D: 3.6222, loss G: 3.4399\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [40/200] Batch 11/12                         Loss D: 3.8672, loss G: 3.4375\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [41/200] Batch 11/12                         Loss D: 4.4447, loss G: 3.4102\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [42/200] Batch 11/12                         Loss D: 5.1653, loss G: 3.3744\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [43/200] Batch 11/12                         Loss D: 5.9918, loss G: 3.3536\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [44/200] Batch 11/12                         Loss D: 6.5055, loss G: 3.3569\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [45/200] Batch 11/12                         Loss D: 6.8490, loss G: 3.3720\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [46/200] Batch 11/12                         Loss D: 7.1509, loss G: 3.3914\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [47/200] Batch 11/12                         Loss D: 7.4325, loss G: 3.4113\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [48/200] Batch 11/12                         Loss D: 7.7364, loss G: 3.4314\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [49/200] Batch 11/12                         Loss D: 7.9982, loss G: 3.4515\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [50/200] Batch 11/12                         Loss D: 8.2458, loss G: 3.4702\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [51/200] Batch 11/12                         Loss D: 8.5078, loss G: 3.4853\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [52/200] Batch 11/12                         Loss D: 8.8261, loss G: 3.4983\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [53/200] Batch 11/12                         Loss D: 8.9423, loss G: 3.5175\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [54/200] Batch 11/12                         Loss D: 8.8315, loss G: 3.5374\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [55/200] Batch 11/12                         Loss D: 8.4919, loss G: 3.5574\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [56/200] Batch 11/12                         Loss D: 8.2028, loss G: 3.5744\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [57/200] Batch 11/12                         Loss D: 7.8744, loss G: 3.5892\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [58/200] Batch 11/12                         Loss D: 7.6333, loss G: 3.6028\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [59/200] Batch 11/12                         Loss D: 7.3938, loss G: 3.6147\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [60/200] Batch 11/12                         Loss D: 7.2346, loss G: 3.6249\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [61/200] Batch 11/12                         Loss D: 7.0966, loss G: 3.6323\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [62/200] Batch 11/12                         Loss D: 6.9698, loss G: 3.6376\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [63/200] Batch 11/12                         Loss D: 6.8389, loss G: 3.6407\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [64/200] Batch 11/12                         Loss D: 6.7446, loss G: 3.6403\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [65/200] Batch 11/12                         Loss D: 6.6637, loss G: 3.6366\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [66/200] Batch 11/12                         Loss D: 6.6360, loss G: 3.6310\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [67/200] Batch 11/12                         Loss D: 6.5533, loss G: 3.6255\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [68/200] Batch 11/12                         Loss D: 6.5753, loss G: 3.6185\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [69/200] Batch 11/12                         Loss D: 6.5220, loss G: 3.6100\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [70/200] Batch 11/12                         Loss D: 6.5040, loss G: 3.6029\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [71/200] Batch 11/12                         Loss D: 6.4752, loss G: 3.5946\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [72/200] Batch 11/12                         Loss D: 6.4288, loss G: 3.5860\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [73/200] Batch 11/12                         Loss D: 6.3961, loss G: 3.5741\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [74/200] Batch 11/12                         Loss D: 6.4300, loss G: 3.5584\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [75/200] Batch 11/12                         Loss D: 6.2998, loss G: 3.5432\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [76/200] Batch 11/12                         Loss D: 6.1859, loss G: 3.5302\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [77/200] Batch 11/12                         Loss D: 6.0243, loss G: 3.5167\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [78/200] Batch 11/12                         Loss D: 5.7789, loss G: 3.5079\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [79/200] Batch 11/12                         Loss D: 5.5500, loss G: 3.5037\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [80/200] Batch 11/12                         Loss D: 5.2546, loss G: 3.5005\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [81/200] Batch 11/12                         Loss D: 4.9188, loss G: 3.4979\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [82/200] Batch 11/12                         Loss D: 4.6479, loss G: 3.4964\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [83/200] Batch 11/12                         Loss D: 4.5289, loss G: 3.4966\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [84/200] Batch 11/12                         Loss D: 4.4991, loss G: 3.4971\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [85/200] Batch 11/12                         Loss D: 4.5485, loss G: 3.4975\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [86/200] Batch 11/12                         Loss D: 4.6338, loss G: 3.4979\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [87/200] Batch 11/12                         Loss D: 4.9599, loss G: 3.4910\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [88/200] Batch 11/12                         Loss D: 8.4349, loss G: 3.3811\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [89/200] Batch 11/12                         Loss D: 12.2448, loss G: 3.2030\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [90/200] Batch 11/12                         Loss D: 14.1467, loss G: 3.0892\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [91/200] Batch 11/12                         Loss D: 14.3482, loss G: 3.0312\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [92/200] Batch 11/12                         Loss D: 13.8044, loss G: 3.0095\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [93/200] Batch 11/12                         Loss D: 12.2679, loss G: 3.0155\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [94/200] Batch 11/12                         Loss D: 9.9827, loss G: 3.0619\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [95/200] Batch 11/12                         Loss D: 7.4983, loss G: 3.1246\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [96/200] Batch 11/12                         Loss D: 4.8905, loss G: 3.2057\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [97/200] Batch 11/12                         Loss D: 1.8779, loss G: 3.2994\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [98/200] Batch 11/12                         Loss D: -1.4559, loss G: 3.3902\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [99/200] Batch 11/12                         Loss D: -4.6167, loss G: 3.4717\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [100/200] Batch 11/12                         Loss D: -7.5535, loss G: 3.5417\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [101/200] Batch 11/12                         Loss D: -9.8098, loss G: 3.5961\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [102/200] Batch 11/12                         Loss D: -12.1572, loss G: 3.6386\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [103/200] Batch 11/12                         Loss D: -13.9014, loss G: 3.6684\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [104/200] Batch 11/12                         Loss D: -15.3644, loss G: 3.6880\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [105/200] Batch 11/12                         Loss D: -16.1364, loss G: 3.6954\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [106/200] Batch 11/12                         Loss D: -16.7551, loss G: 3.6987\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [107/200] Batch 11/12                         Loss D: -16.9798, loss G: 3.6972\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [108/200] Batch 11/12                         Loss D: -17.4102, loss G: 3.7040\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [109/200] Batch 11/12                         Loss D: -18.3358, loss G: 3.7078\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [110/200] Batch 11/12                         Loss D: -18.5798, loss G: 3.7060\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [111/200] Batch 11/12                         Loss D: -18.2396, loss G: 3.6989\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [112/200] Batch 11/12                         Loss D: -18.0105, loss G: 3.6898\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [113/200] Batch 11/12                         Loss D: -18.2837, loss G: 3.6954\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [114/200] Batch 11/12                         Loss D: -18.5089, loss G: 3.7059\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [115/200] Batch 11/12                         Loss D: -18.3818, loss G: 3.7116\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [116/200] Batch 11/12                         Loss D: -17.5654, loss G: 3.7010\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [117/200] Batch 11/12                         Loss D: -16.0289, loss G: 3.6773\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [118/200] Batch 11/12                         Loss D: -15.6044, loss G: 3.6793\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [119/200] Batch 11/12                         Loss D: -14.9931, loss G: 3.6878\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [120/200] Batch 11/12                         Loss D: -14.4392, loss G: 3.6957\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [121/200] Batch 11/12                         Loss D: -14.1365, loss G: 3.7038\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [122/200] Batch 11/12                         Loss D: -13.8170, loss G: 3.7117\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [123/200] Batch 11/12                         Loss D: -13.3312, loss G: 3.7177\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [124/200] Batch 11/12                         Loss D: -12.9215, loss G: 3.7238\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [125/200] Batch 11/12                         Loss D: -12.4166, loss G: 3.7287\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [126/200] Batch 11/12                         Loss D: -11.8460, loss G: 3.7329\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [127/200] Batch 11/12                         Loss D: -11.1851, loss G: 3.7363\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [128/200] Batch 11/12                         Loss D: -10.1787, loss G: 3.7378\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [129/200] Batch 11/12                         Loss D: -9.1535, loss G: 3.7391\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [130/200] Batch 11/12                         Loss D: -8.2319, loss G: 3.7391\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [131/200] Batch 11/12                         Loss D: -7.7068, loss G: 3.7405\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [132/200] Batch 11/12                         Loss D: -7.1060, loss G: 3.7401\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [133/200] Batch 11/12                         Loss D: -6.4907, loss G: 3.7401\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [134/200] Batch 11/12                         Loss D: -5.8916, loss G: 3.7392\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [135/200] Batch 11/12                         Loss D: -5.4919, loss G: 3.7393\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [136/200] Batch 11/12                         Loss D: -4.7448, loss G: 3.7370\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [137/200] Batch 11/12                         Loss D: -4.1593, loss G: 3.7348\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [138/200] Batch 11/12                         Loss D: -3.6954, loss G: 3.7337\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [139/200] Batch 11/12                         Loss D: -3.1107, loss G: 3.7310\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [140/200] Batch 11/12                         Loss D: -2.6870, loss G: 3.7295\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [141/200] Batch 11/12                         Loss D: -2.4897, loss G: 3.7290\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [142/200] Batch 11/12                         Loss D: -2.1378, loss G: 3.7284\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [143/200] Batch 11/12                         Loss D: -1.8506, loss G: 3.7286\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [144/200] Batch 11/12                         Loss D: -1.7251, loss G: 3.7301\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [145/200] Batch 11/12                         Loss D: -1.3795, loss G: 3.7306\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [146/200] Batch 11/12                         Loss D: -1.0735, loss G: 3.7318\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [147/200] Batch 11/12                         Loss D: -0.7050, loss G: 3.7322\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [148/200] Batch 11/12                         Loss D: -0.4378, loss G: 3.7329\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [149/200] Batch 11/12                         Loss D: -0.2092, loss G: 3.7334\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [150/200] Batch 11/12                         Loss D: 0.0589, loss G: 3.7340\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [151/200] Batch 11/12                         Loss D: 0.3422, loss G: 3.7350\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [152/200] Batch 11/12                         Loss D: 0.5733, loss G: 3.7355\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [153/200] Batch 11/12                         Loss D: 0.7926, loss G: 3.7360\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [154/200] Batch 11/12                         Loss D: 1.0237, loss G: 3.7370\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [155/200] Batch 11/12                         Loss D: 1.2990, loss G: 3.7375\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [156/200] Batch 11/12                         Loss D: 1.4868, loss G: 3.7378\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [157/200] Batch 11/12                         Loss D: 1.6372, loss G: 3.7383\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [158/200] Batch 11/12                         Loss D: 1.9134, loss G: 3.7391\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [159/200] Batch 11/12                         Loss D: 2.1615, loss G: 3.7393\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [160/200] Batch 11/12                         Loss D: 2.2752, loss G: 3.7401\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [161/200] Batch 11/12                         Loss D: 2.4924, loss G: 3.7405\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [162/200] Batch 11/12                         Loss D: 2.7485, loss G: 3.7405\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [163/200] Batch 11/12                         Loss D: 2.9218, loss G: 3.7414\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [164/200] Batch 11/12                         Loss D: 3.1493, loss G: 3.7417\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [165/200] Batch 11/12                         Loss D: 3.3255, loss G: 3.7419\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [166/200] Batch 11/12                         Loss D: 3.6083, loss G: 3.7420\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [167/200] Batch 11/12                         Loss D: 3.8683, loss G: 3.7422\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [168/200] Batch 11/12                         Loss D: 4.1385, loss G: 3.7425\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [169/200] Batch 11/12                         Loss D: 4.4044, loss G: 3.7424\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [170/200] Batch 11/12                         Loss D: 4.7590, loss G: 3.7425\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [171/200] Batch 11/12                         Loss D: 5.0314, loss G: 3.7423\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [172/200] Batch 11/12                         Loss D: 5.3331, loss G: 3.7420\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [173/200] Batch 11/12                         Loss D: 5.6749, loss G: 3.7419\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [174/200] Batch 11/12                         Loss D: 6.0358, loss G: 3.7414\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [175/200] Batch 11/12                         Loss D: 6.5366, loss G: 3.7404\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [176/200] Batch 11/12                         Loss D: 8.2420, loss G: 3.7250\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [177/200] Batch 11/12                         Loss D: 10.5340, loss G: 3.6965\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [178/200] Batch 11/12                         Loss D: 10.4963, loss G: 3.6945\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [179/200] Batch 11/12                         Loss D: 10.6445, loss G: 3.6946\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [180/200] Batch 11/12                         Loss D: 10.6410, loss G: 3.6940\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [181/200] Batch 11/12                         Loss D: 10.6042, loss G: 3.6944\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [182/200] Batch 11/12                         Loss D: 10.3893, loss G: 3.6937\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [183/200] Batch 11/12                         Loss D: 10.6135, loss G: 3.6927\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [184/200] Batch 11/12                         Loss D: 10.5646, loss G: 3.6928\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [185/200] Batch 11/12                         Loss D: 10.5998, loss G: 3.6934\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [186/200] Batch 11/12                         Loss D: 10.5285, loss G: 3.6930\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [187/200] Batch 11/12                         Loss D: 10.4496, loss G: 3.6934\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [188/200] Batch 11/12                         Loss D: 10.5758, loss G: 3.6929\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [189/200] Batch 11/12                         Loss D: 10.5352, loss G: 3.6923\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [190/200] Batch 11/12                         Loss D: 10.5829, loss G: 3.6925\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [191/200] Batch 11/12                         Loss D: 10.4889, loss G: 3.6923\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [192/200] Batch 11/12                         Loss D: 10.5085, loss G: 3.6929\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [193/200] Batch 11/12                         Loss D: 10.4372, loss G: 3.6924\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [194/200] Batch 11/12                         Loss D: 10.4771, loss G: 3.6928\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [195/200] Batch 11/12                         Loss D: 10.4311, loss G: 3.6924\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [196/200] Batch 11/12                         Loss D: 10.4340, loss G: 3.6926\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [197/200] Batch 11/12                         Loss D: 10.3539, loss G: 3.6929\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [198/200] Batch 11/12                         Loss D: 10.4474, loss G: 3.6925\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=10, lambda_mean=0.1]                         Epoch [199/200] Batch 11/12                         Loss D: 10.4835, loss G: 3.6922\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [0/200] Batch 11/12                         Loss D: 1.3034, loss G: 34.8907\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [1/200] Batch 11/12                         Loss D: 1.1627, loss G: 34.7744\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [2/200] Batch 11/12                         Loss D: 1.0066, loss G: 34.6552\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [3/200] Batch 11/12                         Loss D: 0.8386, loss G: 34.5274\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [4/200] Batch 11/12                         Loss D: 0.6179, loss G: 34.3744\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [5/200] Batch 11/12                         Loss D: 0.3592, loss G: 34.2131\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [6/200] Batch 11/12                         Loss D: 0.0343, loss G: 33.9977\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [7/200] Batch 11/12                         Loss D: -0.3514, loss G: 33.7712\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [8/200] Batch 11/12                         Loss D: -0.8701, loss G: 33.4923\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [9/200] Batch 11/12                         Loss D: -1.4848, loss G: 33.1705\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [10/200] Batch 11/12                         Loss D: -2.2427, loss G: 32.8060\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [11/200] Batch 11/12                         Loss D: -3.1248, loss G: 32.4357\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [12/200] Batch 11/12                         Loss D: -4.1601, loss G: 32.0377\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [13/200] Batch 11/12                         Loss D: -5.3728, loss G: 31.5837\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [14/200] Batch 11/12                         Loss D: -6.6308, loss G: 31.1605\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [15/200] Batch 11/12                         Loss D: -8.0881, loss G: 30.6910\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [16/200] Batch 11/12                         Loss D: -9.5960, loss G: 30.3854\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [17/200] Batch 11/12                         Loss D: -11.2271, loss G: 30.1482\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [18/200] Batch 11/12                         Loss D: -13.3459, loss G: 29.8382\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [19/200] Batch 11/12                         Loss D: -14.9397, loss G: 29.6633\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [20/200] Batch 11/12                         Loss D: -16.9334, loss G: 29.4618\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [21/200] Batch 11/12                         Loss D: -18.9289, loss G: 29.2899\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [22/200] Batch 11/12                         Loss D: -21.2342, loss G: 29.0803\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [23/200] Batch 11/12                         Loss D: -23.7731, loss G: 28.8911\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [24/200] Batch 11/12                         Loss D: -26.6484, loss G: 28.6995\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [25/200] Batch 11/12                         Loss D: -29.5941, loss G: 28.5073\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [26/200] Batch 11/12                         Loss D: -33.0513, loss G: 28.3080\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [27/200] Batch 11/12                         Loss D: -36.6294, loss G: 28.1227\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [28/200] Batch 11/12                         Loss D: -40.3298, loss G: 27.9610\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [29/200] Batch 11/12                         Loss D: -44.9537, loss G: 27.7785\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [30/200] Batch 11/12                         Loss D: -49.5037, loss G: 27.6307\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [31/200] Batch 11/12                         Loss D: -55.1238, loss G: 27.4248\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [32/200] Batch 11/12                         Loss D: -60.4578, loss G: 27.2702\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [33/200] Batch 11/12                         Loss D: -67.0103, loss G: 27.0494\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [34/200] Batch 11/12                         Loss D: -73.9742, loss G: 26.8469\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [35/200] Batch 11/12                         Loss D: -80.1473, loss G: 26.7545\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [36/200] Batch 11/12                         Loss D: -89.3367, loss G: 26.4843\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [37/200] Batch 11/12                         Loss D: -96.4258, loss G: 26.4266\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [38/200] Batch 11/12                         Loss D: -105.0681, loss G: 26.2905\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [39/200] Batch 11/12                         Loss D: -114.1044, loss G: 26.2045\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [40/200] Batch 11/12                         Loss D: -123.1727, loss G: 26.1305\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [41/200] Batch 11/12                         Loss D: -133.3915, loss G: 26.0812\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [42/200] Batch 11/12                         Loss D: -143.9471, loss G: 26.0339\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [43/200] Batch 11/12                         Loss D: -154.3703, loss G: 26.0327\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [44/200] Batch 11/12                         Loss D: -165.4667, loss G: 26.0524\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [45/200] Batch 11/12                         Loss D: -177.4919, loss G: 26.0598\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [46/200] Batch 11/12                         Loss D: -188.7603, loss G: 26.1648\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [47/200] Batch 11/12                         Loss D: -200.2360, loss G: 26.2985\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [48/200] Batch 11/12                         Loss D: -208.7434, loss G: 26.5617\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [49/200] Batch 11/12                         Loss D: -221.9584, loss G: 26.6670\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [50/200] Batch 11/12                         Loss D: -235.9910, loss G: 26.7880\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [51/200] Batch 11/12                         Loss D: -246.8118, loss G: 27.0482\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [52/200] Batch 11/12                         Loss D: -252.8649, loss G: 27.3889\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [53/200] Batch 11/12                         Loss D: -264.7097, loss G: 27.5988\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [54/200] Batch 11/12                         Loss D: -272.8466, loss G: 27.9208\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [55/200] Batch 11/12                         Loss D: -280.4256, loss G: 28.2259\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [56/200] Batch 11/12                         Loss D: -284.1860, loss G: 28.5943\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [57/200] Batch 11/12                         Loss D: -294.7113, loss G: 28.8246\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [58/200] Batch 11/12                         Loss D: -298.7262, loss G: 29.1691\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [59/200] Batch 11/12                         Loss D: -301.7754, loss G: 29.4731\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [60/200] Batch 11/12                         Loss D: -305.1445, loss G: 29.8023\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [61/200] Batch 11/12                         Loss D: -308.2313, loss G: 30.0908\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [62/200] Batch 11/12                         Loss D: -308.0234, loss G: 30.3602\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [63/200] Batch 11/12                         Loss D: -310.6852, loss G: 30.6241\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [64/200] Batch 11/12                         Loss D: -309.7967, loss G: 30.8593\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [65/200] Batch 11/12                         Loss D: -309.2791, loss G: 31.0140\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [66/200] Batch 11/12                         Loss D: -309.9714, loss G: 31.1988\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [67/200] Batch 11/12                         Loss D: -312.2800, loss G: 31.4138\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [68/200] Batch 11/12                         Loss D: -311.4975, loss G: 31.6551\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [69/200] Batch 11/12                         Loss D: -315.1308, loss G: 31.9203\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [70/200] Batch 11/12                         Loss D: -317.9895, loss G: 32.2540\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [71/200] Batch 11/12                         Loss D: -313.3884, loss G: 32.5379\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [72/200] Batch 11/12                         Loss D: -312.7126, loss G: 32.8537\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [73/200] Batch 11/12                         Loss D: -311.0036, loss G: 33.1273\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [74/200] Batch 11/12                         Loss D: -310.3578, loss G: 33.3925\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [75/200] Batch 11/12                         Loss D: -310.5304, loss G: 33.6566\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [76/200] Batch 11/12                         Loss D: -303.9204, loss G: 33.8860\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [77/200] Batch 11/12                         Loss D: -301.4815, loss G: 34.1083\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [78/200] Batch 11/12                         Loss D: -296.0362, loss G: 34.2934\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [79/200] Batch 11/12                         Loss D: -293.1835, loss G: 34.5086\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [80/200] Batch 11/12                         Loss D: -292.2233, loss G: 34.7758\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [81/200] Batch 11/12                         Loss D: -294.3791, loss G: 35.0725\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [82/200] Batch 11/12                         Loss D: -296.2360, loss G: 35.3296\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [83/200] Batch 11/12                         Loss D: -297.3111, loss G: 35.6110\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [84/200] Batch 11/12                         Loss D: -290.6541, loss G: 35.7887\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [85/200] Batch 11/12                         Loss D: -292.3904, loss G: 36.0112\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [86/200] Batch 11/12                         Loss D: -290.2461, loss G: 36.2030\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [87/200] Batch 11/12                         Loss D: -290.7673, loss G: 36.4345\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [88/200] Batch 11/12                         Loss D: -285.5308, loss G: 36.5688\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [89/200] Batch 11/12                         Loss D: -286.0764, loss G: 36.7451\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [90/200] Batch 11/12                         Loss D: -279.6311, loss G: 36.8342\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [91/200] Batch 11/12                         Loss D: -281.9592, loss G: 37.0637\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [92/200] Batch 11/12                         Loss D: -277.2714, loss G: 37.1292\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [93/200] Batch 11/12                         Loss D: -272.9555, loss G: 37.2111\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [94/200] Batch 11/12                         Loss D: -266.5406, loss G: 37.2556\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [95/200] Batch 11/12                         Loss D: -264.9916, loss G: 37.3553\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [96/200] Batch 11/12                         Loss D: -266.5899, loss G: 37.5418\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [97/200] Batch 11/12                         Loss D: -255.9563, loss G: 37.4307\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [98/200] Batch 11/12                         Loss D: -251.2136, loss G: 37.4720\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [99/200] Batch 11/12                         Loss D: -246.5723, loss G: 37.4841\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [100/200] Batch 11/12                         Loss D: -243.9414, loss G: 37.5346\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [101/200] Batch 11/12                         Loss D: -237.6067, loss G: 37.4966\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [102/200] Batch 11/12                         Loss D: -231.9655, loss G: 37.4712\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [103/200] Batch 11/12                         Loss D: -227.3375, loss G: 37.4565\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [104/200] Batch 11/12                         Loss D: -221.1102, loss G: 37.4005\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [105/200] Batch 11/12                         Loss D: -216.9985, loss G: 37.3887\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [106/200] Batch 11/12                         Loss D: -210.9822, loss G: 37.3380\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [107/200] Batch 11/12                         Loss D: -204.8251, loss G: 37.2534\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [108/200] Batch 11/12                         Loss D: -198.0153, loss G: 37.1716\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [109/200] Batch 11/12                         Loss D: -193.9032, loss G: 37.1375\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [110/200] Batch 11/12                         Loss D: -186.5548, loss G: 37.0267\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [111/200] Batch 11/12                         Loss D: -181.7219, loss G: 36.9603\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [112/200] Batch 11/12                         Loss D: -176.1304, loss G: 36.8674\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [113/200] Batch 11/12                         Loss D: -169.5054, loss G: 36.7601\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [114/200] Batch 11/12                         Loss D: -163.7303, loss G: 36.6580\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [115/200] Batch 11/12                         Loss D: -156.1269, loss G: 36.4948\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [116/200] Batch 11/12                         Loss D: -147.3587, loss G: 36.3186\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [117/200] Batch 11/12                         Loss D: -141.6339, loss G: 36.2110\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [118/200] Batch 11/12                         Loss D: -132.6143, loss G: 35.9975\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [119/200] Batch 11/12                         Loss D: -122.6767, loss G: 35.7608\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [120/200] Batch 11/12                         Loss D: -110.2646, loss G: 35.4367\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [121/200] Batch 11/12                         Loss D: -95.4186, loss G: 35.0642\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [122/200] Batch 11/12                         Loss D: -81.5978, loss G: 34.6904\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [123/200] Batch 11/12                         Loss D: -63.5904, loss G: 33.9586\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [124/200] Batch 11/12                         Loss D: -45.2090, loss G: 33.1257\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [125/200] Batch 11/12                         Loss D: -29.7319, loss G: 32.4417\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [126/200] Batch 11/12                         Loss D: -23.1253, loss G: 32.2404\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [127/200] Batch 11/12                         Loss D: -23.1518, loss G: 32.1951\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [128/200] Batch 11/12                         Loss D: -22.9426, loss G: 32.2075\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [129/200] Batch 11/12                         Loss D: -22.2782, loss G: 32.2233\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [130/200] Batch 11/12                         Loss D: -21.5114, loss G: 32.2943\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [131/200] Batch 11/12                         Loss D: -21.0414, loss G: 32.3643\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [132/200] Batch 11/12                         Loss D: -23.0062, loss G: 32.4971\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [133/200] Batch 11/12                         Loss D: -26.2988, loss G: 32.6140\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [134/200] Batch 11/12                         Loss D: -30.6685, loss G: 32.7666\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [135/200] Batch 11/12                         Loss D: -34.8025, loss G: 32.8990\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [136/200] Batch 11/12                         Loss D: -38.7980, loss G: 33.0572\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [137/200] Batch 11/12                         Loss D: -41.2686, loss G: 33.2026\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [138/200] Batch 11/12                         Loss D: -43.9798, loss G: 33.3481\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [139/200] Batch 11/12                         Loss D: -45.5766, loss G: 33.4919\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [140/200] Batch 11/12                         Loss D: -46.9836, loss G: 33.6045\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [141/200] Batch 11/12                         Loss D: -48.2538, loss G: 33.7407\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [142/200] Batch 11/12                         Loss D: -48.8090, loss G: 33.8444\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [143/200] Batch 11/12                         Loss D: -48.4538, loss G: 33.9419\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [144/200] Batch 11/12                         Loss D: -47.0139, loss G: 33.9926\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [145/200] Batch 11/12                         Loss D: -45.1038, loss G: 34.0574\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [146/200] Batch 11/12                         Loss D: -42.7089, loss G: 34.0960\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [147/200] Batch 11/12                         Loss D: -39.8455, loss G: 34.1273\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [148/200] Batch 11/12                         Loss D: -37.1960, loss G: 34.1478\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [149/200] Batch 11/12                         Loss D: -33.6184, loss G: 34.1476\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [150/200] Batch 11/12                         Loss D: -29.7237, loss G: 34.1505\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [151/200] Batch 11/12                         Loss D: -26.0775, loss G: 34.1578\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [152/200] Batch 11/12                         Loss D: -21.5583, loss G: 34.1158\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [153/200] Batch 11/12                         Loss D: -16.7583, loss G: 34.0728\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [154/200] Batch 11/12                         Loss D: -12.4050, loss G: 34.0301\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [155/200] Batch 11/12                         Loss D: -7.3085, loss G: 33.9852\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [156/200] Batch 11/12                         Loss D: -3.1483, loss G: 33.9439\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [157/200] Batch 11/12                         Loss D: -3.3268, loss G: 33.9733\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [158/200] Batch 11/12                         Loss D: -3.4547, loss G: 34.0004\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [159/200] Batch 11/12                         Loss D: -3.3619, loss G: 34.0263\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [160/200] Batch 11/12                         Loss D: -3.1881, loss G: 34.0513\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [161/200] Batch 11/12                         Loss D: -3.2281, loss G: 34.0687\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [162/200] Batch 11/12                         Loss D: -3.9350, loss G: 34.0933\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [163/200] Batch 11/12                         Loss D: -3.7481, loss G: 34.1078\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [164/200] Batch 11/12                         Loss D: -3.6279, loss G: 34.1352\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [165/200] Batch 11/12                         Loss D: -3.7410, loss G: 34.1527\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [166/200] Batch 11/12                         Loss D: -3.6360, loss G: 34.1735\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [167/200] Batch 11/12                         Loss D: -3.4378, loss G: 34.2009\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [168/200] Batch 11/12                         Loss D: -3.5973, loss G: 34.2260\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [169/200] Batch 11/12                         Loss D: -3.2891, loss G: 34.2363\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [170/200] Batch 11/12                         Loss D: -3.4643, loss G: 34.2561\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [171/200] Batch 11/12                         Loss D: -3.7253, loss G: 34.2765\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [172/200] Batch 11/12                         Loss D: -3.5908, loss G: 34.3191\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [173/200] Batch 11/12                         Loss D: -3.4782, loss G: 34.3256\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [174/200] Batch 11/12                         Loss D: -3.5135, loss G: 34.3348\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [175/200] Batch 11/12                         Loss D: -3.5571, loss G: 34.3558\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [176/200] Batch 11/12                         Loss D: -3.5398, loss G: 34.3732\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [177/200] Batch 11/12                         Loss D: -3.6467, loss G: 34.3907\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [178/200] Batch 11/12                         Loss D: -3.4086, loss G: 34.4131\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [179/200] Batch 11/12                         Loss D: -3.3674, loss G: 34.4318\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [180/200] Batch 11/12                         Loss D: -3.5721, loss G: 34.4448\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [181/200] Batch 11/12                         Loss D: -3.4248, loss G: 34.4647\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [182/200] Batch 11/12                         Loss D: -3.5046, loss G: 34.4835\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [183/200] Batch 11/12                         Loss D: -3.0135, loss G: 34.5028\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [184/200] Batch 11/12                         Loss D: -3.6349, loss G: 34.5208\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [185/200] Batch 11/12                         Loss D: -3.5300, loss G: 34.5359\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [186/200] Batch 11/12                         Loss D: -3.4563, loss G: 34.5529\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [187/200] Batch 11/12                         Loss D: -3.4170, loss G: 34.5714\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [188/200] Batch 11/12                         Loss D: -3.1135, loss G: 34.5865\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [189/200] Batch 11/12                         Loss D: -3.2386, loss G: 34.6062\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [190/200] Batch 11/12                         Loss D: -3.5068, loss G: 34.6238\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [191/200] Batch 11/12                         Loss D: -3.6360, loss G: 34.6433\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [192/200] Batch 11/12                         Loss D: -3.3217, loss G: 34.6578\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [193/200] Batch 11/12                         Loss D: -3.2734, loss G: 34.6730\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [194/200] Batch 11/12                         Loss D: -3.1678, loss G: 34.6892\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [195/200] Batch 11/12                         Loss D: -3.4100, loss G: 34.7035\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [196/200] Batch 11/12                         Loss D: -3.1926, loss G: 34.7168\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [197/200] Batch 11/12                         Loss D: -3.2324, loss G: 34.7306\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [198/200] Batch 11/12                         Loss D: -3.4557, loss G: 34.7432\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=1]                         Epoch [199/200] Batch 11/12                         Loss D: -3.3694, loss G: 34.7561\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [0/200] Batch 11/12                         Loss D: 0.4776, loss G: 17.3420\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [1/200] Batch 11/12                         Loss D: 0.4875, loss G: 17.2806\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [2/200] Batch 11/12                         Loss D: 0.5238, loss G: 17.2140\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [3/200] Batch 11/12                         Loss D: 0.5039, loss G: 17.1501\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [4/200] Batch 11/12                         Loss D: 0.4670, loss G: 17.0758\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [5/200] Batch 11/12                         Loss D: 0.4027, loss G: 16.9962\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [6/200] Batch 11/12                         Loss D: 0.2972, loss G: 16.9011\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [7/200] Batch 11/12                         Loss D: 0.1872, loss G: 16.7967\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [8/200] Batch 11/12                         Loss D: 0.0750, loss G: 16.6387\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [9/200] Batch 11/12                         Loss D: -0.0825, loss G: 16.4639\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [10/200] Batch 11/12                         Loss D: -0.3531, loss G: 16.2905\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [11/200] Batch 11/12                         Loss D: -0.8659, loss G: 16.0443\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [12/200] Batch 11/12                         Loss D: -1.5052, loss G: 15.7927\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [13/200] Batch 11/12                         Loss D: -1.9250, loss G: 15.4784\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [14/200] Batch 11/12                         Loss D: -2.2717, loss G: 15.2069\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [15/200] Batch 11/12                         Loss D: -2.6478, loss G: 14.9198\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [16/200] Batch 11/12                         Loss D: -3.1287, loss G: 14.7176\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [17/200] Batch 11/12                         Loss D: -3.5839, loss G: 14.5157\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [18/200] Batch 11/12                         Loss D: -3.9617, loss G: 14.3002\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [19/200] Batch 11/12                         Loss D: -4.3654, loss G: 14.1328\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [20/200] Batch 11/12                         Loss D: -4.8012, loss G: 13.9529\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [21/200] Batch 11/12                         Loss D: -5.3048, loss G: 13.7272\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [22/200] Batch 11/12                         Loss D: -5.8622, loss G: 13.4841\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [23/200] Batch 11/12                         Loss D: -6.4398, loss G: 13.2622\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [24/200] Batch 11/12                         Loss D: -7.1639, loss G: 12.9698\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [25/200] Batch 11/12                         Loss D: -8.0128, loss G: 12.6402\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [26/200] Batch 11/12                         Loss D: -8.8367, loss G: 12.4043\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [27/200] Batch 11/12                         Loss D: -9.7806, loss G: 12.1153\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [28/200] Batch 11/12                         Loss D: -10.7081, loss G: 11.8609\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [29/200] Batch 11/12                         Loss D: -11.7469, loss G: 11.5723\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [30/200] Batch 11/12                         Loss D: -12.1126, loss G: 11.1594\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [31/200] Batch 11/12                         Loss D: -9.3076, loss G: 10.7238\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [32/200] Batch 11/12                         Loss D: -5.9385, loss G: 10.3054\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [33/200] Batch 11/12                         Loss D: -3.8480, loss G: 9.8155\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [34/200] Batch 11/12                         Loss D: -3.2486, loss G: 9.4386\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [35/200] Batch 11/12                         Loss D: -3.1555, loss G: 9.0133\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [36/200] Batch 11/12                         Loss D: -1.9136, loss G: 8.6230\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [37/200] Batch 11/12                         Loss D: 3.5222, loss G: 7.9152\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [38/200] Batch 11/12                         Loss D: 7.7458, loss G: 7.3523\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [39/200] Batch 11/12                         Loss D: 12.8737, loss G: 6.7367\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [40/200] Batch 11/12                         Loss D: 19.7270, loss G: 6.1677\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [41/200] Batch 11/12                         Loss D: 25.0223, loss G: 5.7090\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [42/200] Batch 11/12                         Loss D: 28.6227, loss G: 5.4492\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [43/200] Batch 11/12                         Loss D: 32.0593, loss G: 4.9823\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [44/200] Batch 11/12                         Loss D: 33.2953, loss G: 4.9262\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [45/200] Batch 11/12                         Loss D: 34.0325, loss G: 4.6662\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [46/200] Batch 11/12                         Loss D: 33.6285, loss G: 4.5040\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [47/200] Batch 11/12                         Loss D: 31.9244, loss G: 4.5125\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [48/200] Batch 11/12                         Loss D: 29.3388, loss G: 4.5421\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [49/200] Batch 11/12                         Loss D: 25.7144, loss G: 4.6096\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [50/200] Batch 11/12                         Loss D: 21.3643, loss G: 4.6754\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [51/200] Batch 11/12                         Loss D: 16.2539, loss G: 4.7665\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [52/200] Batch 11/12                         Loss D: 10.3688, loss G: 5.0102\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [53/200] Batch 11/12                         Loss D: 4.4795, loss G: 5.4784\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [54/200] Batch 11/12                         Loss D: -1.5073, loss G: 5.9559\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [55/200] Batch 11/12                         Loss D: -7.4623, loss G: 6.4490\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [56/200] Batch 11/12                         Loss D: -13.7001, loss G: 6.9859\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [57/200] Batch 11/12                         Loss D: -19.5696, loss G: 7.4218\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [58/200] Batch 11/12                         Loss D: -25.9346, loss G: 7.8993\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [59/200] Batch 11/12                         Loss D: -32.0976, loss G: 8.2643\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [60/200] Batch 11/12                         Loss D: -38.5293, loss G: 8.7208\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [61/200] Batch 11/12                         Loss D: -45.1656, loss G: 8.9548\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [62/200] Batch 11/12                         Loss D: -51.2010, loss G: 9.1951\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [63/200] Batch 11/12                         Loss D: -55.6087, loss G: 9.4201\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [64/200] Batch 11/12                         Loss D: -61.5042, loss G: 9.4473\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [65/200] Batch 11/12                         Loss D: -66.0335, loss G: 9.5812\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [66/200] Batch 11/12                         Loss D: -70.0461, loss G: 9.7359\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [67/200] Batch 11/12                         Loss D: -75.0242, loss G: 9.7280\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [68/200] Batch 11/12                         Loss D: -78.3203, loss G: 9.8499\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [69/200] Batch 11/12                         Loss D: -83.1793, loss G: 9.8286\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [70/200] Batch 11/12                         Loss D: -86.8356, loss G: 9.8568\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [71/200] Batch 11/12                         Loss D: -90.3226, loss G: 9.9031\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [72/200] Batch 11/12                         Loss D: -93.3310, loss G: 9.9104\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [73/200] Batch 11/12                         Loss D: -96.9239, loss G: 9.9432\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [74/200] Batch 11/12                         Loss D: -99.2877, loss G: 9.9849\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [75/200] Batch 11/12                         Loss D: -102.8584, loss G: 9.9826\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [76/200] Batch 11/12                         Loss D: -106.1100, loss G: 10.0195\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [77/200] Batch 11/12                         Loss D: -113.4142, loss G: 10.0011\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [78/200] Batch 11/12                         Loss D: -119.8846, loss G: 10.0311\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [79/200] Batch 11/12                         Loss D: -126.8367, loss G: 10.0938\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [80/200] Batch 11/12                         Loss D: -133.8862, loss G: 10.3286\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [81/200] Batch 11/12                         Loss D: -142.3110, loss G: 10.7666\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [82/200] Batch 11/12                         Loss D: -148.1377, loss G: 10.9284\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [83/200] Batch 11/12                         Loss D: -154.9422, loss G: 11.1873\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [84/200] Batch 11/12                         Loss D: -159.5526, loss G: 11.5427\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [85/200] Batch 11/12                         Loss D: -168.5702, loss G: 11.8014\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [86/200] Batch 11/12                         Loss D: -173.0233, loss G: 12.1547\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [87/200] Batch 11/12                         Loss D: -180.4890, loss G: 12.4410\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [88/200] Batch 11/12                         Loss D: -187.0340, loss G: 12.7542\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [89/200] Batch 11/12                         Loss D: -194.2522, loss G: 13.0774\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [90/200] Batch 11/12                         Loss D: -198.2830, loss G: 13.4429\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [91/200] Batch 11/12                         Loss D: -203.2578, loss G: 13.8120\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [92/200] Batch 11/12                         Loss D: -213.0436, loss G: 14.1419\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [93/200] Batch 11/12                         Loss D: -220.4516, loss G: 14.5116\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [94/200] Batch 11/12                         Loss D: -226.7362, loss G: 14.9038\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [95/200] Batch 11/12                         Loss D: -235.2515, loss G: 15.2939\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [96/200] Batch 11/12                         Loss D: -238.4559, loss G: 15.7075\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [97/200] Batch 11/12                         Loss D: -246.7941, loss G: 16.1154\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [98/200] Batch 11/12                         Loss D: -255.1390, loss G: 16.5279\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [99/200] Batch 11/12                         Loss D: -258.3907, loss G: 16.9076\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [100/200] Batch 11/12                         Loss D: -267.0122, loss G: 17.3033\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [101/200] Batch 11/12                         Loss D: -276.0777, loss G: 17.7175\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [102/200] Batch 11/12                         Loss D: -280.1891, loss G: 18.1027\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [103/200] Batch 11/12                         Loss D: -287.4023, loss G: 18.4840\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [104/200] Batch 11/12                         Loss D: -287.7624, loss G: 18.7821\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [105/200] Batch 11/12                         Loss D: -292.7890, loss G: 19.1662\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [106/200] Batch 11/12                         Loss D: -289.6083, loss G: 19.3519\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [107/200] Batch 11/12                         Loss D: -293.4368, loss G: 19.6857\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [108/200] Batch 11/12                         Loss D: -297.9247, loss G: 20.0509\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [109/200] Batch 11/12                         Loss D: -294.2448, loss G: 20.1530\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [110/200] Batch 11/12                         Loss D: -290.2375, loss G: 20.2950\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [111/200] Batch 11/12                         Loss D: -295.6749, loss G: 20.5891\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [112/200] Batch 11/12                         Loss D: -292.1947, loss G: 20.6716\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [113/200] Batch 11/12                         Loss D: -292.0461, loss G: 20.8238\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [114/200] Batch 11/12                         Loss D: -286.9197, loss G: 20.8854\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [115/200] Batch 11/12                         Loss D: -290.2852, loss G: 21.0886\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [116/200] Batch 11/12                         Loss D: -283.3447, loss G: 21.0464\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [117/200] Batch 11/12                         Loss D: -279.4414, loss G: 21.0825\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [118/200] Batch 11/12                         Loss D: -279.6593, loss G: 21.1690\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [119/200] Batch 11/12                         Loss D: -274.4648, loss G: 21.1471\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [120/200] Batch 11/12                         Loss D: -271.9724, loss G: 21.0664\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [121/200] Batch 11/12                         Loss D: -272.4961, loss G: 21.0899\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [122/200] Batch 11/12                         Loss D: -269.9354, loss G: 21.2151\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [123/200] Batch 11/12                         Loss D: -267.5664, loss G: 21.3445\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [124/200] Batch 11/12                         Loss D: -267.2397, loss G: 21.5090\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [125/200] Batch 11/12                         Loss D: -262.0982, loss G: 21.5826\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [126/200] Batch 11/12                         Loss D: -259.8809, loss G: 21.6736\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [127/200] Batch 11/12                         Loss D: -255.6588, loss G: 21.7350\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [128/200] Batch 11/12                         Loss D: -253.9569, loss G: 21.8342\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [129/200] Batch 11/12                         Loss D: -248.1730, loss G: 21.8494\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [130/200] Batch 11/12                         Loss D: -241.9834, loss G: 21.8392\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [131/200] Batch 11/12                         Loss D: -237.4117, loss G: 21.8566\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [132/200] Batch 11/12                         Loss D: -232.8384, loss G: 21.8700\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [133/200] Batch 11/12                         Loss D: -221.9708, loss G: 21.7344\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [134/200] Batch 11/12                         Loss D: -219.7172, loss G: 21.7702\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [135/200] Batch 11/12                         Loss D: -207.6743, loss G: 21.5716\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [136/200] Batch 11/12                         Loss D: -198.2136, loss G: 21.1124\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [137/200] Batch 11/12                         Loss D: -189.0620, loss G: 20.5767\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [138/200] Batch 11/12                         Loss D: -172.4988, loss G: 19.8428\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [139/200] Batch 11/12                         Loss D: -158.1820, loss G: 19.1254\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [140/200] Batch 11/12                         Loss D: -142.7594, loss G: 18.5744\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [141/200] Batch 11/12                         Loss D: -123.8175, loss G: 18.0203\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [142/200] Batch 11/12                         Loss D: -99.6317, loss G: 17.0749\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [143/200] Batch 11/12                         Loss D: -83.5347, loss G: 16.8284\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [144/200] Batch 11/12                         Loss D: -70.6215, loss G: 16.6823\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [145/200] Batch 11/12                         Loss D: -56.4429, loss G: 16.5269\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [146/200] Batch 11/12                         Loss D: -47.7781, loss G: 16.5204\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [147/200] Batch 11/12                         Loss D: -42.0438, loss G: 16.5385\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [148/200] Batch 11/12                         Loss D: -35.2842, loss G: 16.5388\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [149/200] Batch 11/12                         Loss D: -30.4561, loss G: 16.5595\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [150/200] Batch 11/12                         Loss D: -28.1583, loss G: 16.6005\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [151/200] Batch 11/12                         Loss D: -26.7087, loss G: 16.6448\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [152/200] Batch 11/12                         Loss D: -25.0276, loss G: 16.6791\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [153/200] Batch 11/12                         Loss D: -23.7170, loss G: 16.7068\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [154/200] Batch 11/12                         Loss D: -22.1918, loss G: 16.7296\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [155/200] Batch 11/12                         Loss D: -20.7471, loss G: 16.7466\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [156/200] Batch 11/12                         Loss D: -19.6437, loss G: 16.7680\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [157/200] Batch 11/12                         Loss D: -17.9078, loss G: 16.7710\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [158/200] Batch 11/12                         Loss D: -16.7866, loss G: 16.7871\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [159/200] Batch 11/12                         Loss D: -15.7254, loss G: 16.7833\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [160/200] Batch 11/12                         Loss D: -14.5453, loss G: 16.7908\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [161/200] Batch 11/12                         Loss D: -13.5036, loss G: 16.7773\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [162/200] Batch 11/12                         Loss D: -12.3432, loss G: 16.7728\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [163/200] Batch 11/12                         Loss D: -11.0665, loss G: 16.7598\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [164/200] Batch 11/12                         Loss D: -10.1784, loss G: 16.7453\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [165/200] Batch 11/12                         Loss D: -8.9510, loss G: 16.7250\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [166/200] Batch 11/12                         Loss D: -8.0171, loss G: 16.7066\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [167/200] Batch 11/12                         Loss D: -7.2454, loss G: 16.6757\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [168/200] Batch 11/12                         Loss D: -6.3597, loss G: 16.6466\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [169/200] Batch 11/12                         Loss D: -5.5979, loss G: 16.6244\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [170/200] Batch 11/12                         Loss D: -4.7385, loss G: 16.5915\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [171/200] Batch 11/12                         Loss D: -3.9311, loss G: 16.5601\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [172/200] Batch 11/12                         Loss D: -3.3968, loss G: 16.5202\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [173/200] Batch 11/12                         Loss D: -2.8362, loss G: 16.4786\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [174/200] Batch 11/12                         Loss D: -2.6707, loss G: 16.4665\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [175/200] Batch 11/12                         Loss D: -2.2861, loss G: 16.4626\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [176/200] Batch 11/12                         Loss D: -2.3838, loss G: 16.4660\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [177/200] Batch 11/12                         Loss D: -2.4696, loss G: 16.4787\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [178/200] Batch 11/12                         Loss D: -2.4968, loss G: 16.4792\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [179/200] Batch 11/12                         Loss D: -2.4284, loss G: 16.4675\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [180/200] Batch 11/12                         Loss D: -2.3455, loss G: 16.4699\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [181/200] Batch 11/12                         Loss D: -2.4844, loss G: 16.4657\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [182/200] Batch 11/12                         Loss D: -2.3401, loss G: 16.4708\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [183/200] Batch 11/12                         Loss D: -2.4516, loss G: 16.4663\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [184/200] Batch 11/12                         Loss D: -2.3525, loss G: 16.4729\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [185/200] Batch 11/12                         Loss D: -2.4209, loss G: 16.4672\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [186/200] Batch 11/12                         Loss D: -2.3472, loss G: 16.4706\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [187/200] Batch 11/12                         Loss D: -2.5132, loss G: 16.4769\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [188/200] Batch 11/12                         Loss D: -2.0807, loss G: 16.4638\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [189/200] Batch 11/12                         Loss D: -2.3202, loss G: 16.4675\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [190/200] Batch 11/12                         Loss D: -2.2521, loss G: 16.4697\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [191/200] Batch 11/12                         Loss D: -2.4144, loss G: 16.4660\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [192/200] Batch 11/12                         Loss D: -2.2613, loss G: 16.4627\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [193/200] Batch 11/12                         Loss D: -2.2782, loss G: 16.4696\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [194/200] Batch 11/12                         Loss D: -2.2770, loss G: 16.4659\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [195/200] Batch 11/12                         Loss D: -2.3304, loss G: 16.4627\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [196/200] Batch 11/12                         Loss D: -2.3067, loss G: 16.4643\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [197/200] Batch 11/12                         Loss D: -2.1780, loss G: 16.4713\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [198/200] Batch 11/12                         Loss D: -2.3419, loss G: 16.4647\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.5]                         Epoch [199/200] Batch 11/12                         Loss D: -2.2838, loss G: 16.4625\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [0/200] Batch 11/12                         Loss D: 0.2564, loss G: 3.1411\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [1/200] Batch 11/12                         Loss D: 0.3836, loss G: 3.1367\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [2/200] Batch 11/12                         Loss D: 0.4046, loss G: 3.1341\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [3/200] Batch 11/12                         Loss D: 0.4361, loss G: 3.1336\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [4/200] Batch 11/12                         Loss D: 0.5025, loss G: 3.1336\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [5/200] Batch 11/12                         Loss D: 0.6006, loss G: 3.1335\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [6/200] Batch 11/12                         Loss D: 0.6594, loss G: 3.1334\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [7/200] Batch 11/12                         Loss D: 0.7493, loss G: 3.1331\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [8/200] Batch 11/12                         Loss D: 0.8002, loss G: 3.1328\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [9/200] Batch 11/12                         Loss D: 0.9111, loss G: 3.1324\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [10/200] Batch 11/12                         Loss D: 1.0296, loss G: 3.1319\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [11/200] Batch 11/12                         Loss D: 1.1622, loss G: 3.1314\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [12/200] Batch 11/12                         Loss D: 1.2866, loss G: 3.1310\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [13/200] Batch 11/12                         Loss D: 1.5004, loss G: 3.1293\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [14/200] Batch 11/12                         Loss D: 1.9310, loss G: 3.1113\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [15/200] Batch 11/12                         Loss D: 2.3049, loss G: 3.0834\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [16/200] Batch 11/12                         Loss D: 2.7529, loss G: 3.0654\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [17/200] Batch 11/12                         Loss D: 2.8040, loss G: 3.0571\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [18/200] Batch 11/12                         Loss D: 2.8645, loss G: 3.0552\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [19/200] Batch 11/12                         Loss D: 2.8857, loss G: 3.0571\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [20/200] Batch 11/12                         Loss D: 2.9095, loss G: 3.0552\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [21/200] Batch 11/12                         Loss D: 2.5451, loss G: 3.0568\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [22/200] Batch 11/12                         Loss D: 1.9067, loss G: 3.0616\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [23/200] Batch 11/12                         Loss D: 1.2342, loss G: 3.0767\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [24/200] Batch 11/12                         Loss D: 0.6451, loss G: 3.0999\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [25/200] Batch 11/12                         Loss D: 0.0544, loss G: 3.1210\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [26/200] Batch 11/12                         Loss D: -0.5323, loss G: 3.1482\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [27/200] Batch 11/12                         Loss D: -1.0437, loss G: 3.1705\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [28/200] Batch 11/12                         Loss D: -1.4359, loss G: 3.1861\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [29/200] Batch 11/12                         Loss D: -1.6196, loss G: 3.1991\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [30/200] Batch 11/12                         Loss D: -1.7570, loss G: 3.2079\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [31/200] Batch 11/12                         Loss D: -1.7293, loss G: 3.2123\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [32/200] Batch 11/12                         Loss D: -1.6659, loss G: 3.2145\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [33/200] Batch 11/12                         Loss D: -1.5296, loss G: 3.2140\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [34/200] Batch 11/12                         Loss D: -1.3740, loss G: 3.2119\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [35/200] Batch 11/12                         Loss D: -1.2468, loss G: 3.2092\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [36/200] Batch 11/12                         Loss D: -1.1239, loss G: 3.2051\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [37/200] Batch 11/12                         Loss D: -1.0606, loss G: 3.2017\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [38/200] Batch 11/12                         Loss D: -1.0093, loss G: 3.1980\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [39/200] Batch 11/12                         Loss D: -0.9028, loss G: 3.1934\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [40/200] Batch 11/12                         Loss D: -0.8503, loss G: 3.1898\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [41/200] Batch 11/12                         Loss D: -0.7450, loss G: 3.1856\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [42/200] Batch 11/12                         Loss D: -0.7084, loss G: 3.1825\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [43/200] Batch 11/12                         Loss D: -0.6010, loss G: 3.1783\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [44/200] Batch 11/12                         Loss D: -0.5613, loss G: 3.1749\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [45/200] Batch 11/12                         Loss D: -0.4814, loss G: 3.1714\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [46/200] Batch 11/12                         Loss D: -0.4385, loss G: 3.1683\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [47/200] Batch 11/12                         Loss D: -0.4184, loss G: 3.1654\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [48/200] Batch 11/12                         Loss D: -0.3981, loss G: 3.1628\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [49/200] Batch 11/12                         Loss D: -0.4039, loss G: 3.1604\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [50/200] Batch 11/12                         Loss D: -0.3895, loss G: 3.1580\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [51/200] Batch 11/12                         Loss D: -0.4010, loss G: 3.1555\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [52/200] Batch 11/12                         Loss D: -0.4252, loss G: 3.1531\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [53/200] Batch 11/12                         Loss D: -0.4397, loss G: 3.1507\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [54/200] Batch 11/12                         Loss D: -0.4573, loss G: 3.1483\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [55/200] Batch 11/12                         Loss D: -0.5353, loss G: 3.1458\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [56/200] Batch 11/12                         Loss D: -0.5789, loss G: 3.1433\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [57/200] Batch 11/12                         Loss D: -0.6541, loss G: 3.1406\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [58/200] Batch 11/12                         Loss D: -0.7509, loss G: 3.1379\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [59/200] Batch 11/12                         Loss D: -0.8252, loss G: 3.1353\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [60/200] Batch 11/12                         Loss D: -0.9088, loss G: 3.1329\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [61/200] Batch 11/12                         Loss D: -0.9320, loss G: 3.1308\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [62/200] Batch 11/12                         Loss D: -1.0100, loss G: 3.1285\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [63/200] Batch 11/12                         Loss D: -1.0740, loss G: 3.1262\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [64/200] Batch 11/12                         Loss D: -1.1737, loss G: 3.1237\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [65/200] Batch 11/12                         Loss D: -1.2316, loss G: 3.1216\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [66/200] Batch 11/12                         Loss D: -1.3608, loss G: 3.1188\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [67/200] Batch 11/12                         Loss D: -1.4530, loss G: 3.1163\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [68/200] Batch 11/12                         Loss D: -1.5434, loss G: 3.1137\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [69/200] Batch 11/12                         Loss D: -1.6912, loss G: 3.1116\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [70/200] Batch 11/12                         Loss D: -1.8360, loss G: 3.1108\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [71/200] Batch 11/12                         Loss D: -2.0325, loss G: 3.1133\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [72/200] Batch 11/12                         Loss D: -2.1898, loss G: 3.1179\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [73/200] Batch 11/12                         Loss D: -2.3520, loss G: 3.1234\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [74/200] Batch 11/12                         Loss D: -2.4902, loss G: 3.1284\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [75/200] Batch 11/12                         Loss D: -2.6389, loss G: 3.1328\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [76/200] Batch 11/12                         Loss D: -2.7384, loss G: 3.1367\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [77/200] Batch 11/12                         Loss D: -2.8121, loss G: 3.1401\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [78/200] Batch 11/12                         Loss D: -2.6933, loss G: 3.1431\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [79/200] Batch 11/12                         Loss D: -2.5637, loss G: 3.1452\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [80/200] Batch 11/12                         Loss D: -2.3336, loss G: 3.1466\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [81/200] Batch 11/12                         Loss D: -2.0352, loss G: 3.1474\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [82/200] Batch 11/12                         Loss D: -1.8494, loss G: 3.1480\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [83/200] Batch 11/12                         Loss D: -1.8896, loss G: 3.1488\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [84/200] Batch 11/12                         Loss D: -2.0827, loss G: 3.1495\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [85/200] Batch 11/12                         Loss D: -2.3220, loss G: 3.1498\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [86/200] Batch 11/12                         Loss D: -2.6307, loss G: 3.1498\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [87/200] Batch 11/12                         Loss D: -2.9148, loss G: 3.1496\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [88/200] Batch 11/12                         Loss D: -3.2539, loss G: 3.1487\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [89/200] Batch 11/12                         Loss D: -3.5706, loss G: 3.1473\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [90/200] Batch 11/12                         Loss D: -3.8775, loss G: 3.1457\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [91/200] Batch 11/12                         Loss D: -4.1589, loss G: 3.1442\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [92/200] Batch 11/12                         Loss D: -4.3801, loss G: 3.1431\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [93/200] Batch 11/12                         Loss D: -4.6808, loss G: 3.1423\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [94/200] Batch 11/12                         Loss D: -4.9651, loss G: 3.1419\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [95/200] Batch 11/12                         Loss D: -5.3163, loss G: 3.1416\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [96/200] Batch 11/12                         Loss D: -5.6492, loss G: 3.1419\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [97/200] Batch 11/12                         Loss D: -5.9789, loss G: 3.1422\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [98/200] Batch 11/12                         Loss D: -6.2233, loss G: 3.1430\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [99/200] Batch 11/12                         Loss D: -6.4176, loss G: 3.1437\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [100/200] Batch 11/12                         Loss D: -6.6080, loss G: 3.1443\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [101/200] Batch 11/12                         Loss D: -6.7800, loss G: 3.1446\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [102/200] Batch 11/12                         Loss D: -6.9859, loss G: 3.1445\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [103/200] Batch 11/12                         Loss D: -7.1134, loss G: 3.1443\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [104/200] Batch 11/12                         Loss D: -7.2121, loss G: 3.1438\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [105/200] Batch 11/12                         Loss D: -7.5020, loss G: 3.1434\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [106/200] Batch 11/12                         Loss D: -7.6893, loss G: 3.1426\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [107/200] Batch 11/12                         Loss D: -7.9839, loss G: 3.1422\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [108/200] Batch 11/12                         Loss D: -8.2348, loss G: 3.1432\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [109/200] Batch 11/12                         Loss D: -8.5677, loss G: 3.1439\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [110/200] Batch 11/12                         Loss D: -8.8504, loss G: 3.1449\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [111/200] Batch 11/12                         Loss D: -9.2726, loss G: 3.1456\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [112/200] Batch 11/12                         Loss D: -9.6257, loss G: 3.1460\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [113/200] Batch 11/12                         Loss D: -9.9589, loss G: 3.1462\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [114/200] Batch 11/12                         Loss D: -10.3023, loss G: 3.1466\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [115/200] Batch 11/12                         Loss D: -10.6619, loss G: 3.1470\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [116/200] Batch 11/12                         Loss D: -11.0038, loss G: 3.1475\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [117/200] Batch 11/12                         Loss D: -11.3782, loss G: 3.1479\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [118/200] Batch 11/12                         Loss D: -11.7536, loss G: 3.1480\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [119/200] Batch 11/12                         Loss D: -12.1050, loss G: 3.1484\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [120/200] Batch 11/12                         Loss D: -12.4719, loss G: 3.1490\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [121/200] Batch 11/12                         Loss D: -12.8140, loss G: 3.1499\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [122/200] Batch 11/12                         Loss D: -13.2574, loss G: 3.1511\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [123/200] Batch 11/12                         Loss D: -13.6128, loss G: 3.1523\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [124/200] Batch 11/12                         Loss D: -14.0071, loss G: 3.1534\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [125/200] Batch 11/12                         Loss D: -14.4475, loss G: 3.1546\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [126/200] Batch 11/12                         Loss D: -14.8604, loss G: 3.1558\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [127/200] Batch 11/12                         Loss D: -15.2544, loss G: 3.1565\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [128/200] Batch 11/12                         Loss D: -15.6562, loss G: 3.1575\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [129/200] Batch 11/12                         Loss D: -16.1052, loss G: 3.1588\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [130/200] Batch 11/12                         Loss D: -16.5640, loss G: 3.1599\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [131/200] Batch 11/12                         Loss D: -17.0362, loss G: 3.1608\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [132/200] Batch 11/12                         Loss D: -17.5004, loss G: 3.1617\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [133/200] Batch 11/12                         Loss D: -17.9401, loss G: 3.1626\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [134/200] Batch 11/12                         Loss D: -18.3299, loss G: 3.1639\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [135/200] Batch 11/12                         Loss D: -18.7579, loss G: 3.1650\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [136/200] Batch 11/12                         Loss D: -19.0961, loss G: 3.1664\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [137/200] Batch 11/12                         Loss D: -19.5768, loss G: 3.1681\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [138/200] Batch 11/12                         Loss D: -19.8156, loss G: 3.1695\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [139/200] Batch 11/12                         Loss D: -19.9412, loss G: 3.1711\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [140/200] Batch 11/12                         Loss D: -20.2410, loss G: 3.1727\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [141/200] Batch 11/12                         Loss D: -20.2946, loss G: 3.1749\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [142/200] Batch 11/12                         Loss D: -20.1584, loss G: 3.1764\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [143/200] Batch 11/12                         Loss D: -20.1947, loss G: 3.1781\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [144/200] Batch 11/12                         Loss D: -20.3837, loss G: 3.1797\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [145/200] Batch 11/12                         Loss D: -20.1947, loss G: 3.1815\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [146/200] Batch 11/12                         Loss D: -20.2171, loss G: 3.1831\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [147/200] Batch 11/12                         Loss D: -20.0497, loss G: 3.1848\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [148/200] Batch 11/12                         Loss D: -20.0551, loss G: 3.1863\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [149/200] Batch 11/12                         Loss D: -19.9571, loss G: 3.1880\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [150/200] Batch 11/12                         Loss D: -19.8833, loss G: 3.1896\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [151/200] Batch 11/12                         Loss D: -19.7653, loss G: 3.1914\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [152/200] Batch 11/12                         Loss D: -19.7101, loss G: 3.1930\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [153/200] Batch 11/12                         Loss D: -19.5999, loss G: 3.1943\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [154/200] Batch 11/12                         Loss D: -19.3648, loss G: 3.1962\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [155/200] Batch 11/12                         Loss D: -19.3098, loss G: 3.1978\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [156/200] Batch 11/12                         Loss D: -19.0239, loss G: 3.1997\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [157/200] Batch 11/12                         Loss D: -18.7771, loss G: 3.2020\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [158/200] Batch 11/12                         Loss D: -18.5389, loss G: 3.2039\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [159/200] Batch 11/12                         Loss D: -17.8827, loss G: 3.2064\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [160/200] Batch 11/12                         Loss D: -17.4297, loss G: 3.2087\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [161/200] Batch 11/12                         Loss D: -16.4811, loss G: 3.2112\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [162/200] Batch 11/12                         Loss D: -15.1301, loss G: 3.2134\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [163/200] Batch 11/12                         Loss D: -13.0781, loss G: 3.2145\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [164/200] Batch 11/12                         Loss D: 28.6478, loss G: 1.9939\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [165/200] Batch 11/12                         Loss D: 76.2417, loss G: -2.4041\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [166/200] Batch 11/12                         Loss D: 116.3837, loss G: -5.9698\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [167/200] Batch 11/12                         Loss D: 150.4816, loss G: -9.0352\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [168/200] Batch 11/12                         Loss D: 179.6295, loss G: -11.8582\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [169/200] Batch 11/12                         Loss D: 201.0629, loss G: -14.1911\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [170/200] Batch 11/12                         Loss D: 217.6841, loss G: -16.2499\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [171/200] Batch 11/12                         Loss D: 232.1842, loss G: -18.2644\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [172/200] Batch 11/12                         Loss D: 240.3639, loss G: -19.8562\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [173/200] Batch 11/12                         Loss D: 246.3564, loss G: -21.3792\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [174/200] Batch 11/12                         Loss D: 245.2121, loss G: -22.3237\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [175/200] Batch 11/12                         Loss D: 241.6256, loss G: -23.0154\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [176/200] Batch 11/12                         Loss D: 242.5756, loss G: -24.0201\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [177/200] Batch 11/12                         Loss D: 236.3145, loss G: -24.1945\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [178/200] Batch 11/12                         Loss D: 233.2133, loss G: -24.6629\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [179/200] Batch 11/12                         Loss D: 224.4474, loss G: -24.6348\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [180/200] Batch 11/12                         Loss D: 215.5731, loss G: -24.7157\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [181/200] Batch 11/12                         Loss D: 199.3957, loss G: -23.9683\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [182/200] Batch 11/12                         Loss D: 182.7350, loss G: -23.1791\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [183/200] Batch 11/12                         Loss D: 163.6907, loss G: -22.1517\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [184/200] Batch 11/12                         Loss D: 144.8672, loss G: -21.1914\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [185/200] Batch 11/12                         Loss D: 122.8939, loss G: -19.8122\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [186/200] Batch 11/12                         Loss D: 103.7333, loss G: -18.8191\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [187/200] Batch 11/12                         Loss D: 83.9769, loss G: -17.6992\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [188/200] Batch 11/12                         Loss D: 64.2385, loss G: -16.4817\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [189/200] Batch 11/12                         Loss D: 46.1451, loss G: -15.4586\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [190/200] Batch 11/12                         Loss D: 29.0254, loss G: -14.4245\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [191/200] Batch 11/12                         Loss D: 13.3886, loss G: -13.4937\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [192/200] Batch 11/12                         Loss D: -0.0932, loss G: -12.6578\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [193/200] Batch 11/12                         Loss D: -10.8433, loss G: -12.1343\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [194/200] Batch 11/12                         Loss D: -19.7618, loss G: -11.5047\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [195/200] Batch 11/12                         Loss D: -27.1636, loss G: -11.1578\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [196/200] Batch 11/12                         Loss D: -32.8401, loss G: -10.7306\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [197/200] Batch 11/12                         Loss D: -38.2033, loss G: -10.3151\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [198/200] Batch 11/12                         Loss D: -41.7066, loss G: -9.8339\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=1, lambda_mean=0.1]                         Epoch [199/200] Batch 11/12                         Loss D: -44.2964, loss G: -9.6546\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [0/200] Batch 11/12                         Loss D: 0.1479, loss G: 34.5865\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [1/200] Batch 11/12                         Loss D: 0.0109, loss G: 34.4967\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [2/200] Batch 11/12                         Loss D: -0.2024, loss G: 34.3838\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [3/200] Batch 11/12                         Loss D: -0.4329, loss G: 34.2531\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [4/200] Batch 11/12                         Loss D: -0.7190, loss G: 34.1099\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [5/200] Batch 11/12                         Loss D: -1.0625, loss G: 33.9421\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [6/200] Batch 11/12                         Loss D: -1.4761, loss G: 33.7545\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [7/200] Batch 11/12                         Loss D: -1.9520, loss G: 33.5429\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [8/200] Batch 11/12                         Loss D: -2.5004, loss G: 33.3048\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [9/200] Batch 11/12                         Loss D: -3.2101, loss G: 33.0120\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [10/200] Batch 11/12                         Loss D: -3.9862, loss G: 32.7114\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [11/200] Batch 11/12                         Loss D: -4.9635, loss G: 32.3597\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [12/200] Batch 11/12                         Loss D: -6.0704, loss G: 31.9902\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [13/200] Batch 11/12                         Loss D: -7.2882, loss G: 31.6071\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [14/200] Batch 11/12                         Loss D: -8.9253, loss G: 31.1167\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [15/200] Batch 11/12                         Loss D: -10.6077, loss G: 30.6551\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [16/200] Batch 11/12                         Loss D: -12.4247, loss G: 30.2576\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [17/200] Batch 11/12                         Loss D: -14.1463, loss G: 30.0012\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [18/200] Batch 11/12                         Loss D: -16.0764, loss G: 29.6925\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [19/200] Batch 11/12                         Loss D: -17.9934, loss G: 29.4308\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [20/200] Batch 11/12                         Loss D: -20.1433, loss G: 29.1991\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [21/200] Batch 11/12                         Loss D: -22.5536, loss G: 28.9553\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [22/200] Batch 11/12                         Loss D: -25.6233, loss G: 28.6283\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [23/200] Batch 11/12                         Loss D: -27.9397, loss G: 28.4442\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [24/200] Batch 11/12                         Loss D: -31.5572, loss G: 28.0785\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [25/200] Batch 11/12                         Loss D: -35.0044, loss G: 27.7925\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [26/200] Batch 11/12                         Loss D: -39.2841, loss G: 27.4180\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [27/200] Batch 11/12                         Loss D: -42.8243, loss G: 27.1608\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [28/200] Batch 11/12                         Loss D: -46.8753, loss G: 26.8875\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [29/200] Batch 11/12                         Loss D: -51.6940, loss G: 26.5195\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [30/200] Batch 11/12                         Loss D: -56.8359, loss G: 26.1553\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [31/200] Batch 11/12                         Loss D: -62.5625, loss G: 25.7701\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [32/200] Batch 11/12                         Loss D: -68.7799, loss G: 25.3831\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [33/200] Batch 11/12                         Loss D: -75.2139, loss G: 25.0304\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [34/200] Batch 11/12                         Loss D: -81.9496, loss G: 24.6860\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [35/200] Batch 11/12                         Loss D: -89.7028, loss G: 24.2835\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [36/200] Batch 11/12                         Loss D: -96.5332, loss G: 24.0359\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [37/200] Batch 11/12                         Loss D: -106.6012, loss G: 23.5364\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [38/200] Batch 11/12                         Loss D: -113.8569, loss G: 23.3220\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [39/200] Batch 11/12                         Loss D: -124.3280, loss G: 22.8538\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [40/200] Batch 11/12                         Loss D: -133.4360, loss G: 22.4390\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [41/200] Batch 11/12                         Loss D: -142.3008, loss G: 22.0309\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [42/200] Batch 11/12                         Loss D: -152.9352, loss G: 21.5514\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [43/200] Batch 11/12                         Loss D: -164.3404, loss G: 21.0367\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [44/200] Batch 11/12                         Loss D: -173.0403, loss G: 20.7927\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [45/200] Batch 11/12                         Loss D: -186.9454, loss G: 20.2323\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [46/200] Batch 11/12                         Loss D: -197.5096, loss G: 19.8257\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [47/200] Batch 11/12                         Loss D: -204.1726, loss G: 19.5261\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [48/200] Batch 11/12                         Loss D: -208.7422, loss G: 19.4636\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [49/200] Batch 11/12                         Loss D: -216.7990, loss G: 19.1576\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [50/200] Batch 11/12                         Loss D: -216.5963, loss G: 19.3319\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [51/200] Batch 11/12                         Loss D: -225.9480, loss G: 18.8601\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [52/200] Batch 11/12                         Loss D: -233.8533, loss G: 18.5495\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [53/200] Batch 11/12                         Loss D: -239.6156, loss G: 18.3666\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [54/200] Batch 11/12                         Loss D: -247.4503, loss G: 18.0422\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [55/200] Batch 11/12                         Loss D: -253.9383, loss G: 17.8851\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [56/200] Batch 11/12                         Loss D: -260.7052, loss G: 17.6777\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [57/200] Batch 11/12                         Loss D: -268.0660, loss G: 17.3748\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [58/200] Batch 11/12                         Loss D: -276.9710, loss G: 17.1390\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [59/200] Batch 11/12                         Loss D: -284.2856, loss G: 16.8694\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [60/200] Batch 11/12                         Loss D: -290.7224, loss G: 16.7079\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [61/200] Batch 11/12                         Loss D: -298.9861, loss G: 16.4387\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [62/200] Batch 11/12                         Loss D: -301.5985, loss G: 16.7928\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [63/200] Batch 11/12                         Loss D: -306.8832, loss G: 17.0543\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [64/200] Batch 11/12                         Loss D: -315.6186, loss G: 17.7603\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [65/200] Batch 11/12                         Loss D: -315.8716, loss G: 17.6616\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [66/200] Batch 11/12                         Loss D: -321.2448, loss G: 18.1799\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [67/200] Batch 11/12                         Loss D: -318.9573, loss G: 18.5126\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [68/200] Batch 11/12                         Loss D: -328.1394, loss G: 18.8476\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [69/200] Batch 11/12                         Loss D: -325.3146, loss G: 19.0952\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [70/200] Batch 11/12                         Loss D: -333.0095, loss G: 19.4154\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [71/200] Batch 11/12                         Loss D: -333.8329, loss G: 19.6494\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [72/200] Batch 11/12                         Loss D: -336.7729, loss G: 20.0207\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [73/200] Batch 11/12                         Loss D: -330.6250, loss G: 20.3352\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [74/200] Batch 11/12                         Loss D: -338.5105, loss G: 20.5640\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [75/200] Batch 11/12                         Loss D: -334.6833, loss G: 20.7005\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [76/200] Batch 11/12                         Loss D: -335.1667, loss G: 20.9269\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [77/200] Batch 11/12                         Loss D: -335.7191, loss G: 21.0898\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [78/200] Batch 11/12                         Loss D: -337.0522, loss G: 21.4804\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [79/200] Batch 11/12                         Loss D: -335.3318, loss G: 21.6171\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [80/200] Batch 11/12                         Loss D: -330.0359, loss G: 21.7933\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [81/200] Batch 11/12                         Loss D: -326.7318, loss G: 22.0461\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [82/200] Batch 11/12                         Loss D: -324.6105, loss G: 22.1915\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [83/200] Batch 11/12                         Loss D: -327.8602, loss G: 22.7588\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [84/200] Batch 11/12                         Loss D: -316.3549, loss G: 22.5493\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [85/200] Batch 11/12                         Loss D: -312.5055, loss G: 22.6471\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [86/200] Batch 11/12                         Loss D: -309.0860, loss G: 22.7340\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [87/200] Batch 11/12                         Loss D: -303.9044, loss G: 22.8286\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [88/200] Batch 11/12                         Loss D: -301.6148, loss G: 23.0726\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [89/200] Batch 11/12                         Loss D: -293.5640, loss G: 22.9270\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [90/200] Batch 11/12                         Loss D: -286.7631, loss G: 22.9835\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [91/200] Batch 11/12                         Loss D: -278.6309, loss G: 23.0520\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [92/200] Batch 11/12                         Loss D: -271.2084, loss G: 23.0576\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [93/200] Batch 11/12                         Loss D: -261.0273, loss G: 23.1734\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [94/200] Batch 11/12                         Loss D: -253.9080, loss G: 23.1116\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [95/200] Batch 11/12                         Loss D: -246.3249, loss G: 23.0879\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [96/200] Batch 11/12                         Loss D: -234.8393, loss G: 23.1067\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [97/200] Batch 11/12                         Loss D: -223.6264, loss G: 23.1655\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [98/200] Batch 11/12                         Loss D: -214.1959, loss G: 23.0932\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [99/200] Batch 11/12                         Loss D: -206.0558, loss G: 22.8978\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [100/200] Batch 11/12                         Loss D: -195.6710, loss G: 22.7828\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [101/200] Batch 11/12                         Loss D: -182.0550, loss G: 22.7593\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [102/200] Batch 11/12                         Loss D: -170.4007, loss G: 22.5699\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [103/200] Batch 11/12                         Loss D: -155.7246, loss G: 22.5576\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [104/200] Batch 11/12                         Loss D: -143.5172, loss G: 22.2283\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [105/200] Batch 11/12                         Loss D: -130.8216, loss G: 22.0663\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [106/200] Batch 11/12                         Loss D: -116.6683, loss G: 21.8430\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [107/200] Batch 11/12                         Loss D: -108.1690, loss G: 21.6176\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [108/200] Batch 11/12                         Loss D: -104.5478, loss G: 21.7651\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [109/200] Batch 11/12                         Loss D: -106.6666, loss G: 21.7422\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [110/200] Batch 11/12                         Loss D: -107.6381, loss G: 21.8641\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [111/200] Batch 11/12                         Loss D: -109.5216, loss G: 21.9237\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [112/200] Batch 11/12                         Loss D: -111.5230, loss G: 21.9699\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [113/200] Batch 11/12                         Loss D: -111.6710, loss G: 22.2112\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [114/200] Batch 11/12                         Loss D: -113.9500, loss G: 22.2486\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [115/200] Batch 11/12                         Loss D: -116.6476, loss G: 22.2115\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [116/200] Batch 11/12                         Loss D: -118.9340, loss G: 22.3207\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [117/200] Batch 11/12                         Loss D: -119.6565, loss G: 22.4716\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [118/200] Batch 11/12                         Loss D: -121.5112, loss G: 22.5511\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [119/200] Batch 11/12                         Loss D: -124.8107, loss G: 22.7240\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [120/200] Batch 11/12                         Loss D: -125.1537, loss G: 22.7134\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [121/200] Batch 11/12                         Loss D: -126.9882, loss G: 22.8076\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [122/200] Batch 11/12                         Loss D: -130.8824, loss G: 23.1790\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [123/200] Batch 11/12                         Loss D: -129.6892, loss G: 23.0532\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [124/200] Batch 11/12                         Loss D: -132.2571, loss G: 23.0907\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [125/200] Batch 11/12                         Loss D: -134.9524, loss G: 23.1272\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [126/200] Batch 11/12                         Loss D: -136.2263, loss G: 23.2591\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [127/200] Batch 11/12                         Loss D: -136.4396, loss G: 23.4075\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [128/200] Batch 11/12                         Loss D: -139.9025, loss G: 23.4056\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [129/200] Batch 11/12                         Loss D: -141.9919, loss G: 23.4968\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [130/200] Batch 11/12                         Loss D: -143.0605, loss G: 23.6152\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [131/200] Batch 11/12                         Loss D: -144.4337, loss G: 23.6903\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [132/200] Batch 11/12                         Loss D: -147.5118, loss G: 23.8673\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [133/200] Batch 11/12                         Loss D: -145.8791, loss G: 24.0136\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [134/200] Batch 11/12                         Loss D: -148.1043, loss G: 24.0329\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [135/200] Batch 11/12                         Loss D: -150.3601, loss G: 24.0652\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [136/200] Batch 11/12                         Loss D: -152.8292, loss G: 24.1226\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [137/200] Batch 11/12                         Loss D: -152.6407, loss G: 24.3254\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [138/200] Batch 11/12                         Loss D: -155.2747, loss G: 24.3270\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [139/200] Batch 11/12                         Loss D: -158.4166, loss G: 24.3464\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [140/200] Batch 11/12                         Loss D: -158.4185, loss G: 24.5315\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [141/200] Batch 11/12                         Loss D: -160.7857, loss G: 24.5721\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [142/200] Batch 11/12                         Loss D: -162.3307, loss G: 24.6507\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [143/200] Batch 11/12                         Loss D: -162.6304, loss G: 24.7874\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [144/200] Batch 11/12                         Loss D: -165.7227, loss G: 24.8377\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [145/200] Batch 11/12                         Loss D: -166.0989, loss G: 24.9637\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [146/200] Batch 11/12                         Loss D: -166.4686, loss G: 25.0902\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [147/200] Batch 11/12                         Loss D: -169.3190, loss G: 25.1368\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [148/200] Batch 11/12                         Loss D: -169.6716, loss G: 25.2788\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [149/200] Batch 11/12                         Loss D: -170.6309, loss G: 25.3873\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [150/200] Batch 11/12                         Loss D: -171.2053, loss G: 25.4808\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [151/200] Batch 11/12                         Loss D: -172.9257, loss G: 25.6072\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [152/200] Batch 11/12                         Loss D: -173.2935, loss G: 25.7126\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [153/200] Batch 11/12                         Loss D: -173.2359, loss G: 25.8434\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [154/200] Batch 11/12                         Loss D: -176.0466, loss G: 25.8864\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [155/200] Batch 11/12                         Loss D: -175.8583, loss G: 26.0379\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [156/200] Batch 11/12                         Loss D: -177.5145, loss G: 26.0941\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [157/200] Batch 11/12                         Loss D: -178.6347, loss G: 26.2106\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [158/200] Batch 11/12                         Loss D: -179.7160, loss G: 26.2750\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [159/200] Batch 11/12                         Loss D: -179.3709, loss G: 26.4135\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [160/200] Batch 11/12                         Loss D: -179.3963, loss G: 26.5625\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [161/200] Batch 11/12                         Loss D: -180.6363, loss G: 26.6494\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [162/200] Batch 11/12                         Loss D: -182.0033, loss G: 26.7169\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [163/200] Batch 11/12                         Loss D: -183.3255, loss G: 26.8047\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [164/200] Batch 11/12                         Loss D: -181.4237, loss G: 26.9948\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [165/200] Batch 11/12                         Loss D: -183.8902, loss G: 27.0372\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [166/200] Batch 11/12                         Loss D: -183.8457, loss G: 27.1794\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [167/200] Batch 11/12                         Loss D: -184.6454, loss G: 27.2305\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [168/200] Batch 11/12                         Loss D: -181.6387, loss G: 27.4893\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [169/200] Batch 11/12                         Loss D: -184.6216, loss G: 27.4632\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [170/200] Batch 11/12                         Loss D: -183.4734, loss G: 27.6059\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [171/200] Batch 11/12                         Loss D: -185.0604, loss G: 27.6805\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [172/200] Batch 11/12                         Loss D: -183.9977, loss G: 27.8056\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [173/200] Batch 11/12                         Loss D: -185.1273, loss G: 27.8856\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [174/200] Batch 11/12                         Loss D: -183.2152, loss G: 28.0031\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [175/200] Batch 11/12                         Loss D: -182.9233, loss G: 28.1458\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [176/200] Batch 11/12                         Loss D: -181.3053, loss G: 28.3052\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [177/200] Batch 11/12                         Loss D: -183.9885, loss G: 28.3018\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [178/200] Batch 11/12                         Loss D: -182.4431, loss G: 28.4312\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [179/200] Batch 11/12                         Loss D: -183.7766, loss G: 28.4931\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [180/200] Batch 11/12                         Loss D: -182.6459, loss G: 28.6447\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [181/200] Batch 11/12                         Loss D: -180.8769, loss G: 28.7388\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [182/200] Batch 11/12                         Loss D: -181.7036, loss G: 28.8038\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [183/200] Batch 11/12                         Loss D: -182.8566, loss G: 28.8943\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [184/200] Batch 11/12                         Loss D: -189.0574, loss G: 29.0911\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [185/200] Batch 11/12                         Loss D: -197.2188, loss G: 29.2946\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [186/200] Batch 11/12                         Loss D: -203.8591, loss G: 29.5289\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [187/200] Batch 11/12                         Loss D: -213.7177, loss G: 29.7438\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [188/200] Batch 11/12                         Loss D: -221.0101, loss G: 29.9899\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [189/200] Batch 11/12                         Loss D: -233.0587, loss G: 30.1917\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [190/200] Batch 11/12                         Loss D: -241.1918, loss G: 30.4411\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [191/200] Batch 11/12                         Loss D: -252.7966, loss G: 30.6478\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [192/200] Batch 11/12                         Loss D: -265.6946, loss G: 30.9416\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [193/200] Batch 11/12                         Loss D: -272.1218, loss G: 31.1738\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [194/200] Batch 11/12                         Loss D: -287.3253, loss G: 31.3652\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [195/200] Batch 11/12                         Loss D: -302.9100, loss G: 31.5663\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [196/200] Batch 11/12                         Loss D: -316.1472, loss G: 31.8555\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [197/200] Batch 11/12                         Loss D: -326.0609, loss G: 32.0247\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [198/200] Batch 11/12                         Loss D: -337.1169, loss G: 32.2297\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=1]                         Epoch [199/200] Batch 11/12                         Loss D: -350.7116, loss G: 32.4468\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [0/200] Batch 11/12                         Loss D: -0.1123, loss G: 17.2034\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [1/200] Batch 11/12                         Loss D: -0.0818, loss G: 17.1471\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [2/200] Batch 11/12                         Loss D: -0.0657, loss G: 17.0793\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [3/200] Batch 11/12                         Loss D: -0.0685, loss G: 17.0085\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [4/200] Batch 11/12                         Loss D: -0.0843, loss G: 16.9250\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [5/200] Batch 11/12                         Loss D: -0.1327, loss G: 16.8282\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [6/200] Batch 11/12                         Loss D: -0.2039, loss G: 16.7250\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [7/200] Batch 11/12                         Loss D: -0.3045, loss G: 16.5945\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [8/200] Batch 11/12                         Loss D: -0.4414, loss G: 16.4698\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [9/200] Batch 11/12                         Loss D: -0.6219, loss G: 16.3408\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [10/200] Batch 11/12                         Loss D: -0.8804, loss G: 16.1843\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [11/200] Batch 11/12                         Loss D: -1.2102, loss G: 16.0310\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [12/200] Batch 11/12                         Loss D: -1.6080, loss G: 15.8674\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [13/200] Batch 11/12                         Loss D: -2.1136, loss G: 15.6709\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [14/200] Batch 11/12                         Loss D: -2.7216, loss G: 15.4570\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [15/200] Batch 11/12                         Loss D: -3.4296, loss G: 15.2537\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [16/200] Batch 11/12                         Loss D: -4.2415, loss G: 15.1117\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [17/200] Batch 11/12                         Loss D: -5.0526, loss G: 15.0123\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [18/200] Batch 11/12                         Loss D: -5.9489, loss G: 14.9214\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [19/200] Batch 11/12                         Loss D: -6.9212, loss G: 14.8195\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [20/200] Batch 11/12                         Loss D: -7.8053, loss G: 14.7529\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [21/200] Batch 11/12                         Loss D: -8.9572, loss G: 14.6314\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [22/200] Batch 11/12                         Loss D: -10.2271, loss G: 14.5159\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [23/200] Batch 11/12                         Loss D: -11.3385, loss G: 14.4390\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [24/200] Batch 11/12                         Loss D: -12.9634, loss G: 14.2974\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [25/200] Batch 11/12                         Loss D: -14.4792, loss G: 14.1914\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [26/200] Batch 11/12                         Loss D: -16.2100, loss G: 14.0699\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [27/200] Batch 11/12                         Loss D: -18.0809, loss G: 13.9762\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [28/200] Batch 11/12                         Loss D: -20.3862, loss G: 13.8234\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [29/200] Batch 11/12                         Loss D: -22.2371, loss G: 13.7910\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [30/200] Batch 11/12                         Loss D: -24.8815, loss G: 13.6621\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [31/200] Batch 11/12                         Loss D: -27.8202, loss G: 13.5497\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [32/200] Batch 11/12                         Loss D: -30.9016, loss G: 13.4451\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [33/200] Batch 11/12                         Loss D: -34.1591, loss G: 13.3661\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [34/200] Batch 11/12                         Loss D: -37.5041, loss G: 13.3159\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [35/200] Batch 11/12                         Loss D: -41.3567, loss G: 13.2573\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [36/200] Batch 11/12                         Loss D: -45.5604, loss G: 13.1961\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [37/200] Batch 11/12                         Loss D: -50.3514, loss G: 13.1426\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [38/200] Batch 11/12                         Loss D: -54.6698, loss G: 13.1411\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [39/200] Batch 11/12                         Loss D: -60.0112, loss G: 13.1095\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [40/200] Batch 11/12                         Loss D: -64.9401, loss G: 13.1450\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [41/200] Batch 11/12                         Loss D: -72.2369, loss G: 13.0939\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [42/200] Batch 11/12                         Loss D: -77.9531, loss G: 13.1360\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [43/200] Batch 11/12                         Loss D: -84.0104, loss G: 13.2099\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [44/200] Batch 11/12                         Loss D: -89.8394, loss G: 13.3219\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [45/200] Batch 11/12                         Loss D: -98.1560, loss G: 13.3588\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [46/200] Batch 11/12                         Loss D: -104.6660, loss G: 13.5033\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [47/200] Batch 11/12                         Loss D: -111.6238, loss G: 13.6435\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [48/200] Batch 11/12                         Loss D: -119.6869, loss G: 13.7800\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [49/200] Batch 11/12                         Loss D: -125.0276, loss G: 14.0227\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [50/200] Batch 11/12                         Loss D: -128.3384, loss G: 14.3228\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [51/200] Batch 11/12                         Loss D: -132.2220, loss G: 14.5995\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [52/200] Batch 11/12                         Loss D: -137.0778, loss G: 14.8375\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [53/200] Batch 11/12                         Loss D: -141.7637, loss G: 15.1066\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [54/200] Batch 11/12                         Loss D: -144.8958, loss G: 15.3450\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [55/200] Batch 11/12                         Loss D: -145.4519, loss G: 15.5862\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [56/200] Batch 11/12                         Loss D: -149.0564, loss G: 15.8105\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [57/200] Batch 11/12                         Loss D: -152.7421, loss G: 16.0227\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [58/200] Batch 11/12                         Loss D: -154.7096, loss G: 16.2301\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [59/200] Batch 11/12                         Loss D: -154.8514, loss G: 16.4412\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [60/200] Batch 11/12                         Loss D: -156.1595, loss G: 16.6211\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [61/200] Batch 11/12                         Loss D: -156.9237, loss G: 16.8068\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [62/200] Batch 11/12                         Loss D: -158.8353, loss G: 16.9714\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [63/200] Batch 11/12                         Loss D: -159.5205, loss G: 17.1269\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [64/200] Batch 11/12                         Loss D: -161.2828, loss G: 17.2690\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [65/200] Batch 11/12                         Loss D: -160.8233, loss G: 17.4088\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [66/200] Batch 11/12                         Loss D: -160.8794, loss G: 17.5272\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [67/200] Batch 11/12                         Loss D: -160.4471, loss G: 17.6408\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [68/200] Batch 11/12                         Loss D: -159.8352, loss G: 17.7456\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [69/200] Batch 11/12                         Loss D: -160.9804, loss G: 17.8427\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [70/200] Batch 11/12                         Loss D: -157.1477, loss G: 17.9105\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [71/200] Batch 11/12                         Loss D: -157.8232, loss G: 17.9870\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [72/200] Batch 11/12                         Loss D: -156.8181, loss G: 18.0458\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [73/200] Batch 11/12                         Loss D: -153.3721, loss G: 18.0823\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [74/200] Batch 11/12                         Loss D: -151.6926, loss G: 18.1167\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [75/200] Batch 11/12                         Loss D: -149.5810, loss G: 18.1412\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [76/200] Batch 11/12                         Loss D: -146.0885, loss G: 18.1459\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [77/200] Batch 11/12                         Loss D: -144.8249, loss G: 18.1562\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [78/200] Batch 11/12                         Loss D: -140.8719, loss G: 18.1324\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [79/200] Batch 11/12                         Loss D: -135.5844, loss G: 18.0429\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [80/200] Batch 11/12                         Loss D: -129.4849, loss G: 17.9106\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [81/200] Batch 11/12                         Loss D: -124.3757, loss G: 17.8410\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [82/200] Batch 11/12                         Loss D: -121.6693, loss G: 17.8422\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [83/200] Batch 11/12                         Loss D: -119.0154, loss G: 17.8505\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [84/200] Batch 11/12                         Loss D: -113.7837, loss G: 17.8808\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [85/200] Batch 11/12                         Loss D: -115.5439, loss G: 18.0368\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [86/200] Batch 11/12                         Loss D: -117.9859, loss G: 18.1843\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [87/200] Batch 11/12                         Loss D: -118.9193, loss G: 18.3113\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [88/200] Batch 11/12                         Loss D: -120.9083, loss G: 18.4406\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [89/200] Batch 11/12                         Loss D: -121.0420, loss G: 18.5455\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [90/200] Batch 11/12                         Loss D: -122.4041, loss G: 18.6537\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [91/200] Batch 11/12                         Loss D: -120.8969, loss G: 18.7254\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [92/200] Batch 11/12                         Loss D: -122.4843, loss G: 18.8250\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [93/200] Batch 11/12                         Loss D: -122.3937, loss G: 18.9020\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [94/200] Batch 11/12                         Loss D: -120.7683, loss G: 18.9534\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [95/200] Batch 11/12                         Loss D: -121.4106, loss G: 19.0301\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [96/200] Batch 11/12                         Loss D: -120.0635, loss G: 19.0747\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [97/200] Batch 11/12                         Loss D: -120.6478, loss G: 19.1408\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [98/200] Batch 11/12                         Loss D: -118.4740, loss G: 19.1627\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [99/200] Batch 11/12                         Loss D: -117.4327, loss G: 19.1973\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [100/200] Batch 11/12                         Loss D: -115.0268, loss G: 19.2033\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [101/200] Batch 11/12                         Loss D: -112.5914, loss G: 19.2054\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [102/200] Batch 11/12                         Loss D: -111.8396, loss G: 19.2294\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [103/200] Batch 11/12                         Loss D: -109.1896, loss G: 19.2188\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [104/200] Batch 11/12                         Loss D: -107.1533, loss G: 19.2116\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [105/200] Batch 11/12                         Loss D: -104.0490, loss G: 19.1831\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [106/200] Batch 11/12                         Loss D: -101.4840, loss G: 19.1558\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [107/200] Batch 11/12                         Loss D: -99.4814, loss G: 19.1383\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [108/200] Batch 11/12                         Loss D: -96.3413, loss G: 19.0959\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [109/200] Batch 11/12                         Loss D: -93.8578, loss G: 19.0612\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [110/200] Batch 11/12                         Loss D: -89.4071, loss G: 18.9888\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [111/200] Batch 11/12                         Loss D: -86.0521, loss G: 18.9248\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [112/200] Batch 11/12                         Loss D: -81.4422, loss G: 18.8491\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [113/200] Batch 11/12                         Loss D: -77.3046, loss G: 18.7841\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [114/200] Batch 11/12                         Loss D: -71.4148, loss G: 18.6904\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [115/200] Batch 11/12                         Loss D: -66.6472, loss G: 18.6119\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [116/200] Batch 11/12                         Loss D: -60.3285, loss G: 18.5105\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [117/200] Batch 11/12                         Loss D: -54.2870, loss G: 18.4215\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [118/200] Batch 11/12                         Loss D: -47.0124, loss G: 18.3194\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [119/200] Batch 11/12                         Loss D: -39.8936, loss G: 18.2187\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [120/200] Batch 11/12                         Loss D: -33.0833, loss G: 18.1167\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [121/200] Batch 11/12                         Loss D: -26.1767, loss G: 18.0181\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [122/200] Batch 11/12                         Loss D: -14.9195, loss G: 17.9064\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [123/200] Batch 11/12                         Loss D: 1.1536, loss G: 17.5542\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [124/200] Batch 11/12                         Loss D: 32.9332, loss G: 15.0138\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [125/200] Batch 11/12                         Loss D: 58.7783, loss G: 13.0703\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [126/200] Batch 11/12                         Loss D: 80.2163, loss G: 11.4399\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [127/200] Batch 11/12                         Loss D: 93.7050, loss G: 10.8160\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [128/200] Batch 11/12                         Loss D: 99.2483, loss G: 10.4621\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [129/200] Batch 11/12                         Loss D: 104.6895, loss G: 10.1045\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [130/200] Batch 11/12                         Loss D: 107.2392, loss G: 9.9109\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [131/200] Batch 11/12                         Loss D: 107.8108, loss G: 9.8271\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [132/200] Batch 11/12                         Loss D: 107.2316, loss G: 9.7921\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [133/200] Batch 11/12                         Loss D: 104.7008, loss G: 9.8395\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [134/200] Batch 11/12                         Loss D: 101.0043, loss G: 9.9380\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [135/200] Batch 11/12                         Loss D: 95.8013, loss G: 10.0974\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [136/200] Batch 11/12                         Loss D: 91.0351, loss G: 10.2004\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [137/200] Batch 11/12                         Loss D: 84.5404, loss G: 10.3787\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [138/200] Batch 11/12                         Loss D: 76.3749, loss G: 10.6378\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [139/200] Batch 11/12                         Loss D: 68.6085, loss G: 10.8266\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [140/200] Batch 11/12                         Loss D: 60.7641, loss G: 11.1531\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [141/200] Batch 11/12                         Loss D: 52.7020, loss G: 11.5372\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [142/200] Batch 11/12                         Loss D: 44.1072, loss G: 11.9836\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [143/200] Batch 11/12                         Loss D: 34.9627, loss G: 12.4338\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [144/200] Batch 11/12                         Loss D: 25.7871, loss G: 12.9115\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [145/200] Batch 11/12                         Loss D: 16.0915, loss G: 13.4715\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [146/200] Batch 11/12                         Loss D: 6.3778, loss G: 13.9851\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [147/200] Batch 11/12                         Loss D: -3.2033, loss G: 14.5419\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [148/200] Batch 11/12                         Loss D: -12.9339, loss G: 15.1139\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [149/200] Batch 11/12                         Loss D: -22.8665, loss G: 15.6567\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [150/200] Batch 11/12                         Loss D: -31.1423, loss G: 16.2334\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [151/200] Batch 11/12                         Loss D: -40.4804, loss G: 16.7705\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [152/200] Batch 11/12                         Loss D: -49.6699, loss G: 17.3067\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [153/200] Batch 11/12                         Loss D: -57.5934, loss G: 17.8345\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [154/200] Batch 11/12                         Loss D: -63.8154, loss G: 18.3077\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [155/200] Batch 11/12                         Loss D: -71.1782, loss G: 18.7788\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [156/200] Batch 11/12                         Loss D: -75.8203, loss G: 19.1769\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [157/200] Batch 11/12                         Loss D: -81.3203, loss G: 19.5728\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [158/200] Batch 11/12                         Loss D: -85.4862, loss G: 19.9232\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [159/200] Batch 11/12                         Loss D: -89.2243, loss G: 20.2487\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [160/200] Batch 11/12                         Loss D: -92.0643, loss G: 20.5131\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [161/200] Batch 11/12                         Loss D: -94.4935, loss G: 20.7622\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [162/200] Batch 11/12                         Loss D: -96.9772, loss G: 20.9939\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [163/200] Batch 11/12                         Loss D: -96.5317, loss G: 21.1138\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [164/200] Batch 11/12                         Loss D: -97.4812, loss G: 21.2679\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [165/200] Batch 11/12                         Loss D: -96.8036, loss G: 21.3550\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [166/200] Batch 11/12                         Loss D: -96.7812, loss G: 21.4537\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [167/200] Batch 11/12                         Loss D: -94.9346, loss G: 21.4729\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [168/200] Batch 11/12                         Loss D: -94.0842, loss G: 21.5172\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [169/200] Batch 11/12                         Loss D: -92.1745, loss G: 21.5113\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [170/200] Batch 11/12                         Loss D: -90.3819, loss G: 21.5040\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [171/200] Batch 11/12                         Loss D: -88.2506, loss G: 21.4753\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [172/200] Batch 11/12                         Loss D: -85.0080, loss G: 21.3924\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [173/200] Batch 11/12                         Loss D: -83.3125, loss G: 21.3676\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [174/200] Batch 11/12                         Loss D: -78.5252, loss G: 21.2036\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [175/200] Batch 11/12                         Loss D: -76.0168, loss G: 21.1311\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [176/200] Batch 11/12                         Loss D: -72.5125, loss G: 21.0101\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [177/200] Batch 11/12                         Loss D: -69.0921, loss G: 20.8885\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [178/200] Batch 11/12                         Loss D: -65.2295, loss G: 20.7412\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [179/200] Batch 11/12                         Loss D: -61.4275, loss G: 20.5927\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [180/200] Batch 11/12                         Loss D: -57.5988, loss G: 20.4359\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [181/200] Batch 11/12                         Loss D: -54.1656, loss G: 20.2997\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [182/200] Batch 11/12                         Loss D: -50.0340, loss G: 20.1188\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [183/200] Batch 11/12                         Loss D: -46.0281, loss G: 19.9392\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [184/200] Batch 11/12                         Loss D: -41.7229, loss G: 19.7419\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [185/200] Batch 11/12                         Loss D: -38.0364, loss G: 19.5721\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [186/200] Batch 11/12                         Loss D: -33.6455, loss G: 19.3633\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [187/200] Batch 11/12                         Loss D: -29.4545, loss G: 19.1588\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [188/200] Batch 11/12                         Loss D: -25.3889, loss G: 18.9594\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [189/200] Batch 11/12                         Loss D: -21.0471, loss G: 18.7402\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [190/200] Batch 11/12                         Loss D: -17.0802, loss G: 18.5405\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [191/200] Batch 11/12                         Loss D: -12.8520, loss G: 18.3224\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [192/200] Batch 11/12                         Loss D: -8.3876, loss G: 18.0856\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [193/200] Batch 11/12                         Loss D: -4.0993, loss G: 17.8549\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [194/200] Batch 11/12                         Loss D: 0.4152, loss G: 17.6221\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [195/200] Batch 11/12                         Loss D: 3.1443, loss G: 17.5186\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [196/200] Batch 11/12                         Loss D: 3.8212, loss G: 17.5046\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [197/200] Batch 11/12                         Loss D: 4.1574, loss G: 17.4959\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [198/200] Batch 11/12                         Loss D: 4.4735, loss G: 17.4916\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [199/200] Batch 11/12                         Loss D: 4.7022, loss G: 17.4854\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [0/200] Batch 11/12                         Loss D: 0.1889, loss G: 3.4619\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [1/200] Batch 11/12                         Loss D: 0.3454, loss G: 3.4569\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [2/200] Batch 11/12                         Loss D: 0.4069, loss G: 3.4532\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [3/200] Batch 11/12                         Loss D: 0.4572, loss G: 3.4501\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [4/200] Batch 11/12                         Loss D: 0.4108, loss G: 3.4473\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [5/200] Batch 11/12                         Loss D: 0.3310, loss G: 3.4450\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [6/200] Batch 11/12                         Loss D: 0.2666, loss G: 3.4435\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [7/200] Batch 11/12                         Loss D: 0.2229, loss G: 3.4424\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [8/200] Batch 11/12                         Loss D: 0.1560, loss G: 3.4416\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [9/200] Batch 11/12                         Loss D: 0.1273, loss G: 3.4412\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [10/200] Batch 11/12                         Loss D: 0.0948, loss G: 3.4405\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [11/200] Batch 11/12                         Loss D: 0.0655, loss G: 3.4402\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [12/200] Batch 11/12                         Loss D: 0.0488, loss G: 3.4402\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [13/200] Batch 11/12                         Loss D: 0.0054, loss G: 3.4404\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [14/200] Batch 11/12                         Loss D: -0.0071, loss G: 3.4411\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [15/200] Batch 11/12                         Loss D: -0.0545, loss G: 3.4422\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [16/200] Batch 11/12                         Loss D: -0.1019, loss G: 3.4435\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [17/200] Batch 11/12                         Loss D: -0.1839, loss G: 3.4449\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [18/200] Batch 11/12                         Loss D: -0.2460, loss G: 3.4452\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [19/200] Batch 11/12                         Loss D: -0.2806, loss G: 3.4449\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [20/200] Batch 11/12                         Loss D: -0.3128, loss G: 3.4445\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [21/200] Batch 11/12                         Loss D: -0.3377, loss G: 3.4444\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [22/200] Batch 11/12                         Loss D: -0.3703, loss G: 3.4443\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [23/200] Batch 11/12                         Loss D: -0.3899, loss G: 3.4443\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [24/200] Batch 11/12                         Loss D: -0.4025, loss G: 3.4445\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [25/200] Batch 11/12                         Loss D: -0.4089, loss G: 3.4448\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [26/200] Batch 11/12                         Loss D: -0.4475, loss G: 3.4450\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [27/200] Batch 11/12                         Loss D: -0.4825, loss G: 3.4453\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [28/200] Batch 11/12                         Loss D: -0.4947, loss G: 3.4457\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [29/200] Batch 11/12                         Loss D: -0.5233, loss G: 3.4464\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [30/200] Batch 11/12                         Loss D: -0.5411, loss G: 3.4472\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [31/200] Batch 11/12                         Loss D: -0.5585, loss G: 3.4481\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [32/200] Batch 11/12                         Loss D: -0.5828, loss G: 3.4490\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [33/200] Batch 11/12                         Loss D: -0.5898, loss G: 3.4500\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [34/200] Batch 11/12                         Loss D: -0.5918, loss G: 3.4509\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [35/200] Batch 11/12                         Loss D: -0.5969, loss G: 3.4518\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [36/200] Batch 11/12                         Loss D: -0.5552, loss G: 3.4523\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [37/200] Batch 11/12                         Loss D: -0.5162, loss G: 3.4522\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [38/200] Batch 11/12                         Loss D: -0.5228, loss G: 3.4520\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [39/200] Batch 11/12                         Loss D: -0.5239, loss G: 3.4515\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [40/200] Batch 11/12                         Loss D: -0.5627, loss G: 3.4513\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [41/200] Batch 11/12                         Loss D: -0.6050, loss G: 3.4508\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [42/200] Batch 11/12                         Loss D: -0.6762, loss G: 3.4503\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [43/200] Batch 11/12                         Loss D: -0.7239, loss G: 3.4497\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [44/200] Batch 11/12                         Loss D: -0.7743, loss G: 3.4490\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [45/200] Batch 11/12                         Loss D: -0.8628, loss G: 3.4482\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [46/200] Batch 11/12                         Loss D: -0.9350, loss G: 3.4474\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [47/200] Batch 11/12                         Loss D: -1.0303, loss G: 3.4465\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [48/200] Batch 11/12                         Loss D: -1.1015, loss G: 3.4453\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [49/200] Batch 11/12                         Loss D: -1.1628, loss G: 3.4439\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [50/200] Batch 11/12                         Loss D: -1.1940, loss G: 3.4425\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [51/200] Batch 11/12                         Loss D: -1.2077, loss G: 3.4410\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [52/200] Batch 11/12                         Loss D: -1.1398, loss G: 3.4389\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [53/200] Batch 11/12                         Loss D: -0.5558, loss G: 3.4273\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [54/200] Batch 11/12                         Loss D: 1.7691, loss G: 3.2513\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [55/200] Batch 11/12                         Loss D: 3.9192, loss G: 3.0969\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [56/200] Batch 11/12                         Loss D: 4.6677, loss G: 3.0153\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [57/200] Batch 11/12                         Loss D: 4.7966, loss G: 2.9943\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [58/200] Batch 11/12                         Loss D: 6.3567, loss G: 3.0383\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [59/200] Batch 11/12                         Loss D: 5.6644, loss G: 3.1097\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [60/200] Batch 11/12                         Loss D: 4.6037, loss G: 3.1907\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [61/200] Batch 11/12                         Loss D: 3.7391, loss G: 3.3035\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [62/200] Batch 11/12                         Loss D: 2.6020, loss G: 3.4485\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [63/200] Batch 11/12                         Loss D: 1.3884, loss G: 3.5743\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [64/200] Batch 11/12                         Loss D: 0.5850, loss G: 3.6323\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [65/200] Batch 11/12                         Loss D: 0.0849, loss G: 3.6435\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [66/200] Batch 11/12                         Loss D: -0.1142, loss G: 3.6347\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [67/200] Batch 11/12                         Loss D: -0.2219, loss G: 3.6123\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [68/200] Batch 11/12                         Loss D: -0.3315, loss G: 3.5854\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [69/200] Batch 11/12                         Loss D: -0.5310, loss G: 3.5622\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [70/200] Batch 11/12                         Loss D: -0.9335, loss G: 3.5383\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [71/200] Batch 11/12                         Loss D: -1.2816, loss G: 3.5086\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [72/200] Batch 11/12                         Loss D: -1.3930, loss G: 3.4787\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [73/200] Batch 11/12                         Loss D: -1.5267, loss G: 3.4405\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [74/200] Batch 11/12                         Loss D: -1.6743, loss G: 3.3908\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [75/200] Batch 11/12                         Loss D: -0.9491, loss G: 3.3611\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [76/200] Batch 11/12                         Loss D: 0.0413, loss G: 3.3216\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [77/200] Batch 11/12                         Loss D: 0.8073, loss G: 3.3066\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [78/200] Batch 11/12                         Loss D: 1.2895, loss G: 3.2981\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [79/200] Batch 11/12                         Loss D: 1.1420, loss G: 3.3030\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [80/200] Batch 11/12                         Loss D: 0.7451, loss G: 3.3141\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [81/200] Batch 11/12                         Loss D: 0.3844, loss G: 3.3275\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [82/200] Batch 11/12                         Loss D: 0.5301, loss G: 3.3354\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [83/200] Batch 11/12                         Loss D: 0.6045, loss G: 3.3438\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [84/200] Batch 11/12                         Loss D: 0.3943, loss G: 3.3517\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [85/200] Batch 11/12                         Loss D: 0.2726, loss G: 3.3603\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [86/200] Batch 11/12                         Loss D: 0.2464, loss G: 3.3706\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [87/200] Batch 11/12                         Loss D: -0.8935, loss G: 3.3866\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [88/200] Batch 11/12                         Loss D: -1.8781, loss G: 3.4027\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [89/200] Batch 11/12                         Loss D: -2.0887, loss G: 3.4162\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [90/200] Batch 11/12                         Loss D: -2.2402, loss G: 3.4288\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [91/200] Batch 11/12                         Loss D: -2.1924, loss G: 3.4385\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [92/200] Batch 11/12                         Loss D: -1.5986, loss G: 3.4454\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [93/200] Batch 11/12                         Loss D: -1.2425, loss G: 3.4507\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [94/200] Batch 11/12                         Loss D: -0.9151, loss G: 3.4558\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [95/200] Batch 11/12                         Loss D: -0.6315, loss G: 3.4658\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [96/200] Batch 11/12                         Loss D: -0.5555, loss G: 3.4683\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [97/200] Batch 11/12                         Loss D: -0.3665, loss G: 3.4738\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [98/200] Batch 11/12                         Loss D: -0.3055, loss G: 3.4789\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [99/200] Batch 11/12                         Loss D: 0.0141, loss G: 3.4832\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [100/200] Batch 11/12                         Loss D: 0.2587, loss G: 3.4882\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [101/200] Batch 11/12                         Loss D: 0.7872, loss G: 3.4896\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [102/200] Batch 11/12                         Loss D: 1.2417, loss G: 3.4917\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [103/200] Batch 11/12                         Loss D: 1.7555, loss G: 3.4923\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [104/200] Batch 11/12                         Loss D: 2.2806, loss G: 3.4922\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [105/200] Batch 11/12                         Loss D: 3.2199, loss G: 3.4739\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [106/200] Batch 11/12                         Loss D: 5.0133, loss G: 3.4554\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [107/200] Batch 11/12                         Loss D: 6.3281, loss G: 3.4393\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [108/200] Batch 11/12                         Loss D: 6.3880, loss G: 3.4274\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [109/200] Batch 11/12                         Loss D: 5.9410, loss G: 3.4236\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [110/200] Batch 11/12                         Loss D: 5.5630, loss G: 3.4203\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [111/200] Batch 11/12                         Loss D: 5.2111, loss G: 3.4172\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [112/200] Batch 11/12                         Loss D: 4.8383, loss G: 3.4158\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [113/200] Batch 11/12                         Loss D: 4.5446, loss G: 3.4123\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [114/200] Batch 11/12                         Loss D: 4.2249, loss G: 3.4107\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [115/200] Batch 11/12                         Loss D: 3.9344, loss G: 3.4084\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [116/200] Batch 11/12                         Loss D: 3.6595, loss G: 3.4065\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [117/200] Batch 11/12                         Loss D: 3.4131, loss G: 3.4031\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [118/200] Batch 11/12                         Loss D: 3.1484, loss G: 3.4020\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [119/200] Batch 11/12                         Loss D: 2.9027, loss G: 3.3997\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [120/200] Batch 11/12                         Loss D: 2.6530, loss G: 3.3987\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [121/200] Batch 11/12                         Loss D: 2.4431, loss G: 3.3971\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [122/200] Batch 11/12                         Loss D: 2.2101, loss G: 3.3906\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [123/200] Batch 11/12                         Loss D: 1.9985, loss G: 3.3860\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [124/200] Batch 11/12                         Loss D: 1.7501, loss G: 3.3802\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [125/200] Batch 11/12                         Loss D: 1.4444, loss G: 3.3755\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [126/200] Batch 11/12                         Loss D: 1.1532, loss G: 3.3713\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [127/200] Batch 11/12                         Loss D: 0.8952, loss G: 3.3682\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [128/200] Batch 11/12                         Loss D: 0.6548, loss G: 3.3659\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [129/200] Batch 11/12                         Loss D: 0.4392, loss G: 3.3625\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [130/200] Batch 11/12                         Loss D: 0.2392, loss G: 3.3603\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [131/200] Batch 11/12                         Loss D: 0.0502, loss G: 3.3603\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [132/200] Batch 11/12                         Loss D: -0.1327, loss G: 3.3562\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [133/200] Batch 11/12                         Loss D: 0.0796, loss G: 3.2835\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [134/200] Batch 11/12                         Loss D: 0.5674, loss G: 3.1548\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [135/200] Batch 11/12                         Loss D: 0.7067, loss G: 3.0572\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [136/200] Batch 11/12                         Loss D: 0.6840, loss G: 2.9908\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [137/200] Batch 11/12                         Loss D: 0.5797, loss G: 2.9687\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [138/200] Batch 11/12                         Loss D: -0.1689, loss G: 2.9756\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [139/200] Batch 11/12                         Loss D: -1.6614, loss G: 3.0081\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [140/200] Batch 11/12                         Loss D: -3.1423, loss G: 3.0527\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [141/200] Batch 11/12                         Loss D: -4.6337, loss G: 3.1094\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [142/200] Batch 11/12                         Loss D: -5.9135, loss G: 3.1733\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [143/200] Batch 11/12                         Loss D: -7.0329, loss G: 3.2363\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [144/200] Batch 11/12                         Loss D: -7.9198, loss G: 3.2906\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [145/200] Batch 11/12                         Loss D: -8.5103, loss G: 3.3380\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [146/200] Batch 11/12                         Loss D: -8.7725, loss G: 3.3778\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [147/200] Batch 11/12                         Loss D: -8.8508, loss G: 3.4105\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [148/200] Batch 11/12                         Loss D: -8.6802, loss G: 3.4335\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [149/200] Batch 11/12                         Loss D: -8.1628, loss G: 3.4477\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [150/200] Batch 11/12                         Loss D: -7.5377, loss G: 3.4553\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [151/200] Batch 11/12                         Loss D: -6.7092, loss G: 3.4546\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [152/200] Batch 11/12                         Loss D: -5.8498, loss G: 3.4501\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [153/200] Batch 11/12                         Loss D: -4.9114, loss G: 3.4408\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [154/200] Batch 11/12                         Loss D: -3.9540, loss G: 3.4276\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [155/200] Batch 11/12                         Loss D: -3.0264, loss G: 3.4123\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [156/200] Batch 11/12                         Loss D: -2.0630, loss G: 3.3938\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [157/200] Batch 11/12                         Loss D: -1.1741, loss G: 3.3720\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [158/200] Batch 11/12                         Loss D: -1.1441, loss G: 3.3684\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [159/200] Batch 11/12                         Loss D: -1.2226, loss G: 3.3660\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [160/200] Batch 11/12                         Loss D: -1.3159, loss G: 3.3635\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [161/200] Batch 11/12                         Loss D: -1.4001, loss G: 3.3628\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [162/200] Batch 11/12                         Loss D: -1.5623, loss G: 3.3599\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [163/200] Batch 11/12                         Loss D: -1.7323, loss G: 3.3595\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [164/200] Batch 11/12                         Loss D: -1.8661, loss G: 3.3620\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [165/200] Batch 11/12                         Loss D: -1.9866, loss G: 3.3591\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [166/200] Batch 11/12                         Loss D: -2.0974, loss G: 3.3585\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [167/200] Batch 11/12                         Loss D: -2.1915, loss G: 3.3582\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [168/200] Batch 11/12                         Loss D: -2.2848, loss G: 3.3583\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [169/200] Batch 11/12                         Loss D: -2.3589, loss G: 3.3578\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [170/200] Batch 11/12                         Loss D: -2.4428, loss G: 3.3590\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [171/200] Batch 11/12                         Loss D: -2.5190, loss G: 3.3572\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [172/200] Batch 11/12                         Loss D: -2.5970, loss G: 3.3573\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [173/200] Batch 11/12                         Loss D: -2.6721, loss G: 3.3575\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [174/200] Batch 11/12                         Loss D: -2.7370, loss G: 3.3572\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [175/200] Batch 11/12                         Loss D: -2.8189, loss G: 3.3568\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [176/200] Batch 11/12                         Loss D: -2.8788, loss G: 3.3569\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [177/200] Batch 11/12                         Loss D: -2.9627, loss G: 3.3570\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [178/200] Batch 11/12                         Loss D: -3.0376, loss G: 3.3564\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [179/200] Batch 11/12                         Loss D: -3.0831, loss G: 3.3565\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [180/200] Batch 11/12                         Loss D: -3.1741, loss G: 3.3564\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [181/200] Batch 11/12                         Loss D: -3.2475, loss G: 3.3566\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [182/200] Batch 11/12                         Loss D: -3.3153, loss G: 3.3566\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [183/200] Batch 11/12                         Loss D: -3.3920, loss G: 3.3563\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [184/200] Batch 11/12                         Loss D: -3.4537, loss G: 3.3563\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [185/200] Batch 11/12                         Loss D: -3.5686, loss G: 3.3562\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [186/200] Batch 11/12                         Loss D: -3.6176, loss G: 3.3561\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [187/200] Batch 11/12                         Loss D: -3.7231, loss G: 3.3565\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [188/200] Batch 11/12                         Loss D: -3.7759, loss G: 3.3566\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [189/200] Batch 11/12                         Loss D: -3.8608, loss G: 3.3565\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [190/200] Batch 11/12                         Loss D: -3.9683, loss G: 3.3562\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [191/200] Batch 11/12                         Loss D: -4.0678, loss G: 3.3562\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [192/200] Batch 11/12                         Loss D: -4.1308, loss G: 3.3563\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [193/200] Batch 11/12                         Loss D: -4.1924, loss G: 3.3565\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [194/200] Batch 11/12                         Loss D: -4.2940, loss G: 3.3570\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [195/200] Batch 11/12                         Loss D: -4.4113, loss G: 3.3568\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [196/200] Batch 11/12                         Loss D: -4.5175, loss G: 3.3567\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [197/200] Batch 11/12                         Loss D: -4.5966, loss G: 3.3570\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [198/200] Batch 11/12                         Loss D: -4.6993, loss G: 3.3574\n",
      "[lr_G=5e-05, lr_D=0.0001, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [199/200] Batch 11/12                         Loss D: -4.8186, loss G: 3.3573\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [0/200] Batch 11/12                         Loss D: 8.6078, loss G: 34.3744\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [1/200] Batch 11/12                         Loss D: 8.5865, loss G: 34.2676\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [2/200] Batch 11/12                         Loss D: 8.5752, loss G: 34.1530\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [3/200] Batch 11/12                         Loss D: 8.5677, loss G: 34.0247\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [4/200] Batch 11/12                         Loss D: 8.5646, loss G: 33.8721\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [5/200] Batch 11/12                         Loss D: 8.5977, loss G: 33.7166\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [6/200] Batch 11/12                         Loss D: 8.7031, loss G: 33.4916\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [7/200] Batch 11/12                         Loss D: 8.8282, loss G: 33.2372\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [8/200] Batch 11/12                         Loss D: 8.9529, loss G: 32.9373\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [9/200] Batch 11/12                         Loss D: 9.0263, loss G: 32.6279\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [10/200] Batch 11/12                         Loss D: 9.0929, loss G: 32.2327\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [11/200] Batch 11/12                         Loss D: 9.1508, loss G: 31.8839\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [12/200] Batch 11/12                         Loss D: 9.1966, loss G: 31.3874\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [13/200] Batch 11/12                         Loss D: 9.2318, loss G: 30.9274\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [14/200] Batch 11/12                         Loss D: 9.1632, loss G: 30.4345\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [15/200] Batch 11/12                         Loss D: 9.0886, loss G: 29.8921\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [16/200] Batch 11/12                         Loss D: 9.0032, loss G: 29.4164\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [17/200] Batch 11/12                         Loss D: 8.7851, loss G: 29.0953\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [18/200] Batch 11/12                         Loss D: 8.6278, loss G: 28.7517\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [19/200] Batch 11/12                         Loss D: 8.3405, loss G: 28.3424\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [20/200] Batch 11/12                         Loss D: 8.0327, loss G: 27.9760\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [21/200] Batch 11/12                         Loss D: 7.5966, loss G: 27.5367\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [22/200] Batch 11/12                         Loss D: 7.1229, loss G: 27.1391\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [23/200] Batch 11/12                         Loss D: 6.5372, loss G: 26.6817\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [24/200] Batch 11/12                         Loss D: 5.8543, loss G: 26.2285\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [25/200] Batch 11/12                         Loss D: 4.9910, loss G: 25.6218\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [26/200] Batch 11/12                         Loss D: 4.0564, loss G: 25.1253\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [27/200] Batch 11/12                         Loss D: 2.9649, loss G: 24.5588\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [28/200] Batch 11/12                         Loss D: 1.8712, loss G: 24.1781\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [29/200] Batch 11/12                         Loss D: 0.3610, loss G: 23.3427\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [30/200] Batch 11/12                         Loss D: -1.2866, loss G: 22.5988\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [31/200] Batch 11/12                         Loss D: -3.1267, loss G: 21.8786\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [32/200] Batch 11/12                         Loss D: -5.0131, loss G: 21.2943\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [33/200] Batch 11/12                         Loss D: -7.5171, loss G: 20.2871\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [34/200] Batch 11/12                         Loss D: -9.5912, loss G: 19.8138\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [35/200] Batch 11/12                         Loss D: -12.5666, loss G: 18.7807\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [36/200] Batch 11/12                         Loss D: -15.5716, loss G: 17.9153\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [37/200] Batch 11/12                         Loss D: -19.0960, loss G: 16.8798\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [38/200] Batch 11/12                         Loss D: -22.5359, loss G: 16.0400\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [39/200] Batch 11/12                         Loss D: -26.3343, loss G: 15.1764\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [40/200] Batch 11/12                         Loss D: -30.8960, loss G: 14.0610\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [41/200] Batch 11/12                         Loss D: -34.9968, loss G: 13.3066\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [42/200] Batch 11/12                         Loss D: -38.8441, loss G: 12.7270\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [43/200] Batch 11/12                         Loss D: -42.6276, loss G: 12.4263\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [44/200] Batch 11/12                         Loss D: -46.1521, loss G: 12.1183\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [45/200] Batch 11/12                         Loss D: -48.7613, loss G: 11.9283\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [46/200] Batch 11/12                         Loss D: -52.2356, loss G: 11.6212\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [47/200] Batch 11/12                         Loss D: -56.1160, loss G: 11.1819\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [48/200] Batch 11/12                         Loss D: -59.9139, loss G: 10.8389\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [49/200] Batch 11/12                         Loss D: -63.4903, loss G: 10.5858\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [50/200] Batch 11/12                         Loss D: -67.2422, loss G: 10.2458\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [51/200] Batch 11/12                         Loss D: -71.5030, loss G: 9.9875\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [52/200] Batch 11/12                         Loss D: -75.4199, loss G: 9.7018\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [53/200] Batch 11/12                         Loss D: -79.2969, loss G: 9.3289\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [54/200] Batch 11/12                         Loss D: -82.9636, loss G: 9.1982\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [55/200] Batch 11/12                         Loss D: -87.1541, loss G: 8.9182\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [56/200] Batch 11/12                         Loss D: -92.7302, loss G: 8.3453\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [57/200] Batch 11/12                         Loss D: -97.7199, loss G: 8.0076\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [58/200] Batch 11/12                         Loss D: -103.7670, loss G: 7.7857\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [59/200] Batch 11/12                         Loss D: -108.0061, loss G: 7.3070\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [60/200] Batch 11/12                         Loss D: -113.1438, loss G: 7.0162\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [61/200] Batch 11/12                         Loss D: -118.5419, loss G: 6.8361\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [62/200] Batch 11/12                         Loss D: -122.7041, loss G: 7.2634\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [63/200] Batch 11/12                         Loss D: -124.3721, loss G: 7.3578\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [64/200] Batch 11/12                         Loss D: -128.2954, loss G: 7.4261\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [65/200] Batch 11/12                         Loss D: -131.4963, loss G: 7.6207\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [66/200] Batch 11/12                         Loss D: -135.1097, loss G: 7.8204\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [67/200] Batch 11/12                         Loss D: -138.3567, loss G: 7.9686\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [68/200] Batch 11/12                         Loss D: -142.3584, loss G: 8.3618\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [69/200] Batch 11/12                         Loss D: -143.7736, loss G: 8.4800\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [70/200] Batch 11/12                         Loss D: -148.3004, loss G: 8.5927\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [71/200] Batch 11/12                         Loss D: -150.4271, loss G: 8.8099\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [72/200] Batch 11/12                         Loss D: -153.4778, loss G: 9.0029\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [73/200] Batch 11/12                         Loss D: -157.5194, loss G: 9.0740\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [74/200] Batch 11/12                         Loss D: -159.8366, loss G: 9.3763\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [75/200] Batch 11/12                         Loss D: -163.7652, loss G: 9.4637\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [76/200] Batch 11/12                         Loss D: -165.9276, loss G: 9.7661\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [77/200] Batch 11/12                         Loss D: -169.6401, loss G: 9.8927\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [78/200] Batch 11/12                         Loss D: -174.5126, loss G: 10.1947\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [79/200] Batch 11/12                         Loss D: -175.5936, loss G: 10.3335\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [80/200] Batch 11/12                         Loss D: -177.0265, loss G: 10.7237\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [81/200] Batch 11/12                         Loss D: -184.5229, loss G: 10.8182\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [82/200] Batch 11/12                         Loss D: -184.7882, loss G: 10.9107\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [83/200] Batch 11/12                         Loss D: -188.6911, loss G: 11.0136\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [84/200] Batch 11/12                         Loss D: -193.9595, loss G: 11.3083\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [85/200] Batch 11/12                         Loss D: -194.2747, loss G: 11.5121\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [86/200] Batch 11/12                         Loss D: -200.1570, loss G: 11.5904\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [87/200] Batch 11/12                         Loss D: -202.4793, loss G: 11.7146\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [88/200] Batch 11/12                         Loss D: -204.1170, loss G: 12.0800\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [89/200] Batch 11/12                         Loss D: -210.1729, loss G: 12.1719\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [90/200] Batch 11/12                         Loss D: -211.6228, loss G: 12.3522\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [91/200] Batch 11/12                         Loss D: -216.9668, loss G: 12.5967\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [92/200] Batch 11/12                         Loss D: -220.0193, loss G: 12.7435\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [93/200] Batch 11/12                         Loss D: -222.0377, loss G: 12.9103\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [94/200] Batch 11/12                         Loss D: -225.9962, loss G: 13.0681\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [95/200] Batch 11/12                         Loss D: -231.5968, loss G: 13.5398\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [96/200] Batch 11/12                         Loss D: -231.2574, loss G: 13.6052\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [97/200] Batch 11/12                         Loss D: -234.3020, loss G: 13.8273\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [98/200] Batch 11/12                         Loss D: -238.5947, loss G: 13.9602\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [99/200] Batch 11/12                         Loss D: -245.7681, loss G: 14.3740\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [100/200] Batch 11/12                         Loss D: -245.4390, loss G: 14.3626\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [101/200] Batch 11/12                         Loss D: -248.9663, loss G: 14.5601\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [102/200] Batch 11/12                         Loss D: -255.3400, loss G: 14.7428\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [103/200] Batch 11/12                         Loss D: -258.0447, loss G: 14.8326\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [104/200] Batch 11/12                         Loss D: -258.5129, loss G: 15.2450\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [105/200] Batch 11/12                         Loss D: -265.0845, loss G: 15.2544\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [106/200] Batch 11/12                         Loss D: -263.6559, loss G: 15.8184\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [107/200] Batch 11/12                         Loss D: -271.4678, loss G: 15.7088\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [108/200] Batch 11/12                         Loss D: -275.4224, loss G: 15.8964\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [109/200] Batch 11/12                         Loss D: -279.9387, loss G: 16.1466\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [110/200] Batch 11/12                         Loss D: -280.7181, loss G: 16.4511\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [111/200] Batch 11/12                         Loss D: -290.5082, loss G: 17.0017\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [112/200] Batch 11/12                         Loss D: -289.6296, loss G: 16.7801\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [113/200] Batch 11/12                         Loss D: -296.8667, loss G: 17.2640\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [114/200] Batch 11/12                         Loss D: -301.5117, loss G: 17.5980\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [115/200] Batch 11/12                         Loss D: -299.7695, loss G: 17.5073\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [116/200] Batch 11/12                         Loss D: -304.3229, loss G: 17.6681\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [117/200] Batch 11/12                         Loss D: -308.5600, loss G: 17.8838\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [118/200] Batch 11/12                         Loss D: -309.7075, loss G: 18.2605\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [119/200] Batch 11/12                         Loss D: -317.4124, loss G: 18.2681\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [120/200] Batch 11/12                         Loss D: -321.9655, loss G: 18.5797\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [121/200] Batch 11/12                         Loss D: -325.5970, loss G: 18.7248\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [122/200] Batch 11/12                         Loss D: -331.2449, loss G: 19.1677\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [123/200] Batch 11/12                         Loss D: -332.8347, loss G: 19.1968\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [124/200] Batch 11/12                         Loss D: -332.9002, loss G: 19.6006\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [125/200] Batch 11/12                         Loss D: -342.4423, loss G: 19.7469\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [126/200] Batch 11/12                         Loss D: -345.7468, loss G: 19.8847\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [127/200] Batch 11/12                         Loss D: -346.7474, loss G: 20.2228\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [128/200] Batch 11/12                         Loss D: -353.4490, loss G: 20.4036\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [129/200] Batch 11/12                         Loss D: -351.6022, loss G: 20.8175\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [130/200] Batch 11/12                         Loss D: -365.4555, loss G: 21.2853\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [131/200] Batch 11/12                         Loss D: -364.4837, loss G: 21.1215\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [132/200] Batch 11/12                         Loss D: -366.7033, loss G: 21.4237\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [133/200] Batch 11/12                         Loss D: -373.9284, loss G: 21.5712\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [134/200] Batch 11/12                         Loss D: -380.7839, loss G: 22.0366\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [135/200] Batch 11/12                         Loss D: -384.8480, loss G: 22.2172\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [136/200] Batch 11/12                         Loss D: -387.9012, loss G: 22.3376\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [137/200] Batch 11/12                         Loss D: -391.9805, loss G: 22.5469\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [138/200] Batch 11/12                         Loss D: -389.6337, loss G: 22.9641\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [139/200] Batch 11/12                         Loss D: -398.3792, loss G: 23.1049\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [140/200] Batch 11/12                         Loss D: -401.4958, loss G: 23.3934\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [141/200] Batch 11/12                         Loss D: -406.7740, loss G: 23.6305\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [142/200] Batch 11/12                         Loss D: -411.2885, loss G: 23.8737\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [143/200] Batch 11/12                         Loss D: -407.9647, loss G: 24.3233\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [144/200] Batch 11/12                         Loss D: -423.6583, loss G: 24.4976\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [145/200] Batch 11/12                         Loss D: -430.3544, loss G: 24.9572\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [146/200] Batch 11/12                         Loss D: -425.5547, loss G: 24.9910\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [147/200] Batch 11/12                         Loss D: -434.3681, loss G: 25.1957\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [148/200] Batch 11/12                         Loss D: -438.9142, loss G: 25.4537\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [149/200] Batch 11/12                         Loss D: -446.7825, loss G: 25.8335\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [150/200] Batch 11/12                         Loss D: -440.6682, loss G: 26.0915\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [151/200] Batch 11/12                         Loss D: -453.9127, loss G: 26.2308\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [152/200] Batch 11/12                         Loss D: -454.5957, loss G: 26.5627\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [153/200] Batch 11/12                         Loss D: -462.7450, loss G: 26.7843\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [154/200] Batch 11/12                         Loss D: -469.6970, loss G: 27.1128\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [155/200] Batch 11/12                         Loss D: -470.7768, loss G: 27.3610\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [156/200] Batch 11/12                         Loss D: -471.0818, loss G: 27.6833\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [157/200] Batch 11/12                         Loss D: -479.5488, loss G: 27.9158\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [158/200] Batch 11/12                         Loss D: -481.2572, loss G: 28.2384\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [159/200] Batch 11/12                         Loss D: -487.8751, loss G: 28.5046\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [160/200] Batch 11/12                         Loss D: -489.8371, loss G: 28.8118\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [161/200] Batch 11/12                         Loss D: -502.3898, loss G: 29.2005\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [162/200] Batch 11/12                         Loss D: -504.5773, loss G: 29.3345\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [163/200] Batch 11/12                         Loss D: -506.2033, loss G: 29.6499\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [164/200] Batch 11/12                         Loss D: -507.4661, loss G: 29.9665\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [165/200] Batch 11/12                         Loss D: -516.2057, loss G: 30.2376\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [166/200] Batch 11/12                         Loss D: -520.8733, loss G: 30.5381\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [167/200] Batch 11/12                         Loss D: -521.1998, loss G: 30.8367\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [168/200] Batch 11/12                         Loss D: -524.7877, loss G: 31.1296\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [169/200] Batch 11/12                         Loss D: -535.4854, loss G: 31.4339\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [170/200] Batch 11/12                         Loss D: -536.5866, loss G: 31.7201\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [171/200] Batch 11/12                         Loss D: -537.2219, loss G: 32.0276\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [172/200] Batch 11/12                         Loss D: -550.0442, loss G: 32.4205\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [173/200] Batch 11/12                         Loss D: -548.0195, loss G: 32.6225\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [174/200] Batch 11/12                         Loss D: -549.0742, loss G: 32.9251\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [175/200] Batch 11/12                         Loss D: -558.7152, loss G: 33.2261\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [176/200] Batch 11/12                         Loss D: -559.9432, loss G: 33.5355\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [177/200] Batch 11/12                         Loss D: -562.2401, loss G: 33.8327\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [178/200] Batch 11/12                         Loss D: -565.1586, loss G: 34.1360\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [179/200] Batch 11/12                         Loss D: -565.9993, loss G: 34.4548\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [180/200] Batch 11/12                         Loss D: -569.6584, loss G: 34.7332\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [181/200] Batch 11/12                         Loss D: -571.0361, loss G: 35.0214\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [182/200] Batch 11/12                         Loss D: -573.0900, loss G: 35.3269\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [183/200] Batch 11/12                         Loss D: -577.5644, loss G: 35.6098\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [184/200] Batch 11/12                         Loss D: -578.0183, loss G: 35.8953\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [185/200] Batch 11/12                         Loss D: -578.5638, loss G: 36.1696\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [186/200] Batch 11/12                         Loss D: -582.1959, loss G: 36.4653\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [187/200] Batch 11/12                         Loss D: -581.0345, loss G: 36.7353\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [188/200] Batch 11/12                         Loss D: -573.2190, loss G: 36.9649\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [189/200] Batch 11/12                         Loss D: -577.5497, loss G: 37.2338\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [190/200] Batch 11/12                         Loss D: -580.8206, loss G: 37.5170\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [191/200] Batch 11/12                         Loss D: -581.4703, loss G: 37.8020\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [192/200] Batch 11/12                         Loss D: -569.1611, loss G: 37.9500\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [193/200] Batch 11/12                         Loss D: -565.9565, loss G: 38.1625\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [194/200] Batch 11/12                         Loss D: -564.3823, loss G: 38.3807\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [195/200] Batch 11/12                         Loss D: -565.4894, loss G: 38.6325\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [196/200] Batch 11/12                         Loss D: -558.2454, loss G: 38.7807\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [197/200] Batch 11/12                         Loss D: -556.2116, loss G: 38.9896\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [198/200] Batch 11/12                         Loss D: -541.8774, loss G: 39.0766\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=1]                         Epoch [199/200] Batch 11/12                         Loss D: -543.3572, loss G: 39.2982\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [0/200] Batch 11/12                         Loss D: 8.6196, loss G: 17.5232\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [1/200] Batch 11/12                         Loss D: 8.6310, loss G: 17.4821\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [2/200] Batch 11/12                         Loss D: 8.6684, loss G: 17.4400\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [3/200] Batch 11/12                         Loss D: 8.6985, loss G: 17.3908\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [4/200] Batch 11/12                         Loss D: 8.8377, loss G: 17.3239\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [5/200] Batch 11/12                         Loss D: 9.0771, loss G: 17.2178\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [6/200] Batch 11/12                         Loss D: 9.3522, loss G: 17.0765\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [7/200] Batch 11/12                         Loss D: 9.6415, loss G: 16.9241\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [8/200] Batch 11/12                         Loss D: 9.8744, loss G: 16.7738\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [9/200] Batch 11/12                         Loss D: 10.1851, loss G: 16.6174\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [10/200] Batch 11/12                         Loss D: 10.4894, loss G: 16.4608\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [11/200] Batch 11/12                         Loss D: 10.9077, loss G: 16.2500\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [12/200] Batch 11/12                         Loss D: 11.1438, loss G: 16.0958\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [13/200] Batch 11/12                         Loss D: 11.4575, loss G: 15.8948\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [14/200] Batch 11/12                         Loss D: 11.6795, loss G: 15.6859\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [15/200] Batch 11/12                         Loss D: 11.9327, loss G: 15.4264\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [16/200] Batch 11/12                         Loss D: 11.9826, loss G: 15.2031\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [17/200] Batch 11/12                         Loss D: 12.0835, loss G: 14.9293\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [18/200] Batch 11/12                         Loss D: 12.0755, loss G: 14.6717\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [19/200] Batch 11/12                         Loss D: 12.0143, loss G: 14.5077\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [20/200] Batch 11/12                         Loss D: 11.9239, loss G: 14.3124\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [21/200] Batch 11/12                         Loss D: 11.7719, loss G: 14.1152\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [22/200] Batch 11/12                         Loss D: 11.4520, loss G: 13.9240\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [23/200] Batch 11/12                         Loss D: 11.0354, loss G: 13.7099\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [24/200] Batch 11/12                         Loss D: 10.4934, loss G: 13.4835\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [25/200] Batch 11/12                         Loss D: 9.8024, loss G: 13.2439\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [26/200] Batch 11/12                         Loss D: 8.9466, loss G: 13.0403\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [27/200] Batch 11/12                         Loss D: 7.9587, loss G: 12.8388\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [28/200] Batch 11/12                         Loss D: 6.7846, loss G: 12.6036\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [29/200] Batch 11/12                         Loss D: 5.5029, loss G: 12.4367\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [30/200] Batch 11/12                         Loss D: 3.9272, loss G: 12.1910\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [31/200] Batch 11/12                         Loss D: 2.1665, loss G: 11.9564\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [32/200] Batch 11/12                         Loss D: 0.1952, loss G: 11.7259\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [33/200] Batch 11/12                         Loss D: -1.9681, loss G: 11.5105\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [34/200] Batch 11/12                         Loss D: -4.3862, loss G: 11.3085\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [35/200] Batch 11/12                         Loss D: -7.2850, loss G: 11.0153\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [36/200] Batch 11/12                         Loss D: -9.9691, loss G: 10.8938\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [37/200] Batch 11/12                         Loss D: -13.4367, loss G: 10.6046\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [38/200] Batch 11/12                         Loss D: -16.8858, loss G: 10.4208\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [39/200] Batch 11/12                         Loss D: -20.3906, loss G: 10.2999\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [40/200] Batch 11/12                         Loss D: -24.5477, loss G: 10.0861\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [41/200] Batch 11/12                         Loss D: -29.0870, loss G: 9.8628\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [42/200] Batch 11/12                         Loss D: -34.3647, loss G: 9.5859\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [43/200] Batch 11/12                         Loss D: -39.2661, loss G: 9.4394\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [44/200] Batch 11/12                         Loss D: -43.5558, loss G: 9.5166\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [45/200] Batch 11/12                         Loss D: -48.2744, loss G: 9.6004\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [46/200] Batch 11/12                         Loss D: -51.7031, loss G: 9.7361\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [47/200] Batch 11/12                         Loss D: -55.7939, loss G: 9.8400\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [48/200] Batch 11/12                         Loss D: -59.6820, loss G: 9.9698\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [49/200] Batch 11/12                         Loss D: -63.0112, loss G: 10.1373\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [50/200] Batch 11/12                         Loss D: -68.4836, loss G: 10.2404\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [51/200] Batch 11/12                         Loss D: -71.2459, loss G: 10.3301\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [52/200] Batch 11/12                         Loss D: -75.8556, loss G: 10.4884\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [53/200] Batch 11/12                         Loss D: -78.7558, loss G: 10.5870\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [54/200] Batch 11/12                         Loss D: -83.2626, loss G: 10.7144\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [55/200] Batch 11/12                         Loss D: -85.8476, loss G: 10.8620\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [56/200] Batch 11/12                         Loss D: -90.0223, loss G: 10.9588\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [57/200] Batch 11/12                         Loss D: -94.6480, loss G: 11.1801\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [58/200] Batch 11/12                         Loss D: -96.9852, loss G: 11.2243\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [59/200] Batch 11/12                         Loss D: -99.4523, loss G: 11.4112\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [60/200] Batch 11/12                         Loss D: -101.9087, loss G: 11.5833\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [61/200] Batch 11/12                         Loss D: -107.2095, loss G: 11.6352\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [62/200] Batch 11/12                         Loss D: -111.6851, loss G: 11.8480\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [63/200] Batch 11/12                         Loss D: -113.8371, loss G: 11.9305\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [64/200] Batch 11/12                         Loss D: -118.2594, loss G: 12.1361\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [65/200] Batch 11/12                         Loss D: -119.7533, loss G: 12.2098\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [66/200] Batch 11/12                         Loss D: -122.4206, loss G: 12.3572\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [67/200] Batch 11/12                         Loss D: -126.0203, loss G: 12.4878\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [68/200] Batch 11/12                         Loss D: -128.2012, loss G: 12.6386\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [69/200] Batch 11/12                         Loss D: -130.9537, loss G: 12.7940\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [70/200] Batch 11/12                         Loss D: -135.5811, loss G: 12.9907\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [71/200] Batch 11/12                         Loss D: -135.3455, loss G: 13.0974\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [72/200] Batch 11/12                         Loss D: -138.2488, loss G: 13.2325\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [73/200] Batch 11/12                         Loss D: -141.5401, loss G: 13.3600\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [74/200] Batch 11/12                         Loss D: -143.3357, loss G: 13.5105\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [75/200] Batch 11/12                         Loss D: -145.0531, loss G: 13.6683\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [76/200] Batch 11/12                         Loss D: -149.2307, loss G: 13.7751\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [77/200] Batch 11/12                         Loss D: -149.9862, loss G: 13.9317\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [78/200] Batch 11/12                         Loss D: -151.0970, loss G: 14.0825\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [79/200] Batch 11/12                         Loss D: -155.4322, loss G: 14.2123\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [80/200] Batch 11/12                         Loss D: -155.6698, loss G: 14.3356\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [81/200] Batch 11/12                         Loss D: -157.5270, loss G: 14.4762\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [82/200] Batch 11/12                         Loss D: -158.2356, loss G: 14.6068\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [83/200] Batch 11/12                         Loss D: -161.7610, loss G: 14.7476\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [84/200] Batch 11/12                         Loss D: -161.9046, loss G: 14.8610\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [85/200] Batch 11/12                         Loss D: -162.7517, loss G: 14.9882\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [86/200] Batch 11/12                         Loss D: -164.6754, loss G: 15.1064\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [87/200] Batch 11/12                         Loss D: -166.0204, loss G: 15.2167\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [88/200] Batch 11/12                         Loss D: -165.0947, loss G: 15.3422\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [89/200] Batch 11/12                         Loss D: -167.3145, loss G: 15.4477\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [90/200] Batch 11/12                         Loss D: -165.1878, loss G: 15.5723\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [91/200] Batch 11/12                         Loss D: -166.9264, loss G: 15.6778\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [92/200] Batch 11/12                         Loss D: -169.3504, loss G: 15.7745\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [93/200] Batch 11/12                         Loss D: -168.0387, loss G: 15.8832\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [94/200] Batch 11/12                         Loss D: -168.9910, loss G: 15.9822\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [95/200] Batch 11/12                         Loss D: -168.2069, loss G: 16.0780\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [96/200] Batch 11/12                         Loss D: -169.8676, loss G: 16.1692\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [97/200] Batch 11/12                         Loss D: -168.0400, loss G: 16.2580\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [98/200] Batch 11/12                         Loss D: -169.6750, loss G: 16.3462\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [99/200] Batch 11/12                         Loss D: -170.6991, loss G: 16.4350\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [100/200] Batch 11/12                         Loss D: -169.2056, loss G: 16.5115\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [101/200] Batch 11/12                         Loss D: -170.0595, loss G: 16.5917\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [102/200] Batch 11/12                         Loss D: -168.1420, loss G: 16.6604\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [103/200] Batch 11/12                         Loss D: -169.0302, loss G: 16.7373\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [104/200] Batch 11/12                         Loss D: -167.1519, loss G: 16.7972\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [105/200] Batch 11/12                         Loss D: -167.4859, loss G: 16.8644\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [106/200] Batch 11/12                         Loss D: -165.4854, loss G: 16.9175\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [107/200] Batch 11/12                         Loss D: -164.1527, loss G: 16.9691\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [108/200] Batch 11/12                         Loss D: -164.3710, loss G: 17.0267\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [109/200] Batch 11/12                         Loss D: -161.3297, loss G: 17.0641\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [110/200] Batch 11/12                         Loss D: -159.8147, loss G: 17.1054\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [111/200] Batch 11/12                         Loss D: -158.7608, loss G: 17.1464\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [112/200] Batch 11/12                         Loss D: -158.8729, loss G: 17.1913\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [113/200] Batch 11/12                         Loss D: -154.6319, loss G: 17.2019\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [114/200] Batch 11/12                         Loss D: -151.7475, loss G: 17.2173\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [115/200] Batch 11/12                         Loss D: -148.7226, loss G: 17.2262\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [116/200] Batch 11/12                         Loss D: -146.7302, loss G: 17.2378\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [117/200] Batch 11/12                         Loss D: -142.5735, loss G: 17.2269\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [118/200] Batch 11/12                         Loss D: -138.1851, loss G: 17.2105\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [119/200] Batch 11/12                         Loss D: -136.7378, loss G: 17.2103\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [120/200] Batch 11/12                         Loss D: -131.9149, loss G: 17.1768\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [121/200] Batch 11/12                         Loss D: -127.0153, loss G: 17.1351\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [122/200] Batch 11/12                         Loss D: -121.8502, loss G: 17.0749\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [123/200] Batch 11/12                         Loss D: -114.5355, loss G: 16.9823\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [124/200] Batch 11/12                         Loss D: -107.8040, loss G: 16.8881\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [125/200] Batch 11/12                         Loss D: -99.7384, loss G: 16.7759\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [126/200] Batch 11/12                         Loss D: -94.3866, loss G: 16.6749\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [127/200] Batch 11/12                         Loss D: -86.7236, loss G: 16.5560\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [128/200] Batch 11/12                         Loss D: -79.0989, loss G: 16.4379\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [129/200] Batch 11/12                         Loss D: -76.8833, loss G: 16.4536\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [130/200] Batch 11/12                         Loss D: -76.3603, loss G: 16.4999\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [131/200] Batch 11/12                         Loss D: -75.5094, loss G: 16.5432\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [132/200] Batch 11/12                         Loss D: -75.5874, loss G: 16.5885\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [133/200] Batch 11/12                         Loss D: -74.9169, loss G: 16.6300\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [134/200] Batch 11/12                         Loss D: -74.1298, loss G: 16.6679\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [135/200] Batch 11/12                         Loss D: -73.5968, loss G: 16.7035\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [136/200] Batch 11/12                         Loss D: -73.8029, loss G: 16.7437\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [137/200] Batch 11/12                         Loss D: -73.5567, loss G: 16.7766\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [138/200] Batch 11/12                         Loss D: -72.9092, loss G: 16.8077\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [139/200] Batch 11/12                         Loss D: -72.6270, loss G: 16.8384\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [140/200] Batch 11/12                         Loss D: -71.5642, loss G: 16.8601\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [141/200] Batch 11/12                         Loss D: -72.0127, loss G: 16.8918\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [142/200] Batch 11/12                         Loss D: -71.2179, loss G: 16.9145\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [143/200] Batch 11/12                         Loss D: -69.7500, loss G: 16.9258\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [144/200] Batch 11/12                         Loss D: -69.4164, loss G: 16.9476\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [145/200] Batch 11/12                         Loss D: -68.8309, loss G: 16.9639\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [146/200] Batch 11/12                         Loss D: -68.0863, loss G: 16.9769\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [147/200] Batch 11/12                         Loss D: -66.8588, loss G: 16.9827\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [148/200] Batch 11/12                         Loss D: -67.2339, loss G: 16.7186\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [149/200] Batch 11/12                         Loss D: -68.6907, loss G: 16.6017\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [150/200] Batch 11/12                         Loss D: -70.5200, loss G: 16.5468\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [151/200] Batch 11/12                         Loss D: -71.8029, loss G: 16.4818\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [152/200] Batch 11/12                         Loss D: -71.1687, loss G: 16.2687\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [153/200] Batch 11/12                         Loss D: -72.6817, loss G: 16.1115\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [154/200] Batch 11/12                         Loss D: -73.8051, loss G: 15.9523\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [155/200] Batch 11/12                         Loss D: -76.0311, loss G: 15.7896\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [156/200] Batch 11/12                         Loss D: -75.0017, loss G: 15.6424\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [157/200] Batch 11/12                         Loss D: -71.2063, loss G: 15.4832\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [158/200] Batch 11/12                         Loss D: -68.8089, loss G: 15.3085\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [159/200] Batch 11/12                         Loss D: -66.2553, loss G: 15.1612\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [160/200] Batch 11/12                         Loss D: -63.5499, loss G: 15.0411\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [161/200] Batch 11/12                         Loss D: -61.4765, loss G: 14.9805\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [162/200] Batch 11/12                         Loss D: -67.8950, loss G: 14.9807\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [163/200] Batch 11/12                         Loss D: -68.1091, loss G: 15.0331\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [164/200] Batch 11/12                         Loss D: -68.8714, loss G: 15.0784\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [165/200] Batch 11/12                         Loss D: -69.6194, loss G: 15.1273\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [166/200] Batch 11/12                         Loss D: -71.2158, loss G: 15.1729\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [167/200] Batch 11/12                         Loss D: -71.3427, loss G: 15.2338\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [168/200] Batch 11/12                         Loss D: -71.0319, loss G: 15.2983\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [169/200] Batch 11/12                         Loss D: -71.2006, loss G: 15.3643\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [170/200] Batch 11/12                         Loss D: -71.8577, loss G: 15.4271\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [171/200] Batch 11/12                         Loss D: -72.2981, loss G: 15.4959\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [172/200] Batch 11/12                         Loss D: -71.9984, loss G: 15.5707\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [173/200] Batch 11/12                         Loss D: -71.9208, loss G: 15.6447\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [174/200] Batch 11/12                         Loss D: -70.9520, loss G: 15.7221\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [175/200] Batch 11/12                         Loss D: -70.9598, loss G: 15.7969\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [176/200] Batch 11/12                         Loss D: -70.5086, loss G: 15.8722\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [177/200] Batch 11/12                         Loss D: -70.7563, loss G: 15.9467\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [178/200] Batch 11/12                         Loss D: -71.2719, loss G: 16.0202\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [179/200] Batch 11/12                         Loss D: -70.3842, loss G: 16.0929\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [180/200] Batch 11/12                         Loss D: -69.8694, loss G: 16.1651\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [181/200] Batch 11/12                         Loss D: -69.0876, loss G: 16.2355\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [182/200] Batch 11/12                         Loss D: -68.5311, loss G: 16.3034\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [183/200] Batch 11/12                         Loss D: -67.9976, loss G: 16.3689\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [184/200] Batch 11/12                         Loss D: -66.9424, loss G: 16.4271\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [185/200] Batch 11/12                         Loss D: -65.7278, loss G: 16.4818\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [186/200] Batch 11/12                         Loss D: -64.6745, loss G: 16.5335\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [187/200] Batch 11/12                         Loss D: -63.2266, loss G: 16.5769\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [188/200] Batch 11/12                         Loss D: -62.6880, loss G: 16.6257\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [189/200] Batch 11/12                         Loss D: -60.6904, loss G: 16.6556\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [190/200] Batch 11/12                         Loss D: -59.6258, loss G: 16.6910\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [191/200] Batch 11/12                         Loss D: -57.7423, loss G: 16.7155\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [192/200] Batch 11/12                         Loss D: -56.2871, loss G: 16.7366\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [193/200] Batch 11/12                         Loss D: -54.4515, loss G: 16.7521\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [194/200] Batch 11/12                         Loss D: -52.8785, loss G: 16.7669\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [195/200] Batch 11/12                         Loss D: -51.9651, loss G: 16.7878\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [196/200] Batch 11/12                         Loss D: -50.2184, loss G: 16.7910\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [197/200] Batch 11/12                         Loss D: -48.2156, loss G: 16.7883\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [198/200] Batch 11/12                         Loss D: -46.5852, loss G: 16.7881\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.5]                         Epoch [199/200] Batch 11/12                         Loss D: -45.1797, loss G: 16.7893\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [0/200] Batch 11/12                         Loss D: 9.2912, loss G: 3.4371\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [1/200] Batch 11/12                         Loss D: 9.2458, loss G: 3.4248\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [2/200] Batch 11/12                         Loss D: 9.1784, loss G: 3.4102\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [3/200] Batch 11/12                         Loss D: 9.0839, loss G: 3.3837\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [4/200] Batch 11/12                         Loss D: 9.0248, loss G: 3.3557\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [5/200] Batch 11/12                         Loss D: 9.0902, loss G: 3.3294\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [6/200] Batch 11/12                         Loss D: 9.1708, loss G: 3.2992\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [7/200] Batch 11/12                         Loss D: 9.2603, loss G: 3.2660\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [8/200] Batch 11/12                         Loss D: 9.4562, loss G: 3.2258\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [9/200] Batch 11/12                         Loss D: 9.6889, loss G: 3.1804\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [10/200] Batch 11/12                         Loss D: 9.9652, loss G: 3.1277\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [11/200] Batch 11/12                         Loss D: 10.2271, loss G: 3.0761\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [12/200] Batch 11/12                         Loss D: 10.4526, loss G: 3.0238\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [13/200] Batch 11/12                         Loss D: 10.6332, loss G: 2.9641\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [14/200] Batch 11/12                         Loss D: 10.7291, loss G: 2.9254\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [15/200] Batch 11/12                         Loss D: 10.6914, loss G: 2.9060\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [16/200] Batch 11/12                         Loss D: 10.4990, loss G: 2.8898\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [17/200] Batch 11/12                         Loss D: 10.3480, loss G: 2.8703\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [18/200] Batch 11/12                         Loss D: 10.1351, loss G: 2.8513\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [19/200] Batch 11/12                         Loss D: 9.8789, loss G: 2.8301\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [20/200] Batch 11/12                         Loss D: 9.6157, loss G: 2.8076\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [21/200] Batch 11/12                         Loss D: 9.2996, loss G: 2.7803\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [22/200] Batch 11/12                         Loss D: 8.8811, loss G: 2.7503\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [23/200] Batch 11/12                         Loss D: 8.8023, loss G: 2.7272\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [24/200] Batch 11/12                         Loss D: 8.7847, loss G: 2.7122\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [25/200] Batch 11/12                         Loss D: 8.8025, loss G: 2.6903\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [26/200] Batch 11/12                         Loss D: 8.8369, loss G: 2.6725\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [27/200] Batch 11/12                         Loss D: 8.7669, loss G: 2.6630\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [28/200] Batch 11/12                         Loss D: 8.7063, loss G: 2.6392\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [29/200] Batch 11/12                         Loss D: 8.5485, loss G: 2.6308\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [30/200] Batch 11/12                         Loss D: 8.3441, loss G: 2.6191\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [31/200] Batch 11/12                         Loss D: 8.0469, loss G: 2.6125\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [32/200] Batch 11/12                         Loss D: 7.6498, loss G: 2.6086\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [33/200] Batch 11/12                         Loss D: 7.1488, loss G: 2.6152\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [34/200] Batch 11/12                         Loss D: 6.5806, loss G: 2.6062\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [35/200] Batch 11/12                         Loss D: 5.8369, loss G: 2.6112\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [36/200] Batch 11/12                         Loss D: 4.9845, loss G: 2.6177\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [37/200] Batch 11/12                         Loss D: 3.9891, loss G: 2.6184\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [38/200] Batch 11/12                         Loss D: 2.8182, loss G: 2.6258\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [39/200] Batch 11/12                         Loss D: 1.8583, loss G: 2.6367\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [40/200] Batch 11/12                         Loss D: 1.5085, loss G: 2.6401\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [41/200] Batch 11/12                         Loss D: 1.5143, loss G: 2.6483\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [42/200] Batch 11/12                         Loss D: 1.7646, loss G: 2.6639\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [43/200] Batch 11/12                         Loss D: 1.9380, loss G: 2.6685\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [44/200] Batch 11/12                         Loss D: 2.1621, loss G: 2.6744\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [45/200] Batch 11/12                         Loss D: 2.4795, loss G: 2.6846\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [46/200] Batch 11/12                         Loss D: 2.7406, loss G: 2.6977\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [47/200] Batch 11/12                         Loss D: 2.9921, loss G: 2.7056\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [48/200] Batch 11/12                         Loss D: 3.2419, loss G: 2.7204\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [49/200] Batch 11/12                         Loss D: 5.0934, loss G: 2.6634\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [50/200] Batch 11/12                         Loss D: 11.8880, loss G: 1.9961\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [51/200] Batch 11/12                         Loss D: 16.6698, loss G: 1.4941\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [52/200] Batch 11/12                         Loss D: 20.7830, loss G: 1.1237\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [53/200] Batch 11/12                         Loss D: 25.4518, loss G: 0.7712\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [54/200] Batch 11/12                         Loss D: 28.2595, loss G: 0.4251\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [55/200] Batch 11/12                         Loss D: 29.1771, loss G: 0.3339\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [56/200] Batch 11/12                         Loss D: 28.9018, loss G: 0.3376\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [57/200] Batch 11/12                         Loss D: 27.9472, loss G: 0.3708\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [58/200] Batch 11/12                         Loss D: 27.5822, loss G: 0.3816\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [59/200] Batch 11/12                         Loss D: 26.6221, loss G: 0.4212\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [60/200] Batch 11/12                         Loss D: 26.3038, loss G: 0.4350\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [61/200] Batch 11/12                         Loss D: 25.6852, loss G: 0.4597\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [62/200] Batch 11/12                         Loss D: 25.1447, loss G: 0.4838\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [63/200] Batch 11/12                         Loss D: 24.5156, loss G: 0.5116\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [64/200] Batch 11/12                         Loss D: 23.8208, loss G: 0.5450\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [65/200] Batch 11/12                         Loss D: 23.3073, loss G: 0.5719\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [66/200] Batch 11/12                         Loss D: 22.5852, loss G: 0.6089\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [67/200] Batch 11/12                         Loss D: 22.0152, loss G: 0.6411\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [68/200] Batch 11/12                         Loss D: 21.1715, loss G: 0.6853\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [69/200] Batch 11/12                         Loss D: 20.5065, loss G: 0.7243\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [70/200] Batch 11/12                         Loss D: 19.8175, loss G: 0.7614\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [71/200] Batch 11/12                         Loss D: 19.1665, loss G: 0.8022\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [72/200] Batch 11/12                         Loss D: 18.4119, loss G: 0.8459\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [73/200] Batch 11/12                         Loss D: 17.7324, loss G: 0.8884\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [74/200] Batch 11/12                         Loss D: 16.7893, loss G: 0.9415\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [75/200] Batch 11/12                         Loss D: 16.0927, loss G: 0.9876\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [76/200] Batch 11/12                         Loss D: 15.3761, loss G: 1.0351\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [77/200] Batch 11/12                         Loss D: 14.6275, loss G: 1.0860\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [78/200] Batch 11/12                         Loss D: 13.7162, loss G: 1.1390\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [79/200] Batch 11/12                         Loss D: 12.9075, loss G: 1.1909\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [80/200] Batch 11/12                         Loss D: 12.0478, loss G: 1.2443\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [81/200] Batch 11/12                         Loss D: 11.1677, loss G: 1.3062\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [82/200] Batch 11/12                         Loss D: 10.2412, loss G: 1.3876\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [83/200] Batch 11/12                         Loss D: 9.2002, loss G: 1.4688\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [84/200] Batch 11/12                         Loss D: 8.2654, loss G: 1.5500\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [85/200] Batch 11/12                         Loss D: 7.3326, loss G: 1.6235\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [86/200] Batch 11/12                         Loss D: 6.4659, loss G: 1.6952\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [87/200] Batch 11/12                         Loss D: 5.6420, loss G: 1.7594\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [88/200] Batch 11/12                         Loss D: 4.8871, loss G: 1.8183\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [89/200] Batch 11/12                         Loss D: 4.1704, loss G: 1.8723\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [90/200] Batch 11/12                         Loss D: 3.4799, loss G: 1.9250\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [91/200] Batch 11/12                         Loss D: 2.9109, loss G: 1.9644\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [92/200] Batch 11/12                         Loss D: 2.4456, loss G: 2.0059\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [93/200] Batch 11/12                         Loss D: 1.9702, loss G: 2.0391\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [94/200] Batch 11/12                         Loss D: 1.6189, loss G: 2.0628\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [95/200] Batch 11/12                         Loss D: 1.2133, loss G: 2.1002\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [96/200] Batch 11/12                         Loss D: 0.8840, loss G: 2.1125\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [97/200] Batch 11/12                         Loss D: 0.6829, loss G: 2.1229\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [98/200] Batch 11/12                         Loss D: 0.4281, loss G: 2.1442\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [99/200] Batch 11/12                         Loss D: 0.5802, loss G: 2.1573\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [100/200] Batch 11/12                         Loss D: 0.6451, loss G: 2.1824\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [101/200] Batch 11/12                         Loss D: 1.1185, loss G: 2.2204\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [102/200] Batch 11/12                         Loss D: 1.4945, loss G: 2.2437\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [103/200] Batch 11/12                         Loss D: 2.0374, loss G: 2.2550\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [104/200] Batch 11/12                         Loss D: 2.4287, loss G: 2.2806\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [105/200] Batch 11/12                         Loss D: 3.0533, loss G: 2.2988\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [106/200] Batch 11/12                         Loss D: 3.3446, loss G: 2.3074\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [107/200] Batch 11/12                         Loss D: 3.6551, loss G: 2.3236\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [108/200] Batch 11/12                         Loss D: 3.6970, loss G: 2.3268\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [109/200] Batch 11/12                         Loss D: 3.7822, loss G: 2.3483\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [110/200] Batch 11/12                         Loss D: 3.9716, loss G: 2.3477\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [111/200] Batch 11/12                         Loss D: 3.9363, loss G: 2.3387\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [112/200] Batch 11/12                         Loss D: 3.9074, loss G: 2.3333\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [113/200] Batch 11/12                         Loss D: 3.8006, loss G: 2.3293\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [114/200] Batch 11/12                         Loss D: 3.5500, loss G: 2.3201\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [115/200] Batch 11/12                         Loss D: 3.5841, loss G: 2.3176\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [116/200] Batch 11/12                         Loss D: 3.4756, loss G: 2.3080\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [117/200] Batch 11/12                         Loss D: 3.3301, loss G: 2.2962\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [118/200] Batch 11/12                         Loss D: 3.0566, loss G: 2.2879\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [119/200] Batch 11/12                         Loss D: 2.9489, loss G: 2.2794\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [120/200] Batch 11/12                         Loss D: 2.7653, loss G: 2.2704\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [121/200] Batch 11/12                         Loss D: 2.6986, loss G: 2.2703\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [122/200] Batch 11/12                         Loss D: 2.5809, loss G: 2.2559\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [123/200] Batch 11/12                         Loss D: 2.4393, loss G: 2.2421\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [124/200] Batch 11/12                         Loss D: 2.1638, loss G: 2.2386\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [125/200] Batch 11/12                         Loss D: 2.1693, loss G: 2.2238\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [126/200] Batch 11/12                         Loss D: 1.8991, loss G: 2.2139\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [127/200] Batch 11/12                         Loss D: 1.8015, loss G: 2.2008\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [128/200] Batch 11/12                         Loss D: 1.6541, loss G: 2.2247\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [129/200] Batch 11/12                         Loss D: 1.2639, loss G: 2.2251\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [130/200] Batch 11/12                         Loss D: 0.7889, loss G: 2.2515\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [131/200] Batch 11/12                         Loss D: 0.7559, loss G: 2.2654\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [132/200] Batch 11/12                         Loss D: 0.3462, loss G: 2.2691\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [133/200] Batch 11/12                         Loss D: 0.0987, loss G: 2.2861\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [134/200] Batch 11/12                         Loss D: -0.3587, loss G: 2.3022\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [135/200] Batch 11/12                         Loss D: -0.6038, loss G: 2.3078\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [136/200] Batch 11/12                         Loss D: -0.8537, loss G: 2.3280\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [137/200] Batch 11/12                         Loss D: -1.1735, loss G: 2.3394\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [138/200] Batch 11/12                         Loss D: -1.3092, loss G: 2.3636\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [139/200] Batch 11/12                         Loss D: -1.7345, loss G: 2.3742\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [140/200] Batch 11/12                         Loss D: -1.9883, loss G: 2.3931\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [141/200] Batch 11/12                         Loss D: -2.5133, loss G: 2.4062\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [142/200] Batch 11/12                         Loss D: -2.7023, loss G: 2.4166\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [143/200] Batch 11/12                         Loss D: -2.9239, loss G: 2.4454\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [144/200] Batch 11/12                         Loss D: -3.1620, loss G: 2.4625\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [145/200] Batch 11/12                         Loss D: -3.8340, loss G: 2.4697\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [146/200] Batch 11/12                         Loss D: -4.1370, loss G: 2.4781\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [147/200] Batch 11/12                         Loss D: -4.3650, loss G: 2.4945\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [148/200] Batch 11/12                         Loss D: -4.8603, loss G: 2.5241\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [149/200] Batch 11/12                         Loss D: -5.1556, loss G: 2.5315\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [150/200] Batch 11/12                         Loss D: -5.5430, loss G: 2.5484\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [151/200] Batch 11/12                         Loss D: -5.8248, loss G: 2.5623\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [152/200] Batch 11/12                         Loss D: -6.1891, loss G: 2.5830\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [153/200] Batch 11/12                         Loss D: -6.5073, loss G: 2.5976\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [154/200] Batch 11/12                         Loss D: -6.9441, loss G: 2.6219\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [155/200] Batch 11/12                         Loss D: -7.2213, loss G: 2.6324\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [156/200] Batch 11/12                         Loss D: -7.7948, loss G: 2.6604\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [157/200] Batch 11/12                         Loss D: -7.9336, loss G: 2.6705\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [158/200] Batch 11/12                         Loss D: -8.2966, loss G: 2.6868\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [159/200] Batch 11/12                         Loss D: -8.7053, loss G: 2.7040\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [160/200] Batch 11/12                         Loss D: -8.8866, loss G: 2.7290\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [161/200] Batch 11/12                         Loss D: -9.4874, loss G: 2.7414\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [162/200] Batch 11/12                         Loss D: -9.6047, loss G: 2.7663\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [163/200] Batch 11/12                         Loss D: -10.0899, loss G: 2.7838\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [164/200] Batch 11/12                         Loss D: -10.5261, loss G: 2.7980\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [165/200] Batch 11/12                         Loss D: -10.9272, loss G: 2.8222\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [166/200] Batch 11/12                         Loss D: -11.4447, loss G: 2.8375\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [167/200] Batch 11/12                         Loss D: -11.8051, loss G: 2.8587\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [168/200] Batch 11/12                         Loss D: -12.4400, loss G: 2.8921\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [169/200] Batch 11/12                         Loss D: -12.7130, loss G: 2.8996\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [170/200] Batch 11/12                         Loss D: -12.8470, loss G: 2.9231\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [171/200] Batch 11/12                         Loss D: -13.5200, loss G: 2.9394\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [172/200] Batch 11/12                         Loss D: -14.1796, loss G: 2.9643\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [173/200] Batch 11/12                         Loss D: -14.2176, loss G: 2.9842\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [174/200] Batch 11/12                         Loss D: -14.5510, loss G: 3.0102\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [175/200] Batch 11/12                         Loss D: -15.5136, loss G: 3.0273\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [176/200] Batch 11/12                         Loss D: -15.6419, loss G: 3.0504\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [177/200] Batch 11/12                         Loss D: -16.4668, loss G: 3.0753\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [178/200] Batch 11/12                         Loss D: -16.6776, loss G: 3.0930\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [179/200] Batch 11/12                         Loss D: -17.2457, loss G: 3.1146\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [180/200] Batch 11/12                         Loss D: -17.4664, loss G: 3.1421\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [181/200] Batch 11/12                         Loss D: -18.1494, loss G: 3.1628\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [182/200] Batch 11/12                         Loss D: -18.7606, loss G: 3.1851\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [183/200] Batch 11/12                         Loss D: -19.1502, loss G: 3.2088\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [184/200] Batch 11/12                         Loss D: -19.9862, loss G: 3.2433\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [185/200] Batch 11/12                         Loss D: -20.0627, loss G: 3.2592\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [186/200] Batch 11/12                         Loss D: -20.5446, loss G: 3.2837\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [187/200] Batch 11/12                         Loss D: -21.2577, loss G: 3.3089\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [188/200] Batch 11/12                         Loss D: -21.6302, loss G: 3.3351\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [189/200] Batch 11/12                         Loss D: -22.1729, loss G: 3.3586\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [190/200] Batch 11/12                         Loss D: -23.1602, loss G: 3.3897\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [191/200] Batch 11/12                         Loss D: -23.1764, loss G: 3.4112\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [192/200] Batch 11/12                         Loss D: -23.7948, loss G: 3.4395\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [193/200] Batch 11/12                         Loss D: -24.0101, loss G: 3.4640\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [194/200] Batch 11/12                         Loss D: -24.8174, loss G: 3.4923\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [195/200] Batch 11/12                         Loss D: -25.1089, loss G: 3.5191\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [196/200] Batch 11/12                         Loss D: -25.2264, loss G: 3.5437\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [197/200] Batch 11/12                         Loss D: -25.5632, loss G: 3.5695\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [198/200] Batch 11/12                         Loss D: -25.9442, loss G: 3.5947\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=0.1]                         Epoch [199/200] Batch 11/12                         Loss D: -25.7352, loss G: 3.6181\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [0/200] Batch 11/12                         Loss D: 0.9724, loss G: 34.7451\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [1/200] Batch 11/12                         Loss D: 0.8721, loss G: 34.6267\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [2/200] Batch 11/12                         Loss D: 0.7885, loss G: 34.5121\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [3/200] Batch 11/12                         Loss D: 0.7246, loss G: 34.3866\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [4/200] Batch 11/12                         Loss D: 0.5791, loss G: 34.2391\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [5/200] Batch 11/12                         Loss D: 0.3769, loss G: 34.0771\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [6/200] Batch 11/12                         Loss D: 0.1000, loss G: 33.8896\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [7/200] Batch 11/12                         Loss D: -0.1903, loss G: 33.6971\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [8/200] Batch 11/12                         Loss D: -0.5797, loss G: 33.4445\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [9/200] Batch 11/12                         Loss D: -1.0144, loss G: 33.1740\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [10/200] Batch 11/12                         Loss D: -1.5458, loss G: 32.8670\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [11/200] Batch 11/12                         Loss D: -2.0790, loss G: 32.5517\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [12/200] Batch 11/12                         Loss D: -2.7115, loss G: 32.1704\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [13/200] Batch 11/12                         Loss D: -3.3846, loss G: 31.7789\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [14/200] Batch 11/12                         Loss D: -4.1084, loss G: 31.3471\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [15/200] Batch 11/12                         Loss D: -4.9736, loss G: 30.8574\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [16/200] Batch 11/12                         Loss D: -5.9047, loss G: 30.3705\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [17/200] Batch 11/12                         Loss D: -7.1341, loss G: 30.0358\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [18/200] Batch 11/12                         Loss D: -8.7596, loss G: 29.7247\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [19/200] Batch 11/12                         Loss D: -9.9883, loss G: 29.5314\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [20/200] Batch 11/12                         Loss D: -11.5887, loss G: 29.2496\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [21/200] Batch 11/12                         Loss D: -13.2401, loss G: 28.9785\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [22/200] Batch 11/12                         Loss D: -15.2448, loss G: 28.6474\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [23/200] Batch 11/12                         Loss D: -16.8460, loss G: 28.4323\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [24/200] Batch 11/12                         Loss D: -19.1197, loss G: 28.0653\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [25/200] Batch 11/12                         Loss D: -21.5708, loss G: 27.6992\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [26/200] Batch 11/12                         Loss D: -23.7088, loss G: 27.4096\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [27/200] Batch 11/12                         Loss D: -26.5475, loss G: 27.0091\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [28/200] Batch 11/12                         Loss D: -29.2816, loss G: 26.6554\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [29/200] Batch 11/12                         Loss D: -32.5708, loss G: 26.2117\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [30/200] Batch 11/12                         Loss D: -36.0919, loss G: 25.7645\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [31/200] Batch 11/12                         Loss D: -39.6388, loss G: 25.3477\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [32/200] Batch 11/12                         Loss D: -43.7768, loss G: 24.8948\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [33/200] Batch 11/12                         Loss D: -47.2228, loss G: 24.5664\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [34/200] Batch 11/12                         Loss D: -51.5924, loss G: 24.1611\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [35/200] Batch 11/12                         Loss D: -56.9772, loss G: 23.5805\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [36/200] Batch 11/12                         Loss D: -61.3573, loss G: 23.1961\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [37/200] Batch 11/12                         Loss D: -66.9308, loss G: 22.6889\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [38/200] Batch 11/12                         Loss D: -73.2418, loss G: 22.1178\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [39/200] Batch 11/12                         Loss D: -78.0322, loss G: 21.7751\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [40/200] Batch 11/12                         Loss D: -85.9564, loss G: 21.0654\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [41/200] Batch 11/12                         Loss D: -92.4152, loss G: 20.5912\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [42/200] Batch 11/12                         Loss D: -100.4235, loss G: 19.9584\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [43/200] Batch 11/12                         Loss D: -107.7350, loss G: 19.4442\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [44/200] Batch 11/12                         Loss D: -115.8426, loss G: 18.8875\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [45/200] Batch 11/12                         Loss D: -125.1093, loss G: 18.2505\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [46/200] Batch 11/12                         Loss D: -130.4952, loss G: 18.1159\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [47/200] Batch 11/12                         Loss D: -135.7510, loss G: 18.0909\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [48/200] Batch 11/12                         Loss D: -140.8503, loss G: 18.0904\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [49/200] Batch 11/12                         Loss D: -143.7301, loss G: 17.9994\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [50/200] Batch 11/12                         Loss D: -147.5417, loss G: 18.0309\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [51/200] Batch 11/12                         Loss D: -152.8101, loss G: 17.9364\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [52/200] Batch 11/12                         Loss D: -155.4295, loss G: 18.1518\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [53/200] Batch 11/12                         Loss D: -161.8595, loss G: 17.9264\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [54/200] Batch 11/12                         Loss D: -169.0784, loss G: 17.8675\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [55/200] Batch 11/12                         Loss D: -173.2510, loss G: 17.8042\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [56/200] Batch 11/12                         Loss D: -176.4777, loss G: 17.8887\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [57/200] Batch 11/12                         Loss D: -183.2099, loss G: 17.8356\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [58/200] Batch 11/12                         Loss D: -188.0762, loss G: 17.8173\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [59/200] Batch 11/12                         Loss D: -191.4139, loss G: 17.9326\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [60/200] Batch 11/12                         Loss D: -197.6631, loss G: 17.8855\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [61/200] Batch 11/12                         Loss D: -204.2074, loss G: 17.8217\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [62/200] Batch 11/12                         Loss D: -211.2319, loss G: 17.8803\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [63/200] Batch 11/12                         Loss D: -214.0925, loss G: 17.9618\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [64/200] Batch 11/12                         Loss D: -219.8979, loss G: 17.9915\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [65/200] Batch 11/12                         Loss D: -228.2975, loss G: 17.9085\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [66/200] Batch 11/12                         Loss D: -234.1815, loss G: 17.9674\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [67/200] Batch 11/12                         Loss D: -238.9888, loss G: 18.0673\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [68/200] Batch 11/12                         Loss D: -247.0845, loss G: 18.1054\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [69/200] Batch 11/12                         Loss D: -250.0959, loss G: 18.2933\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [70/200] Batch 11/12                         Loss D: -258.2342, loss G: 18.2685\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [71/200] Batch 11/12                         Loss D: -264.5358, loss G: 18.3614\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [72/200] Batch 11/12                         Loss D: -272.6273, loss G: 18.3931\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [73/200] Batch 11/12                         Loss D: -278.2874, loss G: 18.5361\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [74/200] Batch 11/12                         Loss D: -288.2078, loss G: 18.6507\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [75/200] Batch 11/12                         Loss D: -292.5376, loss G: 18.7479\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [76/200] Batch 11/12                         Loss D: -301.1985, loss G: 18.8538\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [77/200] Batch 11/12                         Loss D: -304.8501, loss G: 19.0902\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [78/200] Batch 11/12                         Loss D: -315.7179, loss G: 19.0852\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [79/200] Batch 11/12                         Loss D: -323.9021, loss G: 19.2305\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [80/200] Batch 11/12                         Loss D: -330.5924, loss G: 19.3969\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [81/200] Batch 11/12                         Loss D: -330.8751, loss G: 19.7547\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [82/200] Batch 11/12                         Loss D: -342.4093, loss G: 20.1246\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [83/200] Batch 11/12                         Loss D: -343.7325, loss G: 20.0410\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [84/200] Batch 11/12                         Loss D: -350.8109, loss G: 20.5484\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [85/200] Batch 11/12                         Loss D: -346.4264, loss G: 20.7179\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [86/200] Batch 11/12                         Loss D: -353.3069, loss G: 20.8151\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [87/200] Batch 11/12                         Loss D: -362.5577, loss G: 21.0932\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [88/200] Batch 11/12                         Loss D: -365.4644, loss G: 21.1887\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [89/200] Batch 11/12                         Loss D: -368.6991, loss G: 21.3879\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [90/200] Batch 11/12                         Loss D: -369.3565, loss G: 21.6993\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [91/200] Batch 11/12                         Loss D: -369.5188, loss G: 22.0247\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [92/200] Batch 11/12                         Loss D: -378.0278, loss G: 22.1199\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [93/200] Batch 11/12                         Loss D: -382.6777, loss G: 22.3289\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [94/200] Batch 11/12                         Loss D: -391.9391, loss G: 22.6358\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [95/200] Batch 11/12                         Loss D: -392.6711, loss G: 22.7613\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [96/200] Batch 11/12                         Loss D: -397.9670, loss G: 22.9791\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [97/200] Batch 11/12                         Loss D: -400.0927, loss G: 23.2852\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [98/200] Batch 11/12                         Loss D: -403.9400, loss G: 23.5232\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [99/200] Batch 11/12                         Loss D: -408.5366, loss G: 23.7685\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [100/200] Batch 11/12                         Loss D: -416.4363, loss G: 23.9812\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [101/200] Batch 11/12                         Loss D: -418.0797, loss G: 24.2698\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [102/200] Batch 11/12                         Loss D: -424.0493, loss G: 24.4885\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [103/200] Batch 11/12                         Loss D: -433.3206, loss G: 25.3111\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [104/200] Batch 11/12                         Loss D: -424.9614, loss G: 25.1400\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [105/200] Batch 11/12                         Loss D: -437.9469, loss G: 25.2834\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [106/200] Batch 11/12                         Loss D: -438.3207, loss G: 25.5624\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [107/200] Batch 11/12                         Loss D: -438.5777, loss G: 25.8747\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [108/200] Batch 11/12                         Loss D: -444.8271, loss G: 26.1324\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [109/200] Batch 11/12                         Loss D: -449.3766, loss G: 26.3619\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [110/200] Batch 11/12                         Loss D: -454.5383, loss G: 26.6384\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [111/200] Batch 11/12                         Loss D: -458.2874, loss G: 26.8856\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [112/200] Batch 11/12                         Loss D: -465.7292, loss G: 27.1283\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [113/200] Batch 11/12                         Loss D: -467.1434, loss G: 27.4277\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [114/200] Batch 11/12                         Loss D: -472.9632, loss G: 27.6614\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [115/200] Batch 11/12                         Loss D: -475.9806, loss G: 27.9363\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [116/200] Batch 11/12                         Loss D: -486.3607, loss G: 28.2187\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [117/200] Batch 11/12                         Loss D: -486.7551, loss G: 28.4787\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [118/200] Batch 11/12                         Loss D: -492.5079, loss G: 28.7599\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [119/200] Batch 11/12                         Loss D: -492.1332, loss G: 29.0579\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [120/200] Batch 11/12                         Loss D: -501.5102, loss G: 29.2999\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [121/200] Batch 11/12                         Loss D: -501.7796, loss G: 29.5709\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [122/200] Batch 11/12                         Loss D: -501.1215, loss G: 29.8793\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [123/200] Batch 11/12                         Loss D: -510.6828, loss G: 30.1423\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [124/200] Batch 11/12                         Loss D: -512.9186, loss G: 30.4312\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [125/200] Batch 11/12                         Loss D: -520.7032, loss G: 30.6718\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [126/200] Batch 11/12                         Loss D: -523.4529, loss G: 30.9525\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [127/200] Batch 11/12                         Loss D: -527.8435, loss G: 31.2245\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [128/200] Batch 11/12                         Loss D: -526.2165, loss G: 31.5262\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [129/200] Batch 11/12                         Loss D: -532.1566, loss G: 31.7675\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [130/200] Batch 11/12                         Loss D: -539.2433, loss G: 32.0363\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [131/200] Batch 11/12                         Loss D: -536.6573, loss G: 32.3335\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [132/200] Batch 11/12                         Loss D: -545.0435, loss G: 32.5863\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [133/200] Batch 11/12                         Loss D: -549.1470, loss G: 32.8420\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [134/200] Batch 11/12                         Loss D: -550.3972, loss G: 33.0901\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [135/200] Batch 11/12                         Loss D: -554.0105, loss G: 33.3642\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [136/200] Batch 11/12                         Loss D: -555.1296, loss G: 33.6074\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [137/200] Batch 11/12                         Loss D: -562.0634, loss G: 33.8889\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [138/200] Batch 11/12                         Loss D: -560.5255, loss G: 34.1065\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [139/200] Batch 11/12                         Loss D: -564.0924, loss G: 34.3578\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [140/200] Batch 11/12                         Loss D: -562.0369, loss G: 34.5986\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [141/200] Batch 11/12                         Loss D: -566.5565, loss G: 34.8487\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [142/200] Batch 11/12                         Loss D: -562.5182, loss G: 35.0423\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [143/200] Batch 11/12                         Loss D: -567.2846, loss G: 35.2865\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [144/200] Batch 11/12                         Loss D: -566.3900, loss G: 35.4871\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [145/200] Batch 11/12                         Loss D: -572.7950, loss G: 35.7537\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [146/200] Batch 11/12                         Loss D: -561.8177, loss G: 35.8718\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [147/200] Batch 11/12                         Loss D: -562.2757, loss G: 36.0822\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [148/200] Batch 11/12                         Loss D: -567.2964, loss G: 36.3113\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [149/200] Batch 11/12                         Loss D: -564.0816, loss G: 36.4841\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [150/200] Batch 11/12                         Loss D: -561.0919, loss G: 36.6447\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [151/200] Batch 11/12                         Loss D: -561.2203, loss G: 36.8531\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [152/200] Batch 11/12                         Loss D: -559.5857, loss G: 37.0033\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [153/200] Batch 11/12                         Loss D: -559.2288, loss G: 37.1806\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [154/200] Batch 11/12                         Loss D: -551.2468, loss G: 37.2914\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [155/200] Batch 11/12                         Loss D: -554.9362, loss G: 37.4808\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [156/200] Batch 11/12                         Loss D: -548.8881, loss G: 37.5931\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [157/200] Batch 11/12                         Loss D: -541.2510, loss G: 37.6697\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [158/200] Batch 11/12                         Loss D: -537.6033, loss G: 37.7984\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [159/200] Batch 11/12                         Loss D: -538.4631, loss G: 37.9444\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [160/200] Batch 11/12                         Loss D: -535.4657, loss G: 38.0700\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [161/200] Batch 11/12                         Loss D: -532.6643, loss G: 38.1818\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [162/200] Batch 11/12                         Loss D: -522.7917, loss G: 38.2198\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [163/200] Batch 11/12                         Loss D: -515.9946, loss G: 38.2495\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [164/200] Batch 11/12                         Loss D: -505.2205, loss G: 38.2541\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [165/200] Batch 11/12                         Loss D: -506.4889, loss G: 38.3876\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [166/200] Batch 11/12                         Loss D: -497.9433, loss G: 38.4071\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [167/200] Batch 11/12                         Loss D: -498.8377, loss G: 38.5448\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [168/200] Batch 11/12                         Loss D: -489.9366, loss G: 38.5299\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [169/200] Batch 11/12                         Loss D: -481.9504, loss G: 38.5182\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [170/200] Batch 11/12                         Loss D: -476.9951, loss G: 38.5713\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [171/200] Batch 11/12                         Loss D: -466.1506, loss G: 38.5180\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [172/200] Batch 11/12                         Loss D: -457.0708, loss G: 38.4803\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [173/200] Batch 11/12                         Loss D: -453.7302, loss G: 38.5190\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [174/200] Batch 11/12                         Loss D: -444.7224, loss G: 38.4666\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [175/200] Batch 11/12                         Loss D: -438.1729, loss G: 38.4566\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [176/200] Batch 11/12                         Loss D: -428.0480, loss G: 38.3694\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [177/200] Batch 11/12                         Loss D: -418.3882, loss G: 38.2967\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [178/200] Batch 11/12                         Loss D: -408.9746, loss G: 38.2103\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [179/200] Batch 11/12                         Loss D: -392.7906, loss G: 38.0295\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [180/200] Batch 11/12                         Loss D: -380.1175, loss G: 37.8839\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [181/200] Batch 11/12                         Loss D: -366.4053, loss G: 37.7243\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [182/200] Batch 11/12                         Loss D: -352.8896, loss G: 37.5590\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [183/200] Batch 11/12                         Loss D: -335.2514, loss G: 37.3075\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [184/200] Batch 11/12                         Loss D: -321.4923, loss G: 37.1339\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [185/200] Batch 11/12                         Loss D: -302.4023, loss G: 36.8302\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [186/200] Batch 11/12                         Loss D: -281.4382, loss G: 36.3573\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [187/200] Batch 11/12                         Loss D: -252.6754, loss G: 35.7333\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [188/200] Batch 11/12                         Loss D: -226.0448, loss G: 35.0916\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [189/200] Batch 11/12                         Loss D: -195.7871, loss G: 34.2806\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [190/200] Batch 11/12                         Loss D: -165.6311, loss G: 33.3081\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [191/200] Batch 11/12                         Loss D: -133.5037, loss G: 32.2017\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [192/200] Batch 11/12                         Loss D: -100.5753, loss G: 30.9538\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [193/200] Batch 11/12                         Loss D: -81.4367, loss G: 30.4098\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [194/200] Batch 11/12                         Loss D: -73.5502, loss G: 30.2560\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [195/200] Batch 11/12                         Loss D: -73.6783, loss G: 30.2389\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [196/200] Batch 11/12                         Loss D: -76.1526, loss G: 30.2612\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [197/200] Batch 11/12                         Loss D: -79.4297, loss G: 30.3163\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [198/200] Batch 11/12                         Loss D: -84.4952, loss G: 30.3699\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=1]                         Epoch [199/200] Batch 11/12                         Loss D: -87.3961, loss G: 30.4454\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [0/200] Batch 11/12                         Loss D: 0.9231, loss G: 17.0927\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [1/200] Batch 11/12                         Loss D: 0.8982, loss G: 17.0238\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [2/200] Batch 11/12                         Loss D: 0.8546, loss G: 16.9504\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [3/200] Batch 11/12                         Loss D: 0.7810, loss G: 16.8711\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [4/200] Batch 11/12                         Loss D: 0.7240, loss G: 16.7968\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [5/200] Batch 11/12                         Loss D: 0.6643, loss G: 16.7143\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [6/200] Batch 11/12                         Loss D: 0.5747, loss G: 16.6087\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [7/200] Batch 11/12                         Loss D: 0.4597, loss G: 16.5051\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [8/200] Batch 11/12                         Loss D: 0.2920, loss G: 16.3820\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [9/200] Batch 11/12                         Loss D: -0.0374, loss G: 16.2507\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [10/200] Batch 11/12                         Loss D: -0.4856, loss G: 16.0977\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [11/200] Batch 11/12                         Loss D: -0.9932, loss G: 15.9344\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [12/200] Batch 11/12                         Loss D: -1.6037, loss G: 15.7541\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [13/200] Batch 11/12                         Loss D: -2.2351, loss G: 15.5669\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [14/200] Batch 11/12                         Loss D: -2.8037, loss G: 15.3918\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [15/200] Batch 11/12                         Loss D: -3.4887, loss G: 15.1440\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [16/200] Batch 11/12                         Loss D: -4.0521, loss G: 14.9450\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [17/200] Batch 11/12                         Loss D: -4.7363, loss G: 14.7371\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [18/200] Batch 11/12                         Loss D: -5.3735, loss G: 14.6052\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [19/200] Batch 11/12                         Loss D: -5.9598, loss G: 14.4930\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [20/200] Batch 11/12                         Loss D: -6.6824, loss G: 14.3510\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [21/200] Batch 11/12                         Loss D: -7.3355, loss G: 14.2344\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [22/200] Batch 11/12                         Loss D: -8.2219, loss G: 14.0566\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [23/200] Batch 11/12                         Loss D: -9.1541, loss G: 13.8893\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [24/200] Batch 11/12                         Loss D: -9.9877, loss G: 13.7515\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [25/200] Batch 11/12                         Loss D: -11.1050, loss G: 13.5601\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [26/200] Batch 11/12                         Loss D: -12.2193, loss G: 13.3822\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [27/200] Batch 11/12                         Loss D: -13.6731, loss G: 13.1505\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [28/200] Batch 11/12                         Loss D: -14.9055, loss G: 12.9638\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [29/200] Batch 11/12                         Loss D: -16.7567, loss G: 12.6862\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [30/200] Batch 11/12                         Loss D: -17.9855, loss G: 12.5217\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [31/200] Batch 11/12                         Loss D: -19.8104, loss G: 12.2583\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [32/200] Batch 11/12                         Loss D: -21.7341, loss G: 12.0021\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [33/200] Batch 11/12                         Loss D: -23.8555, loss G: 11.7123\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [34/200] Batch 11/12                         Loss D: -25.8419, loss G: 11.4745\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [35/200] Batch 11/12                         Loss D: -28.1010, loss G: 11.2035\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [36/200] Batch 11/12                         Loss D: -30.7566, loss G: 10.8860\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [37/200] Batch 11/12                         Loss D: -33.3800, loss G: 10.5914\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [38/200] Batch 11/12                         Loss D: -36.3726, loss G: 10.2605\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [39/200] Batch 11/12                         Loss D: -39.8087, loss G: 9.8920\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [40/200] Batch 11/12                         Loss D: -42.5789, loss G: 9.6483\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [41/200] Batch 11/12                         Loss D: -46.4618, loss G: 9.2541\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [42/200] Batch 11/12                         Loss D: -49.7662, loss G: 8.9335\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [43/200] Batch 11/12                         Loss D: -54.3322, loss G: 8.4710\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [44/200] Batch 11/12                         Loss D: -58.2595, loss G: 8.0554\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [45/200] Batch 11/12                         Loss D: -60.4854, loss G: 7.7980\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [46/200] Batch 11/12                         Loss D: -63.3024, loss G: 7.4035\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [47/200] Batch 11/12                         Loss D: -64.9727, loss G: 7.1929\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [48/200] Batch 11/12                         Loss D: -67.4055, loss G: 6.7761\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [49/200] Batch 11/12                         Loss D: -68.4116, loss G: 6.5354\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [50/200] Batch 11/12                         Loss D: -69.3234, loss G: 6.2744\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [51/200] Batch 11/12                         Loss D: -70.5591, loss G: 5.9932\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [52/200] Batch 11/12                         Loss D: -71.1438, loss G: 5.7576\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [53/200] Batch 11/12                         Loss D: -73.8528, loss G: 5.4851\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [54/200] Batch 11/12                         Loss D: -74.5760, loss G: 5.1169\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [55/200] Batch 11/12                         Loss D: -75.1238, loss G: 4.9215\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [56/200] Batch 11/12                         Loss D: -76.3521, loss G: 4.7400\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [57/200] Batch 11/12                         Loss D: -77.6796, loss G: 4.5042\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [58/200] Batch 11/12                         Loss D: -80.6790, loss G: 4.1360\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [59/200] Batch 11/12                         Loss D: -81.2362, loss G: 4.1028\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [60/200] Batch 11/12                         Loss D: -84.2365, loss G: 4.0639\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [61/200] Batch 11/12                         Loss D: -86.3578, loss G: 4.2526\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [62/200] Batch 11/12                         Loss D: -88.4935, loss G: 4.4844\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [63/200] Batch 11/12                         Loss D: -90.6938, loss G: 4.5808\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [64/200] Batch 11/12                         Loss D: -93.7825, loss G: 4.6581\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [65/200] Batch 11/12                         Loss D: -95.7292, loss G: 4.7624\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [66/200] Batch 11/12                         Loss D: -98.6519, loss G: 5.0096\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [67/200] Batch 11/12                         Loss D: -99.9105, loss G: 5.0451\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [68/200] Batch 11/12                         Loss D: -101.3121, loss G: 5.1984\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [69/200] Batch 11/12                         Loss D: -104.5779, loss G: 5.3003\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [70/200] Batch 11/12                         Loss D: -105.5247, loss G: 5.4824\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [71/200] Batch 11/12                         Loss D: -108.6387, loss G: 5.5580\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [72/200] Batch 11/12                         Loss D: -110.9262, loss G: 5.7506\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [73/200] Batch 11/12                         Loss D: -111.4423, loss G: 5.8257\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [74/200] Batch 11/12                         Loss D: -113.9458, loss G: 5.9148\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [75/200] Batch 11/12                         Loss D: -116.1060, loss G: 6.0119\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [76/200] Batch 11/12                         Loss D: -116.8727, loss G: 6.2006\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [77/200] Batch 11/12                         Loss D: -117.8519, loss G: 6.3411\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [78/200] Batch 11/12                         Loss D: -120.8958, loss G: 6.3720\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [79/200] Batch 11/12                         Loss D: -121.1935, loss G: 6.4552\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [80/200] Batch 11/12                         Loss D: -122.5128, loss G: 6.6170\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [81/200] Batch 11/12                         Loss D: -124.6896, loss G: 6.6394\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [82/200] Batch 11/12                         Loss D: -126.7002, loss G: 6.7232\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [83/200] Batch 11/12                         Loss D: -127.5964, loss G: 6.8370\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [84/200] Batch 11/12                         Loss D: -129.5211, loss G: 6.9327\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [85/200] Batch 11/12                         Loss D: -128.8042, loss G: 7.1987\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [86/200] Batch 11/12                         Loss D: -134.8077, loss G: 7.2496\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [87/200] Batch 11/12                         Loss D: -133.8595, loss G: 7.2459\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [88/200] Batch 11/12                         Loss D: -136.8418, loss G: 7.3080\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [89/200] Batch 11/12                         Loss D: -137.9237, loss G: 7.3773\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [90/200] Batch 11/12                         Loss D: -140.3521, loss G: 7.5352\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [91/200] Batch 11/12                         Loss D: -139.2917, loss G: 7.6961\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [92/200] Batch 11/12                         Loss D: -142.0328, loss G: 7.6814\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [93/200] Batch 11/12                         Loss D: -144.9140, loss G: 7.8561\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [94/200] Batch 11/12                         Loss D: -147.1023, loss G: 7.9740\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [95/200] Batch 11/12                         Loss D: -146.9912, loss G: 7.9804\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [96/200] Batch 11/12                         Loss D: -149.0827, loss G: 8.0592\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [97/200] Batch 11/12                         Loss D: -151.2665, loss G: 8.1708\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [98/200] Batch 11/12                         Loss D: -151.7294, loss G: 8.2938\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [99/200] Batch 11/12                         Loss D: -153.2397, loss G: 8.3885\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [100/200] Batch 11/12                         Loss D: -154.3773, loss G: 8.4896\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [101/200] Batch 11/12                         Loss D: -154.9577, loss G: 8.6711\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [102/200] Batch 11/12                         Loss D: -158.5954, loss G: 8.6674\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [103/200] Batch 11/12                         Loss D: -158.9966, loss G: 8.8495\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [104/200] Batch 11/12                         Loss D: -162.4521, loss G: 8.8679\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [105/200] Batch 11/12                         Loss D: -163.3569, loss G: 8.9839\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [106/200] Batch 11/12                         Loss D: -164.8293, loss G: 9.1075\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [107/200] Batch 11/12                         Loss D: -166.2566, loss G: 9.2360\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [108/200] Batch 11/12                         Loss D: -168.0460, loss G: 9.3307\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [109/200] Batch 11/12                         Loss D: -172.1271, loss G: 9.4658\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [110/200] Batch 11/12                         Loss D: -170.3665, loss G: 9.5645\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [111/200] Batch 11/12                         Loss D: -174.6163, loss G: 9.6075\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [112/200] Batch 11/12                         Loss D: -174.9709, loss G: 9.7325\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [113/200] Batch 11/12                         Loss D: -176.3950, loss G: 9.8652\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [114/200] Batch 11/12                         Loss D: -177.3263, loss G: 10.0084\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [115/200] Batch 11/12                         Loss D: -183.3782, loss G: 10.1480\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [116/200] Batch 11/12                         Loss D: -181.4679, loss G: 10.1921\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [117/200] Batch 11/12                         Loss D: -185.9498, loss G: 10.3213\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [118/200] Batch 11/12                         Loss D: -186.3804, loss G: 10.3704\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [119/200] Batch 11/12                         Loss D: -187.2651, loss G: 10.5129\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [120/200] Batch 11/12                         Loss D: -189.7075, loss G: 10.6023\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [121/200] Batch 11/12                         Loss D: -189.4987, loss G: 10.7802\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [122/200] Batch 11/12                         Loss D: -193.8013, loss G: 10.8195\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [123/200] Batch 11/12                         Loss D: -194.9649, loss G: 10.9538\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [124/200] Batch 11/12                         Loss D: -196.8563, loss G: 11.0619\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [125/200] Batch 11/12                         Loss D: -201.3492, loss G: 11.2838\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [126/200] Batch 11/12                         Loss D: -198.3492, loss G: 11.3634\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [127/200] Batch 11/12                         Loss D: -203.4517, loss G: 11.3919\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [128/200] Batch 11/12                         Loss D: -205.4299, loss G: 11.5088\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [129/200] Batch 11/12                         Loss D: -206.5232, loss G: 11.6535\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [130/200] Batch 11/12                         Loss D: -211.5818, loss G: 11.9386\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [131/200] Batch 11/12                         Loss D: -207.9115, loss G: 11.9515\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [132/200] Batch 11/12                         Loss D: -212.5115, loss G: 12.0148\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [133/200] Batch 11/12                         Loss D: -214.9296, loss G: 12.1280\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [134/200] Batch 11/12                         Loss D: -216.4074, loss G: 12.2615\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [135/200] Batch 11/12                         Loss D: -219.5061, loss G: 12.3833\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [136/200] Batch 11/12                         Loss D: -222.0642, loss G: 12.5639\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [137/200] Batch 11/12                         Loss D: -220.8277, loss G: 12.6740\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [138/200] Batch 11/12                         Loss D: -222.6759, loss G: 12.7987\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [139/200] Batch 11/12                         Loss D: -224.2634, loss G: 12.9338\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [140/200] Batch 11/12                         Loss D: -228.1101, loss G: 13.0321\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [141/200] Batch 11/12                         Loss D: -227.6594, loss G: 13.2057\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [142/200] Batch 11/12                         Loss D: -231.0435, loss G: 13.3215\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [143/200] Batch 11/12                         Loss D: -234.3819, loss G: 13.4321\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [144/200] Batch 11/12                         Loss D: -236.2978, loss G: 13.5697\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [145/200] Batch 11/12                         Loss D: -239.4349, loss G: 13.7670\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [146/200] Batch 11/12                         Loss D: -239.2598, loss G: 13.8529\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [147/200] Batch 11/12                         Loss D: -239.3169, loss G: 14.0205\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [148/200] Batch 11/12                         Loss D: -241.2088, loss G: 14.1539\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [149/200] Batch 11/12                         Loss D: -242.7080, loss G: 14.2982\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [150/200] Batch 11/12                         Loss D: -246.0507, loss G: 14.4268\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [151/200] Batch 11/12                         Loss D: -247.2118, loss G: 14.5763\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [152/200] Batch 11/12                         Loss D: -251.6747, loss G: 14.7001\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [153/200] Batch 11/12                         Loss D: -252.8329, loss G: 14.8525\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [154/200] Batch 11/12                         Loss D: -252.3002, loss G: 15.0188\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [155/200] Batch 11/12                         Loss D: -256.5642, loss G: 15.1421\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [156/200] Batch 11/12                         Loss D: -257.7499, loss G: 15.2990\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [157/200] Batch 11/12                         Loss D: -262.1653, loss G: 15.4886\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [158/200] Batch 11/12                         Loss D: -260.5615, loss G: 15.5987\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [159/200] Batch 11/12                         Loss D: -262.7701, loss G: 15.7491\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [160/200] Batch 11/12                         Loss D: -266.6435, loss G: 15.9074\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [161/200] Batch 11/12                         Loss D: -267.8062, loss G: 16.0578\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [162/200] Batch 11/12                         Loss D: -270.4985, loss G: 16.2299\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [163/200] Batch 11/12                         Loss D: -271.9705, loss G: 16.3731\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [164/200] Batch 11/12                         Loss D: -270.4455, loss G: 16.5297\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [165/200] Batch 11/12                         Loss D: -273.3937, loss G: 16.6833\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [166/200] Batch 11/12                         Loss D: -274.4888, loss G: 16.8448\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [167/200] Batch 11/12                         Loss D: -279.7126, loss G: 17.0086\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [168/200] Batch 11/12                         Loss D: -278.4873, loss G: 17.1591\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [169/200] Batch 11/12                         Loss D: -280.2659, loss G: 17.3219\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [170/200] Batch 11/12                         Loss D: -282.2860, loss G: 17.4864\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [171/200] Batch 11/12                         Loss D: -282.8605, loss G: 17.6435\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [172/200] Batch 11/12                         Loss D: -283.2335, loss G: 17.7960\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [173/200] Batch 11/12                         Loss D: -283.6050, loss G: 17.9518\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [174/200] Batch 11/12                         Loss D: -285.9377, loss G: 18.1133\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [175/200] Batch 11/12                         Loss D: -284.5026, loss G: 18.2665\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [176/200] Batch 11/12                         Loss D: -287.1712, loss G: 18.4165\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [177/200] Batch 11/12                         Loss D: -287.2547, loss G: 18.5668\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [178/200] Batch 11/12                         Loss D: -288.1403, loss G: 18.7220\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [179/200] Batch 11/12                         Loss D: -287.8473, loss G: 18.8502\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [180/200] Batch 11/12                         Loss D: -286.7807, loss G: 18.9763\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [181/200] Batch 11/12                         Loss D: -284.6726, loss G: 19.0944\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [182/200] Batch 11/12                         Loss D: -284.5552, loss G: 19.2193\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [183/200] Batch 11/12                         Loss D: -284.3130, loss G: 19.3364\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [184/200] Batch 11/12                         Loss D: -283.3467, loss G: 19.4547\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [185/200] Batch 11/12                         Loss D: -285.2438, loss G: 19.5832\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [186/200] Batch 11/12                         Loss D: -282.5638, loss G: 19.6554\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [187/200] Batch 11/12                         Loss D: -284.5110, loss G: 19.7741\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [188/200] Batch 11/12                         Loss D: -283.0193, loss G: 19.8515\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [189/200] Batch 11/12                         Loss D: -283.2891, loss G: 19.9561\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [190/200] Batch 11/12                         Loss D: -280.2049, loss G: 20.0046\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [191/200] Batch 11/12                         Loss D: -281.2371, loss G: 20.1021\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [192/200] Batch 11/12                         Loss D: -278.2817, loss G: 20.1344\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [193/200] Batch 11/12                         Loss D: -276.5642, loss G: 20.1812\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [194/200] Batch 11/12                         Loss D: -275.6127, loss G: 20.2336\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [195/200] Batch 11/12                         Loss D: -270.0088, loss G: 20.1997\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [196/200] Batch 11/12                         Loss D: -269.2545, loss G: 20.2409\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [197/200] Batch 11/12                         Loss D: -266.2884, loss G: 20.2333\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [198/200] Batch 11/12                         Loss D: -264.9792, loss G: 20.2495\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.5]                         Epoch [199/200] Batch 11/12                         Loss D: -260.7932, loss G: 20.1866\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [0/200] Batch 11/12                         Loss D: 1.0482, loss G: 3.8078\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [1/200] Batch 11/12                         Loss D: 1.0102, loss G: 3.7782\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [2/200] Batch 11/12                         Loss D: 0.9574, loss G: 3.7403\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [3/200] Batch 11/12                         Loss D: 0.8562, loss G: 3.7049\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [4/200] Batch 11/12                         Loss D: 0.7288, loss G: 3.6696\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [5/200] Batch 11/12                         Loss D: 0.6408, loss G: 3.6380\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [6/200] Batch 11/12                         Loss D: 0.5647, loss G: 3.6085\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [7/200] Batch 11/12                         Loss D: 0.5634, loss G: 3.5915\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [8/200] Batch 11/12                         Loss D: 0.5370, loss G: 3.5665\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [9/200] Batch 11/12                         Loss D: 0.5197, loss G: 3.5418\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [10/200] Batch 11/12                         Loss D: 0.4613, loss G: 3.5114\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [11/200] Batch 11/12                         Loss D: 0.3993, loss G: 3.4815\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [12/200] Batch 11/12                         Loss D: 0.3373, loss G: 3.4516\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [13/200] Batch 11/12                         Loss D: 0.2788, loss G: 3.4265\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [14/200] Batch 11/12                         Loss D: 0.2217, loss G: 3.3992\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [15/200] Batch 11/12                         Loss D: 0.1454, loss G: 3.3680\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [16/200] Batch 11/12                         Loss D: 0.0673, loss G: 3.3373\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [17/200] Batch 11/12                         Loss D: 0.0094, loss G: 3.3191\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [18/200] Batch 11/12                         Loss D: -0.1305, loss G: 3.3293\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [19/200] Batch 11/12                         Loss D: -0.2046, loss G: 3.3403\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [20/200] Batch 11/12                         Loss D: -0.2971, loss G: 3.3526\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [21/200] Batch 11/12                         Loss D: -0.3702, loss G: 3.3637\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [22/200] Batch 11/12                         Loss D: -0.4179, loss G: 3.3740\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [23/200] Batch 11/12                         Loss D: -0.4678, loss G: 3.3845\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [24/200] Batch 11/12                         Loss D: -0.5061, loss G: 3.3946\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [25/200] Batch 11/12                         Loss D: -0.5043, loss G: 3.4054\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [26/200] Batch 11/12                         Loss D: -0.5068, loss G: 3.4150\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [27/200] Batch 11/12                         Loss D: -0.5005, loss G: 3.4240\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [28/200] Batch 11/12                         Loss D: -0.5159, loss G: 3.4336\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [29/200] Batch 11/12                         Loss D: -0.5585, loss G: 3.4437\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [30/200] Batch 11/12                         Loss D: -0.6275, loss G: 3.4524\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [31/200] Batch 11/12                         Loss D: -0.7137, loss G: 3.4614\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [32/200] Batch 11/12                         Loss D: -0.8168, loss G: 3.4692\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [33/200] Batch 11/12                         Loss D: -0.8934, loss G: 3.4770\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [34/200] Batch 11/12                         Loss D: -0.9856, loss G: 3.4844\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [35/200] Batch 11/12                         Loss D: -1.0639, loss G: 3.4907\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [36/200] Batch 11/12                         Loss D: -1.2166, loss G: 3.4977\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [37/200] Batch 11/12                         Loss D: -1.3339, loss G: 3.5041\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [38/200] Batch 11/12                         Loss D: -1.4300, loss G: 3.5095\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [39/200] Batch 11/12                         Loss D: -1.5913, loss G: 3.5153\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [40/200] Batch 11/12                         Loss D: -1.6850, loss G: 3.5202\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [41/200] Batch 11/12                         Loss D: -1.7594, loss G: 3.5254\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [42/200] Batch 11/12                         Loss D: -1.8663, loss G: 3.5318\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [43/200] Batch 11/12                         Loss D: -1.9348, loss G: 3.5376\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [44/200] Batch 11/12                         Loss D: -2.0193, loss G: 3.5447\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [45/200] Batch 11/12                         Loss D: -2.0932, loss G: 3.5519\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [46/200] Batch 11/12                         Loss D: -2.1284, loss G: 3.5584\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [47/200] Batch 11/12                         Loss D: -2.1999, loss G: 3.5654\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [48/200] Batch 11/12                         Loss D: -2.2444, loss G: 3.5715\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [49/200] Batch 11/12                         Loss D: -2.2965, loss G: 3.5777\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [50/200] Batch 11/12                         Loss D: -2.2737, loss G: 3.5829\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [51/200] Batch 11/12                         Loss D: -2.2569, loss G: 3.5878\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [52/200] Batch 11/12                         Loss D: -2.2333, loss G: 3.5930\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [53/200] Batch 11/12                         Loss D: -2.1876, loss G: 3.5978\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [54/200] Batch 11/12                         Loss D: -2.1962, loss G: 3.6027\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [55/200] Batch 11/12                         Loss D: -2.1309, loss G: 3.6076\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [56/200] Batch 11/12                         Loss D: -2.1584, loss G: 3.6117\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [57/200] Batch 11/12                         Loss D: -2.2032, loss G: 3.6179\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [58/200] Batch 11/12                         Loss D: -2.1723, loss G: 3.6226\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [59/200] Batch 11/12                         Loss D: -2.2620, loss G: 3.6262\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [60/200] Batch 11/12                         Loss D: -2.3952, loss G: 3.6310\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [61/200] Batch 11/12                         Loss D: -2.4927, loss G: 3.6371\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [62/200] Batch 11/12                         Loss D: -2.6348, loss G: 3.6422\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [63/200] Batch 11/12                         Loss D: -2.7622, loss G: 3.6488\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [64/200] Batch 11/12                         Loss D: -2.8966, loss G: 3.6550\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [65/200] Batch 11/12                         Loss D: -2.9955, loss G: 3.6613\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [66/200] Batch 11/12                         Loss D: -3.1407, loss G: 3.6675\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [67/200] Batch 11/12                         Loss D: -3.2189, loss G: 3.6733\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [68/200] Batch 11/12                         Loss D: -3.3205, loss G: 3.6792\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [69/200] Batch 11/12                         Loss D: -3.4295, loss G: 3.6866\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [70/200] Batch 11/12                         Loss D: -3.4632, loss G: 3.6911\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [71/200] Batch 11/12                         Loss D: -3.5306, loss G: 3.6966\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [72/200] Batch 11/12                         Loss D: -3.5734, loss G: 3.7030\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [73/200] Batch 11/12                         Loss D: -3.6104, loss G: 3.7072\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [74/200] Batch 11/12                         Loss D: -3.6532, loss G: 3.7121\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [75/200] Batch 11/12                         Loss D: -3.7040, loss G: 3.7172\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [76/200] Batch 11/12                         Loss D: -3.7204, loss G: 3.7217\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [77/200] Batch 11/12                         Loss D: -3.7241, loss G: 3.7258\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [78/200] Batch 11/12                         Loss D: -3.7089, loss G: 3.7305\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [79/200] Batch 11/12                         Loss D: -3.7257, loss G: 3.7337\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [80/200] Batch 11/12                         Loss D: -3.7713, loss G: 3.7372\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [81/200] Batch 11/12                         Loss D: -3.7068, loss G: 3.7405\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [82/200] Batch 11/12                         Loss D: -3.6266, loss G: 3.7438\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [83/200] Batch 11/12                         Loss D: -3.4986, loss G: 3.7472\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [84/200] Batch 11/12                         Loss D: -3.3098, loss G: 3.7490\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [85/200] Batch 11/12                         Loss D: -3.3539, loss G: 3.7529\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [86/200] Batch 11/12                         Loss D: -3.4530, loss G: 3.7564\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [87/200] Batch 11/12                         Loss D: -3.5920, loss G: 3.7613\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [88/200] Batch 11/12                         Loss D: -3.6377, loss G: 3.7645\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [89/200] Batch 11/12                         Loss D: -3.7605, loss G: 3.7683\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [90/200] Batch 11/12                         Loss D: -3.8551, loss G: 3.7730\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [91/200] Batch 11/12                         Loss D: -3.9002, loss G: 3.7782\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [92/200] Batch 11/12                         Loss D: -4.0022, loss G: 3.7814\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [93/200] Batch 11/12                         Loss D: -4.0987, loss G: 3.7848\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [94/200] Batch 11/12                         Loss D: -4.1812, loss G: 3.7796\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [95/200] Batch 11/12                         Loss D: -4.3379, loss G: 3.7449\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [96/200] Batch 11/12                         Loss D: -3.5850, loss G: 3.7104\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [97/200] Batch 11/12                         Loss D: -4.1639, loss G: 3.7245\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [98/200] Batch 11/12                         Loss D: -4.4036, loss G: 3.7400\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [99/200] Batch 11/12                         Loss D: -4.6935, loss G: 3.7571\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [100/200] Batch 11/12                         Loss D: -4.8556, loss G: 3.7723\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [101/200] Batch 11/12                         Loss D: -5.0930, loss G: 3.7861\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [102/200] Batch 11/12                         Loss D: -5.2786, loss G: 3.8002\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [103/200] Batch 11/12                         Loss D: -5.4919, loss G: 3.8148\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [104/200] Batch 11/12                         Loss D: -5.6515, loss G: 3.8279\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [105/200] Batch 11/12                         Loss D: -5.8095, loss G: 3.8420\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [106/200] Batch 11/12                         Loss D: -5.9776, loss G: 3.8557\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [107/200] Batch 11/12                         Loss D: -6.1000, loss G: 3.8689\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [108/200] Batch 11/12                         Loss D: -6.1135, loss G: 3.8819\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [109/200] Batch 11/12                         Loss D: -6.1193, loss G: 3.8945\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [110/200] Batch 11/12                         Loss D: -6.0003, loss G: 3.9058\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [111/200] Batch 11/12                         Loss D: -5.7404, loss G: 3.9148\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [112/200] Batch 11/12                         Loss D: -5.3962, loss G: 3.9224\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [113/200] Batch 11/12                         Loss D: -4.9926, loss G: 3.9285\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [114/200] Batch 11/12                         Loss D: -4.4505, loss G: 3.9317\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [115/200] Batch 11/12                         Loss D: -3.9225, loss G: 3.9343\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [116/200] Batch 11/12                         Loss D: -3.3437, loss G: 3.9350\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [117/200] Batch 11/12                         Loss D: -2.7436, loss G: 3.9344\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [118/200] Batch 11/12                         Loss D: -2.0773, loss G: 3.9321\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [119/200] Batch 11/12                         Loss D: -1.4255, loss G: 3.9287\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [120/200] Batch 11/12                         Loss D: -0.7812, loss G: 3.9257\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [121/200] Batch 11/12                         Loss D: -0.0733, loss G: 3.9203\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [122/200] Batch 11/12                         Loss D: 0.7104, loss G: 3.9090\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [123/200] Batch 11/12                         Loss D: 1.6355, loss G: 3.8953\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [124/200] Batch 11/12                         Loss D: 2.3905, loss G: 3.8880\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [125/200] Batch 11/12                         Loss D: 3.1713, loss G: 3.8812\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [126/200] Batch 11/12                         Loss D: 4.7023, loss G: 3.8576\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [127/200] Batch 11/12                         Loss D: 4.9288, loss G: 3.8461\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [128/200] Batch 11/12                         Loss D: 4.7608, loss G: 3.8436\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [129/200] Batch 11/12                         Loss D: 4.4620, loss G: 3.8413\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [130/200] Batch 11/12                         Loss D: 3.8832, loss G: 3.8323\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [131/200] Batch 11/12                         Loss D: 3.3284, loss G: 3.8215\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [132/200] Batch 11/12                         Loss D: 2.8030, loss G: 3.8116\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [133/200] Batch 11/12                         Loss D: 2.1577, loss G: 3.8064\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [134/200] Batch 11/12                         Loss D: 1.3974, loss G: 3.8045\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [135/200] Batch 11/12                         Loss D: 1.1089, loss G: 3.8069\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [136/200] Batch 11/12                         Loss D: 0.9759, loss G: 3.8105\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [137/200] Batch 11/12                         Loss D: 0.9423, loss G: 3.8136\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [138/200] Batch 11/12                         Loss D: 0.8257, loss G: 3.8169\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [139/200] Batch 11/12                         Loss D: 0.7516, loss G: 3.8197\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [140/200] Batch 11/12                         Loss D: 0.6225, loss G: 3.8227\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [141/200] Batch 11/12                         Loss D: 0.5689, loss G: 3.8250\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [142/200] Batch 11/12                         Loss D: 0.4228, loss G: 3.8276\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [143/200] Batch 11/12                         Loss D: 0.3440, loss G: 3.8297\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [144/200] Batch 11/12                         Loss D: 0.2405, loss G: 3.8323\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [145/200] Batch 11/12                         Loss D: 0.1507, loss G: 3.8344\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [146/200] Batch 11/12                         Loss D: 0.1046, loss G: 3.8364\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [147/200] Batch 11/12                         Loss D: -0.0295, loss G: 3.8384\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [148/200] Batch 11/12                         Loss D: -0.1252, loss G: 3.8403\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [149/200] Batch 11/12                         Loss D: -0.1826, loss G: 3.8422\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [150/200] Batch 11/12                         Loss D: -0.3164, loss G: 3.8438\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [151/200] Batch 11/12                         Loss D: -0.4570, loss G: 3.8453\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [152/200] Batch 11/12                         Loss D: -0.5586, loss G: 3.8465\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [153/200] Batch 11/12                         Loss D: -0.7598, loss G: 3.8468\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [154/200] Batch 11/12                         Loss D: -0.8874, loss G: 3.8481\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [155/200] Batch 11/12                         Loss D: -1.0073, loss G: 3.8476\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [156/200] Batch 11/12                         Loss D: -1.1426, loss G: 3.8480\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [157/200] Batch 11/12                         Loss D: -1.2434, loss G: 3.8477\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [158/200] Batch 11/12                         Loss D: -1.3951, loss G: 3.8472\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [159/200] Batch 11/12                         Loss D: -1.5329, loss G: 3.8469\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [160/200] Batch 11/12                         Loss D: -1.6444, loss G: 3.8460\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [161/200] Batch 11/12                         Loss D: -1.7631, loss G: 3.8448\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [162/200] Batch 11/12                         Loss D: -1.8644, loss G: 3.8433\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [163/200] Batch 11/12                         Loss D: -1.9448, loss G: 3.8424\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [164/200] Batch 11/12                         Loss D: -1.9627, loss G: 3.8428\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [165/200] Batch 11/12                         Loss D: -1.9902, loss G: 3.8432\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [166/200] Batch 11/12                         Loss D: -2.0397, loss G: 3.8437\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [167/200] Batch 11/12                         Loss D: -2.0198, loss G: 3.8440\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [168/200] Batch 11/12                         Loss D: -2.0194, loss G: 3.8447\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [169/200] Batch 11/12                         Loss D: -2.0204, loss G: 3.8453\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [170/200] Batch 11/12                         Loss D: -2.0418, loss G: 3.8455\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [171/200] Batch 11/12                         Loss D: -2.0873, loss G: 3.8461\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [172/200] Batch 11/12                         Loss D: -2.0909, loss G: 3.8466\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [173/200] Batch 11/12                         Loss D: -2.1115, loss G: 3.8470\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [174/200] Batch 11/12                         Loss D: -2.0994, loss G: 3.8476\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [175/200] Batch 11/12                         Loss D: -2.1390, loss G: 3.8480\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [176/200] Batch 11/12                         Loss D: -2.1419, loss G: 3.8482\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [177/200] Batch 11/12                         Loss D: -2.1519, loss G: 3.8487\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [178/200] Batch 11/12                         Loss D: -2.2002, loss G: 3.8489\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [179/200] Batch 11/12                         Loss D: -2.2390, loss G: 3.8496\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [180/200] Batch 11/12                         Loss D: -2.2296, loss G: 3.8501\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [181/200] Batch 11/12                         Loss D: -2.2392, loss G: 3.8503\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [182/200] Batch 11/12                         Loss D: -2.2280, loss G: 3.8512\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [183/200] Batch 11/12                         Loss D: -2.2681, loss G: 3.8516\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [184/200] Batch 11/12                         Loss D: -2.3209, loss G: 3.8520\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [185/200] Batch 11/12                         Loss D: -2.3294, loss G: 3.8527\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [186/200] Batch 11/12                         Loss D: -2.3238, loss G: 3.8530\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [187/200] Batch 11/12                         Loss D: -2.3532, loss G: 3.8529\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [188/200] Batch 11/12                         Loss D: -2.3729, loss G: 3.8538\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [189/200] Batch 11/12                         Loss D: -2.3835, loss G: 3.8542\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [190/200] Batch 11/12                         Loss D: -2.4317, loss G: 3.8546\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [191/200] Batch 11/12                         Loss D: -2.4482, loss G: 3.8552\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [192/200] Batch 11/12                         Loss D: -2.4485, loss G: 3.8554\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [193/200] Batch 11/12                         Loss D: -2.4737, loss G: 3.8561\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [194/200] Batch 11/12                         Loss D: -2.5094, loss G: 3.8563\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [195/200] Batch 11/12                         Loss D: -2.5402, loss G: 3.8569\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [196/200] Batch 11/12                         Loss D: -2.5263, loss G: 3.8575\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [197/200] Batch 11/12                         Loss D: -2.6425, loss G: 3.8579\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [198/200] Batch 11/12                         Loss D: -2.6389, loss G: 3.8580\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=1, lambda_mean=0.1]                         Epoch [199/200] Batch 11/12                         Loss D: -2.6335, loss G: 3.8584\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [0/200] Batch 11/12                         Loss D: 0.1724, loss G: 34.3949\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [1/200] Batch 11/12                         Loss D: 0.1305, loss G: 34.2968\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [2/200] Batch 11/12                         Loss D: 0.0886, loss G: 34.2052\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [3/200] Batch 11/12                         Loss D: 0.0137, loss G: 34.0849\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [4/200] Batch 11/12                         Loss D: -0.0685, loss G: 33.9514\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [5/200] Batch 11/12                         Loss D: -0.1898, loss G: 33.8000\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [6/200] Batch 11/12                         Loss D: -0.3459, loss G: 33.6299\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [7/200] Batch 11/12                         Loss D: -0.5629, loss G: 33.4280\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [8/200] Batch 11/12                         Loss D: -0.8317, loss G: 33.2255\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [9/200] Batch 11/12                         Loss D: -1.2171, loss G: 32.9322\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [10/200] Batch 11/12                         Loss D: -1.7110, loss G: 32.6189\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [11/200] Batch 11/12                         Loss D: -2.3414, loss G: 32.2612\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [12/200] Batch 11/12                         Loss D: -3.0411, loss G: 31.8896\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [13/200] Batch 11/12                         Loss D: -3.8596, loss G: 31.4798\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [14/200] Batch 11/12                         Loss D: -4.8736, loss G: 30.9862\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [15/200] Batch 11/12                         Loss D: -5.8693, loss G: 30.5581\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [16/200] Batch 11/12                         Loss D: -7.0800, loss G: 30.0425\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [17/200] Batch 11/12                         Loss D: -8.2600, loss G: 29.5822\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [18/200] Batch 11/12                         Loss D: -9.2310, loss G: 29.2116\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [19/200] Batch 11/12                         Loss D: -10.1165, loss G: 28.8418\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [20/200] Batch 11/12                         Loss D: -10.9111, loss G: 28.5100\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [21/200] Batch 11/12                         Loss D: -11.9823, loss G: 28.1086\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [22/200] Batch 11/12                         Loss D: -13.0906, loss G: 27.6677\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [23/200] Batch 11/12                         Loss D: -14.2979, loss G: 27.2062\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [24/200] Batch 11/12                         Loss D: -15.6880, loss G: 26.7093\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [25/200] Batch 11/12                         Loss D: -16.9508, loss G: 26.2241\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [26/200] Batch 11/12                         Loss D: -18.1988, loss G: 25.7827\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [27/200] Batch 11/12                         Loss D: -20.0062, loss G: 25.1318\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [28/200] Batch 11/12                         Loss D: -21.6342, loss G: 24.5868\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [29/200] Batch 11/12                         Loss D: -23.3783, loss G: 24.0527\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [30/200] Batch 11/12                         Loss D: -25.6444, loss G: 23.3576\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [31/200] Batch 11/12                         Loss D: -27.9902, loss G: 22.6069\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [32/200] Batch 11/12                         Loss D: -30.5059, loss G: 21.8910\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [33/200] Batch 11/12                         Loss D: -32.9303, loss G: 21.2373\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [34/200] Batch 11/12                         Loss D: -35.9775, loss G: 20.3956\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [35/200] Batch 11/12                         Loss D: -39.0862, loss G: 19.6663\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [36/200] Batch 11/12                         Loss D: -42.4380, loss G: 18.7620\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [37/200] Batch 11/12                         Loss D: -45.9888, loss G: 17.9061\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [38/200] Batch 11/12                         Loss D: -49.5052, loss G: 17.1296\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [39/200] Batch 11/12                         Loss D: -53.9749, loss G: 16.2272\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [40/200] Batch 11/12                         Loss D: -57.7110, loss G: 16.0555\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [41/200] Batch 11/12                         Loss D: -61.5719, loss G: 15.8919\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [42/200] Batch 11/12                         Loss D: -64.9766, loss G: 15.8293\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [43/200] Batch 11/12                         Loss D: -68.8650, loss G: 15.7125\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [44/200] Batch 11/12                         Loss D: -72.6280, loss G: 15.6186\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [45/200] Batch 11/12                         Loss D: -76.4959, loss G: 15.5638\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [46/200] Batch 11/12                         Loss D: -79.1658, loss G: 15.6122\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [47/200] Batch 11/12                         Loss D: -83.9203, loss G: 15.3292\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [48/200] Batch 11/12                         Loss D: -88.0873, loss G: 15.2338\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [49/200] Batch 11/12                         Loss D: -92.2321, loss G: 15.1886\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [50/200] Batch 11/12                         Loss D: -95.4344, loss G: 15.3478\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [51/200] Batch 11/12                         Loss D: -101.9225, loss G: 15.0929\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [52/200] Batch 11/12                         Loss D: -105.5667, loss G: 14.9833\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [53/200] Batch 11/12                         Loss D: -110.2832, loss G: 14.9244\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [54/200] Batch 11/12                         Loss D: -115.3910, loss G: 14.9091\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [55/200] Batch 11/12                         Loss D: -120.4966, loss G: 14.9032\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [56/200] Batch 11/12                         Loss D: -125.3443, loss G: 14.8360\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [57/200] Batch 11/12                         Loss D: -130.3622, loss G: 14.8283\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [58/200] Batch 11/12                         Loss D: -136.0570, loss G: 14.7759\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [59/200] Batch 11/12                         Loss D: -140.7626, loss G: 14.7962\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [60/200] Batch 11/12                         Loss D: -147.2515, loss G: 14.7077\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [61/200] Batch 11/12                         Loss D: -153.5801, loss G: 14.7598\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [62/200] Batch 11/12                         Loss D: -158.6770, loss G: 14.7454\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [63/200] Batch 11/12                         Loss D: -166.4242, loss G: 14.7302\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [64/200] Batch 11/12                         Loss D: -173.4986, loss G: 14.7017\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [65/200] Batch 11/12                         Loss D: -179.8503, loss G: 14.7008\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [66/200] Batch 11/12                         Loss D: -187.0030, loss G: 14.6799\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [67/200] Batch 11/12                         Loss D: -192.3349, loss G: 14.7396\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [68/200] Batch 11/12                         Loss D: -197.4554, loss G: 14.9333\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [69/200] Batch 11/12                         Loss D: -209.1732, loss G: 14.9609\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [70/200] Batch 11/12                         Loss D: -214.2082, loss G: 14.9136\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [71/200] Batch 11/12                         Loss D: -222.2805, loss G: 15.0236\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [72/200] Batch 11/12                         Loss D: -231.3013, loss G: 15.1465\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [73/200] Batch 11/12                         Loss D: -233.2397, loss G: 15.4262\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [74/200] Batch 11/12                         Loss D: -238.9875, loss G: 15.5598\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [75/200] Batch 11/12                         Loss D: -240.9359, loss G: 15.7950\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [76/200] Batch 11/12                         Loss D: -244.6297, loss G: 16.0325\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [77/200] Batch 11/12                         Loss D: -248.4773, loss G: 16.2086\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [78/200] Batch 11/12                         Loss D: -250.5846, loss G: 16.5234\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [79/200] Batch 11/12                         Loss D: -254.6568, loss G: 16.7513\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [80/200] Batch 11/12                         Loss D: -263.1510, loss G: 17.2969\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [81/200] Batch 11/12                         Loss D: -261.5752, loss G: 17.1259\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [82/200] Batch 11/12                         Loss D: -267.1979, loss G: 17.2959\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [83/200] Batch 11/12                         Loss D: -268.3130, loss G: 17.5410\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [84/200] Batch 11/12                         Loss D: -273.6683, loss G: 17.7484\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [85/200] Batch 11/12                         Loss D: -276.6865, loss G: 18.0686\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [86/200] Batch 11/12                         Loss D: -278.4254, loss G: 18.1829\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [87/200] Batch 11/12                         Loss D: -283.0720, loss G: 18.3879\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [88/200] Batch 11/12                         Loss D: -285.7305, loss G: 18.6029\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [89/200] Batch 11/12                         Loss D: -291.0073, loss G: 18.8502\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [90/200] Batch 11/12                         Loss D: -292.7314, loss G: 19.0454\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [91/200] Batch 11/12                         Loss D: -297.0757, loss G: 19.3423\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [92/200] Batch 11/12                         Loss D: -298.3107, loss G: 19.4880\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [93/200] Batch 11/12                         Loss D: -303.2315, loss G: 19.6607\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [94/200] Batch 11/12                         Loss D: -304.2471, loss G: 19.8880\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [95/200] Batch 11/12                         Loss D: -309.4799, loss G: 20.0926\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [96/200] Batch 11/12                         Loss D: -313.8643, loss G: 20.3713\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [97/200] Batch 11/12                         Loss D: -318.5415, loss G: 20.6320\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [98/200] Batch 11/12                         Loss D: -320.1459, loss G: 20.7656\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [99/200] Batch 11/12                         Loss D: -320.5553, loss G: 20.9667\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [100/200] Batch 11/12                         Loss D: -330.1321, loss G: 21.5081\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [101/200] Batch 11/12                         Loss D: -328.1347, loss G: 21.3728\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [102/200] Batch 11/12                         Loss D: -334.8665, loss G: 21.6031\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [103/200] Batch 11/12                         Loss D: -334.6009, loss G: 21.8385\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [104/200] Batch 11/12                         Loss D: -340.3661, loss G: 22.0154\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [105/200] Batch 11/12                         Loss D: -338.8719, loss G: 22.3123\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [106/200] Batch 11/12                         Loss D: -349.7034, loss G: 22.7186\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [107/200] Batch 11/12                         Loss D: -346.7526, loss G: 22.7089\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [108/200] Batch 11/12                         Loss D: -350.7772, loss G: 22.9478\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [109/200] Batch 11/12                         Loss D: -353.9884, loss G: 23.1046\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [110/200] Batch 11/12                         Loss D: -355.7495, loss G: 23.3369\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [111/200] Batch 11/12                         Loss D: -364.2412, loss G: 23.5699\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [112/200] Batch 11/12                         Loss D: -364.5310, loss G: 23.7591\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [113/200] Batch 11/12                         Loss D: -364.3683, loss G: 24.0147\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [114/200] Batch 11/12                         Loss D: -375.6359, loss G: 24.2411\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [115/200] Batch 11/12                         Loss D: -375.9960, loss G: 24.3460\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [116/200] Batch 11/12                         Loss D: -384.0905, loss G: 24.8501\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [117/200] Batch 11/12                         Loss D: -379.8470, loss G: 24.7913\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [118/200] Batch 11/12                         Loss D: -383.5605, loss G: 24.9883\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [119/200] Batch 11/12                         Loss D: -388.9503, loss G: 25.2038\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [120/200] Batch 11/12                         Loss D: -390.6278, loss G: 25.3995\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [121/200] Batch 11/12                         Loss D: -393.6302, loss G: 25.6376\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [122/200] Batch 11/12                         Loss D: -396.5929, loss G: 25.8449\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [123/200] Batch 11/12                         Loss D: -402.3817, loss G: 26.0488\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [124/200] Batch 11/12                         Loss D: -399.6706, loss G: 26.3313\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [125/200] Batch 11/12                         Loss D: -406.1382, loss G: 26.4640\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [126/200] Batch 11/12                         Loss D: -407.7568, loss G: 26.6658\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [127/200] Batch 11/12                         Loss D: -411.1035, loss G: 26.8308\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [128/200] Batch 11/12                         Loss D: -412.9090, loss G: 27.0432\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [129/200] Batch 11/12                         Loss D: -411.6237, loss G: 27.3095\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [130/200] Batch 11/12                         Loss D: -416.5023, loss G: 27.4011\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [131/200] Batch 11/12                         Loss D: -416.1176, loss G: 27.6291\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [132/200] Batch 11/12                         Loss D: -415.9707, loss G: 27.9076\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [133/200] Batch 11/12                         Loss D: -421.5734, loss G: 28.0043\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [134/200] Batch 11/12                         Loss D: -422.8752, loss G: 28.1506\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [135/200] Batch 11/12                         Loss D: -424.3827, loss G: 28.3072\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [136/200] Batch 11/12                         Loss D: -423.4800, loss G: 28.5277\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [137/200] Batch 11/12                         Loss D: -427.6746, loss G: 28.6944\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [138/200] Batch 11/12                         Loss D: -426.5926, loss G: 28.8391\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [139/200] Batch 11/12                         Loss D: -425.6983, loss G: 29.0567\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [140/200] Batch 11/12                         Loss D: -428.9316, loss G: 29.1705\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [141/200] Batch 11/12                         Loss D: -425.4423, loss G: 29.3369\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [142/200] Batch 11/12                         Loss D: -431.0838, loss G: 29.5415\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [143/200] Batch 11/12                         Loss D: -427.7608, loss G: 29.6314\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [144/200] Batch 11/12                         Loss D: -430.8881, loss G: 29.7869\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [145/200] Batch 11/12                         Loss D: -427.8472, loss G: 29.8761\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [146/200] Batch 11/12                         Loss D: -422.3664, loss G: 30.0822\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [147/200] Batch 11/12                         Loss D: -428.6927, loss G: 30.1702\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [148/200] Batch 11/12                         Loss D: -423.3574, loss G: 30.2986\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [149/200] Batch 11/12                         Loss D: -421.5689, loss G: 30.4193\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [150/200] Batch 11/12                         Loss D: -421.3037, loss G: 30.5303\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [151/200] Batch 11/12                         Loss D: -418.5849, loss G: 30.6389\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [152/200] Batch 11/12                         Loss D: -419.9348, loss G: 30.7472\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [153/200] Batch 11/12                         Loss D: -420.0722, loss G: 30.7934\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [154/200] Batch 11/12                         Loss D: -419.3538, loss G: 30.9058\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [155/200] Batch 11/12                         Loss D: -417.5460, loss G: 31.0330\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [156/200] Batch 11/12                         Loss D: -415.0505, loss G: 31.0600\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [157/200] Batch 11/12                         Loss D: -412.2686, loss G: 31.1321\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [158/200] Batch 11/12                         Loss D: -409.7888, loss G: 31.2169\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [159/200] Batch 11/12                         Loss D: -407.4064, loss G: 31.2800\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [160/200] Batch 11/12                         Loss D: -403.9221, loss G: 31.3438\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [161/200] Batch 11/12                         Loss D: -403.7741, loss G: 31.4122\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [162/200] Batch 11/12                         Loss D: -397.5827, loss G: 31.4481\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [163/200] Batch 11/12                         Loss D: -394.8564, loss G: 31.5032\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [164/200] Batch 11/12                         Loss D: -391.4285, loss G: 31.5393\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [165/200] Batch 11/12                         Loss D: -385.8587, loss G: 31.5464\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [166/200] Batch 11/12                         Loss D: -382.8181, loss G: 31.5529\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [167/200] Batch 11/12                         Loss D: -377.2247, loss G: 31.5615\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [168/200] Batch 11/12                         Loss D: -373.4564, loss G: 31.5556\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [169/200] Batch 11/12                         Loss D: -366.4885, loss G: 31.5502\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [170/200] Batch 11/12                         Loss D: -357.3628, loss G: 31.5350\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [171/200] Batch 11/12                         Loss D: -350.5315, loss G: 31.2810\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [172/200] Batch 11/12                         Loss D: -344.3213, loss G: 30.9190\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [173/200] Batch 11/12                         Loss D: -332.9478, loss G: 30.4273\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [174/200] Batch 11/12                         Loss D: -320.4672, loss G: 30.0363\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [175/200] Batch 11/12                         Loss D: -309.8941, loss G: 29.5884\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [176/200] Batch 11/12                         Loss D: -297.2963, loss G: 29.1452\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [177/200] Batch 11/12                         Loss D: -285.9468, loss G: 28.7872\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [178/200] Batch 11/12                         Loss D: -270.4131, loss G: 28.4765\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [179/200] Batch 11/12                         Loss D: -257.9052, loss G: 27.9587\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [180/200] Batch 11/12                         Loss D: -241.1965, loss G: 27.5939\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [181/200] Batch 11/12                         Loss D: -227.0641, loss G: 27.1233\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [182/200] Batch 11/12                         Loss D: -209.6036, loss G: 26.7245\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [183/200] Batch 11/12                         Loss D: -191.5312, loss G: 26.0837\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [184/200] Batch 11/12                         Loss D: -176.0899, loss G: 25.7001\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [185/200] Batch 11/12                         Loss D: -159.7595, loss G: 25.4728\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [186/200] Batch 11/12                         Loss D: -152.3617, loss G: 25.3749\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [187/200] Batch 11/12                         Loss D: -148.7555, loss G: 25.4020\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [188/200] Batch 11/12                         Loss D: -146.6673, loss G: 25.4144\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [189/200] Batch 11/12                         Loss D: -146.8955, loss G: 25.5280\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [190/200] Batch 11/12                         Loss D: -148.3254, loss G: 25.5566\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [191/200] Batch 11/12                         Loss D: -147.5802, loss G: 25.6576\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [192/200] Batch 11/12                         Loss D: -150.8945, loss G: 25.6762\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [193/200] Batch 11/12                         Loss D: -150.8981, loss G: 25.7042\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [194/200] Batch 11/12                         Loss D: -151.0095, loss G: 25.8771\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [195/200] Batch 11/12                         Loss D: -150.9930, loss G: 25.9360\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [196/200] Batch 11/12                         Loss D: -151.9762, loss G: 25.9486\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [197/200] Batch 11/12                         Loss D: -154.8577, loss G: 25.9889\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [198/200] Batch 11/12                         Loss D: -155.8246, loss G: 26.0495\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=1]                         Epoch [199/200] Batch 11/12                         Loss D: -157.8258, loss G: 26.2201\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [0/200] Batch 11/12                         Loss D: 0.2025, loss G: 17.6048\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [1/200] Batch 11/12                         Loss D: 0.1950, loss G: 17.5529\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [2/200] Batch 11/12                         Loss D: 0.1835, loss G: 17.4919\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [3/200] Batch 11/12                         Loss D: 0.1672, loss G: 17.4042\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [4/200] Batch 11/12                         Loss D: 0.1476, loss G: 17.3073\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [5/200] Batch 11/12                         Loss D: 0.1216, loss G: 17.1987\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [6/200] Batch 11/12                         Loss D: 0.0906, loss G: 17.0962\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [7/200] Batch 11/12                         Loss D: 0.0530, loss G: 16.9796\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [8/200] Batch 11/12                         Loss D: 0.0044, loss G: 16.8559\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [9/200] Batch 11/12                         Loss D: -0.0587, loss G: 16.7056\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [10/200] Batch 11/12                         Loss D: -0.1316, loss G: 16.5520\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [11/200] Batch 11/12                         Loss D: -0.2212, loss G: 16.3728\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [12/200] Batch 11/12                         Loss D: -0.3251, loss G: 16.1780\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [13/200] Batch 11/12                         Loss D: -0.4469, loss G: 15.9710\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [14/200] Batch 11/12                         Loss D: -0.5895, loss G: 15.7571\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [15/200] Batch 11/12                         Loss D: -0.7584, loss G: 15.5251\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [16/200] Batch 11/12                         Loss D: -0.9537, loss G: 15.3270\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [17/200] Batch 11/12                         Loss D: -1.1147, loss G: 15.1939\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [18/200] Batch 11/12                         Loss D: -1.3242, loss G: 15.0262\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [19/200] Batch 11/12                         Loss D: -1.4897, loss G: 14.8889\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [20/200] Batch 11/12                         Loss D: -1.7143, loss G: 14.6885\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [21/200] Batch 11/12                         Loss D: -1.9268, loss G: 14.5032\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [22/200] Batch 11/12                         Loss D: -2.1548, loss G: 14.3395\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [23/200] Batch 11/12                         Loss D: -2.4734, loss G: 14.0820\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [24/200] Batch 11/12                         Loss D: -2.7393, loss G: 13.8865\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [25/200] Batch 11/12                         Loss D: -3.0636, loss G: 13.6938\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [26/200] Batch 11/12                         Loss D: -3.4512, loss G: 13.4245\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [27/200] Batch 11/12                         Loss D: -3.8565, loss G: 13.1833\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [28/200] Batch 11/12                         Loss D: -4.3451, loss G: 12.9081\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [29/200] Batch 11/12                         Loss D: -4.8777, loss G: 12.6120\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [30/200] Batch 11/12                         Loss D: -5.4819, loss G: 12.3032\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [31/200] Batch 11/12                         Loss D: -6.1380, loss G: 12.0213\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [32/200] Batch 11/12                         Loss D: -6.9851, loss G: 11.6454\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [33/200] Batch 11/12                         Loss D: -7.8318, loss G: 11.3204\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [34/200] Batch 11/12                         Loss D: -8.8183, loss G: 10.9236\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [35/200] Batch 11/12                         Loss D: -9.7997, loss G: 10.5729\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [36/200] Batch 11/12                         Loss D: -10.8886, loss G: 10.1743\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [37/200] Batch 11/12                         Loss D: -12.2429, loss G: 9.6655\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [38/200] Batch 11/12                         Loss D: -13.4615, loss G: 9.2746\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [39/200] Batch 11/12                         Loss D: -14.9182, loss G: 8.8555\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [40/200] Batch 11/12                         Loss D: -16.5182, loss G: 8.4311\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [41/200] Batch 11/12                         Loss D: -18.5253, loss G: 7.8924\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [42/200] Batch 11/12                         Loss D: -20.4557, loss G: 7.5227\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [43/200] Batch 11/12                         Loss D: -22.3015, loss G: 7.4869\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [44/200] Batch 11/12                         Loss D: -23.8488, loss G: 7.4370\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [45/200] Batch 11/12                         Loss D: -25.3975, loss G: 7.4144\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [46/200] Batch 11/12                         Loss D: -27.1901, loss G: 7.3906\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [47/200] Batch 11/12                         Loss D: -29.0025, loss G: 7.3978\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [48/200] Batch 11/12                         Loss D: -30.5711, loss G: 7.3829\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [49/200] Batch 11/12                         Loss D: -32.6585, loss G: 7.3921\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [50/200] Batch 11/12                         Loss D: -34.7107, loss G: 7.4191\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [51/200] Batch 11/12                         Loss D: -36.4694, loss G: 7.3875\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [52/200] Batch 11/12                         Loss D: -38.3098, loss G: 7.4096\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [53/200] Batch 11/12                         Loss D: -40.6913, loss G: 7.4034\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [54/200] Batch 11/12                         Loss D: -43.0220, loss G: 7.4250\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [55/200] Batch 11/12                         Loss D: -45.1895, loss G: 7.4080\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [56/200] Batch 11/12                         Loss D: -47.6624, loss G: 7.4456\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [57/200] Batch 11/12                         Loss D: -50.2151, loss G: 7.4614\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [58/200] Batch 11/12                         Loss D: -52.6225, loss G: 7.4940\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [59/200] Batch 11/12                         Loss D: -55.2284, loss G: 7.5131\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [60/200] Batch 11/12                         Loss D: -57.6899, loss G: 7.5468\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [61/200] Batch 11/12                         Loss D: -59.8220, loss G: 7.5972\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [62/200] Batch 11/12                         Loss D: -63.6236, loss G: 7.6500\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [63/200] Batch 11/12                         Loss D: -66.4009, loss G: 7.7210\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [64/200] Batch 11/12                         Loss D: -69.3764, loss G: 7.7963\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [65/200] Batch 11/12                         Loss D: -73.4358, loss G: 7.8926\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [66/200] Batch 11/12                         Loss D: -75.9810, loss G: 7.9792\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [67/200] Batch 11/12                         Loss D: -80.0607, loss G: 8.0438\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [68/200] Batch 11/12                         Loss D: -82.8522, loss G: 8.1851\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [69/200] Batch 11/12                         Loss D: -84.8756, loss G: 8.4437\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [70/200] Batch 11/12                         Loss D: -90.2763, loss G: 8.3669\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [71/200] Batch 11/12                         Loss D: -92.8087, loss G: 8.5129\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [72/200] Batch 11/12                         Loss D: -95.8816, loss G: 8.6185\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [73/200] Batch 11/12                         Loss D: -99.5442, loss G: 8.7221\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [74/200] Batch 11/12                         Loss D: -102.3618, loss G: 8.9029\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [75/200] Batch 11/12                         Loss D: -106.7537, loss G: 8.9787\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [76/200] Batch 11/12                         Loss D: -107.7941, loss G: 9.1890\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [77/200] Batch 11/12                         Loss D: -113.5947, loss G: 9.2747\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [78/200] Batch 11/12                         Loss D: -116.7393, loss G: 9.3929\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [79/200] Batch 11/12                         Loss D: -118.1383, loss G: 9.5104\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [80/200] Batch 11/12                         Loss D: -122.1196, loss G: 9.6545\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [81/200] Batch 11/12                         Loss D: -123.1049, loss G: 9.8095\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [82/200] Batch 11/12                         Loss D: -128.2403, loss G: 9.9891\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [83/200] Batch 11/12                         Loss D: -127.4929, loss G: 10.1607\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [84/200] Batch 11/12                         Loss D: -131.4229, loss G: 10.2587\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [85/200] Batch 11/12                         Loss D: -134.5712, loss G: 10.3625\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [86/200] Batch 11/12                         Loss D: -135.2630, loss G: 10.6020\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [87/200] Batch 11/12                         Loss D: -138.3005, loss G: 10.6579\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [88/200] Batch 11/12                         Loss D: -141.1052, loss G: 10.7908\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [89/200] Batch 11/12                         Loss D: -142.4521, loss G: 10.9312\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [90/200] Batch 11/12                         Loss D: -143.5745, loss G: 11.0937\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [91/200] Batch 11/12                         Loss D: -146.4786, loss G: 11.2236\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [92/200] Batch 11/12                         Loss D: -148.1279, loss G: 11.3839\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [93/200] Batch 11/12                         Loss D: -149.2233, loss G: 11.5073\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [94/200] Batch 11/12                         Loss D: -151.7496, loss G: 11.7240\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [95/200] Batch 11/12                         Loss D: -150.4556, loss G: 11.7850\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [96/200] Batch 11/12                         Loss D: -149.8660, loss G: 11.9164\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [97/200] Batch 11/12                         Loss D: -153.0036, loss G: 12.0064\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [98/200] Batch 11/12                         Loss D: -153.4857, loss G: 12.1430\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [99/200] Batch 11/12                         Loss D: -151.2256, loss G: 12.2592\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [100/200] Batch 11/12                         Loss D: -154.5176, loss G: 12.3986\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [101/200] Batch 11/12                         Loss D: -154.4448, loss G: 12.4788\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [102/200] Batch 11/12                         Loss D: -152.7001, loss G: 12.5541\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [103/200] Batch 11/12                         Loss D: -153.8133, loss G: 12.6997\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [104/200] Batch 11/12                         Loss D: -153.2138, loss G: 12.7636\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [105/200] Batch 11/12                         Loss D: -150.5314, loss G: 12.8441\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [106/200] Batch 11/12                         Loss D: -151.1320, loss G: 12.9074\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [107/200] Batch 11/12                         Loss D: -150.6745, loss G: 13.0140\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [108/200] Batch 11/12                         Loss D: -149.6474, loss G: 13.0908\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [109/200] Batch 11/12                         Loss D: -147.1639, loss G: 13.1411\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [110/200] Batch 11/12                         Loss D: -144.9888, loss G: 13.2255\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [111/200] Batch 11/12                         Loss D: -144.4088, loss G: 13.2216\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [112/200] Batch 11/12                         Loss D: -145.0564, loss G: 13.3539\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [113/200] Batch 11/12                         Loss D: -141.0760, loss G: 13.3390\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [114/200] Batch 11/12                         Loss D: -139.2930, loss G: 13.3776\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [115/200] Batch 11/12                         Loss D: -138.6436, loss G: 13.4237\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [116/200] Batch 11/12                         Loss D: -136.6821, loss G: 13.4663\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [117/200] Batch 11/12                         Loss D: -134.3005, loss G: 13.4657\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [118/200] Batch 11/12                         Loss D: -131.4043, loss G: 13.4590\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [119/200] Batch 11/12                         Loss D: -128.9292, loss G: 13.5279\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [120/200] Batch 11/12                         Loss D: -127.4751, loss G: 13.5113\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [121/200] Batch 11/12                         Loss D: -125.3989, loss G: 13.5160\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [122/200] Batch 11/12                         Loss D: -121.5055, loss G: 13.5254\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [123/200] Batch 11/12                         Loss D: -121.4464, loss G: 13.5955\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [124/200] Batch 11/12                         Loss D: -118.3261, loss G: 13.5271\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [125/200] Batch 11/12                         Loss D: -115.0818, loss G: 13.4947\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [126/200] Batch 11/12                         Loss D: -111.9857, loss G: 13.5217\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [127/200] Batch 11/12                         Loss D: -109.9139, loss G: 13.4788\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [128/200] Batch 11/12                         Loss D: -107.9440, loss G: 13.4816\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [129/200] Batch 11/12                         Loss D: -104.7813, loss G: 13.4301\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [130/200] Batch 11/12                         Loss D: -102.1528, loss G: 13.4455\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [131/200] Batch 11/12                         Loss D: -97.9034, loss G: 13.3197\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [132/200] Batch 11/12                         Loss D: -93.5607, loss G: 13.2968\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [133/200] Batch 11/12                         Loss D: -90.8452, loss G: 13.2074\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [134/200] Batch 11/12                         Loss D: -87.2300, loss G: 13.1851\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [135/200] Batch 11/12                         Loss D: -84.9831, loss G: 13.1179\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [136/200] Batch 11/12                         Loss D: -80.8838, loss G: 13.0615\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [137/200] Batch 11/12                         Loss D: -77.8362, loss G: 12.9995\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [138/200] Batch 11/12                         Loss D: -74.3772, loss G: 12.9726\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [139/200] Batch 11/12                         Loss D: -71.7221, loss G: 12.8762\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [140/200] Batch 11/12                         Loss D: -68.6058, loss G: 12.8366\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [141/200] Batch 11/12                         Loss D: -65.3224, loss G: 12.7991\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [142/200] Batch 11/12                         Loss D: -61.1157, loss G: 12.7226\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [143/200] Batch 11/12                         Loss D: -58.4481, loss G: 12.6544\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [144/200] Batch 11/12                         Loss D: -54.9398, loss G: 12.5683\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [145/200] Batch 11/12                         Loss D: -52.0327, loss G: 12.5140\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [146/200] Batch 11/12                         Loss D: -49.1436, loss G: 12.4667\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [147/200] Batch 11/12                         Loss D: -47.7319, loss G: 12.4536\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [148/200] Batch 11/12                         Loss D: -46.2709, loss G: 12.4358\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [149/200] Batch 11/12                         Loss D: -45.3403, loss G: 12.4771\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [150/200] Batch 11/12                         Loss D: -43.2706, loss G: 12.4290\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [151/200] Batch 11/12                         Loss D: -41.8675, loss G: 12.4387\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [152/200] Batch 11/12                         Loss D: -41.2434, loss G: 12.4434\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [153/200] Batch 11/12                         Loss D: -39.8293, loss G: 12.3969\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [154/200] Batch 11/12                         Loss D: -39.1029, loss G: 12.4150\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [155/200] Batch 11/12                         Loss D: -37.9708, loss G: 12.4959\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [156/200] Batch 11/12                         Loss D: -37.8954, loss G: 12.4567\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [157/200] Batch 11/12                         Loss D: -37.4709, loss G: 12.4943\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [158/200] Batch 11/12                         Loss D: -37.6598, loss G: 12.5316\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [159/200] Batch 11/12                         Loss D: -37.8994, loss G: 12.5978\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [160/200] Batch 11/12                         Loss D: -37.1496, loss G: 12.5990\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [161/200] Batch 11/12                         Loss D: -37.4801, loss G: 12.6197\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [162/200] Batch 11/12                         Loss D: -38.1252, loss G: 12.6388\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [163/200] Batch 11/12                         Loss D: -38.2602, loss G: 12.6870\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [164/200] Batch 11/12                         Loss D: -39.2529, loss G: 12.7032\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [165/200] Batch 11/12                         Loss D: -40.1190, loss G: 12.7333\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [166/200] Batch 11/12                         Loss D: -40.5137, loss G: 12.7958\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [167/200] Batch 11/12                         Loss D: -41.7063, loss G: 12.8080\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [168/200] Batch 11/12                         Loss D: -42.3940, loss G: 12.8392\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [169/200] Batch 11/12                         Loss D: -43.4707, loss G: 12.9100\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [170/200] Batch 11/12                         Loss D: -43.7790, loss G: 12.9232\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [171/200] Batch 11/12                         Loss D: -44.5492, loss G: 12.9559\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [172/200] Batch 11/12                         Loss D: -45.5499, loss G: 12.9822\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [173/200] Batch 11/12                         Loss D: -46.2053, loss G: 13.0251\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [174/200] Batch 11/12                         Loss D: -46.9310, loss G: 13.0607\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [175/200] Batch 11/12                         Loss D: -47.3790, loss G: 13.1268\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [176/200] Batch 11/12                         Loss D: -48.6751, loss G: 13.1403\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [177/200] Batch 11/12                         Loss D: -49.3437, loss G: 13.1652\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [178/200] Batch 11/12                         Loss D: -49.5147, loss G: 13.2433\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [179/200] Batch 11/12                         Loss D: -51.0280, loss G: 13.2533\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [180/200] Batch 11/12                         Loss D: -51.5499, loss G: 13.2826\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [181/200] Batch 11/12                         Loss D: -51.9629, loss G: 13.3437\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [182/200] Batch 11/12                         Loss D: -53.6359, loss G: 13.4142\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [183/200] Batch 11/12                         Loss D: -53.1578, loss G: 13.4476\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [184/200] Batch 11/12                         Loss D: -54.1685, loss G: 13.4589\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [185/200] Batch 11/12                         Loss D: -55.1502, loss G: 13.4878\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [186/200] Batch 11/12                         Loss D: -55.9916, loss G: 13.5277\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [187/200] Batch 11/12                         Loss D: -56.6114, loss G: 13.5752\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [188/200] Batch 11/12                         Loss D: -57.2694, loss G: 13.6198\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [189/200] Batch 11/12                         Loss D: -58.5971, loss G: 13.6475\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [190/200] Batch 11/12                         Loss D: -59.0364, loss G: 13.6859\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [191/200] Batch 11/12                         Loss D: -59.3733, loss G: 13.7512\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [192/200] Batch 11/12                         Loss D: -60.0728, loss G: 13.7930\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [193/200] Batch 11/12                         Loss D: -61.9178, loss G: 13.8483\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [194/200] Batch 11/12                         Loss D: -61.6705, loss G: 13.8747\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [195/200] Batch 11/12                         Loss D: -62.6437, loss G: 13.9089\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [196/200] Batch 11/12                         Loss D: -63.4934, loss G: 13.9409\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [197/200] Batch 11/12                         Loss D: -64.2101, loss G: 13.9879\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [198/200] Batch 11/12                         Loss D: -65.6562, loss G: 14.0415\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.5]                         Epoch [199/200] Batch 11/12                         Loss D: -65.7952, loss G: 14.0703\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [0/200] Batch 11/12                         Loss D: 0.4934, loss G: 3.5860\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [1/200] Batch 11/12                         Loss D: 0.5489, loss G: 3.5712\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [2/200] Batch 11/12                         Loss D: 0.6039, loss G: 3.5531\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [3/200] Batch 11/12                         Loss D: 0.7147, loss G: 3.5339\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [4/200] Batch 11/12                         Loss D: 0.7229, loss G: 3.5187\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [5/200] Batch 11/12                         Loss D: 0.6831, loss G: 3.5038\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [6/200] Batch 11/12                         Loss D: 0.6193, loss G: 3.4891\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [7/200] Batch 11/12                         Loss D: 0.5268, loss G: 3.4711\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [8/200] Batch 11/12                         Loss D: 0.3847, loss G: 3.4495\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [9/200] Batch 11/12                         Loss D: 0.2057, loss G: 3.4245\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [10/200] Batch 11/12                         Loss D: -0.0484, loss G: 3.3977\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [11/200] Batch 11/12                         Loss D: -0.3392, loss G: 3.3734\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [12/200] Batch 11/12                         Loss D: -0.6476, loss G: 3.3548\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [13/200] Batch 11/12                         Loss D: -0.9125, loss G: 3.3441\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [14/200] Batch 11/12                         Loss D: -1.1522, loss G: 3.3359\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [15/200] Batch 11/12                         Loss D: -1.3230, loss G: 3.3290\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [16/200] Batch 11/12                         Loss D: -1.5383, loss G: 3.3192\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [17/200] Batch 11/12                         Loss D: -1.7166, loss G: 3.3096\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [18/200] Batch 11/12                         Loss D: -1.9366, loss G: 3.2961\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [19/200] Batch 11/12                         Loss D: -2.1253, loss G: 3.2831\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [20/200] Batch 11/12                         Loss D: -2.2990, loss G: 3.2684\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [21/200] Batch 11/12                         Loss D: -2.4983, loss G: 3.2545\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [22/200] Batch 11/12                         Loss D: -2.4800, loss G: 3.2499\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [23/200] Batch 11/12                         Loss D: -2.5018, loss G: 3.2480\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [24/200] Batch 11/12                         Loss D: -2.4715, loss G: 3.2495\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [25/200] Batch 11/12                         Loss D: -2.5656, loss G: 3.2452\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [26/200] Batch 11/12                         Loss D: -2.6203, loss G: 3.2457\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [27/200] Batch 11/12                         Loss D: -2.6558, loss G: 3.2473\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [28/200] Batch 11/12                         Loss D: -2.7534, loss G: 3.2487\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [29/200] Batch 11/12                         Loss D: -2.8472, loss G: 3.2510\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [30/200] Batch 11/12                         Loss D: -2.8858, loss G: 3.2526\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [31/200] Batch 11/12                         Loss D: -2.9147, loss G: 3.2555\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [32/200] Batch 11/12                         Loss D: -2.9105, loss G: 3.2505\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [33/200] Batch 11/12                         Loss D: -2.8610, loss G: 3.2440\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [34/200] Batch 11/12                         Loss D: -2.7580, loss G: 3.2371\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [35/200] Batch 11/12                         Loss D: -2.6630, loss G: 3.2303\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [36/200] Batch 11/12                         Loss D: -2.6495, loss G: 3.2178\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [37/200] Batch 11/12                         Loss D: -2.6096, loss G: 3.2070\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [38/200] Batch 11/12                         Loss D: -2.5670, loss G: 3.1984\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [39/200] Batch 11/12                         Loss D: -2.4889, loss G: 3.1850\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [40/200] Batch 11/12                         Loss D: -2.5084, loss G: 3.1762\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [41/200] Batch 11/12                         Loss D: -2.5675, loss G: 3.1631\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [42/200] Batch 11/12                         Loss D: -2.6245, loss G: 3.1483\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [43/200] Batch 11/12                         Loss D: -2.7018, loss G: 3.1359\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [44/200] Batch 11/12                         Loss D: -2.7822, loss G: 3.1227\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [45/200] Batch 11/12                         Loss D: -2.8717, loss G: 3.1057\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [46/200] Batch 11/12                         Loss D: -2.9810, loss G: 3.0892\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [47/200] Batch 11/12                         Loss D: -3.1039, loss G: 3.0752\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [48/200] Batch 11/12                         Loss D: -3.2554, loss G: 3.0585\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [49/200] Batch 11/12                         Loss D: -3.4141, loss G: 3.0396\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [50/200] Batch 11/12                         Loss D: -3.5839, loss G: 3.0244\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [51/200] Batch 11/12                         Loss D: -3.7896, loss G: 3.0012\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [52/200] Batch 11/12                         Loss D: -4.0409, loss G: 2.9796\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [53/200] Batch 11/12                         Loss D: -4.4544, loss G: 2.9559\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [54/200] Batch 11/12                         Loss D: -5.1442, loss G: 2.9200\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [55/200] Batch 11/12                         Loss D: -5.7073, loss G: 2.8894\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [56/200] Batch 11/12                         Loss D: -6.1951, loss G: 2.8681\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [57/200] Batch 11/12                         Loss D: -6.6410, loss G: 2.8572\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [58/200] Batch 11/12                         Loss D: -7.0930, loss G: 2.8460\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [59/200] Batch 11/12                         Loss D: -7.6137, loss G: 2.8373\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [60/200] Batch 11/12                         Loss D: -8.0958, loss G: 2.8232\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [61/200] Batch 11/12                         Loss D: -8.5364, loss G: 2.8193\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [62/200] Batch 11/12                         Loss D: -9.2206, loss G: 2.8075\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [63/200] Batch 11/12                         Loss D: -9.7102, loss G: 2.8095\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [64/200] Batch 11/12                         Loss D: -9.6579, loss G: 2.8134\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [65/200] Batch 11/12                         Loss D: -9.6896, loss G: 2.8218\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [66/200] Batch 11/12                         Loss D: -9.8239, loss G: 2.8235\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [67/200] Batch 11/12                         Loss D: -9.8430, loss G: 2.8275\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [68/200] Batch 11/12                         Loss D: -9.7507, loss G: 2.8354\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [69/200] Batch 11/12                         Loss D: -9.7246, loss G: 2.8349\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [70/200] Batch 11/12                         Loss D: -9.4387, loss G: 2.8429\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [71/200] Batch 11/12                         Loss D: -9.3523, loss G: 2.8435\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [72/200] Batch 11/12                         Loss D: -9.2580, loss G: 2.8476\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [73/200] Batch 11/12                         Loss D: -9.0150, loss G: 2.8509\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [74/200] Batch 11/12                         Loss D: -8.8530, loss G: 2.8545\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [75/200] Batch 11/12                         Loss D: -8.6201, loss G: 2.8600\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [76/200] Batch 11/12                         Loss D: -8.6838, loss G: 2.8726\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [77/200] Batch 11/12                         Loss D: -9.0417, loss G: 2.8783\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [78/200] Batch 11/12                         Loss D: -9.2397, loss G: 2.8894\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [79/200] Batch 11/12                         Loss D: -9.4820, loss G: 2.9004\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [80/200] Batch 11/12                         Loss D: -9.8963, loss G: 2.9051\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [81/200] Batch 11/12                         Loss D: -10.2443, loss G: 2.9166\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [82/200] Batch 11/12                         Loss D: -10.7549, loss G: 2.9287\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [83/200] Batch 11/12                         Loss D: -11.2704, loss G: 2.9396\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [84/200] Batch 11/12                         Loss D: -11.7501, loss G: 2.9504\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [85/200] Batch 11/12                         Loss D: -12.1367, loss G: 2.9619\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [86/200] Batch 11/12                         Loss D: -12.5644, loss G: 2.9716\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [87/200] Batch 11/12                         Loss D: -13.0987, loss G: 2.9773\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [88/200] Batch 11/12                         Loss D: -13.5766, loss G: 2.9856\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [89/200] Batch 11/12                         Loss D: -14.0931, loss G: 2.9918\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [90/200] Batch 11/12                         Loss D: -14.5977, loss G: 3.0027\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [91/200] Batch 11/12                         Loss D: -14.7838, loss G: 3.0104\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [92/200] Batch 11/12                         Loss D: -15.4656, loss G: 3.0136\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [93/200] Batch 11/12                         Loss D: -15.7854, loss G: 3.0229\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [94/200] Batch 11/12                         Loss D: -16.2505, loss G: 3.0296\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [95/200] Batch 11/12                         Loss D: -16.7575, loss G: 3.0361\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [96/200] Batch 11/12                         Loss D: -17.2440, loss G: 3.0420\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [97/200] Batch 11/12                         Loss D: -17.6518, loss G: 3.0492\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [98/200] Batch 11/12                         Loss D: -17.9994, loss G: 3.0574\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [99/200] Batch 11/12                         Loss D: -18.7196, loss G: 3.0678\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [100/200] Batch 11/12                         Loss D: -19.0548, loss G: 3.0682\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [101/200] Batch 11/12                         Loss D: -19.3151, loss G: 3.0776\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [102/200] Batch 11/12                         Loss D: -20.0140, loss G: 3.0811\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [103/200] Batch 11/12                         Loss D: -20.5319, loss G: 3.0887\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [104/200] Batch 11/12                         Loss D: -20.7930, loss G: 3.0954\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [105/200] Batch 11/12                         Loss D: -21.2828, loss G: 3.1020\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [106/200] Batch 11/12                         Loss D: -21.9030, loss G: 3.1063\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [107/200] Batch 11/12                         Loss D: -22.1758, loss G: 3.1148\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [108/200] Batch 11/12                         Loss D: -22.8851, loss G: 3.1189\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [109/200] Batch 11/12                         Loss D: -23.2626, loss G: 3.1259\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [110/200] Batch 11/12                         Loss D: -23.9259, loss G: 3.1308\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [111/200] Batch 11/12                         Loss D: -24.0453, loss G: 3.1408\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [112/200] Batch 11/12                         Loss D: -24.6451, loss G: 3.1470\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [113/200] Batch 11/12                         Loss D: -25.2557, loss G: 3.1526\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [114/200] Batch 11/12                         Loss D: -25.6178, loss G: 3.1600\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [115/200] Batch 11/12                         Loss D: -26.2335, loss G: 3.1657\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [116/200] Batch 11/12                         Loss D: -26.7765, loss G: 3.1720\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [117/200] Batch 11/12                         Loss D: -27.3411, loss G: 3.1780\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [118/200] Batch 11/12                         Loss D: -27.6856, loss G: 3.1855\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [119/200] Batch 11/12                         Loss D: -28.0275, loss G: 3.1929\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [120/200] Batch 11/12                         Loss D: -28.7111, loss G: 3.1983\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [121/200] Batch 11/12                         Loss D: -29.1754, loss G: 3.2052\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [122/200] Batch 11/12                         Loss D: -29.6632, loss G: 3.2121\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [123/200] Batch 11/12                         Loss D: -30.0754, loss G: 3.2190\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [124/200] Batch 11/12                         Loss D: -30.8722, loss G: 3.2244\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [125/200] Batch 11/12                         Loss D: -31.4447, loss G: 3.2307\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [126/200] Batch 11/12                         Loss D: -31.9721, loss G: 3.2376\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [127/200] Batch 11/12                         Loss D: -32.5699, loss G: 3.2441\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [128/200] Batch 11/12                         Loss D: -32.8722, loss G: 3.2521\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [129/200] Batch 11/12                         Loss D: -33.6552, loss G: 3.2576\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [130/200] Batch 11/12                         Loss D: -34.3627, loss G: 3.2640\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [131/200] Batch 11/12                         Loss D: -34.5117, loss G: 3.2722\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [132/200] Batch 11/12                         Loss D: -35.0537, loss G: 3.2788\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [133/200] Batch 11/12                         Loss D: -35.7362, loss G: 3.2854\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [134/200] Batch 11/12                         Loss D: -36.2787, loss G: 3.2922\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [135/200] Batch 11/12                         Loss D: -37.0520, loss G: 3.2987\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [136/200] Batch 11/12                         Loss D: -37.3551, loss G: 3.3064\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [137/200] Batch 11/12                         Loss D: -37.9264, loss G: 3.3135\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [138/200] Batch 11/12                         Loss D: -38.5894, loss G: 3.3202\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [139/200] Batch 11/12                         Loss D: -39.3255, loss G: 3.3271\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [140/200] Batch 11/12                         Loss D: -39.5421, loss G: 3.3346\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [141/200] Batch 11/12                         Loss D: -40.0453, loss G: 3.3421\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [142/200] Batch 11/12                         Loss D: -40.8237, loss G: 3.3490\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [143/200] Batch 11/12                         Loss D: -41.3110, loss G: 3.3563\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [144/200] Batch 11/12                         Loss D: -41.8161, loss G: 3.3637\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [145/200] Batch 11/12                         Loss D: -42.1994, loss G: 3.3706\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [146/200] Batch 11/12                         Loss D: -42.9129, loss G: 3.3777\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [147/200] Batch 11/12                         Loss D: -43.5041, loss G: 3.3849\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [148/200] Batch 11/12                         Loss D: -44.3756, loss G: 3.3919\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [149/200] Batch 11/12                         Loss D: -44.6626, loss G: 3.3989\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [150/200] Batch 11/12                         Loss D: -45.4538, loss G: 3.4066\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [151/200] Batch 11/12                         Loss D: -45.8346, loss G: 3.4136\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [152/200] Batch 11/12                         Loss D: -46.9738, loss G: 3.4214\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [153/200] Batch 11/12                         Loss D: -46.9812, loss G: 3.4287\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [154/200] Batch 11/12                         Loss D: -47.5802, loss G: 3.4360\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [155/200] Batch 11/12                         Loss D: -48.2667, loss G: 3.4430\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [156/200] Batch 11/12                         Loss D: -49.0698, loss G: 3.4511\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [157/200] Batch 11/12                         Loss D: -49.1963, loss G: 3.4582\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [158/200] Batch 11/12                         Loss D: -49.7164, loss G: 3.4667\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [159/200] Batch 11/12                         Loss D: -50.3973, loss G: 3.4732\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [160/200] Batch 11/12                         Loss D: -50.9011, loss G: 3.4807\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [161/200] Batch 11/12                         Loss D: -51.1679, loss G: 3.4883\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [162/200] Batch 11/12                         Loss D: -51.5769, loss G: 3.4959\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [163/200] Batch 11/12                         Loss D: -52.5636, loss G: 3.5037\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [164/200] Batch 11/12                         Loss D: -52.6532, loss G: 3.5108\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [165/200] Batch 11/12                         Loss D: -53.2438, loss G: 3.5186\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [166/200] Batch 11/12                         Loss D: -53.4585, loss G: 3.5260\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [167/200] Batch 11/12                         Loss D: -53.8469, loss G: 3.5333\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [168/200] Batch 11/12                         Loss D: -53.6899, loss G: 3.5393\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [169/200] Batch 11/12                         Loss D: -54.3187, loss G: 3.5476\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [170/200] Batch 11/12                         Loss D: -54.1025, loss G: 3.5535\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [171/200] Batch 11/12                         Loss D: -54.9573, loss G: 3.5625\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [172/200] Batch 11/12                         Loss D: -55.1103, loss G: 3.5692\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [173/200] Batch 11/12                         Loss D: -55.1747, loss G: 3.5758\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [174/200] Batch 11/12                         Loss D: -55.3239, loss G: 3.5828\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [175/200] Batch 11/12                         Loss D: -55.4751, loss G: 3.5894\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [176/200] Batch 11/12                         Loss D: -55.5062, loss G: 3.5959\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [177/200] Batch 11/12                         Loss D: -56.1808, loss G: 3.6039\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [178/200] Batch 11/12                         Loss D: -55.6109, loss G: 3.6087\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [179/200] Batch 11/12                         Loss D: -55.8645, loss G: 3.6153\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [180/200] Batch 11/12                         Loss D: -55.8864, loss G: 3.6214\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [181/200] Batch 11/12                         Loss D: -56.1004, loss G: 3.6279\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [182/200] Batch 11/12                         Loss D: -55.7501, loss G: 3.6331\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [183/200] Batch 11/12                         Loss D: -55.8649, loss G: 3.6392\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [184/200] Batch 11/12                         Loss D: -55.6335, loss G: 3.6438\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [185/200] Batch 11/12                         Loss D: -56.0376, loss G: 3.6515\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [186/200] Batch 11/12                         Loss D: -55.5453, loss G: 3.6547\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [187/200] Batch 11/12                         Loss D: -55.3179, loss G: 3.6595\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [188/200] Batch 11/12                         Loss D: -55.2296, loss G: 3.6649\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [189/200] Batch 11/12                         Loss D: -54.7922, loss G: 3.6676\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [190/200] Batch 11/12                         Loss D: -54.7408, loss G: 3.6726\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [191/200] Batch 11/12                         Loss D: -54.6554, loss G: 3.6773\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [192/200] Batch 11/12                         Loss D: -54.1919, loss G: 3.6798\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [193/200] Batch 11/12                         Loss D: -53.9920, loss G: 3.6839\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [194/200] Batch 11/12                         Loss D: -53.3432, loss G: 3.6857\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [195/200] Batch 11/12                         Loss D: -53.2468, loss G: 3.6895\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [196/200] Batch 11/12                         Loss D: -52.6029, loss G: 3.6910\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [197/200] Batch 11/12                         Loss D: -52.7772, loss G: 3.6958\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [198/200] Batch 11/12                         Loss D: -52.3467, loss G: 3.6968\n",
      "[lr_G=5e-05, lr_D=5e-05, lambda_GP=0.1, lambda_mean=0.1]                         Epoch [199/200] Batch 11/12                         Loss D: -47.4803, loss G: 3.2773\n",
      "Best parameters: lr_G=5e-05, lr_D=5e-05, lambda_GP=10, lambda_mean=1\n"
     ]
    }
   ],
   "source": [
    "# Define the set of hyperparameters to tune\n",
    "lr_G_values = [0.0002, 0.0001, 0.00005]\n",
    "lr_D_values = [0.0002, 0.0001, 0.00005]\n",
    "lambda_GP_values = [10, 1, 0.1]\n",
    "lambda_mean_values = [1, 0.5, 0.1]\n",
    "\n",
    "# Keep track of the best parameters and their corresponding loss\n",
    "best_params = None\n",
    "best_loss = float('inf')\n",
    "\n",
    "# Perform grid search\n",
    "for lr_G in lr_G_values:\n",
    "    for lr_D in lr_D_values:\n",
    "        for lambda_GP in lambda_GP_values:\n",
    "            for lambda_mean in lambda_mean_values:\n",
    "                # Initialize generator and discriminator\n",
    "                generator = Generator(input_dim=Z_DIM, output_dim=PARAMETERS).to(DEVICE)\n",
    "                discriminator = Discriminator(input_dim=PARAMETERS).to(DEVICE)\n",
    "\n",
    "                # Initialize optimizers with current learning rates\n",
    "                optimizer_G = torch.optim.Adam(generator.parameters(), lr=lr_G, betas=(0.5, 0.999))\n",
    "                optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=lr_D, betas=(0.5, 0.999))\n",
    "\n",
    "                # Perform training here, using lambda_GP and lambda_mean as your gradient penalty and mean penalty\n",
    "                # ...\n",
    "                for epoch in range(NUM_EPOCHS):\n",
    "                    for batch_idx, data in enumerate(dataloader, 0):\n",
    "                        real_data = torch.tensor(df.iloc[:, -3:].values, dtype=torch.float).to(DEVICE)\n",
    "                        batch_size = real_data.shape[0]\n",
    "\n",
    "                        optimizer_D.zero_grad()\n",
    "\n",
    "                        noise = torch.randn(batch_size, Z_DIM).to(DEVICE)\n",
    "                        fake = generator(noise).detach().cpu()\n",
    "                        fake = ss.inverse_transform(fake)\n",
    "                        fake_data = torch.tensor(fake, dtype=torch.float).to(DEVICE)\n",
    "\n",
    "                        real_validity = discriminator(real_data)\n",
    "                        fake_validity = discriminator(fake_data)\n",
    "\n",
    "                        gradient_penalty = compute_gradient_penalty(discriminator, real_data.data, fake_data.data).to(DEVICE)\n",
    "\n",
    "                        d_loss = -torch.mean(real_validity) + torch.mean(fake_validity) + lambda_GP * gradient_penalty\n",
    "\n",
    "                        d_loss.backward()\n",
    "                        optimizer_D.step()\n",
    "\n",
    "                        optimizer_G.zero_grad()\n",
    "\n",
    "                        if batch_idx % CRITIC_ITERATIONS == 0:\n",
    "                            fake_data = generator(noise)\n",
    "                            fake_validity = discriminator(fake_data)\n",
    "\n",
    "                            mean_real_data = torch.mean(real_data, dim=0)\n",
    "                            mean_fake_data = torch.mean(fake_data, dim=0)\n",
    "\n",
    "                            mean_diff = torch.abs(mean_real_data - mean_fake_data)\n",
    "\n",
    "                            penalty = torch.mean(mean_diff)\n",
    "\n",
    "                            g_loss = -torch.mean(fake_validity) + lambda_mean * penalty\n",
    "\n",
    "                            g_loss.backward()\n",
    "                            optimizer_G.step()\n",
    "                    print(\n",
    "                        f\"[lr_G={lr_G}, lr_D={lr_D}, lambda_GP={lambda_GP}, lambda_mean={lambda_mean}] \\\n",
    "                        Epoch [{epoch}/{NUM_EPOCHS}] Batch {batch_idx}/{len(dataloader)} \\\n",
    "                        Loss D: {d_loss:.4f}, loss G: {g_loss:.4f}\"\n",
    "                    )\n",
    "                # Compute the validation loss or another metric to compare the models\n",
    "                # This is a simplification; in practice you should use a separate validation set or some other method\n",
    "                # to objectively compare the models\n",
    "                val_loss = d_loss.item() + g_loss.item()\n",
    "\n",
    "                # Update best parameters if current model is better\n",
    "                if val_loss < best_loss:\n",
    "                    best_params = (lr_G, lr_D, lambda_GP, lambda_mean)\n",
    "                    best_loss = val_loss\n",
    "\n",
    "# Print best parameters\n",
    "print(f\"Best parameters: lr_G={best_params[0]}, lr_D={best_params[1]}, lambda_GP={best_params[2]}, lambda_mean={best_params[3]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0/200] Batch 11/12                 Loss D: 8.6695, loss G: 34.3593\n",
      "Epoch [1/200] Batch 11/12                 Loss D: 8.8512, loss G: 34.2169\n",
      "Epoch [2/200] Batch 11/12                 Loss D: 9.0549, loss G: 34.0531\n",
      "Epoch [3/200] Batch 11/12                 Loss D: 9.2820, loss G: 33.8824\n",
      "Epoch [4/200] Batch 11/12                 Loss D: 9.5410, loss G: 33.6938\n",
      "Epoch [5/200] Batch 11/12                 Loss D: 9.8350, loss G: 33.4831\n",
      "Epoch [6/200] Batch 11/12                 Loss D: 10.1819, loss G: 33.2383\n",
      "Epoch [7/200] Batch 11/12                 Loss D: 10.5819, loss G: 32.9579\n",
      "Epoch [8/200] Batch 11/12                 Loss D: 10.9983, loss G: 32.6618\n",
      "Epoch [9/200] Batch 11/12                 Loss D: 11.4758, loss G: 32.3298\n",
      "Epoch [10/200] Batch 11/12                 Loss D: 12.0275, loss G: 31.9108\n",
      "Epoch [11/200] Batch 11/12                 Loss D: 12.5006, loss G: 31.5339\n",
      "Epoch [12/200] Batch 11/12                 Loss D: 13.1221, loss G: 31.0323\n",
      "Epoch [13/200] Batch 11/12                 Loss D: 13.6831, loss G: 30.5555\n",
      "Epoch [14/200] Batch 11/12                 Loss D: 14.2634, loss G: 30.0350\n",
      "Epoch [15/200] Batch 11/12                 Loss D: 14.8996, loss G: 29.4524\n",
      "Epoch [16/200] Batch 11/12                 Loss D: 15.3904, loss G: 28.9994\n",
      "Epoch [17/200] Batch 11/12                 Loss D: 15.7950, loss G: 28.6421\n",
      "Epoch [18/200] Batch 11/12                 Loss D: 16.1685, loss G: 28.2562\n",
      "Epoch [19/200] Batch 11/12                 Loss D: 16.5064, loss G: 27.8868\n",
      "Epoch [20/200] Batch 11/12                 Loss D: 16.8641, loss G: 27.4765\n",
      "Epoch [21/200] Batch 11/12                 Loss D: 17.2853, loss G: 27.0202\n",
      "Epoch [22/200] Batch 11/12                 Loss D: 17.6309, loss G: 26.5915\n",
      "Epoch [23/200] Batch 11/12                 Loss D: 17.9880, loss G: 26.1444\n",
      "Epoch [24/200] Batch 11/12                 Loss D: 18.4913, loss G: 25.5630\n",
      "Epoch [25/200] Batch 11/12                 Loss D: 18.8520, loss G: 25.0579\n",
      "Epoch [26/200] Batch 11/12                 Loss D: 19.3011, loss G: 24.4966\n",
      "Epoch [27/200] Batch 11/12                 Loss D: 19.7426, loss G: 23.8571\n",
      "Epoch [28/200] Batch 11/12                 Loss D: 20.2695, loss G: 23.1304\n",
      "Epoch [29/200] Batch 11/12                 Loss D: 20.5432, loss G: 22.5868\n",
      "Epoch [30/200] Batch 11/12                 Loss D: 20.9863, loss G: 21.8644\n",
      "Epoch [31/200] Batch 11/12                 Loss D: 21.5814, loss G: 20.9869\n",
      "Epoch [32/200] Batch 11/12                 Loss D: 21.8827, loss G: 20.2679\n",
      "Epoch [33/200] Batch 11/12                 Loss D: 22.3447, loss G: 19.3657\n",
      "Epoch [34/200] Batch 11/12                 Loss D: 22.6715, loss G: 18.5639\n",
      "Epoch [35/200] Batch 11/12                 Loss D: 23.2854, loss G: 17.3879\n",
      "Epoch [36/200] Batch 11/12                 Loss D: 23.5779, loss G: 16.4749\n",
      "Epoch [37/200] Batch 11/12                 Loss D: 23.8229, loss G: 15.5290\n",
      "Epoch [38/200] Batch 11/12                 Loss D: 23.9897, loss G: 14.6185\n",
      "Epoch [39/200] Batch 11/12                 Loss D: 24.4306, loss G: 13.2741\n",
      "Epoch [40/200] Batch 11/12                 Loss D: 24.8647, loss G: 11.8383\n",
      "Epoch [41/200] Batch 11/12                 Loss D: 25.0103, loss G: 10.6839\n",
      "Epoch [42/200] Batch 11/12                 Loss D: 25.1798, loss G: 9.3547\n",
      "Epoch [43/200] Batch 11/12                 Loss D: 25.0492, loss G: 8.2694\n",
      "Epoch [44/200] Batch 11/12                 Loss D: 24.4675, loss G: 7.8426\n",
      "Epoch [45/200] Batch 11/12                 Loss D: 23.9212, loss G: 7.4583\n",
      "Epoch [46/200] Batch 11/12                 Loss D: 23.0164, loss G: 6.9829\n",
      "Epoch [47/200] Batch 11/12                 Loss D: 22.1471, loss G: 6.5970\n",
      "Epoch [48/200] Batch 11/12                 Loss D: 21.4330, loss G: 6.0004\n",
      "Epoch [49/200] Batch 11/12                 Loss D: 20.4054, loss G: 5.6787\n",
      "Epoch [50/200] Batch 11/12                 Loss D: 19.5288, loss G: 5.0912\n",
      "Epoch [51/200] Batch 11/12                 Loss D: 18.5136, loss G: 4.6286\n",
      "Epoch [52/200] Batch 11/12                 Loss D: 17.3590, loss G: 4.1468\n",
      "Epoch [53/200] Batch 11/12                 Loss D: 16.1074, loss G: 3.6766\n",
      "Epoch [54/200] Batch 11/12                 Loss D: 14.9132, loss G: 3.1962\n",
      "Epoch [55/200] Batch 11/12                 Loss D: 13.7209, loss G: 2.6010\n",
      "Epoch [56/200] Batch 11/12                 Loss D: 12.3993, loss G: 2.0658\n",
      "Epoch [57/200] Batch 11/12                 Loss D: 11.0484, loss G: 1.5006\n",
      "Epoch [58/200] Batch 11/12                 Loss D: 9.5918, loss G: 0.9134\n",
      "Epoch [59/200] Batch 11/12                 Loss D: 8.0834, loss G: 0.3428\n",
      "Epoch [60/200] Batch 11/12                 Loss D: 6.5680, loss G: 0.0351\n",
      "Epoch [61/200] Batch 11/12                 Loss D: 5.1374, loss G: 0.1241\n",
      "Epoch [62/200] Batch 11/12                 Loss D: 3.8416, loss G: 0.3417\n",
      "Epoch [63/200] Batch 11/12                 Loss D: 2.4742, loss G: 0.1962\n",
      "Epoch [64/200] Batch 11/12                 Loss D: 1.1303, loss G: 0.5107\n",
      "Epoch [65/200] Batch 11/12                 Loss D: -0.1227, loss G: 0.4158\n",
      "Epoch [66/200] Batch 11/12                 Loss D: -1.5077, loss G: 0.8616\n",
      "Epoch [67/200] Batch 11/12                 Loss D: -2.7351, loss G: 0.6404\n",
      "Epoch [68/200] Batch 11/12                 Loss D: -4.0793, loss G: 0.9386\n",
      "Epoch [69/200] Batch 11/12                 Loss D: -5.2582, loss G: 0.7360\n",
      "Epoch [70/200] Batch 11/12                 Loss D: -6.5182, loss G: 0.8345\n",
      "Epoch [71/200] Batch 11/12                 Loss D: -7.5919, loss G: 1.1050\n",
      "Epoch [72/200] Batch 11/12                 Loss D: -8.8840, loss G: 1.0635\n",
      "Epoch [73/200] Batch 11/12                 Loss D: -10.2233, loss G: 1.0156\n",
      "Epoch [74/200] Batch 11/12                 Loss D: -11.2237, loss G: 1.4720\n",
      "Epoch [75/200] Batch 11/12                 Loss D: -12.8994, loss G: 1.4307\n",
      "Epoch [76/200] Batch 11/12                 Loss D: -14.3189, loss G: 1.7958\n",
      "Epoch [77/200] Batch 11/12                 Loss D: -15.0985, loss G: 1.4226\n",
      "Epoch [78/200] Batch 11/12                 Loss D: -16.3298, loss G: 1.5353\n",
      "Epoch [79/200] Batch 11/12                 Loss D: -17.7370, loss G: 1.5229\n",
      "Epoch [80/200] Batch 11/12                 Loss D: -18.9170, loss G: 1.5378\n",
      "Epoch [81/200] Batch 11/12                 Loss D: -20.1839, loss G: 1.6051\n",
      "Epoch [82/200] Batch 11/12                 Loss D: -21.1351, loss G: 2.0236\n",
      "Epoch [83/200] Batch 11/12                 Loss D: -22.4008, loss G: 2.0408\n",
      "Epoch [84/200] Batch 11/12                 Loss D: -23.7191, loss G: 2.0669\n",
      "Epoch [85/200] Batch 11/12                 Loss D: -25.1658, loss G: 1.9365\n",
      "Epoch [86/200] Batch 11/12                 Loss D: -26.6283, loss G: 2.1465\n",
      "Epoch [87/200] Batch 11/12                 Loss D: -27.5299, loss G: 2.2026\n",
      "Epoch [88/200] Batch 11/12                 Loss D: -28.9459, loss G: 2.1657\n",
      "Epoch [89/200] Batch 11/12                 Loss D: -30.3479, loss G: 2.3357\n",
      "Epoch [90/200] Batch 11/12                 Loss D: -31.8460, loss G: 2.6436\n",
      "Epoch [91/200] Batch 11/12                 Loss D: -32.5608, loss G: 2.5314\n",
      "Epoch [92/200] Batch 11/12                 Loss D: -34.3281, loss G: 2.7069\n",
      "Epoch [93/200] Batch 11/12                 Loss D: -35.0672, loss G: 2.6914\n",
      "Epoch [94/200] Batch 11/12                 Loss D: -36.7324, loss G: 2.7905\n",
      "Epoch [95/200] Batch 11/12                 Loss D: -37.6616, loss G: 2.8549\n",
      "Epoch [96/200] Batch 11/12                 Loss D: -39.1037, loss G: 2.8293\n",
      "Epoch [97/200] Batch 11/12                 Loss D: -40.4412, loss G: 2.8967\n",
      "Epoch [98/200] Batch 11/12                 Loss D: -41.5105, loss G: 3.1039\n",
      "Epoch [99/200] Batch 11/12                 Loss D: -43.1585, loss G: 3.1007\n",
      "Epoch [100/200] Batch 11/12                 Loss D: -44.1740, loss G: 3.1969\n",
      "Epoch [101/200] Batch 11/12                 Loss D: -45.2367, loss G: 3.4068\n",
      "Epoch [102/200] Batch 11/12                 Loss D: -47.3286, loss G: 3.5177\n",
      "Epoch [103/200] Batch 11/12                 Loss D: -48.0781, loss G: 3.4430\n",
      "Epoch [104/200] Batch 11/12                 Loss D: -49.2762, loss G: 3.5894\n",
      "Epoch [105/200] Batch 11/12                 Loss D: -50.9683, loss G: 3.5148\n",
      "Epoch [106/200] Batch 11/12                 Loss D: -51.8046, loss G: 3.8281\n",
      "Epoch [107/200] Batch 11/12                 Loss D: -53.6569, loss G: 3.6813\n",
      "Epoch [108/200] Batch 11/12                 Loss D: -55.4260, loss G: 4.0442\n",
      "Epoch [109/200] Batch 11/12                 Loss D: -56.1930, loss G: 3.9092\n",
      "Epoch [110/200] Batch 11/12                 Loss D: -57.9684, loss G: 4.0945\n",
      "Epoch [111/200] Batch 11/12                 Loss D: -59.6823, loss G: 4.3462\n",
      "Epoch [112/200] Batch 11/12                 Loss D: -60.3119, loss G: 4.1348\n",
      "Epoch [113/200] Batch 11/12                 Loss D: -61.2308, loss G: 4.3669\n",
      "Epoch [114/200] Batch 11/12                 Loss D: -63.1220, loss G: 4.2950\n",
      "Epoch [115/200] Batch 11/12                 Loss D: -64.2829, loss G: 4.4584\n",
      "Epoch [116/200] Batch 11/12                 Loss D: -65.9528, loss G: 4.4108\n",
      "Epoch [117/200] Batch 11/12                 Loss D: -67.9270, loss G: 4.7483\n",
      "Epoch [118/200] Batch 11/12                 Loss D: -69.0185, loss G: 4.6620\n",
      "Epoch [119/200] Batch 11/12                 Loss D: -68.6336, loss G: 5.2379\n",
      "Epoch [120/200] Batch 11/12                 Loss D: -71.6768, loss G: 4.7210\n",
      "Epoch [121/200] Batch 11/12                 Loss D: -71.7312, loss G: 5.2400\n",
      "Epoch [122/200] Batch 11/12                 Loss D: -73.4575, loss G: 5.2015\n",
      "Epoch [123/200] Batch 11/12                 Loss D: -76.8683, loss G: 5.4337\n",
      "Epoch [124/200] Batch 11/12                 Loss D: -78.1432, loss G: 5.5272\n",
      "Epoch [125/200] Batch 11/12                 Loss D: -78.0566, loss G: 5.1712\n",
      "Epoch [126/200] Batch 11/12                 Loss D: -79.6972, loss G: 5.2000\n",
      "Epoch [127/200] Batch 11/12                 Loss D: -79.9629, loss G: 5.5539\n",
      "Epoch [128/200] Batch 11/12                 Loss D: -81.8320, loss G: 5.4662\n",
      "Epoch [129/200] Batch 11/12                 Loss D: -82.2497, loss G: 5.7919\n",
      "Epoch [130/200] Batch 11/12                 Loss D: -84.7121, loss G: 5.5308\n",
      "Epoch [131/200] Batch 11/12                 Loss D: -87.0871, loss G: 5.9460\n",
      "Epoch [132/200] Batch 11/12                 Loss D: -87.4802, loss G: 5.6925\n",
      "Epoch [133/200] Batch 11/12                 Loss D: -89.1272, loss G: 5.8341\n",
      "Epoch [134/200] Batch 11/12                 Loss D: -90.1140, loss G: 5.8888\n",
      "Epoch [135/200] Batch 11/12                 Loss D: -91.5942, loss G: 5.9185\n",
      "Epoch [136/200] Batch 11/12                 Loss D: -93.4103, loss G: 6.1416\n",
      "Epoch [137/200] Batch 11/12                 Loss D: -94.7150, loss G: 6.1699\n",
      "Epoch [138/200] Batch 11/12                 Loss D: -96.0527, loss G: 6.2364\n",
      "Epoch [139/200] Batch 11/12                 Loss D: -96.6113, loss G: 6.4126\n",
      "Epoch [140/200] Batch 11/12                 Loss D: -98.6614, loss G: 6.3576\n",
      "Epoch [141/200] Batch 11/12                 Loss D: -100.4168, loss G: 6.5207\n",
      "Epoch [142/200] Batch 11/12                 Loss D: -101.2908, loss G: 6.5608\n",
      "Epoch [143/200] Batch 11/12                 Loss D: -102.8027, loss G: 6.6511\n",
      "Epoch [144/200] Batch 11/12                 Loss D: -104.5912, loss G: 6.6950\n",
      "Epoch [145/200] Batch 11/12                 Loss D: -106.4992, loss G: 6.9536\n",
      "Epoch [146/200] Batch 11/12                 Loss D: -106.9184, loss G: 6.9997\n",
      "Epoch [147/200] Batch 11/12                 Loss D: -109.4640, loss G: 7.1133\n",
      "Epoch [148/200] Batch 11/12                 Loss D: -109.8278, loss G: 7.2038\n",
      "Epoch [149/200] Batch 11/12                 Loss D: -112.0380, loss G: 7.1472\n",
      "Epoch [150/200] Batch 11/12                 Loss D: -114.5116, loss G: 7.5492\n",
      "Epoch [151/200] Batch 11/12                 Loss D: -114.4393, loss G: 7.4911\n",
      "Epoch [152/200] Batch 11/12                 Loss D: -116.0935, loss G: 7.5303\n",
      "Epoch [153/200] Batch 11/12                 Loss D: -118.4959, loss G: 7.5951\n",
      "Epoch [154/200] Batch 11/12                 Loss D: -120.0107, loss G: 7.6606\n",
      "Epoch [155/200] Batch 11/12                 Loss D: -120.3121, loss G: 7.9102\n",
      "Epoch [156/200] Batch 11/12                 Loss D: -123.4817, loss G: 7.9579\n",
      "Epoch [157/200] Batch 11/12                 Loss D: -124.4151, loss G: 7.9193\n",
      "Epoch [158/200] Batch 11/12                 Loss D: -125.8211, loss G: 8.0901\n",
      "Epoch [159/200] Batch 11/12                 Loss D: -128.2310, loss G: 8.1887\n",
      "Epoch [160/200] Batch 11/12                 Loss D: -130.3403, loss G: 8.4464\n",
      "Epoch [161/200] Batch 11/12                 Loss D: -131.0943, loss G: 8.3495\n",
      "Epoch [162/200] Batch 11/12                 Loss D: -133.5930, loss G: 8.6561\n",
      "Epoch [163/200] Batch 11/12                 Loss D: -133.8572, loss G: 8.5776\n",
      "Epoch [164/200] Batch 11/12                 Loss D: -137.9333, loss G: 9.0979\n",
      "Epoch [165/200] Batch 11/12                 Loss D: -136.4656, loss G: 8.9156\n",
      "Epoch [166/200] Batch 11/12                 Loss D: -140.9789, loss G: 9.1946\n",
      "Epoch [167/200] Batch 11/12                 Loss D: -140.8828, loss G: 8.9422\n",
      "Epoch [168/200] Batch 11/12                 Loss D: -142.1992, loss G: 9.1155\n",
      "Epoch [169/200] Batch 11/12                 Loss D: -143.7029, loss G: 9.2482\n",
      "Epoch [170/200] Batch 11/12                 Loss D: -145.5536, loss G: 9.3386\n",
      "Epoch [171/200] Batch 11/12                 Loss D: -148.0013, loss G: 9.3428\n",
      "Epoch [172/200] Batch 11/12                 Loss D: -148.4801, loss G: 9.6728\n",
      "Epoch [173/200] Batch 11/12                 Loss D: -150.9286, loss G: 9.6562\n",
      "Epoch [174/200] Batch 11/12                 Loss D: -153.0387, loss G: 9.7077\n",
      "Epoch [175/200] Batch 11/12                 Loss D: -153.1958, loss G: 10.0711\n",
      "Epoch [176/200] Batch 11/12                 Loss D: -156.2041, loss G: 10.0004\n",
      "Epoch [177/200] Batch 11/12                 Loss D: -157.1967, loss G: 10.2280\n",
      "Epoch [178/200] Batch 11/12                 Loss D: -161.4493, loss G: 10.2264\n",
      "Epoch [179/200] Batch 11/12                 Loss D: -163.4042, loss G: 10.3342\n",
      "Epoch [180/200] Batch 11/12                 Loss D: -163.2545, loss G: 10.4442\n",
      "Epoch [181/200] Batch 11/12                 Loss D: -165.9916, loss G: 10.4608\n",
      "Epoch [182/200] Batch 11/12                 Loss D: -169.4491, loss G: 10.7688\n",
      "Epoch [183/200] Batch 11/12                 Loss D: -170.5964, loss G: 10.7389\n",
      "Epoch [184/200] Batch 11/12                 Loss D: -173.0416, loss G: 10.9562\n",
      "Epoch [185/200] Batch 11/12                 Loss D: -173.2799, loss G: 10.9793\n",
      "Epoch [186/200] Batch 11/12                 Loss D: -177.2110, loss G: 11.2589\n",
      "Epoch [187/200] Batch 11/12                 Loss D: -177.4559, loss G: 11.1364\n",
      "Epoch [188/200] Batch 11/12                 Loss D: -180.2604, loss G: 11.2616\n",
      "Epoch [189/200] Batch 11/12                 Loss D: -180.5902, loss G: 11.4734\n",
      "Epoch [190/200] Batch 11/12                 Loss D: -182.6217, loss G: 11.5751\n",
      "Epoch [191/200] Batch 11/12                 Loss D: -183.5862, loss G: 11.8212\n",
      "Epoch [192/200] Batch 11/12                 Loss D: -187.6132, loss G: 11.7289\n",
      "Epoch [193/200] Batch 11/12                 Loss D: -188.8110, loss G: 11.9242\n",
      "Epoch [194/200] Batch 11/12                 Loss D: -192.0375, loss G: 11.9684\n",
      "Epoch [195/200] Batch 11/12                 Loss D: -194.1669, loss G: 12.1071\n",
      "Epoch [196/200] Batch 11/12                 Loss D: -196.0374, loss G: 12.1726\n",
      "Epoch [197/200] Batch 11/12                 Loss D: -195.8798, loss G: 12.5249\n",
      "Epoch [198/200] Batch 11/12                 Loss D: -198.4829, loss G: 12.5697\n",
      "Epoch [199/200] Batch 11/12                 Loss D: -202.4227, loss G: 12.5861\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "PARAMETERS = 3\n",
    "Z_DIM = 100\n",
    "BATCH_SIZE = 32\n",
    "NUM_EPOCHS = 200\n",
    "CRITIC_ITERATIONS = 1\n",
    "LAMBDA_GP = 10\n",
    "LAMBDA_MEAN = 1\n",
    "\n",
    "dataset = torch.FloatTensor(df.iloc[:, -3:].values)\n",
    "ss = StandardScaler().fit(dataset)\n",
    "dataset = ss.transform(dataset)\n",
    "dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "# Initialize generator and discriminator\n",
    "generator = Generator(input_dim=Z_DIM, output_dim=PARAMETERS).to(DEVICE)\n",
    "discriminator = Discriminator(input_dim=PARAMETERS).to(DEVICE)\n",
    "\n",
    "optimizer_G = torch.optim.Adam(generator.parameters(), lr=5e-05, betas=(0.5, 0.999))\n",
    "optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=5e-05, betas=(0.5, 0.999))\n",
    "\n",
    "Tensor = torch.FloatTensor\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    for batch_idx, data in enumerate(dataloader, 0):\n",
    "        # real_data1 = Variable(data.type(Tensor))\n",
    "        real_data = torch.tensor(df.iloc[:, -3:].values, dtype=torch.float).to(DEVICE)\n",
    "        batch_size = real_data.shape[0]\n",
    "        # ---------------------\n",
    "        #  Train Discriminator\n",
    "        # ---------------------\n",
    "\n",
    "        optimizer_D.zero_grad()\n",
    "\n",
    "        # Sample noise as generator input\n",
    "        # z = Variable(Tensor(np.random.normal(0, 1, (real_data.shape[0], 100))))\n",
    "\n",
    "        # # Generate a batch of images\n",
    "        # fake_data = generator(z)\n",
    "\n",
    "        noise = torch.randn(batch_size, Z_DIM).to(DEVICE)\n",
    "        fake = generator(noise).detach().cpu()\n",
    "        fake = ss.inverse_transform(fake)\n",
    "        fake_data = torch.tensor(fake, dtype=torch.float).to(DEVICE)\n",
    "\n",
    "        # Real images\n",
    "        real_validity = discriminator(real_data)\n",
    "        # Fake images\n",
    "        fake_validity = discriminator(fake_data)\n",
    "\n",
    "        # Gradient penalty\n",
    "        gradient_penalty = compute_gradient_penalty(discriminator, real_data.data, fake_data.data).to(DEVICE)\n",
    "\n",
    "        # Adversarial loss\n",
    "        d_loss = -torch.mean(real_validity) + torch.mean(fake_validity) + LAMBDA_GP * gradient_penalty\n",
    "\n",
    "        d_loss.backward()\n",
    "        optimizer_D.step()\n",
    "\n",
    "        optimizer_G.zero_grad()\n",
    "\n",
    "        # Train the generator every n_critic steps\n",
    "        if batch_idx % CRITIC_ITERATIONS == 0:\n",
    "\n",
    "            # -----------------\n",
    "            #  Train Generator\n",
    "            # -----------------\n",
    "\n",
    "            # Generate a batch of images\n",
    "            fake_data = generator(noise)\n",
    "            # Loss measures generator's ability to fool the discriminator\n",
    "            # Train on fake images\n",
    "            fake_validity = discriminator(fake_data)\n",
    "\n",
    "            # Calculate the mean of the real data and the generated data\n",
    "            mean_real_data = torch.mean(real_data, dim=0)\n",
    "            mean_fake_data = torch.mean(fake_data, dim=0)\n",
    "\n",
    "            # Calculate the absolute difference between the means\n",
    "            mean_diff = torch.abs(mean_real_data - mean_fake_data)\n",
    "\n",
    "            # Calculate the penalty as the mean of the absolute difference\n",
    "            penalty = torch.mean(mean_diff)\n",
    "\n",
    "            g_loss = -torch.mean(fake_validity) + LAMBDA_MEAN * penalty\n",
    "\n",
    "            g_loss.backward()\n",
    "            optimizer_G.step()\n",
    "\n",
    "    print(\n",
    "        f\"Epoch [{epoch}/{NUM_EPOCHS}] Batch {batch_idx}/{len(dataloader)} \\\n",
    "                Loss D: {d_loss:.4f}, loss G: {g_loss:.4f}\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2400x600 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "noise = torch.randn(361, 100).to(DEVICE)\n",
    "fake = generator(noise).detach().cpu()\n",
    "fake = ss.inverse_transform(fake)\n",
    "\n",
    "fake_rounded = [[round(elem, 2) for elem in inner_list] for inner_list in fake]\n",
    "\n",
    "fake_df = pd.DataFrame(fake_rounded, columns = (['Fazékidő (min)', 'Szakítószilárdság [MPa]', 'Szakadási nyúlás [%]']))\n",
    "\n",
    "# Assuming y_true are your true output values and y_pred are your predicted output values\n",
    "y_true = df.iloc[:, -3:]\n",
    "y_pred = fake_df\n",
    "\n",
    "fig, axs = plt.subplots(1, 3, figsize=(24, 6))  # 1 row, 3 columns\n",
    "\n",
    "# Plot the actual values and the predicted values for the first feature\n",
    "axs[0].scatter(range(df.shape[0]), y_true.iloc[:, 0], color='blue', label='Eredeti értékek')\n",
    "axs[0].scatter(range(fake_df.shape[0]), y_pred.iloc[:, 0], color='red', label='Generált értékek')\n",
    "axs[0].set_title('Fazékidő (min)')\n",
    "axs[0].set_xlabel('#')\n",
    "axs[0].set_ylabel('Értékek')\n",
    "axs[0].legend()\n",
    "\n",
    "# Repeat for the second feature\n",
    "axs[1].scatter(range(df.shape[0]), y_true.iloc[:, 1], color='blue', label='Eredeti értékek')\n",
    "axs[1].scatter(range(fake_df.shape[0]), y_pred.iloc[:, 1], color='red', label='Generált értékek')\n",
    "axs[1].set_title('Szakítószilárdság [MPa]')\n",
    "axs[1].set_xlabel('#')\n",
    "axs[1].set_ylabel('Értékek')\n",
    "axs[1].legend()\n",
    "\n",
    "# Repeat for the third feature\n",
    "axs[2].scatter(range(df.shape[0]), y_true.iloc[:, 2], color='blue', label='Eredeti értékek')\n",
    "axs[2].scatter(range(fake_df.shape[0]), y_pred.iloc[:, 2], color='red', label='Generált értékek')\n",
    "axs[2].set_title('Szakadási nyúlás [%]')\n",
    "axs[2].set_xlabel('#')\n",
    "axs[2].set_ylabel('Értékek')\n",
    "axs[2].legend()\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Fazékidő (min):\n",
      " Min Value: 0.0\n",
      " Max Value: 142.0\n",
      " Average Value: 33.64819944598338\n",
      "\n",
      "For Szakítószilárdság [MPa]:\n",
      " Min Value: 3.7\n",
      " Max Value: 107.38\n",
      " Average Value: 65.36628808864268\n",
      "\n",
      "For Szakadási nyúlás [%]:\n",
      " Min Value: 0.59\n",
      " Max Value: 97.06\n",
      " Average Value: 4.837922437673129\n",
      "\n"
     ]
    }
   ],
   "source": [
    "asd = df.iloc[:, -3:]\n",
    "for column in asd:\n",
    "    min_value = asd[column].min()\n",
    "    max_value = asd[column].max()\n",
    "    avg_value = asd[column].mean()\n",
    "    \n",
    "    print(f\"For {column}:\\n Min Value: {min_value}\\n Max Value: {max_value}\\n Average Value: {avg_value}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
